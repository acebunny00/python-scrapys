{"url": "https://docs.scrapy.org/en/latest/index.html", "head": "<head>\n  <meta charset=\"utf-8\"><meta name=\"generator\" content=\"Docutils 0.17.1: http://docutils.sourceforge.net/\">\n\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Scrapy 2.7 documentation — Scrapy 2.7.1 documentation</title>\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/pygments.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/theme.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster.custom.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster.bundle.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-shadow.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-punk.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-noir.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-light.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-borderless.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/micromodal.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/sphinx_rtd_theme.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/custom.css\" type=\"text/css\">\n    <link rel=\"canonical\" href=\"https://docs.scrapy.org/en/latest/index.html\">\n  <!--[if lt IE 9]>\n    <script src=\"https://docs.scrapy.org/en/latest/_static/js/html5shiv.min.js\"></script>\n  <![endif]-->\n  \n        <script data-url_root=\"./\" id=\"documentation_options\" src=\"https://docs.scrapy.org/en/latest/_static/documentation_options.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/jquery.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/underscore.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/_sphinx_javascript_frameworks_compat.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/doctools.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/hoverxref.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/tooltipster.bundle.min.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/micromodal.min.js\"></script>\n        <script async=\"async\" src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n        <script async=\"async\" src=\"https://docs.scrapy.org/_/static/javascript/readthedocs-doc-embed.js\"></script>\n    <script src=\"https://docs.scrapy.org/en/latest/_static/js/theme.js\"></script>\n    <link rel=\"index\" title=\"Index\" href=\"genindex.html\">\n    <link rel=\"search\" title=\"Search\" href=\"search.html\">\n    <link rel=\"next\" title=\"Scrapy at a glance\" href=\"intro/overview.html\"> \n\n<!-- RTD Extra Head -->\n\n<link rel=\"stylesheet\" href=\"https://docs.scrapy.org/_/static/css/readthedocs-doc-embed.css\" type=\"text/css\">\n\n<script type=\"application/json\" id=\"READTHEDOCS_DATA\">{\"ad_free\": false, \"api_host\": \"https://readthedocs.org\", \"build_date\": \"2022-11-02T11:04:52Z\", \"builder\": \"sphinx\", \"canonical_url\": null, \"commit\": \"6ded3cf4\", \"docroot\": \"/docs/\", \"features\": {\"docsearch_disabled\": false}, \"global_analytics_code\": \"UA-17997319-1\", \"language\": \"en\", \"page\": \"index\", \"programming_language\": \"py\", \"project\": \"scrapy\", \"proxied_api_host\": \"/_\", \"source_suffix\": \".rst\", \"subprojects\": {}, \"theme\": \"sphinx_rtd_theme\", \"user_analytics_code\": \"UA-10231918-2\", \"version\": \"latest\"}</script>\n\n<!--\nUsing this variable directly instead of using `JSON.parse` is deprecated.\nThe READTHEDOCS_DATA global variable will be removed in the future.\n-->\n<script type=\"text/javascript\">\nREADTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);\n</script>\n\n<script type=\"text/javascript\" src=\"https://docs.scrapy.org/_/static/javascript/readthedocs-analytics.js\" async=\"async\"></script>\n\n<!-- end RTD <extrahead> -->\n</head>\n", "markdown_depth": "#", "header_depth": 1, "header_text": "Scrapy 2.7 documentation", "header_href": "#scrapy-version-documentation", "codes": [], "codes_text": [], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/index.html", "head": "<head>\n  <meta charset=\"utf-8\"><meta name=\"generator\" content=\"Docutils 0.17.1: http://docutils.sourceforge.net/\">\n\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Scrapy 2.7 documentation — Scrapy 2.7.1 documentation</title>\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/pygments.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/theme.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster.custom.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster.bundle.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-shadow.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-punk.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-noir.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-light.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-borderless.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/micromodal.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/sphinx_rtd_theme.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/custom.css\" type=\"text/css\">\n    <link rel=\"canonical\" href=\"https://docs.scrapy.org/en/latest/index.html\">\n  <!--[if lt IE 9]>\n    <script src=\"https://docs.scrapy.org/en/latest/_static/js/html5shiv.min.js\"></script>\n  <![endif]-->\n  \n        <script data-url_root=\"./\" id=\"documentation_options\" src=\"https://docs.scrapy.org/en/latest/_static/documentation_options.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/jquery.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/underscore.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/_sphinx_javascript_frameworks_compat.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/doctools.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/hoverxref.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/tooltipster.bundle.min.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/micromodal.min.js\"></script>\n        <script async=\"async\" src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n        <script async=\"async\" src=\"https://docs.scrapy.org/_/static/javascript/readthedocs-doc-embed.js\"></script>\n    <script src=\"https://docs.scrapy.org/en/latest/_static/js/theme.js\"></script>\n    <link rel=\"index\" title=\"Index\" href=\"genindex.html\">\n    <link rel=\"search\" title=\"Search\" href=\"search.html\">\n    <link rel=\"next\" title=\"Scrapy at a glance\" href=\"intro/overview.html\"> \n\n<!-- RTD Extra Head -->\n\n<link rel=\"stylesheet\" href=\"https://docs.scrapy.org/_/static/css/readthedocs-doc-embed.css\" type=\"text/css\">\n\n<script type=\"application/json\" id=\"READTHEDOCS_DATA\">{\"ad_free\": false, \"api_host\": \"https://readthedocs.org\", \"build_date\": \"2022-11-02T11:04:52Z\", \"builder\": \"sphinx\", \"canonical_url\": null, \"commit\": \"6ded3cf4\", \"docroot\": \"/docs/\", \"features\": {\"docsearch_disabled\": false}, \"global_analytics_code\": \"UA-17997319-1\", \"language\": \"en\", \"page\": \"index\", \"programming_language\": \"py\", \"project\": \"scrapy\", \"proxied_api_host\": \"/_\", \"source_suffix\": \".rst\", \"subprojects\": {}, \"theme\": \"sphinx_rtd_theme\", \"user_analytics_code\": \"UA-10231918-2\", \"version\": \"latest\"}</script>\n\n<!--\nUsing this variable directly instead of using `JSON.parse` is deprecated.\nThe READTHEDOCS_DATA global variable will be removed in the future.\n-->\n<script type=\"text/javascript\">\nREADTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);\n</script>\n\n<script type=\"text/javascript\" src=\"https://docs.scrapy.org/_/static/javascript/readthedocs-analytics.js\" async=\"async\"></script>\n\n<!-- end RTD <extrahead> -->\n</head>\n", "markdown_depth": "##", "header_depth": 2, "header_text": "Getting help", "header_href": "#getting-help", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/index.html", "head": "<head>\n  <meta charset=\"utf-8\"><meta name=\"generator\" content=\"Docutils 0.17.1: http://docutils.sourceforge.net/\">\n\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Scrapy 2.7 documentation — Scrapy 2.7.1 documentation</title>\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/pygments.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/theme.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster.custom.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster.bundle.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-shadow.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-punk.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-noir.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-light.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-borderless.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/micromodal.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/sphinx_rtd_theme.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/custom.css\" type=\"text/css\">\n    <link rel=\"canonical\" href=\"https://docs.scrapy.org/en/latest/index.html\">\n  <!--[if lt IE 9]>\n    <script src=\"https://docs.scrapy.org/en/latest/_static/js/html5shiv.min.js\"></script>\n  <![endif]-->\n  \n        <script data-url_root=\"./\" id=\"documentation_options\" src=\"https://docs.scrapy.org/en/latest/_static/documentation_options.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/jquery.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/underscore.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/_sphinx_javascript_frameworks_compat.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/doctools.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/hoverxref.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/tooltipster.bundle.min.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/micromodal.min.js\"></script>\n        <script async=\"async\" src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n        <script async=\"async\" src=\"https://docs.scrapy.org/_/static/javascript/readthedocs-doc-embed.js\"></script>\n    <script src=\"https://docs.scrapy.org/en/latest/_static/js/theme.js\"></script>\n    <link rel=\"index\" title=\"Index\" href=\"genindex.html\">\n    <link rel=\"search\" title=\"Search\" href=\"search.html\">\n    <link rel=\"next\" title=\"Scrapy at a glance\" href=\"intro/overview.html\"> \n\n<!-- RTD Extra Head -->\n\n<link rel=\"stylesheet\" href=\"https://docs.scrapy.org/_/static/css/readthedocs-doc-embed.css\" type=\"text/css\">\n\n<script type=\"application/json\" id=\"READTHEDOCS_DATA\">{\"ad_free\": false, \"api_host\": \"https://readthedocs.org\", \"build_date\": \"2022-11-02T11:04:52Z\", \"builder\": \"sphinx\", \"canonical_url\": null, \"commit\": \"6ded3cf4\", \"docroot\": \"/docs/\", \"features\": {\"docsearch_disabled\": false}, \"global_analytics_code\": \"UA-17997319-1\", \"language\": \"en\", \"page\": \"index\", \"programming_language\": \"py\", \"project\": \"scrapy\", \"proxied_api_host\": \"/_\", \"source_suffix\": \".rst\", \"subprojects\": {}, \"theme\": \"sphinx_rtd_theme\", \"user_analytics_code\": \"UA-10231918-2\", \"version\": \"latest\"}</script>\n\n<!--\nUsing this variable directly instead of using `JSON.parse` is deprecated.\nThe READTHEDOCS_DATA global variable will be removed in the future.\n-->\n<script type=\"text/javascript\">\nREADTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);\n</script>\n\n<script type=\"text/javascript\" src=\"https://docs.scrapy.org/_/static/javascript/readthedocs-analytics.js\" async=\"async\"></script>\n\n<!-- end RTD <extrahead> -->\n</head>\n", "markdown_depth": "##", "header_depth": 2, "header_text": "First steps", "header_href": "#first-steps", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/index.html", "head": "<head>\n  <meta charset=\"utf-8\"><meta name=\"generator\" content=\"Docutils 0.17.1: http://docutils.sourceforge.net/\">\n\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Scrapy 2.7 documentation — Scrapy 2.7.1 documentation</title>\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/pygments.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/theme.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster.custom.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster.bundle.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-shadow.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-punk.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-noir.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-light.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-borderless.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/micromodal.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/sphinx_rtd_theme.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/custom.css\" type=\"text/css\">\n    <link rel=\"canonical\" href=\"https://docs.scrapy.org/en/latest/index.html\">\n  <!--[if lt IE 9]>\n    <script src=\"https://docs.scrapy.org/en/latest/_static/js/html5shiv.min.js\"></script>\n  <![endif]-->\n  \n        <script data-url_root=\"./\" id=\"documentation_options\" src=\"https://docs.scrapy.org/en/latest/_static/documentation_options.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/jquery.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/underscore.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/_sphinx_javascript_frameworks_compat.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/doctools.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/hoverxref.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/tooltipster.bundle.min.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/micromodal.min.js\"></script>\n        <script async=\"async\" src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n        <script async=\"async\" src=\"https://docs.scrapy.org/_/static/javascript/readthedocs-doc-embed.js\"></script>\n    <script src=\"https://docs.scrapy.org/en/latest/_static/js/theme.js\"></script>\n    <link rel=\"index\" title=\"Index\" href=\"genindex.html\">\n    <link rel=\"search\" title=\"Search\" href=\"search.html\">\n    <link rel=\"next\" title=\"Scrapy at a glance\" href=\"intro/overview.html\"> \n\n<!-- RTD Extra Head -->\n\n<link rel=\"stylesheet\" href=\"https://docs.scrapy.org/_/static/css/readthedocs-doc-embed.css\" type=\"text/css\">\n\n<script type=\"application/json\" id=\"READTHEDOCS_DATA\">{\"ad_free\": false, \"api_host\": \"https://readthedocs.org\", \"build_date\": \"2022-11-02T11:04:52Z\", \"builder\": \"sphinx\", \"canonical_url\": null, \"commit\": \"6ded3cf4\", \"docroot\": \"/docs/\", \"features\": {\"docsearch_disabled\": false}, \"global_analytics_code\": \"UA-17997319-1\", \"language\": \"en\", \"page\": \"index\", \"programming_language\": \"py\", \"project\": \"scrapy\", \"proxied_api_host\": \"/_\", \"source_suffix\": \".rst\", \"subprojects\": {}, \"theme\": \"sphinx_rtd_theme\", \"user_analytics_code\": \"UA-10231918-2\", \"version\": \"latest\"}</script>\n\n<!--\nUsing this variable directly instead of using `JSON.parse` is deprecated.\nThe READTHEDOCS_DATA global variable will be removed in the future.\n-->\n<script type=\"text/javascript\">\nREADTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);\n</script>\n\n<script type=\"text/javascript\" src=\"https://docs.scrapy.org/_/static/javascript/readthedocs-analytics.js\" async=\"async\"></script>\n\n<!-- end RTD <extrahead> -->\n</head>\n", "markdown_depth": "##", "header_depth": 2, "header_text": "Basic concepts", "header_href": "#basic-concepts", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/index.html", "head": "<head>\n  <meta charset=\"utf-8\"><meta name=\"generator\" content=\"Docutils 0.17.1: http://docutils.sourceforge.net/\">\n\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Scrapy 2.7 documentation — Scrapy 2.7.1 documentation</title>\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/pygments.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/theme.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster.custom.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster.bundle.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-shadow.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-punk.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-noir.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-light.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-borderless.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/micromodal.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/sphinx_rtd_theme.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/custom.css\" type=\"text/css\">\n    <link rel=\"canonical\" href=\"https://docs.scrapy.org/en/latest/index.html\">\n  <!--[if lt IE 9]>\n    <script src=\"https://docs.scrapy.org/en/latest/_static/js/html5shiv.min.js\"></script>\n  <![endif]-->\n  \n        <script data-url_root=\"./\" id=\"documentation_options\" src=\"https://docs.scrapy.org/en/latest/_static/documentation_options.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/jquery.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/underscore.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/_sphinx_javascript_frameworks_compat.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/doctools.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/hoverxref.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/tooltipster.bundle.min.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/micromodal.min.js\"></script>\n        <script async=\"async\" src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n        <script async=\"async\" src=\"https://docs.scrapy.org/_/static/javascript/readthedocs-doc-embed.js\"></script>\n    <script src=\"https://docs.scrapy.org/en/latest/_static/js/theme.js\"></script>\n    <link rel=\"index\" title=\"Index\" href=\"genindex.html\">\n    <link rel=\"search\" title=\"Search\" href=\"search.html\">\n    <link rel=\"next\" title=\"Scrapy at a glance\" href=\"intro/overview.html\"> \n\n<!-- RTD Extra Head -->\n\n<link rel=\"stylesheet\" href=\"https://docs.scrapy.org/_/static/css/readthedocs-doc-embed.css\" type=\"text/css\">\n\n<script type=\"application/json\" id=\"READTHEDOCS_DATA\">{\"ad_free\": false, \"api_host\": \"https://readthedocs.org\", \"build_date\": \"2022-11-02T11:04:52Z\", \"builder\": \"sphinx\", \"canonical_url\": null, \"commit\": \"6ded3cf4\", \"docroot\": \"/docs/\", \"features\": {\"docsearch_disabled\": false}, \"global_analytics_code\": \"UA-17997319-1\", \"language\": \"en\", \"page\": \"index\", \"programming_language\": \"py\", \"project\": \"scrapy\", \"proxied_api_host\": \"/_\", \"source_suffix\": \".rst\", \"subprojects\": {}, \"theme\": \"sphinx_rtd_theme\", \"user_analytics_code\": \"UA-10231918-2\", \"version\": \"latest\"}</script>\n\n<!--\nUsing this variable directly instead of using `JSON.parse` is deprecated.\nThe READTHEDOCS_DATA global variable will be removed in the future.\n-->\n<script type=\"text/javascript\">\nREADTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);\n</script>\n\n<script type=\"text/javascript\" src=\"https://docs.scrapy.org/_/static/javascript/readthedocs-analytics.js\" async=\"async\"></script>\n\n<!-- end RTD <extrahead> -->\n</head>\n", "markdown_depth": "##", "header_depth": 2, "header_text": "Built-in services", "header_href": "#built-in-services", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/index.html", "head": "<head>\n  <meta charset=\"utf-8\"><meta name=\"generator\" content=\"Docutils 0.17.1: http://docutils.sourceforge.net/\">\n\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Scrapy 2.7 documentation — Scrapy 2.7.1 documentation</title>\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/pygments.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/theme.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster.custom.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster.bundle.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-shadow.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-punk.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-noir.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-light.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-borderless.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/micromodal.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/sphinx_rtd_theme.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/custom.css\" type=\"text/css\">\n    <link rel=\"canonical\" href=\"https://docs.scrapy.org/en/latest/index.html\">\n  <!--[if lt IE 9]>\n    <script src=\"https://docs.scrapy.org/en/latest/_static/js/html5shiv.min.js\"></script>\n  <![endif]-->\n  \n        <script data-url_root=\"./\" id=\"documentation_options\" src=\"https://docs.scrapy.org/en/latest/_static/documentation_options.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/jquery.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/underscore.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/_sphinx_javascript_frameworks_compat.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/doctools.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/hoverxref.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/tooltipster.bundle.min.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/micromodal.min.js\"></script>\n        <script async=\"async\" src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n        <script async=\"async\" src=\"https://docs.scrapy.org/_/static/javascript/readthedocs-doc-embed.js\"></script>\n    <script src=\"https://docs.scrapy.org/en/latest/_static/js/theme.js\"></script>\n    <link rel=\"index\" title=\"Index\" href=\"genindex.html\">\n    <link rel=\"search\" title=\"Search\" href=\"search.html\">\n    <link rel=\"next\" title=\"Scrapy at a glance\" href=\"intro/overview.html\"> \n\n<!-- RTD Extra Head -->\n\n<link rel=\"stylesheet\" href=\"https://docs.scrapy.org/_/static/css/readthedocs-doc-embed.css\" type=\"text/css\">\n\n<script type=\"application/json\" id=\"READTHEDOCS_DATA\">{\"ad_free\": false, \"api_host\": \"https://readthedocs.org\", \"build_date\": \"2022-11-02T11:04:52Z\", \"builder\": \"sphinx\", \"canonical_url\": null, \"commit\": \"6ded3cf4\", \"docroot\": \"/docs/\", \"features\": {\"docsearch_disabled\": false}, \"global_analytics_code\": \"UA-17997319-1\", \"language\": \"en\", \"page\": \"index\", \"programming_language\": \"py\", \"project\": \"scrapy\", \"proxied_api_host\": \"/_\", \"source_suffix\": \".rst\", \"subprojects\": {}, \"theme\": \"sphinx_rtd_theme\", \"user_analytics_code\": \"UA-10231918-2\", \"version\": \"latest\"}</script>\n\n<!--\nUsing this variable directly instead of using `JSON.parse` is deprecated.\nThe READTHEDOCS_DATA global variable will be removed in the future.\n-->\n<script type=\"text/javascript\">\nREADTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);\n</script>\n\n<script type=\"text/javascript\" src=\"https://docs.scrapy.org/_/static/javascript/readthedocs-analytics.js\" async=\"async\"></script>\n\n<!-- end RTD <extrahead> -->\n</head>\n", "markdown_depth": "##", "header_depth": 2, "header_text": "Solving specific problems", "header_href": "#solving-specific-problems", "codes": [], "codes_text": [], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/index.html", "head": "<head>\n  <meta charset=\"utf-8\"><meta name=\"generator\" content=\"Docutils 0.17.1: http://docutils.sourceforge.net/\">\n\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Scrapy 2.7 documentation — Scrapy 2.7.1 documentation</title>\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/pygments.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/theme.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster.custom.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster.bundle.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-shadow.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-punk.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-noir.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-light.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-borderless.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/micromodal.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/sphinx_rtd_theme.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/custom.css\" type=\"text/css\">\n    <link rel=\"canonical\" href=\"https://docs.scrapy.org/en/latest/index.html\">\n  <!--[if lt IE 9]>\n    <script src=\"https://docs.scrapy.org/en/latest/_static/js/html5shiv.min.js\"></script>\n  <![endif]-->\n  \n        <script data-url_root=\"./\" id=\"documentation_options\" src=\"https://docs.scrapy.org/en/latest/_static/documentation_options.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/jquery.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/underscore.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/_sphinx_javascript_frameworks_compat.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/doctools.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/hoverxref.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/tooltipster.bundle.min.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/micromodal.min.js\"></script>\n        <script async=\"async\" src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n        <script async=\"async\" src=\"https://docs.scrapy.org/_/static/javascript/readthedocs-doc-embed.js\"></script>\n    <script src=\"https://docs.scrapy.org/en/latest/_static/js/theme.js\"></script>\n    <link rel=\"index\" title=\"Index\" href=\"genindex.html\">\n    <link rel=\"search\" title=\"Search\" href=\"search.html\">\n    <link rel=\"next\" title=\"Scrapy at a glance\" href=\"intro/overview.html\"> \n\n<!-- RTD Extra Head -->\n\n<link rel=\"stylesheet\" href=\"https://docs.scrapy.org/_/static/css/readthedocs-doc-embed.css\" type=\"text/css\">\n\n<script type=\"application/json\" id=\"READTHEDOCS_DATA\">{\"ad_free\": false, \"api_host\": \"https://readthedocs.org\", \"build_date\": \"2022-11-02T11:04:52Z\", \"builder\": \"sphinx\", \"canonical_url\": null, \"commit\": \"6ded3cf4\", \"docroot\": \"/docs/\", \"features\": {\"docsearch_disabled\": false}, \"global_analytics_code\": \"UA-17997319-1\", \"language\": \"en\", \"page\": \"index\", \"programming_language\": \"py\", \"project\": \"scrapy\", \"proxied_api_host\": \"/_\", \"source_suffix\": \".rst\", \"subprojects\": {}, \"theme\": \"sphinx_rtd_theme\", \"user_analytics_code\": \"UA-10231918-2\", \"version\": \"latest\"}</script>\n\n<!--\nUsing this variable directly instead of using `JSON.parse` is deprecated.\nThe READTHEDOCS_DATA global variable will be removed in the future.\n-->\n<script type=\"text/javascript\">\nREADTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);\n</script>\n\n<script type=\"text/javascript\" src=\"https://docs.scrapy.org/_/static/javascript/readthedocs-analytics.js\" async=\"async\"></script>\n\n<!-- end RTD <extrahead> -->\n</head>\n", "markdown_depth": "##", "header_depth": 2, "header_text": "Extending Scrapy", "header_href": "#extending-scrapy", "codes": [], "codes_text": [], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/index.html", "head": "<head>\n  <meta charset=\"utf-8\"><meta name=\"generator\" content=\"Docutils 0.17.1: http://docutils.sourceforge.net/\">\n\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Scrapy 2.7 documentation — Scrapy 2.7.1 documentation</title>\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/pygments.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/theme.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster.custom.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster.bundle.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-shadow.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-punk.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-noir.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-light.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-borderless.min.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/micromodal.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/css/sphinx_rtd_theme.css\" type=\"text/css\">\n      <link rel=\"stylesheet\" href=\"https://docs.scrapy.org/en/latest/_static/custom.css\" type=\"text/css\">\n    <link rel=\"canonical\" href=\"https://docs.scrapy.org/en/latest/index.html\">\n  <!--[if lt IE 9]>\n    <script src=\"https://docs.scrapy.org/en/latest/_static/js/html5shiv.min.js\"></script>\n  <![endif]-->\n  \n        <script data-url_root=\"./\" id=\"documentation_options\" src=\"https://docs.scrapy.org/en/latest/_static/documentation_options.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/jquery.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/underscore.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/_sphinx_javascript_frameworks_compat.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/doctools.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/hoverxref.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/tooltipster.bundle.min.js\"></script>\n        <script src=\"https://docs.scrapy.org/en/latest/_static/js/micromodal.min.js\"></script>\n        <script async=\"async\" src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n        <script async=\"async\" src=\"https://docs.scrapy.org/_/static/javascript/readthedocs-doc-embed.js\"></script>\n    <script src=\"https://docs.scrapy.org/en/latest/_static/js/theme.js\"></script>\n    <link rel=\"index\" title=\"Index\" href=\"genindex.html\">\n    <link rel=\"search\" title=\"Search\" href=\"search.html\">\n    <link rel=\"next\" title=\"Scrapy at a glance\" href=\"intro/overview.html\"> \n\n<!-- RTD Extra Head -->\n\n<link rel=\"stylesheet\" href=\"https://docs.scrapy.org/_/static/css/readthedocs-doc-embed.css\" type=\"text/css\">\n\n<script type=\"application/json\" id=\"READTHEDOCS_DATA\">{\"ad_free\": false, \"api_host\": \"https://readthedocs.org\", \"build_date\": \"2022-11-02T11:04:52Z\", \"builder\": \"sphinx\", \"canonical_url\": null, \"commit\": \"6ded3cf4\", \"docroot\": \"/docs/\", \"features\": {\"docsearch_disabled\": false}, \"global_analytics_code\": \"UA-17997319-1\", \"language\": \"en\", \"page\": \"index\", \"programming_language\": \"py\", \"project\": \"scrapy\", \"proxied_api_host\": \"/_\", \"source_suffix\": \".rst\", \"subprojects\": {}, \"theme\": \"sphinx_rtd_theme\", \"user_analytics_code\": \"UA-10231918-2\", \"version\": \"latest\"}</script>\n\n<!--\nUsing this variable directly instead of using `JSON.parse` is deprecated.\nThe READTHEDOCS_DATA global variable will be removed in the future.\n-->\n<script type=\"text/javascript\">\nREADTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);\n</script>\n\n<script type=\"text/javascript\" src=\"https://docs.scrapy.org/_/static/javascript/readthedocs-analytics.js\" async=\"async\"></script>\n\n<!-- end RTD <extrahead> -->\n</head>\n", "markdown_depth": "##", "header_depth": 2, "header_text": "All the rest", "header_href": "#all-the-rest", "codes": [], "codes_text": [], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/intro/overview.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Scrapy at a glance", "header_href": "#scrapy-at-a-glance", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'quotes'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/tag/humor/'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'span/small/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n            <span class=\"p\">}</span>\n\n        <span class=\"n\">next_page</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a::attr(\"href\")'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">if</span> <span class=\"n\">next_page</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">next_page</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">runspider</span> <span class=\"n\">quotes_spider</span><span class=\"o\">.</span><span class=\"n\">py</span> <span class=\"o\">-</span><span class=\"n\">o</span> <span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">jsonl</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span><span class=\"s2\">\"author\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Jane Austen\"</span><span class=\"p\">,</span> <span class=\"s2\">\"text\"</span><span class=\"p\">:</span> <span class=\"s2\">\"</span><span class=\"se\">\\u201c</span><span class=\"s2\">The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.</span><span class=\"se\">\\u201d</span><span class=\"s2\">\"</span><span class=\"p\">}</span>\n<span class=\"p\">{</span><span class=\"s2\">\"author\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Steve Martin\"</span><span class=\"p\">,</span> <span class=\"s2\">\"text\"</span><span class=\"p\">:</span> <span class=\"s2\">\"</span><span class=\"se\">\\u201c</span><span class=\"s2\">A day without sunshine is like, you know, night.</span><span class=\"se\">\\u201d</span><span class=\"s2\">\"</span><span class=\"p\">}</span>\n<span class=\"p\">{</span><span class=\"s2\">\"author\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Garrison Keillor\"</span><span class=\"p\">,</span> <span class=\"s2\">\"text\"</span><span class=\"p\">:</span> <span class=\"s2\">\"</span><span class=\"se\">\\u201c</span><span class=\"s2\">Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.</span><span class=\"se\">\\u201d</span><span class=\"s2\">\"</span><span class=\"p\">}</span>\n<span class=\"o\">...</span>\n</pre></div>"], "codes_text": ["import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = 'quotes'\n    start_urls = [\n        'https://quotes.toscrape.com/tag/humor/',\n    ]\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {\n                'author': quote.xpath('span/small/text()').get(),\n                'text': quote.css('span.text::text').get(),\n            }\n\n        next_page = response.css('li.next a::attr(\"href\")').get()\n        if next_page is not None:\n            yield response.follow(next_page, self.parse)\n", "scrapy runspider quotes_spider.py -o quotes.jsonl\n", "{\"author\": \"Jane Austen\", \"text\": \"\\u201cThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.\\u201d\"}\n{\"author\": \"Steve Martin\", \"text\": \"\\u201cA day without sunshine is like, you know, night.\\u201d\"}\n{\"author\": \"Garrison Keillor\", \"text\": \"\\u201cAnyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.\\u201d\"}\n...\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/intro/overview.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Walk-through of an example spider", "header_href": "#walk-through-of-an-example-spider", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'quotes'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/tag/humor/'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'span/small/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n            <span class=\"p\">}</span>\n\n        <span class=\"n\">next_page</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a::attr(\"href\")'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">if</span> <span class=\"n\">next_page</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">next_page</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">runspider</span> <span class=\"n\">quotes_spider</span><span class=\"o\">.</span><span class=\"n\">py</span> <span class=\"o\">-</span><span class=\"n\">o</span> <span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">jsonl</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span><span class=\"s2\">\"author\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Jane Austen\"</span><span class=\"p\">,</span> <span class=\"s2\">\"text\"</span><span class=\"p\">:</span> <span class=\"s2\">\"</span><span class=\"se\">\\u201c</span><span class=\"s2\">The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.</span><span class=\"se\">\\u201d</span><span class=\"s2\">\"</span><span class=\"p\">}</span>\n<span class=\"p\">{</span><span class=\"s2\">\"author\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Steve Martin\"</span><span class=\"p\">,</span> <span class=\"s2\">\"text\"</span><span class=\"p\">:</span> <span class=\"s2\">\"</span><span class=\"se\">\\u201c</span><span class=\"s2\">A day without sunshine is like, you know, night.</span><span class=\"se\">\\u201d</span><span class=\"s2\">\"</span><span class=\"p\">}</span>\n<span class=\"p\">{</span><span class=\"s2\">\"author\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Garrison Keillor\"</span><span class=\"p\">,</span> <span class=\"s2\">\"text\"</span><span class=\"p\">:</span> <span class=\"s2\">\"</span><span class=\"se\">\\u201c</span><span class=\"s2\">Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.</span><span class=\"se\">\\u201d</span><span class=\"s2\">\"</span><span class=\"p\">}</span>\n<span class=\"o\">...</span>\n</pre></div>"], "codes_text": ["import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = 'quotes'\n    start_urls = [\n        'https://quotes.toscrape.com/tag/humor/',\n    ]\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {\n                'author': quote.xpath('span/small/text()').get(),\n                'text': quote.css('span.text::text').get(),\n            }\n\n        next_page = response.css('li.next a::attr(\"href\")').get()\n        if next_page is not None:\n            yield response.follow(next_page, self.parse)\n", "scrapy runspider quotes_spider.py -o quotes.jsonl\n", "{\"author\": \"Jane Austen\", \"text\": \"\\u201cThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.\\u201d\"}\n{\"author\": \"Steve Martin\", \"text\": \"\\u201cA day without sunshine is like, you know, night.\\u201d\"}\n{\"author\": \"Garrison Keillor\", \"text\": \"\\u201cAnyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.\\u201d\"}\n...\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/intro/overview.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "What just happened?", "header_href": "#what-just-happened", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/intro/overview.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "What else?", "header_href": "#what-else", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/intro/overview.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "What’s next?", "header_href": "#what-s-next", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/intro/install.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Installation guide", "header_href": "#installation-guide", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">conda</span> <span class=\"n\">install</span> <span class=\"o\">-</span><span class=\"n\">c</span> <span class=\"n\">conda</span><span class=\"o\">-</span><span class=\"n\">forge</span> <span class=\"n\">scrapy</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">Scrapy</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">conda</span> <span class=\"n\">install</span> <span class=\"o\">-</span><span class=\"n\">c</span> <span class=\"n\">conda</span><span class=\"o\">-</span><span class=\"n\">forge</span> <span class=\"n\">scrapy</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sudo</span> <span class=\"n\">apt</span><span class=\"o\">-</span><span class=\"n\">get</span> <span class=\"n\">install</span> <span class=\"n\">python3</span> <span class=\"n\">python3</span><span class=\"o\">-</span><span class=\"n\">dev</span> <span class=\"n\">python3</span><span class=\"o\">-</span><span class=\"n\">pip</span> <span class=\"n\">libxml2</span><span class=\"o\">-</span><span class=\"n\">dev</span> <span class=\"n\">libxslt1</span><span class=\"o\">-</span><span class=\"n\">dev</span> <span class=\"n\">zlib1g</span><span class=\"o\">-</span><span class=\"n\">dev</span> <span class=\"n\">libffi</span><span class=\"o\">-</span><span class=\"n\">dev</span> <span class=\"n\">libssl</span><span class=\"o\">-</span><span class=\"n\">dev</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">scrapy</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">xcode</span><span class=\"o\">-</span><span class=\"n\">select</span> <span class=\"o\">--</span><span class=\"n\">install</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">echo</span> <span class=\"s2\">\"export PATH=/usr/local/bin:/usr/local/sbin:$PATH\"</span> <span class=\"o\">&gt;&gt;</span> <span class=\"o\">~/.</span><span class=\"n\">bashrc</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">source</span> <span class=\"o\">~/.</span><span class=\"n\">bashrc</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">brew</span> <span class=\"n\">install</span> <span class=\"n\">python</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">brew</span> <span class=\"n\">update</span><span class=\"p\">;</span> <span class=\"n\">brew</span> <span class=\"n\">upgrade</span> <span class=\"n\">python</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">Scrapy</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>[…]\n  File \"[…]/site-packages/twisted/protocols/tls.py\", line 63, in &lt;module&gt;\n    from twisted.internet._sslverify import _setAcceptableProtocols\n  File \"[…]/site-packages/twisted/internet/_sslverify.py\", line 38, in &lt;module&gt;\n    TLSVersion.TLSv1_1: SSL.OP_NO_TLSv1_1,\nAttributeError: 'module' object has no attribute 'OP_NO_TLSv1_1'\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">twisted</span><span class=\"p\">[</span><span class=\"n\">tls</span><span class=\"p\">]</span>\n</pre></div>"], "codes_text": ["conda install -c conda-forge scrapy\n", "pip install Scrapy\n", "conda install -c conda-forge scrapy\n", "sudo apt-get install python3 python3-dev python3-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev\n", "pip install scrapy\n", "xcode-select --install\n", "echo \"export PATH=/usr/local/bin:/usr/local/sbin:$PATH\" >> ~/.bashrc\n", "source ~/.bashrc\n", "brew install python\n", "brew update; brew upgrade python\n", "pip install Scrapy\n", "[…]\n  File \"[…]/site-packages/twisted/protocols/tls.py\", line 63, in <module>\n    from twisted.internet._sslverify import _setAcceptableProtocols\n  File \"[…]/site-packages/twisted/internet/_sslverify.py\", line 38, in <module>\n    TLSVersion.TLSv1_1: SSL.OP_NO_TLSv1_1,\nAttributeError: 'module' object has no attribute 'OP_NO_TLSv1_1'\n", "pip install twisted[tls]\n"], "index": 13}
{"url": "https://docs.scrapy.org/en/latest/intro/install.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Supported Python versions", "header_href": "#supported-python-versions", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/intro/install.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Installing Scrapy", "header_href": "#installing-scrapy", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">conda</span> <span class=\"n\">install</span> <span class=\"o\">-</span><span class=\"n\">c</span> <span class=\"n\">conda</span><span class=\"o\">-</span><span class=\"n\">forge</span> <span class=\"n\">scrapy</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">Scrapy</span>\n</pre></div>"], "codes_text": ["conda install -c conda-forge scrapy\n", "pip install Scrapy\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/intro/install.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Things that are good to know", "header_href": "#things-that-are-good-to-know", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/intro/install.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Using a virtual environment (recommended)", "header_href": "#using-a-virtual-environment-recommended", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/intro/install.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Platform specific installation notes", "header_href": "#platform-specific-installation-notes", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">conda</span> <span class=\"n\">install</span> <span class=\"o\">-</span><span class=\"n\">c</span> <span class=\"n\">conda</span><span class=\"o\">-</span><span class=\"n\">forge</span> <span class=\"n\">scrapy</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sudo</span> <span class=\"n\">apt</span><span class=\"o\">-</span><span class=\"n\">get</span> <span class=\"n\">install</span> <span class=\"n\">python3</span> <span class=\"n\">python3</span><span class=\"o\">-</span><span class=\"n\">dev</span> <span class=\"n\">python3</span><span class=\"o\">-</span><span class=\"n\">pip</span> <span class=\"n\">libxml2</span><span class=\"o\">-</span><span class=\"n\">dev</span> <span class=\"n\">libxslt1</span><span class=\"o\">-</span><span class=\"n\">dev</span> <span class=\"n\">zlib1g</span><span class=\"o\">-</span><span class=\"n\">dev</span> <span class=\"n\">libffi</span><span class=\"o\">-</span><span class=\"n\">dev</span> <span class=\"n\">libssl</span><span class=\"o\">-</span><span class=\"n\">dev</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">scrapy</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">xcode</span><span class=\"o\">-</span><span class=\"n\">select</span> <span class=\"o\">--</span><span class=\"n\">install</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">echo</span> <span class=\"s2\">\"export PATH=/usr/local/bin:/usr/local/sbin:$PATH\"</span> <span class=\"o\">&gt;&gt;</span> <span class=\"o\">~/.</span><span class=\"n\">bashrc</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">source</span> <span class=\"o\">~/.</span><span class=\"n\">bashrc</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">brew</span> <span class=\"n\">install</span> <span class=\"n\">python</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">brew</span> <span class=\"n\">update</span><span class=\"p\">;</span> <span class=\"n\">brew</span> <span class=\"n\">upgrade</span> <span class=\"n\">python</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">Scrapy</span>\n</pre></div>"], "codes_text": ["conda install -c conda-forge scrapy\n", "sudo apt-get install python3 python3-dev python3-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev\n", "pip install scrapy\n", "xcode-select --install\n", "echo \"export PATH=/usr/local/bin:/usr/local/sbin:$PATH\" >> ~/.bashrc\n", "source ~/.bashrc\n", "brew install python\n", "brew update; brew upgrade python\n", "pip install Scrapy\n"], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/intro/install.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Windows", "header_href": "#windows", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">conda</span> <span class=\"n\">install</span> <span class=\"o\">-</span><span class=\"n\">c</span> <span class=\"n\">conda</span><span class=\"o\">-</span><span class=\"n\">forge</span> <span class=\"n\">scrapy</span>\n</pre></div>"], "codes_text": ["conda install -c conda-forge scrapy\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/intro/install.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Ubuntu 14.04 or above", "header_href": "#ubuntu-14-04-or-above", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">sudo</span> <span class=\"n\">apt</span><span class=\"o\">-</span><span class=\"n\">get</span> <span class=\"n\">install</span> <span class=\"n\">python3</span> <span class=\"n\">python3</span><span class=\"o\">-</span><span class=\"n\">dev</span> <span class=\"n\">python3</span><span class=\"o\">-</span><span class=\"n\">pip</span> <span class=\"n\">libxml2</span><span class=\"o\">-</span><span class=\"n\">dev</span> <span class=\"n\">libxslt1</span><span class=\"o\">-</span><span class=\"n\">dev</span> <span class=\"n\">zlib1g</span><span class=\"o\">-</span><span class=\"n\">dev</span> <span class=\"n\">libffi</span><span class=\"o\">-</span><span class=\"n\">dev</span> <span class=\"n\">libssl</span><span class=\"o\">-</span><span class=\"n\">dev</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">scrapy</span>\n</pre></div>"], "codes_text": ["sudo apt-get install python3 python3-dev python3-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev\n", "pip install scrapy\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/intro/install.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "macOS", "header_href": "#macos", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">xcode</span><span class=\"o\">-</span><span class=\"n\">select</span> <span class=\"o\">--</span><span class=\"n\">install</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">echo</span> <span class=\"s2\">\"export PATH=/usr/local/bin:/usr/local/sbin:$PATH\"</span> <span class=\"o\">&gt;&gt;</span> <span class=\"o\">~/.</span><span class=\"n\">bashrc</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">source</span> <span class=\"o\">~/.</span><span class=\"n\">bashrc</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">brew</span> <span class=\"n\">install</span> <span class=\"n\">python</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">brew</span> <span class=\"n\">update</span><span class=\"p\">;</span> <span class=\"n\">brew</span> <span class=\"n\">upgrade</span> <span class=\"n\">python</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">Scrapy</span>\n</pre></div>"], "codes_text": ["xcode-select --install\n", "echo \"export PATH=/usr/local/bin:/usr/local/sbin:$PATH\" >> ~/.bashrc\n", "source ~/.bashrc\n", "brew install python\n", "brew update; brew upgrade python\n", "pip install Scrapy\n"], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/intro/install.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "PyPy", "header_href": "#pypy", "codes": [], "codes_text": [], "index": 10}
{"url": "https://docs.scrapy.org/en/latest/intro/install.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Troubleshooting", "header_href": "#troubleshooting", "codes": ["<div class=\"highlight\"><pre><span></span>[…]\n  File \"[…]/site-packages/twisted/protocols/tls.py\", line 63, in &lt;module&gt;\n    from twisted.internet._sslverify import _setAcceptableProtocols\n  File \"[…]/site-packages/twisted/internet/_sslverify.py\", line 38, in &lt;module&gt;\n    TLSVersion.TLSv1_1: SSL.OP_NO_TLSv1_1,\nAttributeError: 'module' object has no attribute 'OP_NO_TLSv1_1'\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">twisted</span><span class=\"p\">[</span><span class=\"n\">tls</span><span class=\"p\">]</span>\n</pre></div>"], "codes_text": ["[…]\n  File \"[…]/site-packages/twisted/protocols/tls.py\", line 63, in <module>\n    from twisted.internet._sslverify import _setAcceptableProtocols\n  File \"[…]/site-packages/twisted/internet/_sslverify.py\", line 38, in <module>\n    TLSVersion.TLSv1_1: SSL.OP_NO_TLSv1_1,\nAttributeError: 'module' object has no attribute 'OP_NO_TLSv1_1'\n", "pip install twisted[tls]\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/intro/install.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "AttributeError: ‘module’ object has no attribute ‘OP_NO_TLSv1_1’", "header_href": "#attributeerror-module-object-has-no-attribute-op-no-tlsv1-1", "codes": ["<div class=\"highlight\"><pre><span></span>[…]\n  File \"[…]/site-packages/twisted/protocols/tls.py\", line 63, in &lt;module&gt;\n    from twisted.internet._sslverify import _setAcceptableProtocols\n  File \"[…]/site-packages/twisted/internet/_sslverify.py\", line 38, in &lt;module&gt;\n    TLSVersion.TLSv1_1: SSL.OP_NO_TLSv1_1,\nAttributeError: 'module' object has no attribute 'OP_NO_TLSv1_1'\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">twisted</span><span class=\"p\">[</span><span class=\"n\">tls</span><span class=\"p\">]</span>\n</pre></div>"], "codes_text": ["[…]\n  File \"[…]/site-packages/twisted/protocols/tls.py\", line 63, in <module>\n    from twisted.internet._sslverify import _setAcceptableProtocols\n  File \"[…]/site-packages/twisted/internet/_sslverify.py\", line 38, in <module>\n    TLSVersion.TLSv1_1: SSL.OP_NO_TLSv1_1,\nAttributeError: 'module' object has no attribute 'OP_NO_TLSv1_1'\n", "pip install twisted[tls]\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Scrapy Tutorial", "header_href": "#scrapy-tutorial", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">startproject</span> <span class=\"n\">tutorial</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tutorial</span><span class=\"o\">/</span>\n    <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">cfg</span>            <span class=\"c1\"># deploy configuration file</span>\n\n    <span class=\"n\">tutorial</span><span class=\"o\">/</span>             <span class=\"c1\"># project's Python module, you'll import your code from here</span>\n        <span class=\"fm\">__init__</span><span class=\"o\">.</span><span class=\"n\">py</span>\n\n        <span class=\"n\">items</span><span class=\"o\">.</span><span class=\"n\">py</span>          <span class=\"c1\"># project items definition file</span>\n\n        <span class=\"n\">middlewares</span><span class=\"o\">.</span><span class=\"n\">py</span>    <span class=\"c1\"># project middlewares file</span>\n\n        <span class=\"n\">pipelines</span><span class=\"o\">.</span><span class=\"n\">py</span>      <span class=\"c1\"># project pipelines file</span>\n\n        <span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">py</span>       <span class=\"c1\"># project settings file</span>\n\n        <span class=\"n\">spiders</span><span class=\"o\">/</span>          <span class=\"c1\"># a directory where you'll later put your spiders</span>\n            <span class=\"fm\">__init__</span><span class=\"o\">.</span><span class=\"n\">py</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"quotes\"</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"n\">urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n            <span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span><span class=\"p\">,</span>\n            <span class=\"s1\">'https://quotes.toscrape.com/page/2/'</span><span class=\"p\">,</span>\n        <span class=\"p\">]</span>\n        <span class=\"k\">for</span> <span class=\"n\">url</span> <span class=\"ow\">in</span> <span class=\"n\">urls</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">page</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s2\">\"/\"</span><span class=\"p\">)[</span><span class=\"o\">-</span><span class=\"mi\">2</span><span class=\"p\">]</span>\n        <span class=\"n\">filename</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">'quotes-</span><span class=\"si\">{</span><span class=\"n\">page</span><span class=\"si\">}</span><span class=\"s1\">.html'</span>\n        <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span> <span class=\"s1\">'wb'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n            <span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">log</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'Saved file </span><span class=\"si\">{</span><span class=\"n\">filename</span><span class=\"si\">}</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">quotes</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">...</span> <span class=\"p\">(</span><span class=\"n\">omitted</span> <span class=\"k\">for</span> <span class=\"n\">brevity</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Spider</span> <span class=\"n\">opened</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">logstats</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"mi\">0</span> <span class=\"n\">pages</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">pages</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">),</span> <span class=\"n\">scraped</span> <span class=\"mi\">0</span> <span class=\"n\">items</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">items</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">telnet</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Telnet</span> <span class=\"n\">console</span> <span class=\"n\">listening</span> <span class=\"n\">on</span> <span class=\"mf\">127.0.0.1</span><span class=\"p\">:</span><span class=\"mi\">6023</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">404</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">robots</span><span class=\"o\">.</span><span class=\"n\">txt</span><span class=\"o\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"o\">/&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">quotes</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Saved</span> <span class=\"n\">file</span> <span class=\"n\">quotes</span><span class=\"o\">-</span><span class=\"mf\">1.</span><span class=\"n\">html</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">quotes</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Saved</span> <span class=\"n\">file</span> <span class=\"n\">quotes</span><span class=\"o\">-</span><span class=\"mf\">2.</span><span class=\"n\">html</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Closing</span> <span class=\"n\">spider</span> <span class=\"p\">(</span><span class=\"n\">finished</span><span class=\"p\">)</span>\n<span class=\"o\">...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"quotes\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/2/'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">page</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s2\">\"/\"</span><span class=\"p\">)[</span><span class=\"o\">-</span><span class=\"mi\">2</span><span class=\"p\">]</span>\n        <span class=\"n\">filename</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">'quotes-</span><span class=\"si\">{</span><span class=\"n\">page</span><span class=\"si\">}</span><span class=\"s1\">.html'</span>\n        <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span> <span class=\"s1\">'wb'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n            <span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"s2\">\"https://quotes.toscrape.com/page/1/\"</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">[</span> <span class=\"o\">...</span> <span class=\"n\">Scrapy</span> <span class=\"n\">log</span> <span class=\"n\">here</span> <span class=\"o\">...</span> <span class=\"p\">]</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">09</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">12</span><span class=\"p\">:</span><span class=\"mi\">09</span><span class=\"p\">:</span><span class=\"mi\">27</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span> <span class=\"n\">Available</span> <span class=\"n\">Scrapy</span> <span class=\"n\">objects</span><span class=\"p\">:</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">scrapy</span>     <span class=\"n\">scrapy</span> <span class=\"n\">module</span> <span class=\"p\">(</span><span class=\"n\">contains</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">,</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Selector</span><span class=\"p\">,</span> <span class=\"n\">etc</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">crawler</span>    <span class=\"o\">&lt;</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">Crawler</span> <span class=\"nb\">object</span> <span class=\"n\">at</span> <span class=\"mh\">0x7fa91d888c90</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">item</span>       <span class=\"p\">{}</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">request</span>    <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">response</span>   <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">settings</span>   <span class=\"o\">&lt;</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">Settings</span> <span class=\"nb\">object</span> <span class=\"n\">at</span> <span class=\"mh\">0x7fa91d888c10</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">spider</span>     <span class=\"o\">&lt;</span><span class=\"n\">DefaultSpider</span> <span class=\"s1\">'default'</span> <span class=\"n\">at</span> <span class=\"mh\">0x7fa91c8af990</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span> <span class=\"n\">Useful</span> <span class=\"n\">shortcuts</span><span class=\"p\">:</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">shelp</span><span class=\"p\">()</span>           <span class=\"n\">Shell</span> <span class=\"n\">help</span> <span class=\"p\">(</span><span class=\"nb\">print</span> <span class=\"n\">this</span> <span class=\"n\">help</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">fetch</span><span class=\"p\">(</span><span class=\"n\">req_or_url</span><span class=\"p\">)</span> <span class=\"n\">Fetch</span> <span class=\"n\">request</span> <span class=\"p\">(</span><span class=\"ow\">or</span> <span class=\"n\">URL</span><span class=\"p\">)</span> <span class=\"ow\">and</span> <span class=\"n\">update</span> <span class=\"n\">local</span> <span class=\"n\">objects</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">view</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">)</span>    <span class=\"n\">View</span> <span class=\"n\">response</span> <span class=\"ow\">in</span> <span class=\"n\">a</span> <span class=\"n\">browser</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title'</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='descendant-or-self::title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['Quotes to Scrape']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['&lt;title&gt;Quotes to Scrape&lt;/title&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Quotes to Scrape'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Quotes to Scrape'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'noelement'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n<span class=\"c\">...</span>\n<span class=\"gr\">IndexError</span>: <span class=\"n\">list index out of range</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"noelement\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'Quotes.*'</span><span class=\"p\">)</span>\n<span class=\"go\">['Quotes to Scrape']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'Q\\w+'</span><span class=\"p\">)</span>\n<span class=\"go\">['Quotes']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'(\\w+) to (\\w+)'</span><span class=\"p\">)</span>\n<span class=\"go\">['Quotes', 'Scrape']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title'</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='//title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Quotes to Scrape'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"quote\"</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">span</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"text\"</span><span class=\"p\">&gt;</span>“The world as we have created it is a process of our\n    thinking. It cannot be changed without changing our thinking.”<span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n        by <span class=\"p\">&lt;</span><span class=\"nt\">small</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"author\"</span><span class=\"p\">&gt;</span>Albert Einstein<span class=\"p\">&lt;/</span><span class=\"nt\">small</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/author/Albert-Einstein\"</span><span class=\"p\">&gt;</span>(about)<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tags\"</span><span class=\"p\">&gt;</span>\n        Tags:\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tag\"</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/tag/change/page/1/\"</span><span class=\"p\">&gt;</span>change<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tag\"</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/tag/deep-thoughts/page/1/\"</span><span class=\"p\">&gt;</span>deep-thoughts<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tag\"</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/tag/thinking/page/1/\"</span><span class=\"p\">&gt;</span>thinking<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tag\"</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/tag/world/page/1/\"</span><span class=\"p\">&gt;</span>world<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"s1\">'https://quotes.toscrape.com'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.quote\"</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='&lt;div class=\"quote\" itemscope itemtype...'&gt;,</span>\n<span class=\"go\"> &lt;Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='&lt;div class=\"quote\" itemscope itemtype...'&gt;,</span>\n<span class=\"go\"> ...]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">quote</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.quote\"</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"span.text::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">text</span>\n<span class=\"go\">'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">author</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"small.author::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">author</span>\n<span class=\"go\">'Albert Einstein'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tags</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.tags a.tag::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tags</span>\n<span class=\"go\">['change', 'deep-thoughts', 'thinking', 'world']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.quote\"</span><span class=\"p\">):</span>\n<span class=\"gp\">... </span>    <span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"span.text::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"n\">author</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"small.author::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"n\">tags</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.tags a.tag::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"n\">author</span><span class=\"o\">=</span><span class=\"n\">author</span><span class=\"p\">,</span> <span class=\"n\">tags</span><span class=\"o\">=</span><span class=\"n\">tags</span><span class=\"p\">))</span>\n<span class=\"go\">{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}</span>\n<span class=\"go\">{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}</span>\n<span class=\"gp\">...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"quotes\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/2/'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'small.author::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'tags'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.tags a.tag::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">(),</span>\n            <span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">09</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">57</span><span class=\"p\">:</span><span class=\"mi\">19</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">scraper</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Scraped</span> <span class=\"kn\">from</span> <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span>\n<span class=\"p\">{</span><span class=\"s1\">'tags'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'life'</span><span class=\"p\">,</span> <span class=\"s1\">'love'</span><span class=\"p\">],</span> <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"s1\">'André Gide'</span><span class=\"p\">,</span> <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"s1\">'“It is better to be hated for what you are than to be loved for what you are not.”'</span><span class=\"p\">}</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">09</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">57</span><span class=\"p\">:</span><span class=\"mi\">19</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">scraper</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Scraped</span> <span class=\"kn\">from</span> <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span>\n<span class=\"p\">{</span><span class=\"s1\">'tags'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'edison'</span><span class=\"p\">,</span> <span class=\"s1\">'failure'</span><span class=\"p\">,</span> <span class=\"s1\">'inspirational'</span><span class=\"p\">,</span> <span class=\"s1\">'paraphrased'</span><span class=\"p\">],</span> <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"s1\">'Thomas A. Edison'</span><span class=\"p\">,</span> <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"s2\">\"“I have not failed. I've just found 10,000 ways that won't work.”\"</span><span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">quotes</span> <span class=\"o\">-</span><span class=\"n\">O</span> <span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">json</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">quotes</span> <span class=\"o\">-</span><span class=\"n\">o</span> <span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">jsonl</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">ul</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"pager\"</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">li</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"next\"</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/page/2/\"</span><span class=\"p\">&gt;</span>Next <span class=\"p\">&lt;</span><span class=\"nt\">span</span> <span class=\"na\">aria-hidden</span><span class=\"o\">=</span><span class=\"s\">\"true\"</span><span class=\"p\">&gt;</span><span class=\"ni\">&amp;rarr;</span><span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;/</span><span class=\"nt\">li</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;/</span><span class=\"nt\">ul</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'&lt;a href=\"/page/2/\"&gt;Next &lt;span aria-hidden=\"true\"&gt;→&lt;/span&gt;&lt;/a&gt;'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'/page/2/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'href'</span><span class=\"p\">]</span>\n<span class=\"go\">'/page/2/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"quotes\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'small.author::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'tags'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.tags a.tag::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">(),</span>\n            <span class=\"p\">}</span>\n\n        <span class=\"n\">next_page</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">if</span> <span class=\"n\">next_page</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n            <span class=\"n\">next_page</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">urljoin</span><span class=\"p\">(</span><span class=\"n\">next_page</span><span class=\"p\">)</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">next_page</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"quotes\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span small::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'tags'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.tags a.tag::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">(),</span>\n            <span class=\"p\">}</span>\n\n        <span class=\"n\">next_page</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">if</span> <span class=\"n\">next_page</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">next_page</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">href</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'ul.pager a::attr(href)'</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">href</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'ul.pager a'</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">anchors</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'ul.pager a'</span><span class=\"p\">)</span>\n<span class=\"k\">yield from</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow_all</span><span class=\"p\">(</span><span class=\"n\">anchors</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">yield from</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow_all</span><span class=\"p\">(</span><span class=\"n\">css</span><span class=\"o\">=</span><span class=\"s1\">'ul.pager a'</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">AuthorSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'author'</span>\n\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://quotes.toscrape.com/'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">author_page_links</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'.author + a'</span><span class=\"p\">)</span>\n        <span class=\"k\">yield from</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow_all</span><span class=\"p\">(</span><span class=\"n\">author_page_links</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_author</span><span class=\"p\">)</span>\n\n        <span class=\"n\">pagination_links</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a'</span><span class=\"p\">)</span>\n        <span class=\"k\">yield from</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow_all</span><span class=\"p\">(</span><span class=\"n\">pagination_links</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_author</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">def</span> <span class=\"nf\">extract_with_css</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"p\">):</span>\n            <span class=\"k\">return</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">default</span><span class=\"o\">=</span><span class=\"s1\">''</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">strip</span><span class=\"p\">()</span>\n\n        <span class=\"k\">yield</span> <span class=\"p\">{</span>\n            <span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"n\">extract_with_css</span><span class=\"p\">(</span><span class=\"s1\">'h3.author-title::text'</span><span class=\"p\">),</span>\n            <span class=\"s1\">'birthdate'</span><span class=\"p\">:</span> <span class=\"n\">extract_with_css</span><span class=\"p\">(</span><span class=\"s1\">'.author-born-date::text'</span><span class=\"p\">),</span>\n            <span class=\"s1\">'bio'</span><span class=\"p\">:</span> <span class=\"n\">extract_with_css</span><span class=\"p\">(</span><span class=\"s1\">'.author-description::text'</span><span class=\"p\">),</span>\n        <span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">quotes</span> <span class=\"o\">-</span><span class=\"n\">O</span> <span class=\"n\">quotes</span><span class=\"o\">-</span><span class=\"n\">humor</span><span class=\"o\">.</span><span class=\"n\">json</span> <span class=\"o\">-</span><span class=\"n\">a</span> <span class=\"n\">tag</span><span class=\"o\">=</span><span class=\"n\">humor</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"quotes\"</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"s1\">'https://quotes.toscrape.com/'</span>\n        <span class=\"n\">tag</span> <span class=\"o\">=</span> <span class=\"nb\">getattr</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"s1\">'tag'</span><span class=\"p\">,</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n        <span class=\"k\">if</span> <span class=\"n\">tag</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n            <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">url</span> <span class=\"o\">+</span> <span class=\"s1\">'tag/'</span> <span class=\"o\">+</span> <span class=\"n\">tag</span>\n        <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'small.author::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n            <span class=\"p\">}</span>\n\n        <span class=\"n\">next_page</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">if</span> <span class=\"n\">next_page</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">next_page</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["scrapy startproject tutorial\n", "tutorial/\n    scrapy.cfg            # deploy configuration file\n\n    tutorial/             # project's Python module, you'll import your code from here\n        __init__.py\n\n        items.py          # project items definition file\n\n        middlewares.py    # project middlewares file\n\n        pipelines.py      # project pipelines file\n\n        settings.py       # project settings file\n\n        spiders/          # a directory where you'll later put your spiders\n            __init__.py\n", "import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n\n    def start_requests(self):\n        urls = [\n            'https://quotes.toscrape.com/page/1/',\n            'https://quotes.toscrape.com/page/2/',\n        ]\n        for url in urls:\n            yield scrapy.Request(url=url, callback=self.parse)\n\n    def parse(self, response):\n        page = response.url.split(\"/\")[-2]\n        filename = f'quotes-{page}.html'\n        with open(filename, 'wb') as f:\n            f.write(response.body)\n        self.log(f'Saved file {filename}')\n", "scrapy crawl quotes\n", "... (omitted for brevity)\n2016-12-16 21:24:05 [scrapy.core.engine] INFO: Spider opened\n2016-12-16 21:24:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n2016-12-16 21:24:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023\n2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://quotes.toscrape.com/robots.txt> (referer: None)\n2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/1/> (referer: None)\n2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/2/> (referer: None)\n2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-1.html\n2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-2.html\n2016-12-16 21:24:05 [scrapy.core.engine] INFO: Closing spider (finished)\n...\n", "import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n    start_urls = [\n        'https://quotes.toscrape.com/page/1/',\n        'https://quotes.toscrape.com/page/2/',\n    ]\n\n    def parse(self, response):\n        page = response.url.split(\"/\")[-2]\n        filename = f'quotes-{page}.html'\n        with open(filename, 'wb') as f:\n            f.write(response.body)\n", "scrapy shell 'https://quotes.toscrape.com/page/1/'\n", "scrapy shell \"https://quotes.toscrape.com/page/1/\"\n", "[ ... Scrapy log here ... ]\n2016-09-19 12:09:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/1/> (referer: None)\n[s] Available Scrapy objects:\n[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)\n[s]   crawler    <scrapy.crawler.Crawler object at 0x7fa91d888c90>\n[s]   item       {}\n[s]   request    <GET https://quotes.toscrape.com/page/1/>\n[s]   response   <200 https://quotes.toscrape.com/page/1/>\n[s]   settings   <scrapy.settings.Settings object at 0x7fa91d888c10>\n[s]   spider     <DefaultSpider 'default' at 0x7fa91c8af990>\n[s] Useful shortcuts:\n[s]   shelp()           Shell help (print this help)\n[s]   fetch(req_or_url) Fetch request (or URL) and update local objects\n[s]   view(response)    View response in a browser\n", ">>> response.css('title')\n[<Selector xpath='descendant-or-self::title' data='<title>Quotes to Scrape</title>'>]\n", ">>> response.css('title::text').getall()\n['Quotes to Scrape']\n", ">>> response.css('title').getall()\n['<title>Quotes to Scrape</title>']\n", ">>> response.css('title::text').get()\n'Quotes to Scrape'\n", ">>> response.css('title::text')[0].get()\n'Quotes to Scrape'\n", ">>> response.css('noelement')[0].get()\nTraceback (most recent call last):\n...\nIndexError: list index out of range\n", ">>> response.css(\"noelement\").get()\n", ">>> response.css('title::text').re(r'Quotes.*')\n['Quotes to Scrape']\n>>> response.css('title::text').re(r'Q\\w+')\n['Quotes']\n>>> response.css('title::text').re(r'(\\w+) to (\\w+)')\n['Quotes', 'Scrape']\n", ">>> response.xpath('//title')\n[<Selector xpath='//title' data='<title>Quotes to Scrape</title>'>]\n>>> response.xpath('//title/text()').get()\n'Quotes to Scrape'\n", "<div class=\"quote\">\n    <span class=\"text\">“The world as we have created it is a process of our\n    thinking. It cannot be changed without changing our thinking.”</span>\n    <span>\n        by <small class=\"author\">Albert Einstein</small>\n        <a href=\"/author/Albert-Einstein\">(about)</a>\n    </span>\n    <div class=\"tags\">\n        Tags:\n        <a class=\"tag\" href=\"/tag/change/page/1/\">change</a>\n        <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\n        <a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>\n        <a class=\"tag\" href=\"/tag/world/page/1/\">world</a>\n    </div>\n</div>\n", "scrapy shell 'https://quotes.toscrape.com'\n", ">>> response.css(\"div.quote\")\n[<Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n <Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n ...]\n", ">>> quote = response.css(\"div.quote\")[0]\n", ">>> text = quote.css(\"span.text::text\").get()\n>>> text\n'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'\n>>> author = quote.css(\"small.author::text\").get()\n>>> author\n'Albert Einstein'\n", ">>> tags = quote.css(\"div.tags a.tag::text\").getall()\n>>> tags\n['change', 'deep-thoughts', 'thinking', 'world']\n", ">>> for quote in response.css(\"div.quote\"):\n...     text = quote.css(\"span.text::text\").get()\n...     author = quote.css(\"small.author::text\").get()\n...     tags = quote.css(\"div.tags a.tag::text\").getall()\n...     print(dict(text=text, author=author, tags=tags))\n{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}\n{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}\n...\n", "import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n    start_urls = [\n        'https://quotes.toscrape.com/page/1/',\n        'https://quotes.toscrape.com/page/2/',\n    ]\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {\n                'text': quote.css('span.text::text').get(),\n                'author': quote.css('small.author::text').get(),\n                'tags': quote.css('div.tags a.tag::text').getall(),\n            }\n", "2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>\n{'tags': ['life', 'love'], 'author': 'André Gide', 'text': '“It is better to be hated for what you are than to be loved for what you are not.”'}\n2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>\n{'tags': ['edison', 'failure', 'inspirational', 'paraphrased'], 'author': 'Thomas A. Edison', 'text': \"“I have not failed. I've just found 10,000 ways that won't work.”\"}\n", "scrapy crawl quotes -O quotes.json\n", "scrapy crawl quotes -o quotes.jsonl\n", "<ul class=\"pager\">\n    <li class=\"next\">\n        <a href=\"/page/2/\">Next <span aria-hidden=\"true\">→</span></a>\n    </li>\n</ul>\n", ">>> response.css('li.next a').get()\n'<a href=\"/page/2/\">Next <span aria-hidden=\"true\">→</span></a>'\n", ">>> response.css('li.next a::attr(href)').get()\n'/page/2/'\n", ">>> response.css('li.next a').attrib['href']\n'/page/2/'\n", "import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n    start_urls = [\n        'https://quotes.toscrape.com/page/1/',\n    ]\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {\n                'text': quote.css('span.text::text').get(),\n                'author': quote.css('small.author::text').get(),\n                'tags': quote.css('div.tags a.tag::text').getall(),\n            }\n\n        next_page = response.css('li.next a::attr(href)').get()\n        if next_page is not None:\n            next_page = response.urljoin(next_page)\n            yield scrapy.Request(next_page, callback=self.parse)\n", "import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n    start_urls = [\n        'https://quotes.toscrape.com/page/1/',\n    ]\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {\n                'text': quote.css('span.text::text').get(),\n                'author': quote.css('span small::text').get(),\n                'tags': quote.css('div.tags a.tag::text').getall(),\n            }\n\n        next_page = response.css('li.next a::attr(href)').get()\n        if next_page is not None:\n            yield response.follow(next_page, callback=self.parse)\n", "for href in response.css('ul.pager a::attr(href)'):\n    yield response.follow(href, callback=self.parse)\n", "for a in response.css('ul.pager a'):\n    yield response.follow(a, callback=self.parse)\n", "anchors = response.css('ul.pager a')\nyield from response.follow_all(anchors, callback=self.parse)\n", "yield from response.follow_all(css='ul.pager a', callback=self.parse)\n", "import scrapy\n\n\nclass AuthorSpider(scrapy.Spider):\n    name = 'author'\n\n    start_urls = ['https://quotes.toscrape.com/']\n\n    def parse(self, response):\n        author_page_links = response.css('.author + a')\n        yield from response.follow_all(author_page_links, self.parse_author)\n\n        pagination_links = response.css('li.next a')\n        yield from response.follow_all(pagination_links, self.parse)\n\n    def parse_author(self, response):\n        def extract_with_css(query):\n            return response.css(query).get(default='').strip()\n\n        yield {\n            'name': extract_with_css('h3.author-title::text'),\n            'birthdate': extract_with_css('.author-born-date::text'),\n            'bio': extract_with_css('.author-description::text'),\n        }\n", "scrapy crawl quotes -O quotes-humor.json -a tag=humor\n", "import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n\n    def start_requests(self):\n        url = 'https://quotes.toscrape.com/'\n        tag = getattr(self, 'tag', None)\n        if tag is not None:\n            url = url + 'tag/' + tag\n        yield scrapy.Request(url, self.parse)\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {\n                'text': quote.css('span.text::text').get(),\n                'author': quote.css('small.author::text').get(),\n            }\n\n        next_page = response.css('li.next a::attr(href)').get()\n        if next_page is not None:\n            yield response.follow(next_page, self.parse)\n"], "index": 42}
{"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Creating a project", "header_href": "#creating-a-project", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">startproject</span> <span class=\"n\">tutorial</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tutorial</span><span class=\"o\">/</span>\n    <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">cfg</span>            <span class=\"c1\"># deploy configuration file</span>\n\n    <span class=\"n\">tutorial</span><span class=\"o\">/</span>             <span class=\"c1\"># project's Python module, you'll import your code from here</span>\n        <span class=\"fm\">__init__</span><span class=\"o\">.</span><span class=\"n\">py</span>\n\n        <span class=\"n\">items</span><span class=\"o\">.</span><span class=\"n\">py</span>          <span class=\"c1\"># project items definition file</span>\n\n        <span class=\"n\">middlewares</span><span class=\"o\">.</span><span class=\"n\">py</span>    <span class=\"c1\"># project middlewares file</span>\n\n        <span class=\"n\">pipelines</span><span class=\"o\">.</span><span class=\"n\">py</span>      <span class=\"c1\"># project pipelines file</span>\n\n        <span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">py</span>       <span class=\"c1\"># project settings file</span>\n\n        <span class=\"n\">spiders</span><span class=\"o\">/</span>          <span class=\"c1\"># a directory where you'll later put your spiders</span>\n            <span class=\"fm\">__init__</span><span class=\"o\">.</span><span class=\"n\">py</span>\n</pre></div>"], "codes_text": ["scrapy startproject tutorial\n", "tutorial/\n    scrapy.cfg            # deploy configuration file\n\n    tutorial/             # project's Python module, you'll import your code from here\n        __init__.py\n\n        items.py          # project items definition file\n\n        middlewares.py    # project middlewares file\n\n        pipelines.py      # project pipelines file\n\n        settings.py       # project settings file\n\n        spiders/          # a directory where you'll later put your spiders\n            __init__.py\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Our first Spider", "header_href": "#our-first-spider", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"quotes\"</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"n\">urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n            <span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span><span class=\"p\">,</span>\n            <span class=\"s1\">'https://quotes.toscrape.com/page/2/'</span><span class=\"p\">,</span>\n        <span class=\"p\">]</span>\n        <span class=\"k\">for</span> <span class=\"n\">url</span> <span class=\"ow\">in</span> <span class=\"n\">urls</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">page</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s2\">\"/\"</span><span class=\"p\">)[</span><span class=\"o\">-</span><span class=\"mi\">2</span><span class=\"p\">]</span>\n        <span class=\"n\">filename</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">'quotes-</span><span class=\"si\">{</span><span class=\"n\">page</span><span class=\"si\">}</span><span class=\"s1\">.html'</span>\n        <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span> <span class=\"s1\">'wb'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n            <span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">log</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'Saved file </span><span class=\"si\">{</span><span class=\"n\">filename</span><span class=\"si\">}</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">quotes</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">...</span> <span class=\"p\">(</span><span class=\"n\">omitted</span> <span class=\"k\">for</span> <span class=\"n\">brevity</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Spider</span> <span class=\"n\">opened</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">logstats</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"mi\">0</span> <span class=\"n\">pages</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">pages</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">),</span> <span class=\"n\">scraped</span> <span class=\"mi\">0</span> <span class=\"n\">items</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">items</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">telnet</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Telnet</span> <span class=\"n\">console</span> <span class=\"n\">listening</span> <span class=\"n\">on</span> <span class=\"mf\">127.0.0.1</span><span class=\"p\">:</span><span class=\"mi\">6023</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">404</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">robots</span><span class=\"o\">.</span><span class=\"n\">txt</span><span class=\"o\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"o\">/&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">quotes</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Saved</span> <span class=\"n\">file</span> <span class=\"n\">quotes</span><span class=\"o\">-</span><span class=\"mf\">1.</span><span class=\"n\">html</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">quotes</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Saved</span> <span class=\"n\">file</span> <span class=\"n\">quotes</span><span class=\"o\">-</span><span class=\"mf\">2.</span><span class=\"n\">html</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Closing</span> <span class=\"n\">spider</span> <span class=\"p\">(</span><span class=\"n\">finished</span><span class=\"p\">)</span>\n<span class=\"o\">...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"quotes\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/2/'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">page</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s2\">\"/\"</span><span class=\"p\">)[</span><span class=\"o\">-</span><span class=\"mi\">2</span><span class=\"p\">]</span>\n        <span class=\"n\">filename</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">'quotes-</span><span class=\"si\">{</span><span class=\"n\">page</span><span class=\"si\">}</span><span class=\"s1\">.html'</span>\n        <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span> <span class=\"s1\">'wb'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n            <span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"s2\">\"https://quotes.toscrape.com/page/1/\"</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">[</span> <span class=\"o\">...</span> <span class=\"n\">Scrapy</span> <span class=\"n\">log</span> <span class=\"n\">here</span> <span class=\"o\">...</span> <span class=\"p\">]</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">09</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">12</span><span class=\"p\">:</span><span class=\"mi\">09</span><span class=\"p\">:</span><span class=\"mi\">27</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span> <span class=\"n\">Available</span> <span class=\"n\">Scrapy</span> <span class=\"n\">objects</span><span class=\"p\">:</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">scrapy</span>     <span class=\"n\">scrapy</span> <span class=\"n\">module</span> <span class=\"p\">(</span><span class=\"n\">contains</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">,</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Selector</span><span class=\"p\">,</span> <span class=\"n\">etc</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">crawler</span>    <span class=\"o\">&lt;</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">Crawler</span> <span class=\"nb\">object</span> <span class=\"n\">at</span> <span class=\"mh\">0x7fa91d888c90</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">item</span>       <span class=\"p\">{}</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">request</span>    <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">response</span>   <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">settings</span>   <span class=\"o\">&lt;</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">Settings</span> <span class=\"nb\">object</span> <span class=\"n\">at</span> <span class=\"mh\">0x7fa91d888c10</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">spider</span>     <span class=\"o\">&lt;</span><span class=\"n\">DefaultSpider</span> <span class=\"s1\">'default'</span> <span class=\"n\">at</span> <span class=\"mh\">0x7fa91c8af990</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span> <span class=\"n\">Useful</span> <span class=\"n\">shortcuts</span><span class=\"p\">:</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">shelp</span><span class=\"p\">()</span>           <span class=\"n\">Shell</span> <span class=\"n\">help</span> <span class=\"p\">(</span><span class=\"nb\">print</span> <span class=\"n\">this</span> <span class=\"n\">help</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">fetch</span><span class=\"p\">(</span><span class=\"n\">req_or_url</span><span class=\"p\">)</span> <span class=\"n\">Fetch</span> <span class=\"n\">request</span> <span class=\"p\">(</span><span class=\"ow\">or</span> <span class=\"n\">URL</span><span class=\"p\">)</span> <span class=\"ow\">and</span> <span class=\"n\">update</span> <span class=\"n\">local</span> <span class=\"n\">objects</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">view</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">)</span>    <span class=\"n\">View</span> <span class=\"n\">response</span> <span class=\"ow\">in</span> <span class=\"n\">a</span> <span class=\"n\">browser</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title'</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='descendant-or-self::title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['Quotes to Scrape']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['&lt;title&gt;Quotes to Scrape&lt;/title&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Quotes to Scrape'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Quotes to Scrape'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'noelement'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n<span class=\"c\">...</span>\n<span class=\"gr\">IndexError</span>: <span class=\"n\">list index out of range</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"noelement\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'Quotes.*'</span><span class=\"p\">)</span>\n<span class=\"go\">['Quotes to Scrape']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'Q\\w+'</span><span class=\"p\">)</span>\n<span class=\"go\">['Quotes']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'(\\w+) to (\\w+)'</span><span class=\"p\">)</span>\n<span class=\"go\">['Quotes', 'Scrape']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title'</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='//title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Quotes to Scrape'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"quote\"</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">span</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"text\"</span><span class=\"p\">&gt;</span>“The world as we have created it is a process of our\n    thinking. It cannot be changed without changing our thinking.”<span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n        by <span class=\"p\">&lt;</span><span class=\"nt\">small</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"author\"</span><span class=\"p\">&gt;</span>Albert Einstein<span class=\"p\">&lt;/</span><span class=\"nt\">small</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/author/Albert-Einstein\"</span><span class=\"p\">&gt;</span>(about)<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tags\"</span><span class=\"p\">&gt;</span>\n        Tags:\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tag\"</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/tag/change/page/1/\"</span><span class=\"p\">&gt;</span>change<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tag\"</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/tag/deep-thoughts/page/1/\"</span><span class=\"p\">&gt;</span>deep-thoughts<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tag\"</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/tag/thinking/page/1/\"</span><span class=\"p\">&gt;</span>thinking<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tag\"</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/tag/world/page/1/\"</span><span class=\"p\">&gt;</span>world<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"s1\">'https://quotes.toscrape.com'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.quote\"</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='&lt;div class=\"quote\" itemscope itemtype...'&gt;,</span>\n<span class=\"go\"> &lt;Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='&lt;div class=\"quote\" itemscope itemtype...'&gt;,</span>\n<span class=\"go\"> ...]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">quote</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.quote\"</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"span.text::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">text</span>\n<span class=\"go\">'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">author</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"small.author::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">author</span>\n<span class=\"go\">'Albert Einstein'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tags</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.tags a.tag::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tags</span>\n<span class=\"go\">['change', 'deep-thoughts', 'thinking', 'world']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.quote\"</span><span class=\"p\">):</span>\n<span class=\"gp\">... </span>    <span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"span.text::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"n\">author</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"small.author::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"n\">tags</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.tags a.tag::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"n\">author</span><span class=\"o\">=</span><span class=\"n\">author</span><span class=\"p\">,</span> <span class=\"n\">tags</span><span class=\"o\">=</span><span class=\"n\">tags</span><span class=\"p\">))</span>\n<span class=\"go\">{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}</span>\n<span class=\"go\">{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}</span>\n<span class=\"gp\">...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"quotes\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/2/'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'small.author::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'tags'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.tags a.tag::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">(),</span>\n            <span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">09</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">57</span><span class=\"p\">:</span><span class=\"mi\">19</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">scraper</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Scraped</span> <span class=\"kn\">from</span> <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span>\n<span class=\"p\">{</span><span class=\"s1\">'tags'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'life'</span><span class=\"p\">,</span> <span class=\"s1\">'love'</span><span class=\"p\">],</span> <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"s1\">'André Gide'</span><span class=\"p\">,</span> <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"s1\">'“It is better to be hated for what you are than to be loved for what you are not.”'</span><span class=\"p\">}</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">09</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">57</span><span class=\"p\">:</span><span class=\"mi\">19</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">scraper</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Scraped</span> <span class=\"kn\">from</span> <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span>\n<span class=\"p\">{</span><span class=\"s1\">'tags'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'edison'</span><span class=\"p\">,</span> <span class=\"s1\">'failure'</span><span class=\"p\">,</span> <span class=\"s1\">'inspirational'</span><span class=\"p\">,</span> <span class=\"s1\">'paraphrased'</span><span class=\"p\">],</span> <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"s1\">'Thomas A. Edison'</span><span class=\"p\">,</span> <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"s2\">\"“I have not failed. I've just found 10,000 ways that won't work.”\"</span><span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n\n    def start_requests(self):\n        urls = [\n            'https://quotes.toscrape.com/page/1/',\n            'https://quotes.toscrape.com/page/2/',\n        ]\n        for url in urls:\n            yield scrapy.Request(url=url, callback=self.parse)\n\n    def parse(self, response):\n        page = response.url.split(\"/\")[-2]\n        filename = f'quotes-{page}.html'\n        with open(filename, 'wb') as f:\n            f.write(response.body)\n        self.log(f'Saved file {filename}')\n", "scrapy crawl quotes\n", "... (omitted for brevity)\n2016-12-16 21:24:05 [scrapy.core.engine] INFO: Spider opened\n2016-12-16 21:24:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n2016-12-16 21:24:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023\n2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://quotes.toscrape.com/robots.txt> (referer: None)\n2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/1/> (referer: None)\n2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/2/> (referer: None)\n2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-1.html\n2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-2.html\n2016-12-16 21:24:05 [scrapy.core.engine] INFO: Closing spider (finished)\n...\n", "import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n    start_urls = [\n        'https://quotes.toscrape.com/page/1/',\n        'https://quotes.toscrape.com/page/2/',\n    ]\n\n    def parse(self, response):\n        page = response.url.split(\"/\")[-2]\n        filename = f'quotes-{page}.html'\n        with open(filename, 'wb') as f:\n            f.write(response.body)\n", "scrapy shell 'https://quotes.toscrape.com/page/1/'\n", "scrapy shell \"https://quotes.toscrape.com/page/1/\"\n", "[ ... Scrapy log here ... ]\n2016-09-19 12:09:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/1/> (referer: None)\n[s] Available Scrapy objects:\n[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)\n[s]   crawler    <scrapy.crawler.Crawler object at 0x7fa91d888c90>\n[s]   item       {}\n[s]   request    <GET https://quotes.toscrape.com/page/1/>\n[s]   response   <200 https://quotes.toscrape.com/page/1/>\n[s]   settings   <scrapy.settings.Settings object at 0x7fa91d888c10>\n[s]   spider     <DefaultSpider 'default' at 0x7fa91c8af990>\n[s] Useful shortcuts:\n[s]   shelp()           Shell help (print this help)\n[s]   fetch(req_or_url) Fetch request (or URL) and update local objects\n[s]   view(response)    View response in a browser\n", ">>> response.css('title')\n[<Selector xpath='descendant-or-self::title' data='<title>Quotes to Scrape</title>'>]\n", ">>> response.css('title::text').getall()\n['Quotes to Scrape']\n", ">>> response.css('title').getall()\n['<title>Quotes to Scrape</title>']\n", ">>> response.css('title::text').get()\n'Quotes to Scrape'\n", ">>> response.css('title::text')[0].get()\n'Quotes to Scrape'\n", ">>> response.css('noelement')[0].get()\nTraceback (most recent call last):\n...\nIndexError: list index out of range\n", ">>> response.css(\"noelement\").get()\n", ">>> response.css('title::text').re(r'Quotes.*')\n['Quotes to Scrape']\n>>> response.css('title::text').re(r'Q\\w+')\n['Quotes']\n>>> response.css('title::text').re(r'(\\w+) to (\\w+)')\n['Quotes', 'Scrape']\n", ">>> response.xpath('//title')\n[<Selector xpath='//title' data='<title>Quotes to Scrape</title>'>]\n>>> response.xpath('//title/text()').get()\n'Quotes to Scrape'\n", "<div class=\"quote\">\n    <span class=\"text\">“The world as we have created it is a process of our\n    thinking. It cannot be changed without changing our thinking.”</span>\n    <span>\n        by <small class=\"author\">Albert Einstein</small>\n        <a href=\"/author/Albert-Einstein\">(about)</a>\n    </span>\n    <div class=\"tags\">\n        Tags:\n        <a class=\"tag\" href=\"/tag/change/page/1/\">change</a>\n        <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\n        <a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>\n        <a class=\"tag\" href=\"/tag/world/page/1/\">world</a>\n    </div>\n</div>\n", "scrapy shell 'https://quotes.toscrape.com'\n", ">>> response.css(\"div.quote\")\n[<Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n <Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n ...]\n", ">>> quote = response.css(\"div.quote\")[0]\n", ">>> text = quote.css(\"span.text::text\").get()\n>>> text\n'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'\n>>> author = quote.css(\"small.author::text\").get()\n>>> author\n'Albert Einstein'\n", ">>> tags = quote.css(\"div.tags a.tag::text\").getall()\n>>> tags\n['change', 'deep-thoughts', 'thinking', 'world']\n", ">>> for quote in response.css(\"div.quote\"):\n...     text = quote.css(\"span.text::text\").get()\n...     author = quote.css(\"small.author::text\").get()\n...     tags = quote.css(\"div.tags a.tag::text\").getall()\n...     print(dict(text=text, author=author, tags=tags))\n{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}\n{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}\n...\n", "import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n    start_urls = [\n        'https://quotes.toscrape.com/page/1/',\n        'https://quotes.toscrape.com/page/2/',\n    ]\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {\n                'text': quote.css('span.text::text').get(),\n                'author': quote.css('small.author::text').get(),\n                'tags': quote.css('div.tags a.tag::text').getall(),\n            }\n", "2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>\n{'tags': ['life', 'love'], 'author': 'André Gide', 'text': '“It is better to be hated for what you are than to be loved for what you are not.”'}\n2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>\n{'tags': ['edison', 'failure', 'inspirational', 'paraphrased'], 'author': 'Thomas A. Edison', 'text': \"“I have not failed. I've just found 10,000 ways that won't work.”\"}\n"], "index": 25}
{"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "How to run our spider", "header_href": "#how-to-run-our-spider", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">quotes</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">...</span> <span class=\"p\">(</span><span class=\"n\">omitted</span> <span class=\"k\">for</span> <span class=\"n\">brevity</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Spider</span> <span class=\"n\">opened</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">logstats</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"mi\">0</span> <span class=\"n\">pages</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">pages</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">),</span> <span class=\"n\">scraped</span> <span class=\"mi\">0</span> <span class=\"n\">items</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">items</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">telnet</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Telnet</span> <span class=\"n\">console</span> <span class=\"n\">listening</span> <span class=\"n\">on</span> <span class=\"mf\">127.0.0.1</span><span class=\"p\">:</span><span class=\"mi\">6023</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">404</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">robots</span><span class=\"o\">.</span><span class=\"n\">txt</span><span class=\"o\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"o\">/&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">quotes</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Saved</span> <span class=\"n\">file</span> <span class=\"n\">quotes</span><span class=\"o\">-</span><span class=\"mf\">1.</span><span class=\"n\">html</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">quotes</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Saved</span> <span class=\"n\">file</span> <span class=\"n\">quotes</span><span class=\"o\">-</span><span class=\"mf\">2.</span><span class=\"n\">html</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">24</span><span class=\"p\">:</span><span class=\"mi\">05</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Closing</span> <span class=\"n\">spider</span> <span class=\"p\">(</span><span class=\"n\">finished</span><span class=\"p\">)</span>\n<span class=\"o\">...</span>\n</pre></div>"], "codes_text": ["scrapy crawl quotes\n", "... (omitted for brevity)\n2016-12-16 21:24:05 [scrapy.core.engine] INFO: Spider opened\n2016-12-16 21:24:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n2016-12-16 21:24:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023\n2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://quotes.toscrape.com/robots.txt> (referer: None)\n2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/1/> (referer: None)\n2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/2/> (referer: None)\n2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-1.html\n2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-2.html\n2016-12-16 21:24:05 [scrapy.core.engine] INFO: Closing spider (finished)\n...\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "What just happened under the hood?", "header_href": "#what-just-happened-under-the-hood", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "A shortcut to the start_requests method", "header_href": "#a-shortcut-to-the-start-requests-method", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"quotes\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/2/'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">page</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s2\">\"/\"</span><span class=\"p\">)[</span><span class=\"o\">-</span><span class=\"mi\">2</span><span class=\"p\">]</span>\n        <span class=\"n\">filename</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">'quotes-</span><span class=\"si\">{</span><span class=\"n\">page</span><span class=\"si\">}</span><span class=\"s1\">.html'</span>\n        <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span> <span class=\"s1\">'wb'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n            <span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n    start_urls = [\n        'https://quotes.toscrape.com/page/1/',\n        'https://quotes.toscrape.com/page/2/',\n    ]\n\n    def parse(self, response):\n        page = response.url.split(\"/\")[-2]\n        filename = f'quotes-{page}.html'\n        with open(filename, 'wb') as f:\n            f.write(response.body)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Extracting data", "header_href": "#extracting-data", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"s2\">\"https://quotes.toscrape.com/page/1/\"</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">[</span> <span class=\"o\">...</span> <span class=\"n\">Scrapy</span> <span class=\"n\">log</span> <span class=\"n\">here</span> <span class=\"o\">...</span> <span class=\"p\">]</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">09</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">12</span><span class=\"p\">:</span><span class=\"mi\">09</span><span class=\"p\">:</span><span class=\"mi\">27</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span> <span class=\"n\">Available</span> <span class=\"n\">Scrapy</span> <span class=\"n\">objects</span><span class=\"p\">:</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">scrapy</span>     <span class=\"n\">scrapy</span> <span class=\"n\">module</span> <span class=\"p\">(</span><span class=\"n\">contains</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">,</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Selector</span><span class=\"p\">,</span> <span class=\"n\">etc</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">crawler</span>    <span class=\"o\">&lt;</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">Crawler</span> <span class=\"nb\">object</span> <span class=\"n\">at</span> <span class=\"mh\">0x7fa91d888c90</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">item</span>       <span class=\"p\">{}</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">request</span>    <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">response</span>   <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">settings</span>   <span class=\"o\">&lt;</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">Settings</span> <span class=\"nb\">object</span> <span class=\"n\">at</span> <span class=\"mh\">0x7fa91d888c10</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">spider</span>     <span class=\"o\">&lt;</span><span class=\"n\">DefaultSpider</span> <span class=\"s1\">'default'</span> <span class=\"n\">at</span> <span class=\"mh\">0x7fa91c8af990</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span> <span class=\"n\">Useful</span> <span class=\"n\">shortcuts</span><span class=\"p\">:</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">shelp</span><span class=\"p\">()</span>           <span class=\"n\">Shell</span> <span class=\"n\">help</span> <span class=\"p\">(</span><span class=\"nb\">print</span> <span class=\"n\">this</span> <span class=\"n\">help</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">fetch</span><span class=\"p\">(</span><span class=\"n\">req_or_url</span><span class=\"p\">)</span> <span class=\"n\">Fetch</span> <span class=\"n\">request</span> <span class=\"p\">(</span><span class=\"ow\">or</span> <span class=\"n\">URL</span><span class=\"p\">)</span> <span class=\"ow\">and</span> <span class=\"n\">update</span> <span class=\"n\">local</span> <span class=\"n\">objects</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">view</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">)</span>    <span class=\"n\">View</span> <span class=\"n\">response</span> <span class=\"ow\">in</span> <span class=\"n\">a</span> <span class=\"n\">browser</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title'</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='descendant-or-self::title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['Quotes to Scrape']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['&lt;title&gt;Quotes to Scrape&lt;/title&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Quotes to Scrape'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Quotes to Scrape'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'noelement'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n<span class=\"c\">...</span>\n<span class=\"gr\">IndexError</span>: <span class=\"n\">list index out of range</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"noelement\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'Quotes.*'</span><span class=\"p\">)</span>\n<span class=\"go\">['Quotes to Scrape']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'Q\\w+'</span><span class=\"p\">)</span>\n<span class=\"go\">['Quotes']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'(\\w+) to (\\w+)'</span><span class=\"p\">)</span>\n<span class=\"go\">['Quotes', 'Scrape']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title'</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='//title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Quotes to Scrape'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"quote\"</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">span</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"text\"</span><span class=\"p\">&gt;</span>“The world as we have created it is a process of our\n    thinking. It cannot be changed without changing our thinking.”<span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n        by <span class=\"p\">&lt;</span><span class=\"nt\">small</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"author\"</span><span class=\"p\">&gt;</span>Albert Einstein<span class=\"p\">&lt;/</span><span class=\"nt\">small</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/author/Albert-Einstein\"</span><span class=\"p\">&gt;</span>(about)<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tags\"</span><span class=\"p\">&gt;</span>\n        Tags:\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tag\"</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/tag/change/page/1/\"</span><span class=\"p\">&gt;</span>change<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tag\"</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/tag/deep-thoughts/page/1/\"</span><span class=\"p\">&gt;</span>deep-thoughts<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tag\"</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/tag/thinking/page/1/\"</span><span class=\"p\">&gt;</span>thinking<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tag\"</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/tag/world/page/1/\"</span><span class=\"p\">&gt;</span>world<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"s1\">'https://quotes.toscrape.com'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.quote\"</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='&lt;div class=\"quote\" itemscope itemtype...'&gt;,</span>\n<span class=\"go\"> &lt;Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='&lt;div class=\"quote\" itemscope itemtype...'&gt;,</span>\n<span class=\"go\"> ...]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">quote</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.quote\"</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"span.text::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">text</span>\n<span class=\"go\">'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">author</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"small.author::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">author</span>\n<span class=\"go\">'Albert Einstein'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tags</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.tags a.tag::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tags</span>\n<span class=\"go\">['change', 'deep-thoughts', 'thinking', 'world']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.quote\"</span><span class=\"p\">):</span>\n<span class=\"gp\">... </span>    <span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"span.text::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"n\">author</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"small.author::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"n\">tags</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.tags a.tag::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"n\">author</span><span class=\"o\">=</span><span class=\"n\">author</span><span class=\"p\">,</span> <span class=\"n\">tags</span><span class=\"o\">=</span><span class=\"n\">tags</span><span class=\"p\">))</span>\n<span class=\"go\">{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}</span>\n<span class=\"go\">{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}</span>\n<span class=\"gp\">...</span>\n</pre></div>"], "codes_text": ["scrapy shell 'https://quotes.toscrape.com/page/1/'\n", "scrapy shell \"https://quotes.toscrape.com/page/1/\"\n", "[ ... Scrapy log here ... ]\n2016-09-19 12:09:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/1/> (referer: None)\n[s] Available Scrapy objects:\n[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)\n[s]   crawler    <scrapy.crawler.Crawler object at 0x7fa91d888c90>\n[s]   item       {}\n[s]   request    <GET https://quotes.toscrape.com/page/1/>\n[s]   response   <200 https://quotes.toscrape.com/page/1/>\n[s]   settings   <scrapy.settings.Settings object at 0x7fa91d888c10>\n[s]   spider     <DefaultSpider 'default' at 0x7fa91c8af990>\n[s] Useful shortcuts:\n[s]   shelp()           Shell help (print this help)\n[s]   fetch(req_or_url) Fetch request (or URL) and update local objects\n[s]   view(response)    View response in a browser\n", ">>> response.css('title')\n[<Selector xpath='descendant-or-self::title' data='<title>Quotes to Scrape</title>'>]\n", ">>> response.css('title::text').getall()\n['Quotes to Scrape']\n", ">>> response.css('title').getall()\n['<title>Quotes to Scrape</title>']\n", ">>> response.css('title::text').get()\n'Quotes to Scrape'\n", ">>> response.css('title::text')[0].get()\n'Quotes to Scrape'\n", ">>> response.css('noelement')[0].get()\nTraceback (most recent call last):\n...\nIndexError: list index out of range\n", ">>> response.css(\"noelement\").get()\n", ">>> response.css('title::text').re(r'Quotes.*')\n['Quotes to Scrape']\n>>> response.css('title::text').re(r'Q\\w+')\n['Quotes']\n>>> response.css('title::text').re(r'(\\w+) to (\\w+)')\n['Quotes', 'Scrape']\n", ">>> response.xpath('//title')\n[<Selector xpath='//title' data='<title>Quotes to Scrape</title>'>]\n>>> response.xpath('//title/text()').get()\n'Quotes to Scrape'\n", "<div class=\"quote\">\n    <span class=\"text\">“The world as we have created it is a process of our\n    thinking. It cannot be changed without changing our thinking.”</span>\n    <span>\n        by <small class=\"author\">Albert Einstein</small>\n        <a href=\"/author/Albert-Einstein\">(about)</a>\n    </span>\n    <div class=\"tags\">\n        Tags:\n        <a class=\"tag\" href=\"/tag/change/page/1/\">change</a>\n        <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\n        <a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>\n        <a class=\"tag\" href=\"/tag/world/page/1/\">world</a>\n    </div>\n</div>\n", "scrapy shell 'https://quotes.toscrape.com'\n", ">>> response.css(\"div.quote\")\n[<Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n <Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n ...]\n", ">>> quote = response.css(\"div.quote\")[0]\n", ">>> text = quote.css(\"span.text::text\").get()\n>>> text\n'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'\n>>> author = quote.css(\"small.author::text\").get()\n>>> author\n'Albert Einstein'\n", ">>> tags = quote.css(\"div.tags a.tag::text\").getall()\n>>> tags\n['change', 'deep-thoughts', 'thinking', 'world']\n", ">>> for quote in response.css(\"div.quote\"):\n...     text = quote.css(\"span.text::text\").get()\n...     author = quote.css(\"small.author::text\").get()\n...     tags = quote.css(\"div.tags a.tag::text\").getall()\n...     print(dict(text=text, author=author, tags=tags))\n{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}\n{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}\n...\n"], "index": 19}
{"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "XPath: a brief intro", "header_href": "#xpath-a-brief-intro", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title'</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='//title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Quotes to Scrape'</span>\n</pre></div>"], "codes_text": [">>> response.xpath('//title')\n[<Selector xpath='//title' data='<title>Quotes to Scrape</title>'>]\n>>> response.xpath('//title/text()').get()\n'Quotes to Scrape'\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Extracting quotes and authors", "header_href": "#extracting-quotes-and-authors", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"quote\"</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">span</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"text\"</span><span class=\"p\">&gt;</span>“The world as we have created it is a process of our\n    thinking. It cannot be changed without changing our thinking.”<span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n        by <span class=\"p\">&lt;</span><span class=\"nt\">small</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"author\"</span><span class=\"p\">&gt;</span>Albert Einstein<span class=\"p\">&lt;/</span><span class=\"nt\">small</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/author/Albert-Einstein\"</span><span class=\"p\">&gt;</span>(about)<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tags\"</span><span class=\"p\">&gt;</span>\n        Tags:\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tag\"</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/tag/change/page/1/\"</span><span class=\"p\">&gt;</span>change<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tag\"</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/tag/deep-thoughts/page/1/\"</span><span class=\"p\">&gt;</span>deep-thoughts<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tag\"</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/tag/thinking/page/1/\"</span><span class=\"p\">&gt;</span>thinking<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tag\"</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/tag/world/page/1/\"</span><span class=\"p\">&gt;</span>world<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"s1\">'https://quotes.toscrape.com'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.quote\"</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='&lt;div class=\"quote\" itemscope itemtype...'&gt;,</span>\n<span class=\"go\"> &lt;Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='&lt;div class=\"quote\" itemscope itemtype...'&gt;,</span>\n<span class=\"go\"> ...]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">quote</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.quote\"</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"span.text::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">text</span>\n<span class=\"go\">'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">author</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"small.author::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">author</span>\n<span class=\"go\">'Albert Einstein'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tags</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.tags a.tag::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tags</span>\n<span class=\"go\">['change', 'deep-thoughts', 'thinking', 'world']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.quote\"</span><span class=\"p\">):</span>\n<span class=\"gp\">... </span>    <span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"span.text::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"n\">author</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"small.author::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"n\">tags</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s2\">\"div.tags a.tag::text\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"n\">author</span><span class=\"o\">=</span><span class=\"n\">author</span><span class=\"p\">,</span> <span class=\"n\">tags</span><span class=\"o\">=</span><span class=\"n\">tags</span><span class=\"p\">))</span>\n<span class=\"go\">{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}</span>\n<span class=\"go\">{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}</span>\n<span class=\"gp\">...</span>\n</pre></div>"], "codes_text": ["<div class=\"quote\">\n    <span class=\"text\">“The world as we have created it is a process of our\n    thinking. It cannot be changed without changing our thinking.”</span>\n    <span>\n        by <small class=\"author\">Albert Einstein</small>\n        <a href=\"/author/Albert-Einstein\">(about)</a>\n    </span>\n    <div class=\"tags\">\n        Tags:\n        <a class=\"tag\" href=\"/tag/change/page/1/\">change</a>\n        <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\n        <a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>\n        <a class=\"tag\" href=\"/tag/world/page/1/\">world</a>\n    </div>\n</div>\n", "scrapy shell 'https://quotes.toscrape.com'\n", ">>> response.css(\"div.quote\")\n[<Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n <Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n ...]\n", ">>> quote = response.css(\"div.quote\")[0]\n", ">>> text = quote.css(\"span.text::text\").get()\n>>> text\n'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'\n>>> author = quote.css(\"small.author::text\").get()\n>>> author\n'Albert Einstein'\n", ">>> tags = quote.css(\"div.tags a.tag::text\").getall()\n>>> tags\n['change', 'deep-thoughts', 'thinking', 'world']\n", ">>> for quote in response.css(\"div.quote\"):\n...     text = quote.css(\"span.text::text\").get()\n...     author = quote.css(\"small.author::text\").get()\n...     tags = quote.css(\"div.tags a.tag::text\").getall()\n...     print(dict(text=text, author=author, tags=tags))\n{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}\n{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}\n...\n"], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Extracting data in our spider", "header_href": "#extracting-data-in-our-spider", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"quotes\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/2/'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'small.author::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'tags'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.tags a.tag::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">(),</span>\n            <span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">09</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">57</span><span class=\"p\">:</span><span class=\"mi\">19</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">scraper</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Scraped</span> <span class=\"kn\">from</span> <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span>\n<span class=\"p\">{</span><span class=\"s1\">'tags'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'life'</span><span class=\"p\">,</span> <span class=\"s1\">'love'</span><span class=\"p\">],</span> <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"s1\">'André Gide'</span><span class=\"p\">,</span> <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"s1\">'“It is better to be hated for what you are than to be loved for what you are not.”'</span><span class=\"p\">}</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">09</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">57</span><span class=\"p\">:</span><span class=\"mi\">19</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">scraper</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Scraped</span> <span class=\"kn\">from</span> <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">/&gt;</span>\n<span class=\"p\">{</span><span class=\"s1\">'tags'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'edison'</span><span class=\"p\">,</span> <span class=\"s1\">'failure'</span><span class=\"p\">,</span> <span class=\"s1\">'inspirational'</span><span class=\"p\">,</span> <span class=\"s1\">'paraphrased'</span><span class=\"p\">],</span> <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"s1\">'Thomas A. Edison'</span><span class=\"p\">,</span> <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"s2\">\"“I have not failed. I've just found 10,000 ways that won't work.”\"</span><span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n    start_urls = [\n        'https://quotes.toscrape.com/page/1/',\n        'https://quotes.toscrape.com/page/2/',\n    ]\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {\n                'text': quote.css('span.text::text').get(),\n                'author': quote.css('small.author::text').get(),\n                'tags': quote.css('div.tags a.tag::text').getall(),\n            }\n", "2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>\n{'tags': ['life', 'love'], 'author': 'André Gide', 'text': '“It is better to be hated for what you are than to be loved for what you are not.”'}\n2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>\n{'tags': ['edison', 'failure', 'inspirational', 'paraphrased'], 'author': 'Thomas A. Edison', 'text': \"“I have not failed. I've just found 10,000 ways that won't work.”\"}\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Storing the scraped data", "header_href": "#storing-the-scraped-data", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">quotes</span> <span class=\"o\">-</span><span class=\"n\">O</span> <span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">json</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">quotes</span> <span class=\"o\">-</span><span class=\"n\">o</span> <span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">jsonl</span>\n</pre></div>"], "codes_text": ["scrapy crawl quotes -O quotes.json\n", "scrapy crawl quotes -o quotes.jsonl\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Following links", "header_href": "#following-links", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">ul</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"pager\"</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">li</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"next\"</span><span class=\"p\">&gt;</span>\n        <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"/page/2/\"</span><span class=\"p\">&gt;</span>Next <span class=\"p\">&lt;</span><span class=\"nt\">span</span> <span class=\"na\">aria-hidden</span><span class=\"o\">=</span><span class=\"s\">\"true\"</span><span class=\"p\">&gt;</span><span class=\"ni\">&amp;rarr;</span><span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;/</span><span class=\"nt\">li</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;/</span><span class=\"nt\">ul</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'&lt;a href=\"/page/2/\"&gt;Next &lt;span aria-hidden=\"true\"&gt;→&lt;/span&gt;&lt;/a&gt;'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'/page/2/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'href'</span><span class=\"p\">]</span>\n<span class=\"go\">'/page/2/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"quotes\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'small.author::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'tags'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.tags a.tag::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">(),</span>\n            <span class=\"p\">}</span>\n\n        <span class=\"n\">next_page</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">if</span> <span class=\"n\">next_page</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n            <span class=\"n\">next_page</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">urljoin</span><span class=\"p\">(</span><span class=\"n\">next_page</span><span class=\"p\">)</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">next_page</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"quotes\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span small::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'tags'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.tags a.tag::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">(),</span>\n            <span class=\"p\">}</span>\n\n        <span class=\"n\">next_page</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">if</span> <span class=\"n\">next_page</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">next_page</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">href</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'ul.pager a::attr(href)'</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">href</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'ul.pager a'</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">anchors</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'ul.pager a'</span><span class=\"p\">)</span>\n<span class=\"k\">yield from</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow_all</span><span class=\"p\">(</span><span class=\"n\">anchors</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">yield from</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow_all</span><span class=\"p\">(</span><span class=\"n\">css</span><span class=\"o\">=</span><span class=\"s1\">'ul.pager a'</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">AuthorSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'author'</span>\n\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://quotes.toscrape.com/'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">author_page_links</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'.author + a'</span><span class=\"p\">)</span>\n        <span class=\"k\">yield from</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow_all</span><span class=\"p\">(</span><span class=\"n\">author_page_links</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_author</span><span class=\"p\">)</span>\n\n        <span class=\"n\">pagination_links</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a'</span><span class=\"p\">)</span>\n        <span class=\"k\">yield from</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow_all</span><span class=\"p\">(</span><span class=\"n\">pagination_links</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_author</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">def</span> <span class=\"nf\">extract_with_css</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"p\">):</span>\n            <span class=\"k\">return</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">default</span><span class=\"o\">=</span><span class=\"s1\">''</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">strip</span><span class=\"p\">()</span>\n\n        <span class=\"k\">yield</span> <span class=\"p\">{</span>\n            <span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"n\">extract_with_css</span><span class=\"p\">(</span><span class=\"s1\">'h3.author-title::text'</span><span class=\"p\">),</span>\n            <span class=\"s1\">'birthdate'</span><span class=\"p\">:</span> <span class=\"n\">extract_with_css</span><span class=\"p\">(</span><span class=\"s1\">'.author-born-date::text'</span><span class=\"p\">),</span>\n            <span class=\"s1\">'bio'</span><span class=\"p\">:</span> <span class=\"n\">extract_with_css</span><span class=\"p\">(</span><span class=\"s1\">'.author-description::text'</span><span class=\"p\">),</span>\n        <span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["<ul class=\"pager\">\n    <li class=\"next\">\n        <a href=\"/page/2/\">Next <span aria-hidden=\"true\">→</span></a>\n    </li>\n</ul>\n", ">>> response.css('li.next a').get()\n'<a href=\"/page/2/\">Next <span aria-hidden=\"true\">→</span></a>'\n", ">>> response.css('li.next a::attr(href)').get()\n'/page/2/'\n", ">>> response.css('li.next a').attrib['href']\n'/page/2/'\n", "import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n    start_urls = [\n        'https://quotes.toscrape.com/page/1/',\n    ]\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {\n                'text': quote.css('span.text::text').get(),\n                'author': quote.css('small.author::text').get(),\n                'tags': quote.css('div.tags a.tag::text').getall(),\n            }\n\n        next_page = response.css('li.next a::attr(href)').get()\n        if next_page is not None:\n            next_page = response.urljoin(next_page)\n            yield scrapy.Request(next_page, callback=self.parse)\n", "import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n    start_urls = [\n        'https://quotes.toscrape.com/page/1/',\n    ]\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {\n                'text': quote.css('span.text::text').get(),\n                'author': quote.css('span small::text').get(),\n                'tags': quote.css('div.tags a.tag::text').getall(),\n            }\n\n        next_page = response.css('li.next a::attr(href)').get()\n        if next_page is not None:\n            yield response.follow(next_page, callback=self.parse)\n", "for href in response.css('ul.pager a::attr(href)'):\n    yield response.follow(href, callback=self.parse)\n", "for a in response.css('ul.pager a'):\n    yield response.follow(a, callback=self.parse)\n", "anchors = response.css('ul.pager a')\nyield from response.follow_all(anchors, callback=self.parse)\n", "yield from response.follow_all(css='ul.pager a', callback=self.parse)\n", "import scrapy\n\n\nclass AuthorSpider(scrapy.Spider):\n    name = 'author'\n\n    start_urls = ['https://quotes.toscrape.com/']\n\n    def parse(self, response):\n        author_page_links = response.css('.author + a')\n        yield from response.follow_all(author_page_links, self.parse_author)\n\n        pagination_links = response.css('li.next a')\n        yield from response.follow_all(pagination_links, self.parse)\n\n    def parse_author(self, response):\n        def extract_with_css(query):\n            return response.css(query).get(default='').strip()\n\n        yield {\n            'name': extract_with_css('h3.author-title::text'),\n            'birthdate': extract_with_css('.author-born-date::text'),\n            'bio': extract_with_css('.author-description::text'),\n        }\n"], "index": 11}
{"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "A shortcut for creating Requests", "header_href": "#a-shortcut-for-creating-requests", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"quotes\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span small::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'tags'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.tags a.tag::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">(),</span>\n            <span class=\"p\">}</span>\n\n        <span class=\"n\">next_page</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">if</span> <span class=\"n\">next_page</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">next_page</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">href</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'ul.pager a::attr(href)'</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">href</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'ul.pager a'</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">anchors</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'ul.pager a'</span><span class=\"p\">)</span>\n<span class=\"k\">yield from</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow_all</span><span class=\"p\">(</span><span class=\"n\">anchors</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">yield from</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow_all</span><span class=\"p\">(</span><span class=\"n\">css</span><span class=\"o\">=</span><span class=\"s1\">'ul.pager a'</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n    start_urls = [\n        'https://quotes.toscrape.com/page/1/',\n    ]\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {\n                'text': quote.css('span.text::text').get(),\n                'author': quote.css('span small::text').get(),\n                'tags': quote.css('div.tags a.tag::text').getall(),\n            }\n\n        next_page = response.css('li.next a::attr(href)').get()\n        if next_page is not None:\n            yield response.follow(next_page, callback=self.parse)\n", "for href in response.css('ul.pager a::attr(href)'):\n    yield response.follow(href, callback=self.parse)\n", "for a in response.css('ul.pager a'):\n    yield response.follow(a, callback=self.parse)\n", "anchors = response.css('ul.pager a')\nyield from response.follow_all(anchors, callback=self.parse)\n", "yield from response.follow_all(css='ul.pager a', callback=self.parse)\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "More examples and patterns", "header_href": "#more-examples-and-patterns", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">AuthorSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'author'</span>\n\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://quotes.toscrape.com/'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">author_page_links</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'.author + a'</span><span class=\"p\">)</span>\n        <span class=\"k\">yield from</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow_all</span><span class=\"p\">(</span><span class=\"n\">author_page_links</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_author</span><span class=\"p\">)</span>\n\n        <span class=\"n\">pagination_links</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a'</span><span class=\"p\">)</span>\n        <span class=\"k\">yield from</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow_all</span><span class=\"p\">(</span><span class=\"n\">pagination_links</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_author</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">def</span> <span class=\"nf\">extract_with_css</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"p\">):</span>\n            <span class=\"k\">return</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">default</span><span class=\"o\">=</span><span class=\"s1\">''</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">strip</span><span class=\"p\">()</span>\n\n        <span class=\"k\">yield</span> <span class=\"p\">{</span>\n            <span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"n\">extract_with_css</span><span class=\"p\">(</span><span class=\"s1\">'h3.author-title::text'</span><span class=\"p\">),</span>\n            <span class=\"s1\">'birthdate'</span><span class=\"p\">:</span> <span class=\"n\">extract_with_css</span><span class=\"p\">(</span><span class=\"s1\">'.author-born-date::text'</span><span class=\"p\">),</span>\n            <span class=\"s1\">'bio'</span><span class=\"p\">:</span> <span class=\"n\">extract_with_css</span><span class=\"p\">(</span><span class=\"s1\">'.author-description::text'</span><span class=\"p\">),</span>\n        <span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["import scrapy\n\n\nclass AuthorSpider(scrapy.Spider):\n    name = 'author'\n\n    start_urls = ['https://quotes.toscrape.com/']\n\n    def parse(self, response):\n        author_page_links = response.css('.author + a')\n        yield from response.follow_all(author_page_links, self.parse_author)\n\n        pagination_links = response.css('li.next a')\n        yield from response.follow_all(pagination_links, self.parse)\n\n    def parse_author(self, response):\n        def extract_with_css(query):\n            return response.css(query).get(default='').strip()\n\n        yield {\n            'name': extract_with_css('h3.author-title::text'),\n            'birthdate': extract_with_css('.author-born-date::text'),\n            'bio': extract_with_css('.author-description::text'),\n        }\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Using spider arguments", "header_href": "#using-spider-arguments", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">quotes</span> <span class=\"o\">-</span><span class=\"n\">O</span> <span class=\"n\">quotes</span><span class=\"o\">-</span><span class=\"n\">humor</span><span class=\"o\">.</span><span class=\"n\">json</span> <span class=\"o\">-</span><span class=\"n\">a</span> <span class=\"n\">tag</span><span class=\"o\">=</span><span class=\"n\">humor</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"quotes\"</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"s1\">'https://quotes.toscrape.com/'</span>\n        <span class=\"n\">tag</span> <span class=\"o\">=</span> <span class=\"nb\">getattr</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"s1\">'tag'</span><span class=\"p\">,</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n        <span class=\"k\">if</span> <span class=\"n\">tag</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n            <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">url</span> <span class=\"o\">+</span> <span class=\"s1\">'tag/'</span> <span class=\"o\">+</span> <span class=\"n\">tag</span>\n        <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'small.author::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n            <span class=\"p\">}</span>\n\n        <span class=\"n\">next_page</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.next a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">if</span> <span class=\"n\">next_page</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">next_page</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["scrapy crawl quotes -O quotes-humor.json -a tag=humor\n", "import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n\n    def start_requests(self):\n        url = 'https://quotes.toscrape.com/'\n        tag = getattr(self, 'tag', None)\n        if tag is not None:\n            url = url + 'tag/' + tag\n        yield scrapy.Request(url, self.parse)\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {\n                'text': quote.css('span.text::text').get(),\n                'author': quote.css('small.author::text').get(),\n            }\n\n        next_page = response.css('li.next a::attr(href)').get()\n        if next_page is not None:\n            yield response.follow(next_page, self.parse)\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Next steps", "header_href": "#next-steps", "codes": [], "codes_text": [], "index": 16}
{"url": "https://docs.scrapy.org/en/latest/intro/examples.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Examples", "header_href": "#examples", "codes": [], "codes_text": [], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Command line tool", "header_href": "#command-line-tool", "codes": ["<div class=\"highlight\"><pre><span></span>scrapy.cfg\nmyproject/\n    __init__.py\n    items.py\n    middlewares.py\n    pipelines.py\n    settings.py\n    spiders/\n        __init__.py\n        spider1.py\n        spider2.py\n        ...\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">[settings]</span><span class=\"w\"></span>\n<span class=\"na\">default</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s\">myproject.settings</span><span class=\"w\"></span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">[settings]</span><span class=\"w\"></span>\n<span class=\"na\">default</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s\">myproject1.settings</span><span class=\"w\"></span>\n<span class=\"na\">project1</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s\">myproject1.settings</span><span class=\"w\"></span>\n<span class=\"na\">project2</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s\">myproject2.settings</span><span class=\"w\"></span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy settings --get BOT_NAME\nProject 1 Bot\n$ export SCRAPY_PROJECT=project2\n$ scrapy settings --get BOT_NAME\nProject 2 Bot\n</pre></div>", "<div class=\"highlight\"><pre><span></span>Scrapy X.Y - no active project\n\nUsage:\n  scrapy &lt;command&gt; [options] [args]\n\nAvailable commands:\n  crawl         Run a spider\n  fetch         Fetch a URL using the Scrapy downloader\n[...]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>Scrapy X.Y - project: myproject\n\nUsage:\n  scrapy &lt;command&gt; [options] [args]\n\n[...]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>scrapy startproject myproject [project_dir]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>cd project_dir\n</pre></div>", "<div class=\"highlight\"><pre><span></span>scrapy genspider mydomain mydomain.com\n</pre></div>", "<div class=\"highlight\"><pre><span></span>scrapy &lt;command&gt; -h\n</pre></div>", "<div class=\"highlight\"><pre><span></span>scrapy -h\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy startproject myproject\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy genspider -l\nAvailable templates:\n  basic\n  crawl\n  csvfeed\n  xmlfeed\n\n$ scrapy genspider example example.com\nCreated spider 'example' using template 'basic'\n\n$ scrapy genspider -t crawl scrapyorg scrapy.org\nCreated spider 'scrapyorg' using template 'crawl'\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy crawl myspider\n[ ... myspider starts crawling ... ]\n\n$ scrapy -o myfile:csv myspider\n[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]\n\n$ scrapy -O myfile:json myspider\n[ ... myspider starts crawling and saves the result in myfile in json format overwriting the original content... ]\n\n$ scrapy -o myfile -t csv myspider\n[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy check -l\nfirst_spider\n  * parse\n  * parse_item\nsecond_spider\n  * parse\n  * parse_item\n\n$ scrapy check\n[FAILED] first_spider:parse_item\n&gt;&gt;&gt; 'RetailPricex' field is missing\n\n[FAILED] first_spider:parse\n&gt;&gt;&gt; Returned 92 requests, expected 0..4\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy list\nspider1\nspider2\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy edit spider1\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy fetch --nolog http://www.example.com/some/page.html\n[ ... html content here ... ]\n\n$ scrapy fetch --nolog --headers http://www.example.com/\n{'Accept-Ranges': ['bytes'],\n 'Age': ['1263   '],\n 'Connection': ['close     '],\n 'Content-Length': ['596'],\n 'Content-Type': ['text/html; charset=UTF-8'],\n 'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],\n 'Etag': ['\"573c1-254-48c9c87349680\"'],\n 'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],\n 'Server': ['Apache/2.2.3 (CentOS)']}\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy view http://www.example.com/some/page.html\n[ ... browser starts ... ]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy shell http://www.example.com/some/page.html\n[ ... scrapy shell starts ... ]\n\n$ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)'\n(200, 'http://www.example.com/')\n\n# shell follows HTTP redirects by default\n$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'\n(200, 'http://example.com/')\n\n# you can disable this with --no-redirect\n# (only for the URL passed as command line argument)\n$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'\n(302, 'http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F')\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy parse http://www.example.com/ -c parse_item\n[ ... scrapy log lines crawling example.com spider ... ]\n\n&gt;&gt;&gt; STATUS DEPTH LEVEL 1 &lt;&lt;&lt;\n# Scraped Items  ------------------------------------------------------------\n[{'name': 'Example item',\n 'category': 'Furniture',\n 'length': '12 cm'}]\n\n# Requests  -----------------------------------------------------------------\n[]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy settings --get BOT_NAME\nscrapybot\n$ scrapy settings --get DOWNLOAD_DELAY\n0\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy runspider myspider.py\n[ ... spider starts crawling ... ]\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">COMMANDS_MODULE</span> <span class=\"o\">=</span> <span class=\"s1\">'mybot.commands'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">setuptools</span> <span class=\"kn\">import</span> <span class=\"n\">setup</span><span class=\"p\">,</span> <span class=\"n\">find_packages</span>\n\n<span class=\"n\">setup</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'scrapy-mymodule'</span><span class=\"p\">,</span>\n  <span class=\"n\">entry_points</span><span class=\"o\">=</span><span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.commands'</span><span class=\"p\">:</span> <span class=\"p\">[</span>\n      <span class=\"s1\">'my_command=my_scrapy_module.commands:MyCommand'</span><span class=\"p\">,</span>\n    <span class=\"p\">],</span>\n  <span class=\"p\">},</span>\n <span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["scrapy.cfg\nmyproject/\n    __init__.py\n    items.py\n    middlewares.py\n    pipelines.py\n    settings.py\n    spiders/\n        __init__.py\n        spider1.py\n        spider2.py\n        ...\n", "[settings]\ndefault = myproject.settings\n", "[settings]\ndefault = myproject1.settings\nproject1 = myproject1.settings\nproject2 = myproject2.settings\n", "$ scrapy settings --get BOT_NAME\nProject 1 Bot\n$ export SCRAPY_PROJECT=project2\n$ scrapy settings --get BOT_NAME\nProject 2 Bot\n", "Scrapy X.Y - no active project\n\nUsage:\n  scrapy <command> [options] [args]\n\nAvailable commands:\n  crawl         Run a spider\n  fetch         Fetch a URL using the Scrapy downloader\n[...]\n", "Scrapy X.Y - project: myproject\n\nUsage:\n  scrapy <command> [options] [args]\n\n[...]\n", "scrapy startproject myproject [project_dir]\n", "cd project_dir\n", "scrapy genspider mydomain mydomain.com\n", "scrapy <command> -h\n", "scrapy -h\n", "$ scrapy startproject myproject\n", "$ scrapy genspider -l\nAvailable templates:\n  basic\n  crawl\n  csvfeed\n  xmlfeed\n\n$ scrapy genspider example example.com\nCreated spider 'example' using template 'basic'\n\n$ scrapy genspider -t crawl scrapyorg scrapy.org\nCreated spider 'scrapyorg' using template 'crawl'\n", "$ scrapy crawl myspider\n[ ... myspider starts crawling ... ]\n\n$ scrapy -o myfile:csv myspider\n[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]\n\n$ scrapy -O myfile:json myspider\n[ ... myspider starts crawling and saves the result in myfile in json format overwriting the original content... ]\n\n$ scrapy -o myfile -t csv myspider\n[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]\n", "$ scrapy check -l\nfirst_spider\n  * parse\n  * parse_item\nsecond_spider\n  * parse\n  * parse_item\n\n$ scrapy check\n[FAILED] first_spider:parse_item\n>>> 'RetailPricex' field is missing\n\n[FAILED] first_spider:parse\n>>> Returned 92 requests, expected 0..4\n", "$ scrapy list\nspider1\nspider2\n", "$ scrapy edit spider1\n", "$ scrapy fetch --nolog http://www.example.com/some/page.html\n[ ... html content here ... ]\n\n$ scrapy fetch --nolog --headers http://www.example.com/\n{'Accept-Ranges': ['bytes'],\n 'Age': ['1263   '],\n 'Connection': ['close     '],\n 'Content-Length': ['596'],\n 'Content-Type': ['text/html; charset=UTF-8'],\n 'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],\n 'Etag': ['\"573c1-254-48c9c87349680\"'],\n 'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],\n 'Server': ['Apache/2.2.3 (CentOS)']}\n", "$ scrapy view http://www.example.com/some/page.html\n[ ... browser starts ... ]\n", "$ scrapy shell http://www.example.com/some/page.html\n[ ... scrapy shell starts ... ]\n\n$ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)'\n(200, 'http://www.example.com/')\n\n# shell follows HTTP redirects by default\n$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http://example.com/ -c '(response.status, response.url)'\n(200, 'http://example.com/')\n\n# you can disable this with --no-redirect\n# (only for the URL passed as command line argument)\n$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http://example.com/ -c '(response.status, response.url)'\n(302, 'http://httpbin.org/redirect-to?url=http://example.com/')\n", "$ scrapy parse http://www.example.com/ -c parse_item\n[ ... scrapy log lines crawling example.com spider ... ]\n\n>>> STATUS DEPTH LEVEL 1 <<<\n# Scraped Items  ------------------------------------------------------------\n[{'name': 'Example item',\n 'category': 'Furniture',\n 'length': '12 cm'}]\n\n# Requests  -----------------------------------------------------------------\n[]\n", "$ scrapy settings --get BOT_NAME\nscrapybot\n$ scrapy settings --get DOWNLOAD_DELAY\n0\n", "$ scrapy runspider myspider.py\n[ ... spider starts crawling ... ]\n", "COMMANDS_MODULE = 'mybot.commands'\n", "from setuptools import setup, find_packages\n\nsetup(name='scrapy-mymodule',\n  entry_points={\n    'scrapy.commands': [\n      'my_command=my_scrapy_module.commands:MyCommand',\n    ],\n  },\n )\n"], "index": 25}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Configuration settings", "header_href": "#configuration-settings", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Default structure of Scrapy projects", "header_href": "#default-structure-of-scrapy-projects", "codes": ["<div class=\"highlight\"><pre><span></span>scrapy.cfg\nmyproject/\n    __init__.py\n    items.py\n    middlewares.py\n    pipelines.py\n    settings.py\n    spiders/\n        __init__.py\n        spider1.py\n        spider2.py\n        ...\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">[settings]</span><span class=\"w\"></span>\n<span class=\"na\">default</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s\">myproject.settings</span><span class=\"w\"></span>\n</pre></div>"], "codes_text": ["scrapy.cfg\nmyproject/\n    __init__.py\n    items.py\n    middlewares.py\n    pipelines.py\n    settings.py\n    spiders/\n        __init__.py\n        spider1.py\n        spider2.py\n        ...\n", "[settings]\ndefault = myproject.settings\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Sharing the root directory between projects", "header_href": "#sharing-the-root-directory-between-projects", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">[settings]</span><span class=\"w\"></span>\n<span class=\"na\">default</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s\">myproject1.settings</span><span class=\"w\"></span>\n<span class=\"na\">project1</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s\">myproject1.settings</span><span class=\"w\"></span>\n<span class=\"na\">project2</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"s\">myproject2.settings</span><span class=\"w\"></span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy settings --get BOT_NAME\nProject 1 Bot\n$ export SCRAPY_PROJECT=project2\n$ scrapy settings --get BOT_NAME\nProject 2 Bot\n</pre></div>"], "codes_text": ["[settings]\ndefault = myproject1.settings\nproject1 = myproject1.settings\nproject2 = myproject2.settings\n", "$ scrapy settings --get BOT_NAME\nProject 1 Bot\n$ export SCRAPY_PROJECT=project2\n$ scrapy settings --get BOT_NAME\nProject 2 Bot\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Using the scrapy tool", "header_href": "#using-the-scrapy-tool", "codes": ["<div class=\"highlight\"><pre><span></span>Scrapy X.Y - no active project\n\nUsage:\n  scrapy &lt;command&gt; [options] [args]\n\nAvailable commands:\n  crawl         Run a spider\n  fetch         Fetch a URL using the Scrapy downloader\n[...]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>Scrapy X.Y - project: myproject\n\nUsage:\n  scrapy &lt;command&gt; [options] [args]\n\n[...]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>scrapy startproject myproject [project_dir]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>cd project_dir\n</pre></div>", "<div class=\"highlight\"><pre><span></span>scrapy genspider mydomain mydomain.com\n</pre></div>"], "codes_text": ["Scrapy X.Y - no active project\n\nUsage:\n  scrapy <command> [options] [args]\n\nAvailable commands:\n  crawl         Run a spider\n  fetch         Fetch a URL using the Scrapy downloader\n[...]\n", "Scrapy X.Y - project: myproject\n\nUsage:\n  scrapy <command> [options] [args]\n\n[...]\n", "scrapy startproject myproject [project_dir]\n", "cd project_dir\n", "scrapy genspider mydomain mydomain.com\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Creating projects", "header_href": "#creating-projects", "codes": ["<div class=\"highlight\"><pre><span></span>scrapy startproject myproject [project_dir]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>cd project_dir\n</pre></div>"], "codes_text": ["scrapy startproject myproject [project_dir]\n", "cd project_dir\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Controlling projects", "header_href": "#controlling-projects", "codes": ["<div class=\"highlight\"><pre><span></span>scrapy genspider mydomain mydomain.com\n</pre></div>"], "codes_text": ["scrapy genspider mydomain mydomain.com\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Available tool commands", "header_href": "#available-tool-commands", "codes": ["<div class=\"highlight\"><pre><span></span>scrapy &lt;command&gt; -h\n</pre></div>", "<div class=\"highlight\"><pre><span></span>scrapy -h\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy startproject myproject\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy genspider -l\nAvailable templates:\n  basic\n  crawl\n  csvfeed\n  xmlfeed\n\n$ scrapy genspider example example.com\nCreated spider 'example' using template 'basic'\n\n$ scrapy genspider -t crawl scrapyorg scrapy.org\nCreated spider 'scrapyorg' using template 'crawl'\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy crawl myspider\n[ ... myspider starts crawling ... ]\n\n$ scrapy -o myfile:csv myspider\n[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]\n\n$ scrapy -O myfile:json myspider\n[ ... myspider starts crawling and saves the result in myfile in json format overwriting the original content... ]\n\n$ scrapy -o myfile -t csv myspider\n[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy check -l\nfirst_spider\n  * parse\n  * parse_item\nsecond_spider\n  * parse\n  * parse_item\n\n$ scrapy check\n[FAILED] first_spider:parse_item\n&gt;&gt;&gt; 'RetailPricex' field is missing\n\n[FAILED] first_spider:parse\n&gt;&gt;&gt; Returned 92 requests, expected 0..4\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy list\nspider1\nspider2\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy edit spider1\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy fetch --nolog http://www.example.com/some/page.html\n[ ... html content here ... ]\n\n$ scrapy fetch --nolog --headers http://www.example.com/\n{'Accept-Ranges': ['bytes'],\n 'Age': ['1263   '],\n 'Connection': ['close     '],\n 'Content-Length': ['596'],\n 'Content-Type': ['text/html; charset=UTF-8'],\n 'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],\n 'Etag': ['\"573c1-254-48c9c87349680\"'],\n 'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],\n 'Server': ['Apache/2.2.3 (CentOS)']}\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy view http://www.example.com/some/page.html\n[ ... browser starts ... ]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy shell http://www.example.com/some/page.html\n[ ... scrapy shell starts ... ]\n\n$ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)'\n(200, 'http://www.example.com/')\n\n# shell follows HTTP redirects by default\n$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'\n(200, 'http://example.com/')\n\n# you can disable this with --no-redirect\n# (only for the URL passed as command line argument)\n$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'\n(302, 'http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F')\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy parse http://www.example.com/ -c parse_item\n[ ... scrapy log lines crawling example.com spider ... ]\n\n&gt;&gt;&gt; STATUS DEPTH LEVEL 1 &lt;&lt;&lt;\n# Scraped Items  ------------------------------------------------------------\n[{'name': 'Example item',\n 'category': 'Furniture',\n 'length': '12 cm'}]\n\n# Requests  -----------------------------------------------------------------\n[]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy settings --get BOT_NAME\nscrapybot\n$ scrapy settings --get DOWNLOAD_DELAY\n0\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy runspider myspider.py\n[ ... spider starts crawling ... ]\n</pre></div>"], "codes_text": ["scrapy <command> -h\n", "scrapy -h\n", "$ scrapy startproject myproject\n", "$ scrapy genspider -l\nAvailable templates:\n  basic\n  crawl\n  csvfeed\n  xmlfeed\n\n$ scrapy genspider example example.com\nCreated spider 'example' using template 'basic'\n\n$ scrapy genspider -t crawl scrapyorg scrapy.org\nCreated spider 'scrapyorg' using template 'crawl'\n", "$ scrapy crawl myspider\n[ ... myspider starts crawling ... ]\n\n$ scrapy -o myfile:csv myspider\n[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]\n\n$ scrapy -O myfile:json myspider\n[ ... myspider starts crawling and saves the result in myfile in json format overwriting the original content... ]\n\n$ scrapy -o myfile -t csv myspider\n[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]\n", "$ scrapy check -l\nfirst_spider\n  * parse\n  * parse_item\nsecond_spider\n  * parse\n  * parse_item\n\n$ scrapy check\n[FAILED] first_spider:parse_item\n>>> 'RetailPricex' field is missing\n\n[FAILED] first_spider:parse\n>>> Returned 92 requests, expected 0..4\n", "$ scrapy list\nspider1\nspider2\n", "$ scrapy edit spider1\n", "$ scrapy fetch --nolog http://www.example.com/some/page.html\n[ ... html content here ... ]\n\n$ scrapy fetch --nolog --headers http://www.example.com/\n{'Accept-Ranges': ['bytes'],\n 'Age': ['1263   '],\n 'Connection': ['close     '],\n 'Content-Length': ['596'],\n 'Content-Type': ['text/html; charset=UTF-8'],\n 'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],\n 'Etag': ['\"573c1-254-48c9c87349680\"'],\n 'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],\n 'Server': ['Apache/2.2.3 (CentOS)']}\n", "$ scrapy view http://www.example.com/some/page.html\n[ ... browser starts ... ]\n", "$ scrapy shell http://www.example.com/some/page.html\n[ ... scrapy shell starts ... ]\n\n$ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)'\n(200, 'http://www.example.com/')\n\n# shell follows HTTP redirects by default\n$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http://example.com/ -c '(response.status, response.url)'\n(200, 'http://example.com/')\n\n# you can disable this with --no-redirect\n# (only for the URL passed as command line argument)\n$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http://example.com/ -c '(response.status, response.url)'\n(302, 'http://httpbin.org/redirect-to?url=http://example.com/')\n", "$ scrapy parse http://www.example.com/ -c parse_item\n[ ... scrapy log lines crawling example.com spider ... ]\n\n>>> STATUS DEPTH LEVEL 1 <<<\n# Scraped Items  ------------------------------------------------------------\n[{'name': 'Example item',\n 'category': 'Furniture',\n 'length': '12 cm'}]\n\n# Requests  -----------------------------------------------------------------\n[]\n", "$ scrapy settings --get BOT_NAME\nscrapybot\n$ scrapy settings --get DOWNLOAD_DELAY\n0\n", "$ scrapy runspider myspider.py\n[ ... spider starts crawling ... ]\n"], "index": 14}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "startproject", "header_href": "#startproject", "codes": ["<div class=\"highlight\"><pre><span></span>$ scrapy startproject myproject\n</pre></div>"], "codes_text": ["$ scrapy startproject myproject\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "genspider", "header_href": "#genspider", "codes": ["<div class=\"highlight\"><pre><span></span>$ scrapy genspider -l\nAvailable templates:\n  basic\n  crawl\n  csvfeed\n  xmlfeed\n\n$ scrapy genspider example example.com\nCreated spider 'example' using template 'basic'\n\n$ scrapy genspider -t crawl scrapyorg scrapy.org\nCreated spider 'scrapyorg' using template 'crawl'\n</pre></div>"], "codes_text": ["$ scrapy genspider -l\nAvailable templates:\n  basic\n  crawl\n  csvfeed\n  xmlfeed\n\n$ scrapy genspider example example.com\nCreated spider 'example' using template 'basic'\n\n$ scrapy genspider -t crawl scrapyorg scrapy.org\nCreated spider 'scrapyorg' using template 'crawl'\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "crawl", "header_href": "#crawl", "codes": ["<div class=\"highlight\"><pre><span></span>$ scrapy crawl myspider\n[ ... myspider starts crawling ... ]\n\n$ scrapy -o myfile:csv myspider\n[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]\n\n$ scrapy -O myfile:json myspider\n[ ... myspider starts crawling and saves the result in myfile in json format overwriting the original content... ]\n\n$ scrapy -o myfile -t csv myspider\n[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]\n</pre></div>"], "codes_text": ["$ scrapy crawl myspider\n[ ... myspider starts crawling ... ]\n\n$ scrapy -o myfile:csv myspider\n[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]\n\n$ scrapy -O myfile:json myspider\n[ ... myspider starts crawling and saves the result in myfile in json format overwriting the original content... ]\n\n$ scrapy -o myfile -t csv myspider\n[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "check", "header_href": "#check", "codes": ["<div class=\"highlight\"><pre><span></span>$ scrapy check -l\nfirst_spider\n  * parse\n  * parse_item\nsecond_spider\n  * parse\n  * parse_item\n\n$ scrapy check\n[FAILED] first_spider:parse_item\n&gt;&gt;&gt; 'RetailPricex' field is missing\n\n[FAILED] first_spider:parse\n&gt;&gt;&gt; Returned 92 requests, expected 0..4\n</pre></div>"], "codes_text": ["$ scrapy check -l\nfirst_spider\n  * parse\n  * parse_item\nsecond_spider\n  * parse\n  * parse_item\n\n$ scrapy check\n[FAILED] first_spider:parse_item\n>>> 'RetailPricex' field is missing\n\n[FAILED] first_spider:parse\n>>> Returned 92 requests, expected 0..4\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "list", "header_href": "#list", "codes": ["<div class=\"highlight\"><pre><span></span>$ scrapy list\nspider1\nspider2\n</pre></div>"], "codes_text": ["$ scrapy list\nspider1\nspider2\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "edit", "header_href": "#edit", "codes": ["<div class=\"highlight\"><pre><span></span>$ scrapy edit spider1\n</pre></div>"], "codes_text": ["$ scrapy edit spider1\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "fetch", "header_href": "#fetch", "codes": ["<div class=\"highlight\"><pre><span></span>$ scrapy fetch --nolog http://www.example.com/some/page.html\n[ ... html content here ... ]\n\n$ scrapy fetch --nolog --headers http://www.example.com/\n{'Accept-Ranges': ['bytes'],\n 'Age': ['1263   '],\n 'Connection': ['close     '],\n 'Content-Length': ['596'],\n 'Content-Type': ['text/html; charset=UTF-8'],\n 'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],\n 'Etag': ['\"573c1-254-48c9c87349680\"'],\n 'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],\n 'Server': ['Apache/2.2.3 (CentOS)']}\n</pre></div>"], "codes_text": ["$ scrapy fetch --nolog http://www.example.com/some/page.html\n[ ... html content here ... ]\n\n$ scrapy fetch --nolog --headers http://www.example.com/\n{'Accept-Ranges': ['bytes'],\n 'Age': ['1263   '],\n 'Connection': ['close     '],\n 'Content-Length': ['596'],\n 'Content-Type': ['text/html; charset=UTF-8'],\n 'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],\n 'Etag': ['\"573c1-254-48c9c87349680\"'],\n 'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],\n 'Server': ['Apache/2.2.3 (CentOS)']}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "view", "header_href": "#view", "codes": ["<div class=\"highlight\"><pre><span></span>$ scrapy view http://www.example.com/some/page.html\n[ ... browser starts ... ]\n</pre></div>"], "codes_text": ["$ scrapy view http://www.example.com/some/page.html\n[ ... browser starts ... ]\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "shell", "header_href": "#shell", "codes": ["<div class=\"highlight\"><pre><span></span>$ scrapy shell http://www.example.com/some/page.html\n[ ... scrapy shell starts ... ]\n\n$ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)'\n(200, 'http://www.example.com/')\n\n# shell follows HTTP redirects by default\n$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'\n(200, 'http://example.com/')\n\n# you can disable this with --no-redirect\n# (only for the URL passed as command line argument)\n$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'\n(302, 'http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F')\n</pre></div>"], "codes_text": ["$ scrapy shell http://www.example.com/some/page.html\n[ ... scrapy shell starts ... ]\n\n$ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)'\n(200, 'http://www.example.com/')\n\n# shell follows HTTP redirects by default\n$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http://example.com/ -c '(response.status, response.url)'\n(200, 'http://example.com/')\n\n# you can disable this with --no-redirect\n# (only for the URL passed as command line argument)\n$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http://example.com/ -c '(response.status, response.url)'\n(302, 'http://httpbin.org/redirect-to?url=http://example.com/')\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "parse", "header_href": "#parse", "codes": ["<div class=\"highlight\"><pre><span></span>$ scrapy parse http://www.example.com/ -c parse_item\n[ ... scrapy log lines crawling example.com spider ... ]\n\n&gt;&gt;&gt; STATUS DEPTH LEVEL 1 &lt;&lt;&lt;\n# Scraped Items  ------------------------------------------------------------\n[{'name': 'Example item',\n 'category': 'Furniture',\n 'length': '12 cm'}]\n\n# Requests  -----------------------------------------------------------------\n[]\n</pre></div>"], "codes_text": ["$ scrapy parse http://www.example.com/ -c parse_item\n[ ... scrapy log lines crawling example.com spider ... ]\n\n>>> STATUS DEPTH LEVEL 1 <<<\n# Scraped Items  ------------------------------------------------------------\n[{'name': 'Example item',\n 'category': 'Furniture',\n 'length': '12 cm'}]\n\n# Requests  -----------------------------------------------------------------\n[]\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "settings", "header_href": "#settings", "codes": ["<div class=\"highlight\"><pre><span></span>$ scrapy settings --get BOT_NAME\nscrapybot\n$ scrapy settings --get DOWNLOAD_DELAY\n0\n</pre></div>"], "codes_text": ["$ scrapy settings --get BOT_NAME\nscrapybot\n$ scrapy settings --get DOWNLOAD_DELAY\n0\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "runspider", "header_href": "#runspider", "codes": ["<div class=\"highlight\"><pre><span></span>$ scrapy runspider myspider.py\n[ ... spider starts crawling ... ]\n</pre></div>"], "codes_text": ["$ scrapy runspider myspider.py\n[ ... spider starts crawling ... ]\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "version", "header_href": "#version", "codes": [], "codes_text": [], "index": 21}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "bench", "header_href": "#bench", "codes": [], "codes_text": [], "index": 22}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Custom project commands", "header_href": "#custom-project-commands", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">COMMANDS_MODULE</span> <span class=\"o\">=</span> <span class=\"s1\">'mybot.commands'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">setuptools</span> <span class=\"kn\">import</span> <span class=\"n\">setup</span><span class=\"p\">,</span> <span class=\"n\">find_packages</span>\n\n<span class=\"n\">setup</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'scrapy-mymodule'</span><span class=\"p\">,</span>\n  <span class=\"n\">entry_points</span><span class=\"o\">=</span><span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.commands'</span><span class=\"p\">:</span> <span class=\"p\">[</span>\n      <span class=\"s1\">'my_command=my_scrapy_module.commands:MyCommand'</span><span class=\"p\">,</span>\n    <span class=\"p\">],</span>\n  <span class=\"p\">},</span>\n <span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["COMMANDS_MODULE = 'mybot.commands'\n", "from setuptools import setup, find_packages\n\nsetup(name='scrapy-mymodule',\n  entry_points={\n    'scrapy.commands': [\n      'my_command=my_scrapy_module.commands:MyCommand',\n    ],\n  },\n )\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "COMMANDS_MODULE", "header_href": "#commands-module", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">COMMANDS_MODULE</span> <span class=\"o\">=</span> <span class=\"s1\">'mybot.commands'</span>\n</pre></div>"], "codes_text": ["COMMANDS_MODULE = 'mybot.commands'\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/commands.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Register commands via setup.py entry points", "header_href": "#register-commands-via-setup-py-entry-points", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">setuptools</span> <span class=\"kn\">import</span> <span class=\"n\">setup</span><span class=\"p\">,</span> <span class=\"n\">find_packages</span>\n\n<span class=\"n\">setup</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'scrapy-mymodule'</span><span class=\"p\">,</span>\n  <span class=\"n\">entry_points</span><span class=\"o\">=</span><span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.commands'</span><span class=\"p\">:</span> <span class=\"p\">[</span>\n      <span class=\"s1\">'my_command=my_scrapy_module.commands:MyCommand'</span><span class=\"p\">,</span>\n    <span class=\"p\">],</span>\n  <span class=\"p\">},</span>\n <span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["from setuptools import setup, find_packages\n\nsetup(name='scrapy-mymodule',\n  entry_points={\n    'scrapy.commands': [\n      'my_command=my_scrapy_module.commands:MyCommand',\n    ],\n  },\n )\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/spiders.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Spiders", "header_href": "#spiders", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">FormRequest</span><span class=\"p\">(</span><span class=\"s2\">\"http://www.example.com/login\"</span><span class=\"p\">,</span>\n                                   <span class=\"n\">formdata</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'user'</span><span class=\"p\">:</span> <span class=\"s1\">'john'</span><span class=\"p\">,</span> <span class=\"s1\">'pass'</span><span class=\"p\">:</span> <span class=\"s1\">'secret'</span><span class=\"p\">},</span>\n                                   <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logged_in</span><span class=\"p\">)]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">logged_in</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"c1\"># here you would extract links to follow and return Requests for</span>\n        <span class=\"c1\"># each of them, with another callback</span>\n        <span class=\"k\">pass</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'http://www.example.com/1.html'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'http://www.example.com/2.html'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'http://www.example.com/3.html'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'A response from </span><span class=\"si\">%s</span><span class=\"s1\"> just arrived!'</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'http://www.example.com/1.html'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'http://www.example.com/2.html'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'http://www.example.com/3.html'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">h3</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//h3'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">():</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span><span class=\"s2\">\"title\"</span><span class=\"p\">:</span> <span class=\"n\">h3</span><span class=\"p\">}</span>\n\n        <span class=\"k\">for</span> <span class=\"n\">href</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a/@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">():</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">urljoin</span><span class=\"p\">(</span><span class=\"n\">href</span><span class=\"p\">),</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.items</span> <span class=\"kn\">import</span> <span class=\"n\">MyItem</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s1\">'http://www.example.com/1.html'</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n        <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s1\">'http://www.example.com/2.html'</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n        <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s1\">'http://www.example.com/3.html'</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">h3</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//h3'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">():</span>\n            <span class=\"k\">yield</span> <span class=\"n\">MyItem</span><span class=\"p\">(</span><span class=\"n\">title</span><span class=\"o\">=</span><span class=\"n\">h3</span><span class=\"p\">)</span>\n\n        <span class=\"k\">for</span> <span class=\"n\">href</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a/@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">():</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">urljoin</span><span class=\"p\">(</span><span class=\"n\">href</span><span class=\"p\">),</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">myspider</span> <span class=\"o\">-</span><span class=\"n\">a</span> <span class=\"n\">category</span><span class=\"o\">=</span><span class=\"n\">electronics</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">category</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">MySpider</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"sa\">f</span><span class=\"s1\">'http://www.example.com/categories/</span><span class=\"si\">{</span><span class=\"n\">category</span><span class=\"si\">}</span><span class=\"s1\">'</span><span class=\"p\">]</span>\n        <span class=\"c1\"># ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'http://www.example.com/categories/</span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">category</span><span class=\"si\">}</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">process</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerProcess</span><span class=\"p\">()</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider</span><span class=\"p\">,</span> <span class=\"n\">category</span><span class=\"o\">=</span><span class=\"s2\">\"electronics\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">myspider</span> <span class=\"o\">-</span><span class=\"n\">a</span> <span class=\"n\">http_user</span><span class=\"o\">=</span><span class=\"n\">myuser</span> <span class=\"o\">-</span><span class=\"n\">a</span> <span class=\"n\">http_pass</span><span class=\"o\">=</span><span class=\"n\">mypassword</span> <span class=\"o\">-</span><span class=\"n\">a</span> <span class=\"n\">user_agent</span><span class=\"o\">=</span><span class=\"n\">mybot</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">TestItem</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"nb\">id</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">description</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlSpider</span><span class=\"p\">,</span> <span class=\"n\">Rule</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.linkextractors</span> <span class=\"kn\">import</span> <span class=\"n\">LinkExtractor</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com'</span><span class=\"p\">]</span>\n\n    <span class=\"n\">rules</span> <span class=\"o\">=</span> <span class=\"p\">(</span>\n        <span class=\"c1\"># Extract links matching 'category.php' (but not matching 'subsection.php')</span>\n        <span class=\"c1\"># and follow links from them (since no callback means follow=True by default).</span>\n        <span class=\"n\">Rule</span><span class=\"p\">(</span><span class=\"n\">LinkExtractor</span><span class=\"p\">(</span><span class=\"n\">allow</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'category\\.php'</span><span class=\"p\">,</span> <span class=\"p\">),</span> <span class=\"n\">deny</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'subsection\\.php'</span><span class=\"p\">,</span> <span class=\"p\">))),</span>\n\n        <span class=\"c1\"># Extract links matching 'item.php' and parse them with the spider's method parse_item</span>\n        <span class=\"n\">Rule</span><span class=\"p\">(</span><span class=\"n\">LinkExtractor</span><span class=\"p\">(</span><span class=\"n\">allow</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'item\\.php'</span><span class=\"p\">,</span> <span class=\"p\">)),</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"s1\">'parse_item'</span><span class=\"p\">),</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Hi, this is an item page! </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n        <span class=\"n\">item</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//td[@id=\"item_id\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'ID: (\\d+)'</span><span class=\"p\">)</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//td[@id=\"item_name\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//td[@id=\"item_description\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'link_text'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"p\">[</span><span class=\"s1\">'link_text'</span><span class=\"p\">]</span>\n        <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//td[@id=\"additional_data\"]/@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_additional_page</span><span class=\"p\">,</span> <span class=\"n\">cb_kwargs</span><span class=\"o\">=</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"o\">=</span><span class=\"n\">item</span><span class=\"p\">))</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_additional_page</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'additional_data'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[@id=\"additional_data\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">itertag</span> <span class=\"o\">=</span> <span class=\"s1\">'product'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">YourSpider</span><span class=\"p\">(</span><span class=\"n\">XMLFeedSpider</span><span class=\"p\">):</span>\n\n    <span class=\"n\">namespaces</span> <span class=\"o\">=</span> <span class=\"p\">[(</span><span class=\"s1\">'n'</span><span class=\"p\">,</span> <span class=\"s1\">'http://www.sitemaps.org/schemas/sitemap/0.9'</span><span class=\"p\">)]</span>\n    <span class=\"n\">itertag</span> <span class=\"o\">=</span> <span class=\"s1\">'n:url'</span>\n    <span class=\"c1\"># ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">XMLFeedSpider</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.items</span> <span class=\"kn\">import</span> <span class=\"n\">TestItem</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">XMLFeedSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/feed.xml'</span><span class=\"p\">]</span>\n    <span class=\"n\">iterator</span> <span class=\"o\">=</span> <span class=\"s1\">'iternodes'</span>  <span class=\"c1\"># This is actually unnecessary, since it's the default value</span>\n    <span class=\"n\">itertag</span> <span class=\"o\">=</span> <span class=\"s1\">'item'</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_node</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">node</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Hi, this is a &lt;</span><span class=\"si\">%s</span><span class=\"s1\">&gt; node!: </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">itertag</span><span class=\"p\">,</span> <span class=\"s1\">''</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()))</span>\n\n        <span class=\"n\">item</span> <span class=\"o\">=</span> <span class=\"n\">TestItem</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'@id'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'description'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">CSVFeedSpider</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.items</span> <span class=\"kn\">import</span> <span class=\"n\">TestItem</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CSVFeedSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/feed.csv'</span><span class=\"p\">]</span>\n    <span class=\"n\">delimiter</span> <span class=\"o\">=</span> <span class=\"s1\">';'</span>\n    <span class=\"n\">quotechar</span> <span class=\"o\">=</span> <span class=\"s2\">\"'\"</span>\n    <span class=\"n\">headers</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">,</span> <span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'description'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_row</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">row</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Hi, this is a row!: </span><span class=\"si\">%r</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">row</span><span class=\"p\">)</span>\n\n        <span class=\"n\">item</span> <span class=\"o\">=</span> <span class=\"n\">TestItem</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sitemap_rules</span> <span class=\"o\">=</span> <span class=\"p\">[(</span><span class=\"s1\">'/product/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_product'</span><span class=\"p\">)]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">url</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">loc</span><span class=\"o\">&gt;</span><span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/&lt;/</span><span class=\"n\">loc</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">xhtml</span><span class=\"p\">:</span><span class=\"n\">link</span> <span class=\"n\">rel</span><span class=\"o\">=</span><span class=\"s2\">\"alternate\"</span> <span class=\"n\">hreflang</span><span class=\"o\">=</span><span class=\"s2\">\"de\"</span> <span class=\"n\">href</span><span class=\"o\">=</span><span class=\"s2\">\"http://example.com/de\"</span><span class=\"o\">/&gt;</span>\n<span class=\"o\">&lt;/</span><span class=\"n\">url</span><span class=\"o\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">url</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">loc</span><span class=\"o\">&gt;</span><span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/&lt;/</span><span class=\"n\">loc</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">lastmod</span><span class=\"o\">&gt;</span><span class=\"mi\">2005</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">&lt;/</span><span class=\"n\">lastmod</span><span class=\"o\">&gt;</span>\n<span class=\"o\">&lt;/</span><span class=\"n\">url</span><span class=\"o\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">datetime</span> <span class=\"kn\">import</span> <span class=\"n\">datetime</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">FilteredSitemapSpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'filtered_sitemap_spider'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://example.com/sitemap.xml'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">sitemap_filter</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">entries</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">entry</span> <span class=\"ow\">in</span> <span class=\"n\">entries</span><span class=\"p\">:</span>\n            <span class=\"n\">date_time</span> <span class=\"o\">=</span> <span class=\"n\">datetime</span><span class=\"o\">.</span><span class=\"n\">strptime</span><span class=\"p\">(</span><span class=\"n\">entry</span><span class=\"p\">[</span><span class=\"s1\">'lastmod'</span><span class=\"p\">],</span> <span class=\"s1\">'%Y-%m-</span><span class=\"si\">%d</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n            <span class=\"k\">if</span> <span class=\"n\">date_time</span><span class=\"o\">.</span><span class=\"n\">year</span> <span class=\"o\">&gt;=</span> <span class=\"mi\">2005</span><span class=\"p\">:</span>\n                <span class=\"k\">yield</span> <span class=\"n\">entry</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/sitemap.xml'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape item here ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/sitemap.xml'</span><span class=\"p\">]</span>\n    <span class=\"n\">sitemap_rules</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"p\">(</span><span class=\"s1\">'/product/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_product'</span><span class=\"p\">),</span>\n        <span class=\"p\">(</span><span class=\"s1\">'/category/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_category'</span><span class=\"p\">),</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_product</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape product ...</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_category</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape category ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/robots.txt'</span><span class=\"p\">]</span>\n    <span class=\"n\">sitemap_rules</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"p\">(</span><span class=\"s1\">'/shop/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_shop'</span><span class=\"p\">),</span>\n    <span class=\"p\">]</span>\n    <span class=\"n\">sitemap_follow</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'/sitemap_shops'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_shop</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape shop here ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/robots.txt'</span><span class=\"p\">]</span>\n    <span class=\"n\">sitemap_rules</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"p\">(</span><span class=\"s1\">'/shop/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_shop'</span><span class=\"p\">),</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"n\">other_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/about'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"n\">requests</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">MySpider</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">start_requests</span><span class=\"p\">())</span>\n        <span class=\"n\">requests</span> <span class=\"o\">+=</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_other</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">other_urls</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">requests</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_shop</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape shop here ...</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_other</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape other here ...</span>\n</pre></div>"], "codes_text": ["class MySpider(scrapy.Spider):\n    name = 'myspider'\n\n    def start_requests(self):\n        return [scrapy.FormRequest(\"http://www.example.com/login\",\n                                   formdata={'user': 'john', 'pass': 'secret'},\n                                   callback=self.logged_in)]\n\n    def logged_in(self, response):\n        # here you would extract links to follow and return Requests for\n        # each of them, with another callback\n        pass\n", "import scrapy\n\n\nclass MySpider(scrapy.Spider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n    start_urls = [\n        'http://www.example.com/1.html',\n        'http://www.example.com/2.html',\n        'http://www.example.com/3.html',\n    ]\n\n    def parse(self, response):\n        self.logger.info('A response from %s just arrived!', response.url)\n", "import scrapy\n\nclass MySpider(scrapy.Spider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n    start_urls = [\n        'http://www.example.com/1.html',\n        'http://www.example.com/2.html',\n        'http://www.example.com/3.html',\n    ]\n\n    def parse(self, response):\n        for h3 in response.xpath('//h3').getall():\n            yield {\"title\": h3}\n\n        for href in response.xpath('//a/@href').getall():\n            yield scrapy.Request(response.urljoin(href), self.parse)\n", "import scrapy\nfrom myproject.items import MyItem\n\nclass MySpider(scrapy.Spider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n\n    def start_requests(self):\n        yield scrapy.Request('http://www.example.com/1.html', self.parse)\n        yield scrapy.Request('http://www.example.com/2.html', self.parse)\n        yield scrapy.Request('http://www.example.com/3.html', self.parse)\n\n    def parse(self, response):\n        for h3 in response.xpath('//h3').getall():\n            yield MyItem(title=h3)\n\n        for href in response.xpath('//a/@href').getall():\n            yield scrapy.Request(response.urljoin(href), self.parse)\n", "scrapy crawl myspider -a category=electronics\n", "import scrapy\n\nclass MySpider(scrapy.Spider):\n    name = 'myspider'\n\n    def __init__(self, category=None, *args, **kwargs):\n        super(MySpider, self).__init__(*args, **kwargs)\n        self.start_urls = [f'http://www.example.com/categories/{category}']\n        # ...\n", "import scrapy\n\nclass MySpider(scrapy.Spider):\n    name = 'myspider'\n\n    def start_requests(self):\n        yield scrapy.Request(f'http://www.example.com/categories/{self.category}')\n", "process = CrawlerProcess()\nprocess.crawl(MySpider, category=\"electronics\")\n", "scrapy crawl myspider -a http_user=myuser -a http_pass=mypassword -a user_agent=mybot\n", "import scrapy\n\nclass TestItem(scrapy.Item):\n    id = scrapy.Field()\n    name = scrapy.Field()\n    description = scrapy.Field()\n", "import scrapy\nfrom scrapy.spiders import CrawlSpider, Rule\nfrom scrapy.linkextractors import LinkExtractor\n\nclass MySpider(CrawlSpider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n    start_urls = ['http://www.example.com']\n\n    rules = (\n        # Extract links matching 'category.php' (but not matching 'subsection.php')\n        # and follow links from them (since no callback means follow=True by default).\n        Rule(LinkExtractor(allow=('category\\.php', ), deny=('subsection\\.php', ))),\n\n        # Extract links matching 'item.php' and parse them with the spider's method parse_item\n        Rule(LinkExtractor(allow=('item\\.php', )), callback='parse_item'),\n    )\n\n    def parse_item(self, response):\n        self.logger.info('Hi, this is an item page! %s', response.url)\n        item = scrapy.Item()\n        item['id'] = response.xpath('//td[@id=\"item_id\"]/text()').re(r'ID: (\\d+)')\n        item['name'] = response.xpath('//td[@id=\"item_name\"]/text()').get()\n        item['description'] = response.xpath('//td[@id=\"item_description\"]/text()').get()\n        item['link_text'] = response.meta['link_text']\n        url = response.xpath('//td[@id=\"additional_data\"]/@href').get()\n        return response.follow(url, self.parse_additional_page, cb_kwargs=dict(item=item))\n\n    def parse_additional_page(self, response, item):\n        item['additional_data'] = response.xpath('//p[@id=\"additional_data\"]/text()').get()\n        return item\n", "itertag = 'product'\n", "class YourSpider(XMLFeedSpider):\n\n    namespaces = [('n', 'http://www.sitemaps.org/schemas/sitemap/0.9')]\n    itertag = 'n:url'\n    # ...\n", "from scrapy.spiders import XMLFeedSpider\nfrom myproject.items import TestItem\n\nclass MySpider(XMLFeedSpider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n    start_urls = ['http://www.example.com/feed.xml']\n    iterator = 'iternodes'  # This is actually unnecessary, since it's the default value\n    itertag = 'item'\n\n    def parse_node(self, response, node):\n        self.logger.info('Hi, this is a <%s> node!: %s', self.itertag, ''.join(node.getall()))\n\n        item = TestItem()\n        item['id'] = node.xpath('@id').get()\n        item['name'] = node.xpath('name').get()\n        item['description'] = node.xpath('description').get()\n        return item\n", "from scrapy.spiders import CSVFeedSpider\nfrom myproject.items import TestItem\n\nclass MySpider(CSVFeedSpider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n    start_urls = ['http://www.example.com/feed.csv']\n    delimiter = ';'\n    quotechar = \"'\"\n    headers = ['id', 'name', 'description']\n\n    def parse_row(self, response, row):\n        self.logger.info('Hi, this is a row!: %r', row)\n\n        item = TestItem()\n        item['id'] = row['id']\n        item['name'] = row['name']\n        item['description'] = row['description']\n        return item\n", "sitemap_rules = [('/product/', 'parse_product')]\n", "<url>\n    <loc>http://example.com/</loc>\n    <xhtml:link rel=\"alternate\" hreflang=\"de\" href=\"http://example.com/de\"/>\n</url>\n", "<url>\n    <loc>http://example.com/</loc>\n    <lastmod>2005-01-01</lastmod>\n</url>\n", "from datetime import datetime\nfrom scrapy.spiders import SitemapSpider\n\nclass FilteredSitemapSpider(SitemapSpider):\n    name = 'filtered_sitemap_spider'\n    allowed_domains = ['example.com']\n    sitemap_urls = ['http://example.com/sitemap.xml']\n\n    def sitemap_filter(self, entries):\n        for entry in entries:\n            date_time = datetime.strptime(entry['lastmod'], '%Y-%m-%d')\n            if date_time.year >= 2005:\n                yield entry\n", "from scrapy.spiders import SitemapSpider\n\nclass MySpider(SitemapSpider):\n    sitemap_urls = ['http://www.example.com/sitemap.xml']\n\n    def parse(self, response):\n        pass # ... scrape item here ...\n", "from scrapy.spiders import SitemapSpider\n\nclass MySpider(SitemapSpider):\n    sitemap_urls = ['http://www.example.com/sitemap.xml']\n    sitemap_rules = [\n        ('/product/', 'parse_product'),\n        ('/category/', 'parse_category'),\n    ]\n\n    def parse_product(self, response):\n        pass # ... scrape product ...\n\n    def parse_category(self, response):\n        pass # ... scrape category ...\n", "from scrapy.spiders import SitemapSpider\n\nclass MySpider(SitemapSpider):\n    sitemap_urls = ['http://www.example.com/robots.txt']\n    sitemap_rules = [\n        ('/shop/', 'parse_shop'),\n    ]\n    sitemap_follow = ['/sitemap_shops']\n\n    def parse_shop(self, response):\n        pass # ... scrape shop here ...\n", "from scrapy.spiders import SitemapSpider\n\nclass MySpider(SitemapSpider):\n    sitemap_urls = ['http://www.example.com/robots.txt']\n    sitemap_rules = [\n        ('/shop/', 'parse_shop'),\n    ]\n\n    other_urls = ['http://www.example.com/about']\n\n    def start_requests(self):\n        requests = list(super(MySpider, self).start_requests())\n        requests += [scrapy.Request(x, self.parse_other) for x in self.other_urls]\n        return requests\n\n    def parse_shop(self, response):\n        pass # ... scrape shop here ...\n\n    def parse_other(self, response):\n        pass # ... scrape other here ...\n"], "index": 23}
{"url": "https://docs.scrapy.org/en/latest/topics/spiders.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "scrapy.Spider", "header_href": "#scrapy-spider", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">FormRequest</span><span class=\"p\">(</span><span class=\"s2\">\"http://www.example.com/login\"</span><span class=\"p\">,</span>\n                                   <span class=\"n\">formdata</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'user'</span><span class=\"p\">:</span> <span class=\"s1\">'john'</span><span class=\"p\">,</span> <span class=\"s1\">'pass'</span><span class=\"p\">:</span> <span class=\"s1\">'secret'</span><span class=\"p\">},</span>\n                                   <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logged_in</span><span class=\"p\">)]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">logged_in</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"c1\"># here you would extract links to follow and return Requests for</span>\n        <span class=\"c1\"># each of them, with another callback</span>\n        <span class=\"k\">pass</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'http://www.example.com/1.html'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'http://www.example.com/2.html'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'http://www.example.com/3.html'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'A response from </span><span class=\"si\">%s</span><span class=\"s1\"> just arrived!'</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s1\">'http://www.example.com/1.html'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'http://www.example.com/2.html'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'http://www.example.com/3.html'</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">h3</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//h3'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">():</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span><span class=\"s2\">\"title\"</span><span class=\"p\">:</span> <span class=\"n\">h3</span><span class=\"p\">}</span>\n\n        <span class=\"k\">for</span> <span class=\"n\">href</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a/@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">():</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">urljoin</span><span class=\"p\">(</span><span class=\"n\">href</span><span class=\"p\">),</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.items</span> <span class=\"kn\">import</span> <span class=\"n\">MyItem</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s1\">'http://www.example.com/1.html'</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n        <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s1\">'http://www.example.com/2.html'</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n        <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s1\">'http://www.example.com/3.html'</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">h3</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//h3'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">():</span>\n            <span class=\"k\">yield</span> <span class=\"n\">MyItem</span><span class=\"p\">(</span><span class=\"n\">title</span><span class=\"o\">=</span><span class=\"n\">h3</span><span class=\"p\">)</span>\n\n        <span class=\"k\">for</span> <span class=\"n\">href</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a/@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">():</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">urljoin</span><span class=\"p\">(</span><span class=\"n\">href</span><span class=\"p\">),</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["class MySpider(scrapy.Spider):\n    name = 'myspider'\n\n    def start_requests(self):\n        return [scrapy.FormRequest(\"http://www.example.com/login\",\n                                   formdata={'user': 'john', 'pass': 'secret'},\n                                   callback=self.logged_in)]\n\n    def logged_in(self, response):\n        # here you would extract links to follow and return Requests for\n        # each of them, with another callback\n        pass\n", "import scrapy\n\n\nclass MySpider(scrapy.Spider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n    start_urls = [\n        'http://www.example.com/1.html',\n        'http://www.example.com/2.html',\n        'http://www.example.com/3.html',\n    ]\n\n    def parse(self, response):\n        self.logger.info('A response from %s just arrived!', response.url)\n", "import scrapy\n\nclass MySpider(scrapy.Spider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n    start_urls = [\n        'http://www.example.com/1.html',\n        'http://www.example.com/2.html',\n        'http://www.example.com/3.html',\n    ]\n\n    def parse(self, response):\n        for h3 in response.xpath('//h3').getall():\n            yield {\"title\": h3}\n\n        for href in response.xpath('//a/@href').getall():\n            yield scrapy.Request(response.urljoin(href), self.parse)\n", "import scrapy\nfrom myproject.items import MyItem\n\nclass MySpider(scrapy.Spider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n\n    def start_requests(self):\n        yield scrapy.Request('http://www.example.com/1.html', self.parse)\n        yield scrapy.Request('http://www.example.com/2.html', self.parse)\n        yield scrapy.Request('http://www.example.com/3.html', self.parse)\n\n    def parse(self, response):\n        for h3 in response.xpath('//h3').getall():\n            yield MyItem(title=h3)\n\n        for href in response.xpath('//a/@href').getall():\n            yield scrapy.Request(response.urljoin(href), self.parse)\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/spiders.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Spider arguments", "header_href": "#spider-arguments", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">myspider</span> <span class=\"o\">-</span><span class=\"n\">a</span> <span class=\"n\">category</span><span class=\"o\">=</span><span class=\"n\">electronics</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">category</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">MySpider</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"sa\">f</span><span class=\"s1\">'http://www.example.com/categories/</span><span class=\"si\">{</span><span class=\"n\">category</span><span class=\"si\">}</span><span class=\"s1\">'</span><span class=\"p\">]</span>\n        <span class=\"c1\"># ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'http://www.example.com/categories/</span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">category</span><span class=\"si\">}</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">process</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerProcess</span><span class=\"p\">()</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider</span><span class=\"p\">,</span> <span class=\"n\">category</span><span class=\"o\">=</span><span class=\"s2\">\"electronics\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">myspider</span> <span class=\"o\">-</span><span class=\"n\">a</span> <span class=\"n\">http_user</span><span class=\"o\">=</span><span class=\"n\">myuser</span> <span class=\"o\">-</span><span class=\"n\">a</span> <span class=\"n\">http_pass</span><span class=\"o\">=</span><span class=\"n\">mypassword</span> <span class=\"o\">-</span><span class=\"n\">a</span> <span class=\"n\">user_agent</span><span class=\"o\">=</span><span class=\"n\">mybot</span>\n</pre></div>"], "codes_text": ["scrapy crawl myspider -a category=electronics\n", "import scrapy\n\nclass MySpider(scrapy.Spider):\n    name = 'myspider'\n\n    def __init__(self, category=None, *args, **kwargs):\n        super(MySpider, self).__init__(*args, **kwargs)\n        self.start_urls = [f'http://www.example.com/categories/{category}']\n        # ...\n", "import scrapy\n\nclass MySpider(scrapy.Spider):\n    name = 'myspider'\n\n    def start_requests(self):\n        yield scrapy.Request(f'http://www.example.com/categories/{self.category}')\n", "process = CrawlerProcess()\nprocess.crawl(MySpider, category=\"electronics\")\n", "scrapy crawl myspider -a http_user=myuser -a http_pass=mypassword -a user_agent=mybot\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/spiders.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Generic Spiders", "header_href": "#generic-spiders", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">TestItem</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"nb\">id</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">description</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlSpider</span><span class=\"p\">,</span> <span class=\"n\">Rule</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.linkextractors</span> <span class=\"kn\">import</span> <span class=\"n\">LinkExtractor</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com'</span><span class=\"p\">]</span>\n\n    <span class=\"n\">rules</span> <span class=\"o\">=</span> <span class=\"p\">(</span>\n        <span class=\"c1\"># Extract links matching 'category.php' (but not matching 'subsection.php')</span>\n        <span class=\"c1\"># and follow links from them (since no callback means follow=True by default).</span>\n        <span class=\"n\">Rule</span><span class=\"p\">(</span><span class=\"n\">LinkExtractor</span><span class=\"p\">(</span><span class=\"n\">allow</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'category\\.php'</span><span class=\"p\">,</span> <span class=\"p\">),</span> <span class=\"n\">deny</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'subsection\\.php'</span><span class=\"p\">,</span> <span class=\"p\">))),</span>\n\n        <span class=\"c1\"># Extract links matching 'item.php' and parse them with the spider's method parse_item</span>\n        <span class=\"n\">Rule</span><span class=\"p\">(</span><span class=\"n\">LinkExtractor</span><span class=\"p\">(</span><span class=\"n\">allow</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'item\\.php'</span><span class=\"p\">,</span> <span class=\"p\">)),</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"s1\">'parse_item'</span><span class=\"p\">),</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Hi, this is an item page! </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n        <span class=\"n\">item</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//td[@id=\"item_id\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'ID: (\\d+)'</span><span class=\"p\">)</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//td[@id=\"item_name\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//td[@id=\"item_description\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'link_text'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"p\">[</span><span class=\"s1\">'link_text'</span><span class=\"p\">]</span>\n        <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//td[@id=\"additional_data\"]/@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_additional_page</span><span class=\"p\">,</span> <span class=\"n\">cb_kwargs</span><span class=\"o\">=</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"o\">=</span><span class=\"n\">item</span><span class=\"p\">))</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_additional_page</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'additional_data'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[@id=\"additional_data\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">itertag</span> <span class=\"o\">=</span> <span class=\"s1\">'product'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">YourSpider</span><span class=\"p\">(</span><span class=\"n\">XMLFeedSpider</span><span class=\"p\">):</span>\n\n    <span class=\"n\">namespaces</span> <span class=\"o\">=</span> <span class=\"p\">[(</span><span class=\"s1\">'n'</span><span class=\"p\">,</span> <span class=\"s1\">'http://www.sitemaps.org/schemas/sitemap/0.9'</span><span class=\"p\">)]</span>\n    <span class=\"n\">itertag</span> <span class=\"o\">=</span> <span class=\"s1\">'n:url'</span>\n    <span class=\"c1\"># ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">XMLFeedSpider</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.items</span> <span class=\"kn\">import</span> <span class=\"n\">TestItem</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">XMLFeedSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/feed.xml'</span><span class=\"p\">]</span>\n    <span class=\"n\">iterator</span> <span class=\"o\">=</span> <span class=\"s1\">'iternodes'</span>  <span class=\"c1\"># This is actually unnecessary, since it's the default value</span>\n    <span class=\"n\">itertag</span> <span class=\"o\">=</span> <span class=\"s1\">'item'</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_node</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">node</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Hi, this is a &lt;</span><span class=\"si\">%s</span><span class=\"s1\">&gt; node!: </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">itertag</span><span class=\"p\">,</span> <span class=\"s1\">''</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()))</span>\n\n        <span class=\"n\">item</span> <span class=\"o\">=</span> <span class=\"n\">TestItem</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'@id'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'description'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">CSVFeedSpider</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.items</span> <span class=\"kn\">import</span> <span class=\"n\">TestItem</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CSVFeedSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/feed.csv'</span><span class=\"p\">]</span>\n    <span class=\"n\">delimiter</span> <span class=\"o\">=</span> <span class=\"s1\">';'</span>\n    <span class=\"n\">quotechar</span> <span class=\"o\">=</span> <span class=\"s2\">\"'\"</span>\n    <span class=\"n\">headers</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">,</span> <span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'description'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_row</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">row</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Hi, this is a row!: </span><span class=\"si\">%r</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">row</span><span class=\"p\">)</span>\n\n        <span class=\"n\">item</span> <span class=\"o\">=</span> <span class=\"n\">TestItem</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sitemap_rules</span> <span class=\"o\">=</span> <span class=\"p\">[(</span><span class=\"s1\">'/product/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_product'</span><span class=\"p\">)]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">url</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">loc</span><span class=\"o\">&gt;</span><span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/&lt;/</span><span class=\"n\">loc</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">xhtml</span><span class=\"p\">:</span><span class=\"n\">link</span> <span class=\"n\">rel</span><span class=\"o\">=</span><span class=\"s2\">\"alternate\"</span> <span class=\"n\">hreflang</span><span class=\"o\">=</span><span class=\"s2\">\"de\"</span> <span class=\"n\">href</span><span class=\"o\">=</span><span class=\"s2\">\"http://example.com/de\"</span><span class=\"o\">/&gt;</span>\n<span class=\"o\">&lt;/</span><span class=\"n\">url</span><span class=\"o\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">url</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">loc</span><span class=\"o\">&gt;</span><span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/&lt;/</span><span class=\"n\">loc</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">lastmod</span><span class=\"o\">&gt;</span><span class=\"mi\">2005</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">&lt;/</span><span class=\"n\">lastmod</span><span class=\"o\">&gt;</span>\n<span class=\"o\">&lt;/</span><span class=\"n\">url</span><span class=\"o\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">datetime</span> <span class=\"kn\">import</span> <span class=\"n\">datetime</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">FilteredSitemapSpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'filtered_sitemap_spider'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://example.com/sitemap.xml'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">sitemap_filter</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">entries</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">entry</span> <span class=\"ow\">in</span> <span class=\"n\">entries</span><span class=\"p\">:</span>\n            <span class=\"n\">date_time</span> <span class=\"o\">=</span> <span class=\"n\">datetime</span><span class=\"o\">.</span><span class=\"n\">strptime</span><span class=\"p\">(</span><span class=\"n\">entry</span><span class=\"p\">[</span><span class=\"s1\">'lastmod'</span><span class=\"p\">],</span> <span class=\"s1\">'%Y-%m-</span><span class=\"si\">%d</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n            <span class=\"k\">if</span> <span class=\"n\">date_time</span><span class=\"o\">.</span><span class=\"n\">year</span> <span class=\"o\">&gt;=</span> <span class=\"mi\">2005</span><span class=\"p\">:</span>\n                <span class=\"k\">yield</span> <span class=\"n\">entry</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/sitemap.xml'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape item here ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/sitemap.xml'</span><span class=\"p\">]</span>\n    <span class=\"n\">sitemap_rules</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"p\">(</span><span class=\"s1\">'/product/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_product'</span><span class=\"p\">),</span>\n        <span class=\"p\">(</span><span class=\"s1\">'/category/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_category'</span><span class=\"p\">),</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_product</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape product ...</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_category</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape category ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/robots.txt'</span><span class=\"p\">]</span>\n    <span class=\"n\">sitemap_rules</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"p\">(</span><span class=\"s1\">'/shop/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_shop'</span><span class=\"p\">),</span>\n    <span class=\"p\">]</span>\n    <span class=\"n\">sitemap_follow</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'/sitemap_shops'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_shop</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape shop here ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/robots.txt'</span><span class=\"p\">]</span>\n    <span class=\"n\">sitemap_rules</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"p\">(</span><span class=\"s1\">'/shop/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_shop'</span><span class=\"p\">),</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"n\">other_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/about'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"n\">requests</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">MySpider</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">start_requests</span><span class=\"p\">())</span>\n        <span class=\"n\">requests</span> <span class=\"o\">+=</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_other</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">other_urls</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">requests</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_shop</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape shop here ...</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_other</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape other here ...</span>\n</pre></div>"], "codes_text": ["import scrapy\n\nclass TestItem(scrapy.Item):\n    id = scrapy.Field()\n    name = scrapy.Field()\n    description = scrapy.Field()\n", "import scrapy\nfrom scrapy.spiders import CrawlSpider, Rule\nfrom scrapy.linkextractors import LinkExtractor\n\nclass MySpider(CrawlSpider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n    start_urls = ['http://www.example.com']\n\n    rules = (\n        # Extract links matching 'category.php' (but not matching 'subsection.php')\n        # and follow links from them (since no callback means follow=True by default).\n        Rule(LinkExtractor(allow=('category\\.php', ), deny=('subsection\\.php', ))),\n\n        # Extract links matching 'item.php' and parse them with the spider's method parse_item\n        Rule(LinkExtractor(allow=('item\\.php', )), callback='parse_item'),\n    )\n\n    def parse_item(self, response):\n        self.logger.info('Hi, this is an item page! %s', response.url)\n        item = scrapy.Item()\n        item['id'] = response.xpath('//td[@id=\"item_id\"]/text()').re(r'ID: (\\d+)')\n        item['name'] = response.xpath('//td[@id=\"item_name\"]/text()').get()\n        item['description'] = response.xpath('//td[@id=\"item_description\"]/text()').get()\n        item['link_text'] = response.meta['link_text']\n        url = response.xpath('//td[@id=\"additional_data\"]/@href').get()\n        return response.follow(url, self.parse_additional_page, cb_kwargs=dict(item=item))\n\n    def parse_additional_page(self, response, item):\n        item['additional_data'] = response.xpath('//p[@id=\"additional_data\"]/text()').get()\n        return item\n", "itertag = 'product'\n", "class YourSpider(XMLFeedSpider):\n\n    namespaces = [('n', 'http://www.sitemaps.org/schemas/sitemap/0.9')]\n    itertag = 'n:url'\n    # ...\n", "from scrapy.spiders import XMLFeedSpider\nfrom myproject.items import TestItem\n\nclass MySpider(XMLFeedSpider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n    start_urls = ['http://www.example.com/feed.xml']\n    iterator = 'iternodes'  # This is actually unnecessary, since it's the default value\n    itertag = 'item'\n\n    def parse_node(self, response, node):\n        self.logger.info('Hi, this is a <%s> node!: %s', self.itertag, ''.join(node.getall()))\n\n        item = TestItem()\n        item['id'] = node.xpath('@id').get()\n        item['name'] = node.xpath('name').get()\n        item['description'] = node.xpath('description').get()\n        return item\n", "from scrapy.spiders import CSVFeedSpider\nfrom myproject.items import TestItem\n\nclass MySpider(CSVFeedSpider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n    start_urls = ['http://www.example.com/feed.csv']\n    delimiter = ';'\n    quotechar = \"'\"\n    headers = ['id', 'name', 'description']\n\n    def parse_row(self, response, row):\n        self.logger.info('Hi, this is a row!: %r', row)\n\n        item = TestItem()\n        item['id'] = row['id']\n        item['name'] = row['name']\n        item['description'] = row['description']\n        return item\n", "sitemap_rules = [('/product/', 'parse_product')]\n", "<url>\n    <loc>http://example.com/</loc>\n    <xhtml:link rel=\"alternate\" hreflang=\"de\" href=\"http://example.com/de\"/>\n</url>\n", "<url>\n    <loc>http://example.com/</loc>\n    <lastmod>2005-01-01</lastmod>\n</url>\n", "from datetime import datetime\nfrom scrapy.spiders import SitemapSpider\n\nclass FilteredSitemapSpider(SitemapSpider):\n    name = 'filtered_sitemap_spider'\n    allowed_domains = ['example.com']\n    sitemap_urls = ['http://example.com/sitemap.xml']\n\n    def sitemap_filter(self, entries):\n        for entry in entries:\n            date_time = datetime.strptime(entry['lastmod'], '%Y-%m-%d')\n            if date_time.year >= 2005:\n                yield entry\n", "from scrapy.spiders import SitemapSpider\n\nclass MySpider(SitemapSpider):\n    sitemap_urls = ['http://www.example.com/sitemap.xml']\n\n    def parse(self, response):\n        pass # ... scrape item here ...\n", "from scrapy.spiders import SitemapSpider\n\nclass MySpider(SitemapSpider):\n    sitemap_urls = ['http://www.example.com/sitemap.xml']\n    sitemap_rules = [\n        ('/product/', 'parse_product'),\n        ('/category/', 'parse_category'),\n    ]\n\n    def parse_product(self, response):\n        pass # ... scrape product ...\n\n    def parse_category(self, response):\n        pass # ... scrape category ...\n", "from scrapy.spiders import SitemapSpider\n\nclass MySpider(SitemapSpider):\n    sitemap_urls = ['http://www.example.com/robots.txt']\n    sitemap_rules = [\n        ('/shop/', 'parse_shop'),\n    ]\n    sitemap_follow = ['/sitemap_shops']\n\n    def parse_shop(self, response):\n        pass # ... scrape shop here ...\n", "from scrapy.spiders import SitemapSpider\n\nclass MySpider(SitemapSpider):\n    sitemap_urls = ['http://www.example.com/robots.txt']\n    sitemap_rules = [\n        ('/shop/', 'parse_shop'),\n    ]\n\n    other_urls = ['http://www.example.com/about']\n\n    def start_requests(self):\n        requests = list(super(MySpider, self).start_requests())\n        requests += [scrapy.Request(x, self.parse_other) for x in self.other_urls]\n        return requests\n\n    def parse_shop(self, response):\n        pass # ... scrape shop here ...\n\n    def parse_other(self, response):\n        pass # ... scrape other here ...\n"], "index": 14}
{"url": "https://docs.scrapy.org/en/latest/topics/spiders.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "CrawlSpider", "header_href": "#crawlspider", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlSpider</span><span class=\"p\">,</span> <span class=\"n\">Rule</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.linkextractors</span> <span class=\"kn\">import</span> <span class=\"n\">LinkExtractor</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com'</span><span class=\"p\">]</span>\n\n    <span class=\"n\">rules</span> <span class=\"o\">=</span> <span class=\"p\">(</span>\n        <span class=\"c1\"># Extract links matching 'category.php' (but not matching 'subsection.php')</span>\n        <span class=\"c1\"># and follow links from them (since no callback means follow=True by default).</span>\n        <span class=\"n\">Rule</span><span class=\"p\">(</span><span class=\"n\">LinkExtractor</span><span class=\"p\">(</span><span class=\"n\">allow</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'category\\.php'</span><span class=\"p\">,</span> <span class=\"p\">),</span> <span class=\"n\">deny</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'subsection\\.php'</span><span class=\"p\">,</span> <span class=\"p\">))),</span>\n\n        <span class=\"c1\"># Extract links matching 'item.php' and parse them with the spider's method parse_item</span>\n        <span class=\"n\">Rule</span><span class=\"p\">(</span><span class=\"n\">LinkExtractor</span><span class=\"p\">(</span><span class=\"n\">allow</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'item\\.php'</span><span class=\"p\">,</span> <span class=\"p\">)),</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"s1\">'parse_item'</span><span class=\"p\">),</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Hi, this is an item page! </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n        <span class=\"n\">item</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//td[@id=\"item_id\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'ID: (\\d+)'</span><span class=\"p\">)</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//td[@id=\"item_name\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//td[@id=\"item_description\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'link_text'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"p\">[</span><span class=\"s1\">'link_text'</span><span class=\"p\">]</span>\n        <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//td[@id=\"additional_data\"]/@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_additional_page</span><span class=\"p\">,</span> <span class=\"n\">cb_kwargs</span><span class=\"o\">=</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"o\">=</span><span class=\"n\">item</span><span class=\"p\">))</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_additional_page</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'additional_data'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[@id=\"additional_data\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>"], "codes_text": ["import scrapy\nfrom scrapy.spiders import CrawlSpider, Rule\nfrom scrapy.linkextractors import LinkExtractor\n\nclass MySpider(CrawlSpider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n    start_urls = ['http://www.example.com']\n\n    rules = (\n        # Extract links matching 'category.php' (but not matching 'subsection.php')\n        # and follow links from them (since no callback means follow=True by default).\n        Rule(LinkExtractor(allow=('category\\.php', ), deny=('subsection\\.php', ))),\n\n        # Extract links matching 'item.php' and parse them with the spider's method parse_item\n        Rule(LinkExtractor(allow=('item\\.php', )), callback='parse_item'),\n    )\n\n    def parse_item(self, response):\n        self.logger.info('Hi, this is an item page! %s', response.url)\n        item = scrapy.Item()\n        item['id'] = response.xpath('//td[@id=\"item_id\"]/text()').re(r'ID: (\\d+)')\n        item['name'] = response.xpath('//td[@id=\"item_name\"]/text()').get()\n        item['description'] = response.xpath('//td[@id=\"item_description\"]/text()').get()\n        item['link_text'] = response.meta['link_text']\n        url = response.xpath('//td[@id=\"additional_data\"]/@href').get()\n        return response.follow(url, self.parse_additional_page, cb_kwargs=dict(item=item))\n\n    def parse_additional_page(self, response, item):\n        item['additional_data'] = response.xpath('//p[@id=\"additional_data\"]/text()').get()\n        return item\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/spiders.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Crawling rules", "header_href": "#crawling-rules", "codes": [], "codes_text": [], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/spiders.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "CrawlSpider example", "header_href": "#crawlspider-example", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlSpider</span><span class=\"p\">,</span> <span class=\"n\">Rule</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.linkextractors</span> <span class=\"kn\">import</span> <span class=\"n\">LinkExtractor</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com'</span><span class=\"p\">]</span>\n\n    <span class=\"n\">rules</span> <span class=\"o\">=</span> <span class=\"p\">(</span>\n        <span class=\"c1\"># Extract links matching 'category.php' (but not matching 'subsection.php')</span>\n        <span class=\"c1\"># and follow links from them (since no callback means follow=True by default).</span>\n        <span class=\"n\">Rule</span><span class=\"p\">(</span><span class=\"n\">LinkExtractor</span><span class=\"p\">(</span><span class=\"n\">allow</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'category\\.php'</span><span class=\"p\">,</span> <span class=\"p\">),</span> <span class=\"n\">deny</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'subsection\\.php'</span><span class=\"p\">,</span> <span class=\"p\">))),</span>\n\n        <span class=\"c1\"># Extract links matching 'item.php' and parse them with the spider's method parse_item</span>\n        <span class=\"n\">Rule</span><span class=\"p\">(</span><span class=\"n\">LinkExtractor</span><span class=\"p\">(</span><span class=\"n\">allow</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'item\\.php'</span><span class=\"p\">,</span> <span class=\"p\">)),</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"s1\">'parse_item'</span><span class=\"p\">),</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Hi, this is an item page! </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n        <span class=\"n\">item</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//td[@id=\"item_id\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'ID: (\\d+)'</span><span class=\"p\">)</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//td[@id=\"item_name\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//td[@id=\"item_description\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'link_text'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"p\">[</span><span class=\"s1\">'link_text'</span><span class=\"p\">]</span>\n        <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//td[@id=\"additional_data\"]/@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_additional_page</span><span class=\"p\">,</span> <span class=\"n\">cb_kwargs</span><span class=\"o\">=</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"o\">=</span><span class=\"n\">item</span><span class=\"p\">))</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_additional_page</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'additional_data'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[@id=\"additional_data\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>"], "codes_text": ["import scrapy\nfrom scrapy.spiders import CrawlSpider, Rule\nfrom scrapy.linkextractors import LinkExtractor\n\nclass MySpider(CrawlSpider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n    start_urls = ['http://www.example.com']\n\n    rules = (\n        # Extract links matching 'category.php' (but not matching 'subsection.php')\n        # and follow links from them (since no callback means follow=True by default).\n        Rule(LinkExtractor(allow=('category\\.php', ), deny=('subsection\\.php', ))),\n\n        # Extract links matching 'item.php' and parse them with the spider's method parse_item\n        Rule(LinkExtractor(allow=('item\\.php', )), callback='parse_item'),\n    )\n\n    def parse_item(self, response):\n        self.logger.info('Hi, this is an item page! %s', response.url)\n        item = scrapy.Item()\n        item['id'] = response.xpath('//td[@id=\"item_id\"]/text()').re(r'ID: (\\d+)')\n        item['name'] = response.xpath('//td[@id=\"item_name\"]/text()').get()\n        item['description'] = response.xpath('//td[@id=\"item_description\"]/text()').get()\n        item['link_text'] = response.meta['link_text']\n        url = response.xpath('//td[@id=\"additional_data\"]/@href').get()\n        return response.follow(url, self.parse_additional_page, cb_kwargs=dict(item=item))\n\n    def parse_additional_page(self, response, item):\n        item['additional_data'] = response.xpath('//p[@id=\"additional_data\"]/text()').get()\n        return item\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/spiders.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "XMLFeedSpider", "header_href": "#xmlfeedspider", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">itertag</span> <span class=\"o\">=</span> <span class=\"s1\">'product'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">YourSpider</span><span class=\"p\">(</span><span class=\"n\">XMLFeedSpider</span><span class=\"p\">):</span>\n\n    <span class=\"n\">namespaces</span> <span class=\"o\">=</span> <span class=\"p\">[(</span><span class=\"s1\">'n'</span><span class=\"p\">,</span> <span class=\"s1\">'http://www.sitemaps.org/schemas/sitemap/0.9'</span><span class=\"p\">)]</span>\n    <span class=\"n\">itertag</span> <span class=\"o\">=</span> <span class=\"s1\">'n:url'</span>\n    <span class=\"c1\"># ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">XMLFeedSpider</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.items</span> <span class=\"kn\">import</span> <span class=\"n\">TestItem</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">XMLFeedSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/feed.xml'</span><span class=\"p\">]</span>\n    <span class=\"n\">iterator</span> <span class=\"o\">=</span> <span class=\"s1\">'iternodes'</span>  <span class=\"c1\"># This is actually unnecessary, since it's the default value</span>\n    <span class=\"n\">itertag</span> <span class=\"o\">=</span> <span class=\"s1\">'item'</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_node</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">node</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Hi, this is a &lt;</span><span class=\"si\">%s</span><span class=\"s1\">&gt; node!: </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">itertag</span><span class=\"p\">,</span> <span class=\"s1\">''</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()))</span>\n\n        <span class=\"n\">item</span> <span class=\"o\">=</span> <span class=\"n\">TestItem</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'@id'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'description'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>"], "codes_text": ["itertag = 'product'\n", "class YourSpider(XMLFeedSpider):\n\n    namespaces = [('n', 'http://www.sitemaps.org/schemas/sitemap/0.9')]\n    itertag = 'n:url'\n    # ...\n", "from scrapy.spiders import XMLFeedSpider\nfrom myproject.items import TestItem\n\nclass MySpider(XMLFeedSpider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n    start_urls = ['http://www.example.com/feed.xml']\n    iterator = 'iternodes'  # This is actually unnecessary, since it's the default value\n    itertag = 'item'\n\n    def parse_node(self, response, node):\n        self.logger.info('Hi, this is a <%s> node!: %s', self.itertag, ''.join(node.getall()))\n\n        item = TestItem()\n        item['id'] = node.xpath('@id').get()\n        item['name'] = node.xpath('name').get()\n        item['description'] = node.xpath('description').get()\n        return item\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/spiders.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "XMLFeedSpider example", "header_href": "#xmlfeedspider-example", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">XMLFeedSpider</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.items</span> <span class=\"kn\">import</span> <span class=\"n\">TestItem</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">XMLFeedSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/feed.xml'</span><span class=\"p\">]</span>\n    <span class=\"n\">iterator</span> <span class=\"o\">=</span> <span class=\"s1\">'iternodes'</span>  <span class=\"c1\"># This is actually unnecessary, since it's the default value</span>\n    <span class=\"n\">itertag</span> <span class=\"o\">=</span> <span class=\"s1\">'item'</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_node</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">node</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Hi, this is a &lt;</span><span class=\"si\">%s</span><span class=\"s1\">&gt; node!: </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">itertag</span><span class=\"p\">,</span> <span class=\"s1\">''</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()))</span>\n\n        <span class=\"n\">item</span> <span class=\"o\">=</span> <span class=\"n\">TestItem</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'@id'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'description'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>"], "codes_text": ["from scrapy.spiders import XMLFeedSpider\nfrom myproject.items import TestItem\n\nclass MySpider(XMLFeedSpider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n    start_urls = ['http://www.example.com/feed.xml']\n    iterator = 'iternodes'  # This is actually unnecessary, since it's the default value\n    itertag = 'item'\n\n    def parse_node(self, response, node):\n        self.logger.info('Hi, this is a <%s> node!: %s', self.itertag, ''.join(node.getall()))\n\n        item = TestItem()\n        item['id'] = node.xpath('@id').get()\n        item['name'] = node.xpath('name').get()\n        item['description'] = node.xpath('description').get()\n        return item\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/spiders.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "CSVFeedSpider", "header_href": "#csvfeedspider", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">CSVFeedSpider</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.items</span> <span class=\"kn\">import</span> <span class=\"n\">TestItem</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CSVFeedSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/feed.csv'</span><span class=\"p\">]</span>\n    <span class=\"n\">delimiter</span> <span class=\"o\">=</span> <span class=\"s1\">';'</span>\n    <span class=\"n\">quotechar</span> <span class=\"o\">=</span> <span class=\"s2\">\"'\"</span>\n    <span class=\"n\">headers</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">,</span> <span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'description'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_row</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">row</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Hi, this is a row!: </span><span class=\"si\">%r</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">row</span><span class=\"p\">)</span>\n\n        <span class=\"n\">item</span> <span class=\"o\">=</span> <span class=\"n\">TestItem</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>"], "codes_text": ["from scrapy.spiders import CSVFeedSpider\nfrom myproject.items import TestItem\n\nclass MySpider(CSVFeedSpider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n    start_urls = ['http://www.example.com/feed.csv']\n    delimiter = ';'\n    quotechar = \"'\"\n    headers = ['id', 'name', 'description']\n\n    def parse_row(self, response, row):\n        self.logger.info('Hi, this is a row!: %r', row)\n\n        item = TestItem()\n        item['id'] = row['id']\n        item['name'] = row['name']\n        item['description'] = row['description']\n        return item\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/spiders.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "CSVFeedSpider example", "header_href": "#csvfeedspider-example", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">CSVFeedSpider</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.items</span> <span class=\"kn\">import</span> <span class=\"n\">TestItem</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CSVFeedSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/feed.csv'</span><span class=\"p\">]</span>\n    <span class=\"n\">delimiter</span> <span class=\"o\">=</span> <span class=\"s1\">';'</span>\n    <span class=\"n\">quotechar</span> <span class=\"o\">=</span> <span class=\"s2\">\"'\"</span>\n    <span class=\"n\">headers</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">,</span> <span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'description'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_row</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">row</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Hi, this is a row!: </span><span class=\"si\">%r</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">row</span><span class=\"p\">)</span>\n\n        <span class=\"n\">item</span> <span class=\"o\">=</span> <span class=\"n\">TestItem</span><span class=\"p\">()</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span>\n        <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>"], "codes_text": ["from scrapy.spiders import CSVFeedSpider\nfrom myproject.items import TestItem\n\nclass MySpider(CSVFeedSpider):\n    name = 'example.com'\n    allowed_domains = ['example.com']\n    start_urls = ['http://www.example.com/feed.csv']\n    delimiter = ';'\n    quotechar = \"'\"\n    headers = ['id', 'name', 'description']\n\n    def parse_row(self, response, row):\n        self.logger.info('Hi, this is a row!: %r', row)\n\n        item = TestItem()\n        item['id'] = row['id']\n        item['name'] = row['name']\n        item['description'] = row['description']\n        return item\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/spiders.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "SitemapSpider", "header_href": "#sitemapspider", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">sitemap_rules</span> <span class=\"o\">=</span> <span class=\"p\">[(</span><span class=\"s1\">'/product/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_product'</span><span class=\"p\">)]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">url</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">loc</span><span class=\"o\">&gt;</span><span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/&lt;/</span><span class=\"n\">loc</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">xhtml</span><span class=\"p\">:</span><span class=\"n\">link</span> <span class=\"n\">rel</span><span class=\"o\">=</span><span class=\"s2\">\"alternate\"</span> <span class=\"n\">hreflang</span><span class=\"o\">=</span><span class=\"s2\">\"de\"</span> <span class=\"n\">href</span><span class=\"o\">=</span><span class=\"s2\">\"http://example.com/de\"</span><span class=\"o\">/&gt;</span>\n<span class=\"o\">&lt;/</span><span class=\"n\">url</span><span class=\"o\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">url</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">loc</span><span class=\"o\">&gt;</span><span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/&lt;/</span><span class=\"n\">loc</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">lastmod</span><span class=\"o\">&gt;</span><span class=\"mi\">2005</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">&lt;/</span><span class=\"n\">lastmod</span><span class=\"o\">&gt;</span>\n<span class=\"o\">&lt;/</span><span class=\"n\">url</span><span class=\"o\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">datetime</span> <span class=\"kn\">import</span> <span class=\"n\">datetime</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">FilteredSitemapSpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'filtered_sitemap_spider'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'example.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://example.com/sitemap.xml'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">sitemap_filter</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">entries</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">entry</span> <span class=\"ow\">in</span> <span class=\"n\">entries</span><span class=\"p\">:</span>\n            <span class=\"n\">date_time</span> <span class=\"o\">=</span> <span class=\"n\">datetime</span><span class=\"o\">.</span><span class=\"n\">strptime</span><span class=\"p\">(</span><span class=\"n\">entry</span><span class=\"p\">[</span><span class=\"s1\">'lastmod'</span><span class=\"p\">],</span> <span class=\"s1\">'%Y-%m-</span><span class=\"si\">%d</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n            <span class=\"k\">if</span> <span class=\"n\">date_time</span><span class=\"o\">.</span><span class=\"n\">year</span> <span class=\"o\">&gt;=</span> <span class=\"mi\">2005</span><span class=\"p\">:</span>\n                <span class=\"k\">yield</span> <span class=\"n\">entry</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/sitemap.xml'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape item here ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/sitemap.xml'</span><span class=\"p\">]</span>\n    <span class=\"n\">sitemap_rules</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"p\">(</span><span class=\"s1\">'/product/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_product'</span><span class=\"p\">),</span>\n        <span class=\"p\">(</span><span class=\"s1\">'/category/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_category'</span><span class=\"p\">),</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_product</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape product ...</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_category</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape category ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/robots.txt'</span><span class=\"p\">]</span>\n    <span class=\"n\">sitemap_rules</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"p\">(</span><span class=\"s1\">'/shop/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_shop'</span><span class=\"p\">),</span>\n    <span class=\"p\">]</span>\n    <span class=\"n\">sitemap_follow</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'/sitemap_shops'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_shop</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape shop here ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/robots.txt'</span><span class=\"p\">]</span>\n    <span class=\"n\">sitemap_rules</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"p\">(</span><span class=\"s1\">'/shop/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_shop'</span><span class=\"p\">),</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"n\">other_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/about'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"n\">requests</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">MySpider</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">start_requests</span><span class=\"p\">())</span>\n        <span class=\"n\">requests</span> <span class=\"o\">+=</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_other</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">other_urls</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">requests</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_shop</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape shop here ...</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_other</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape other here ...</span>\n</pre></div>"], "codes_text": ["sitemap_rules = [('/product/', 'parse_product')]\n", "<url>\n    <loc>http://example.com/</loc>\n    <xhtml:link rel=\"alternate\" hreflang=\"de\" href=\"http://example.com/de\"/>\n</url>\n", "<url>\n    <loc>http://example.com/</loc>\n    <lastmod>2005-01-01</lastmod>\n</url>\n", "from datetime import datetime\nfrom scrapy.spiders import SitemapSpider\n\nclass FilteredSitemapSpider(SitemapSpider):\n    name = 'filtered_sitemap_spider'\n    allowed_domains = ['example.com']\n    sitemap_urls = ['http://example.com/sitemap.xml']\n\n    def sitemap_filter(self, entries):\n        for entry in entries:\n            date_time = datetime.strptime(entry['lastmod'], '%Y-%m-%d')\n            if date_time.year >= 2005:\n                yield entry\n", "from scrapy.spiders import SitemapSpider\n\nclass MySpider(SitemapSpider):\n    sitemap_urls = ['http://www.example.com/sitemap.xml']\n\n    def parse(self, response):\n        pass # ... scrape item here ...\n", "from scrapy.spiders import SitemapSpider\n\nclass MySpider(SitemapSpider):\n    sitemap_urls = ['http://www.example.com/sitemap.xml']\n    sitemap_rules = [\n        ('/product/', 'parse_product'),\n        ('/category/', 'parse_category'),\n    ]\n\n    def parse_product(self, response):\n        pass # ... scrape product ...\n\n    def parse_category(self, response):\n        pass # ... scrape category ...\n", "from scrapy.spiders import SitemapSpider\n\nclass MySpider(SitemapSpider):\n    sitemap_urls = ['http://www.example.com/robots.txt']\n    sitemap_rules = [\n        ('/shop/', 'parse_shop'),\n    ]\n    sitemap_follow = ['/sitemap_shops']\n\n    def parse_shop(self, response):\n        pass # ... scrape shop here ...\n", "from scrapy.spiders import SitemapSpider\n\nclass MySpider(SitemapSpider):\n    sitemap_urls = ['http://www.example.com/robots.txt']\n    sitemap_rules = [\n        ('/shop/', 'parse_shop'),\n    ]\n\n    other_urls = ['http://www.example.com/about']\n\n    def start_requests(self):\n        requests = list(super(MySpider, self).start_requests())\n        requests += [scrapy.Request(x, self.parse_other) for x in self.other_urls]\n        return requests\n\n    def parse_shop(self, response):\n        pass # ... scrape shop here ...\n\n    def parse_other(self, response):\n        pass # ... scrape other here ...\n"], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/spiders.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "SitemapSpider examples", "header_href": "#sitemapspider-examples", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/sitemap.xml'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape item here ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/sitemap.xml'</span><span class=\"p\">]</span>\n    <span class=\"n\">sitemap_rules</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"p\">(</span><span class=\"s1\">'/product/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_product'</span><span class=\"p\">),</span>\n        <span class=\"p\">(</span><span class=\"s1\">'/category/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_category'</span><span class=\"p\">),</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_product</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape product ...</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_category</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape category ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/robots.txt'</span><span class=\"p\">]</span>\n    <span class=\"n\">sitemap_rules</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"p\">(</span><span class=\"s1\">'/shop/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_shop'</span><span class=\"p\">),</span>\n    <span class=\"p\">]</span>\n    <span class=\"n\">sitemap_follow</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'/sitemap_shops'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_shop</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape shop here ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">SitemapSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">SitemapSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">sitemap_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/robots.txt'</span><span class=\"p\">]</span>\n    <span class=\"n\">sitemap_rules</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"p\">(</span><span class=\"s1\">'/shop/'</span><span class=\"p\">,</span> <span class=\"s1\">'parse_shop'</span><span class=\"p\">),</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"n\">other_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/about'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"n\">requests</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">MySpider</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">start_requests</span><span class=\"p\">())</span>\n        <span class=\"n\">requests</span> <span class=\"o\">+=</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_other</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">other_urls</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">requests</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_shop</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape shop here ...</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_other</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span> <span class=\"c1\"># ... scrape other here ...</span>\n</pre></div>"], "codes_text": ["from scrapy.spiders import SitemapSpider\n\nclass MySpider(SitemapSpider):\n    sitemap_urls = ['http://www.example.com/sitemap.xml']\n\n    def parse(self, response):\n        pass # ... scrape item here ...\n", "from scrapy.spiders import SitemapSpider\n\nclass MySpider(SitemapSpider):\n    sitemap_urls = ['http://www.example.com/sitemap.xml']\n    sitemap_rules = [\n        ('/product/', 'parse_product'),\n        ('/category/', 'parse_category'),\n    ]\n\n    def parse_product(self, response):\n        pass # ... scrape product ...\n\n    def parse_category(self, response):\n        pass # ... scrape category ...\n", "from scrapy.spiders import SitemapSpider\n\nclass MySpider(SitemapSpider):\n    sitemap_urls = ['http://www.example.com/robots.txt']\n    sitemap_rules = [\n        ('/shop/', 'parse_shop'),\n    ]\n    sitemap_follow = ['/sitemap_shops']\n\n    def parse_shop(self, response):\n        pass # ... scrape shop here ...\n", "from scrapy.spiders import SitemapSpider\n\nclass MySpider(SitemapSpider):\n    sitemap_urls = ['http://www.example.com/robots.txt']\n    sitemap_rules = [\n        ('/shop/', 'parse_shop'),\n    ]\n\n    other_urls = ['http://www.example.com/about']\n\n    def start_requests(self):\n        requests = list(super(MySpider, self).start_requests())\n        requests += [scrapy.Request(x, self.parse_other) for x in self.other_urls]\n        return requests\n\n    def parse_shop(self, response):\n        pass # ... scrape shop here ...\n\n    def parse_other(self, response):\n        pass # ... scrape other here ...\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Selectors", "header_href": "#selectors", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//span/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'good'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//span/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'good'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'good'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.selector</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">body</span> <span class=\"o\">=</span> <span class=\"s1\">'&lt;html&gt;&lt;body&gt;&lt;span&gt;good&lt;/span&gt;&lt;/body&gt;&lt;/html&gt;'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">body</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//span/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'good'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.selector</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.http</span> <span class=\"kn\">import</span> <span class=\"n\">HtmlResponse</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">HtmlResponse</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s1\">'http://example.com'</span><span class=\"p\">,</span> <span class=\"n\">body</span><span class=\"o\">=</span><span class=\"n\">body</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//span/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'good'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"cp\">&lt;!DOCTYPE html&gt;</span>\n\n<span class=\"p\">&lt;</span><span class=\"nt\">html</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">head</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">base</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'http://example.com/'</span> <span class=\"p\">/&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">title</span><span class=\"p\">&gt;</span>Example website<span class=\"p\">&lt;/</span><span class=\"nt\">title</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;/</span><span class=\"nt\">head</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">body</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">id</span><span class=\"o\">=</span><span class=\"s\">'images'</span><span class=\"p\">&gt;</span>\n      <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'image1.html'</span><span class=\"p\">&gt;</span>Name: My image 1 <span class=\"p\">&lt;</span><span class=\"nt\">br</span> <span class=\"p\">/&gt;&lt;</span><span class=\"nt\">img</span> <span class=\"na\">src</span><span class=\"o\">=</span><span class=\"s\">'image1_thumb.jpg'</span> <span class=\"na\">alt</span><span class=\"o\">=</span><span class=\"s\">'image1'</span><span class=\"p\">/&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n      <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'image2.html'</span><span class=\"p\">&gt;</span>Name: My image 2 <span class=\"p\">&lt;</span><span class=\"nt\">br</span> <span class=\"p\">/&gt;&lt;</span><span class=\"nt\">img</span> <span class=\"na\">src</span><span class=\"o\">=</span><span class=\"s\">'image2_thumb.jpg'</span> <span class=\"na\">alt</span><span class=\"o\">=</span><span class=\"s\">'image2'</span><span class=\"p\">/&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n      <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'image3.html'</span><span class=\"p\">&gt;</span>Name: My image 3 <span class=\"p\">&lt;</span><span class=\"nt\">br</span> <span class=\"p\">/&gt;&lt;</span><span class=\"nt\">img</span> <span class=\"na\">src</span><span class=\"o\">=</span><span class=\"s\">'image3_thumb.jpg'</span> <span class=\"na\">alt</span><span class=\"o\">=</span><span class=\"s\">'image3'</span><span class=\"p\">/&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n      <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'image4.html'</span><span class=\"p\">&gt;</span>Name: My image 4 <span class=\"p\">&lt;</span><span class=\"nt\">br</span> <span class=\"p\">/&gt;&lt;</span><span class=\"nt\">img</span> <span class=\"na\">src</span><span class=\"o\">=</span><span class=\"s\">'image4_thumb.jpg'</span> <span class=\"na\">alt</span><span class=\"o\">=</span><span class=\"s\">'image4'</span><span class=\"p\">/&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n      <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'image5.html'</span><span class=\"p\">&gt;</span>Name: My image 5 <span class=\"p\">&lt;</span><span class=\"nt\">br</span> <span class=\"p\">/&gt;&lt;</span><span class=\"nt\">img</span> <span class=\"na\">src</span><span class=\"o\">=</span><span class=\"s\">'image5_thumb.jpg'</span> <span class=\"na\">alt</span><span class=\"o\">=</span><span class=\"s\">'image5'</span><span class=\"p\">/&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;/</span><span class=\"nt\">body</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;/</span><span class=\"nt\">html</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>scrapy shell https://docs.scrapy.org/en/latest/_static/selectors-sample1.html\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='//title/text()' data='Example website'&gt;]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['Example website']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Example website'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Example website'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'@src'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1_thumb.jpg',</span>\n<span class=\"go\"> 'image2_thumb.jpg',</span>\n<span class=\"go\"> 'image3_thumb.jpg',</span>\n<span class=\"go\"> 'image4_thumb.jpg',</span>\n<span class=\"go\"> 'image5_thumb.jpg']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[@id=\"images\"]/a/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Name: My image 1 '</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[@id=\"not-exists\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span> <span class=\"ow\">is</span> <span class=\"kc\">None</span>\n<span class=\"go\">True</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[@id=\"not-exists\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">default</span><span class=\"o\">=</span><span class=\"s1\">'not-found'</span><span class=\"p\">)</span>\n<span class=\"go\">'not-found'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"p\">[</span><span class=\"n\">img</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'src'</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">img</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img'</span><span class=\"p\">)]</span>\n<span class=\"go\">['image1_thumb.jpg',</span>\n<span class=\"go\"> 'image2_thumb.jpg',</span>\n<span class=\"go\"> 'image3_thumb.jpg',</span>\n<span class=\"go\"> 'image4_thumb.jpg',</span>\n<span class=\"go\"> 'image5_thumb.jpg']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'src'</span><span class=\"p\">]</span>\n<span class=\"go\">'image1_thumb.jpg'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'base'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'href'</span><span class=\"p\">]</span>\n<span class=\"go\">'http://example.com/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//base/@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'http://example.com/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'base::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'http://example.com/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'base'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'href'</span><span class=\"p\">]</span>\n<span class=\"go\">'http://example.com/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[contains(@href, \"image\")]/@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html',</span>\n<span class=\"go\"> 'image2.html',</span>\n<span class=\"go\"> 'image3.html',</span>\n<span class=\"go\"> 'image4.html',</span>\n<span class=\"go\"> 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a[href*=image]::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html',</span>\n<span class=\"go\"> 'image2.html',</span>\n<span class=\"go\"> 'image3.html',</span>\n<span class=\"go\"> 'image4.html',</span>\n<span class=\"go\"> 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[contains(@href, \"image\")]/img/@src'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1_thumb.jpg',</span>\n<span class=\"go\"> 'image2_thumb.jpg',</span>\n<span class=\"go\"> 'image3_thumb.jpg',</span>\n<span class=\"go\"> 'image4_thumb.jpg',</span>\n<span class=\"go\"> 'image5_thumb.jpg']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a[href*=image] img::attr(src)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1_thumb.jpg',</span>\n<span class=\"go\"> 'image2_thumb.jpg',</span>\n<span class=\"go\"> 'image3_thumb.jpg',</span>\n<span class=\"go\"> 'image4_thumb.jpg',</span>\n<span class=\"go\"> 'image5_thumb.jpg']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Example website'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'#images *::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['\\n   ',</span>\n<span class=\"go\"> 'Name: My image 1 ',</span>\n<span class=\"go\"> '\\n   ',</span>\n<span class=\"go\"> 'Name: My image 2 ',</span>\n<span class=\"go\"> '\\n   ',</span>\n<span class=\"go\"> 'Name: My image 3 ',</span>\n<span class=\"go\"> '\\n   ',</span>\n<span class=\"go\"> 'Name: My image 4 ',</span>\n<span class=\"go\"> '\\n   ',</span>\n<span class=\"go\"> 'Name: My image 5 ',</span>\n<span class=\"go\"> '\\n  ']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">[]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">default</span><span class=\"o\">=</span><span class=\"s1\">''</span><span class=\"p\">)</span>\n<span class=\"go\">''</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html',</span>\n<span class=\"go\"> 'image2.html',</span>\n<span class=\"go\"> 'image3.html',</span>\n<span class=\"go\"> 'image4.html',</span>\n<span class=\"go\"> 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">links</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[contains(@href, \"image\")]'</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">links</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['&lt;a href=\"image1.html\"&gt;Name: My image 1 &lt;br&gt;&lt;img src=\"image1_thumb.jpg\"&gt;&lt;/a&gt;',</span>\n<span class=\"go\"> '&lt;a href=\"image2.html\"&gt;Name: My image 2 &lt;br&gt;&lt;img src=\"image2_thumb.jpg\"&gt;&lt;/a&gt;',</span>\n<span class=\"go\"> '&lt;a href=\"image3.html\"&gt;Name: My image 3 &lt;br&gt;&lt;img src=\"image3_thumb.jpg\"&gt;&lt;/a&gt;',</span>\n<span class=\"go\"> '&lt;a href=\"image4.html\"&gt;Name: My image 4 &lt;br&gt;&lt;img src=\"image4_thumb.jpg\"&gt;&lt;/a&gt;',</span>\n<span class=\"go\"> '&lt;a href=\"image5.html\"&gt;Name: My image 5 &lt;br&gt;&lt;img src=\"image5_thumb.jpg\"&gt;&lt;/a&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">index</span><span class=\"p\">,</span> <span class=\"n\">link</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">links</span><span class=\"p\">):</span>\n<span class=\"gp\">... </span>    <span class=\"n\">href_xpath</span> <span class=\"o\">=</span> <span class=\"n\">link</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"n\">img_xpath</span> <span class=\"o\">=</span> <span class=\"n\">link</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'img/@src'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'Link number </span><span class=\"si\">{</span><span class=\"n\">index</span><span class=\"si\">}</span><span class=\"s1\"> points to url </span><span class=\"si\">{</span><span class=\"n\">href_xpath</span><span class=\"si\">!r}</span><span class=\"s1\"> and image </span><span class=\"si\">{</span><span class=\"n\">img_xpath</span><span class=\"si\">!r}</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n<span class=\"go\">Link number 0 points to url 'image1.html' and image 'image1_thumb.jpg'</span>\n<span class=\"go\">Link number 1 points to url 'image2.html' and image 'image2_thumb.jpg'</span>\n<span class=\"go\">Link number 2 points to url 'image3.html' and image 'image3_thumb.jpg'</span>\n<span class=\"go\">Link number 3 points to url 'image4.html' and image 'image4_thumb.jpg'</span>\n<span class=\"go\">Link number 4 points to url 'image5.html' and image 'image5_thumb.jpg'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//a/@href\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"p\">[</span><span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'href'</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a'</span><span class=\"p\">)]</span>\n<span class=\"go\">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'base'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span>\n<span class=\"go\">{'href': 'http://example.com/'}</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'base'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'href'</span><span class=\"p\">]</span>\n<span class=\"go\">'http://example.com/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'foo'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span>\n<span class=\"go\">{}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[contains(@href, \"image\")]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'Name:\\s*(.*)'</span><span class=\"p\">)</span>\n<span class=\"go\">['My image 1',</span>\n<span class=\"go\"> 'My image 2',</span>\n<span class=\"go\"> 'My image 3',</span>\n<span class=\"go\"> 'My image 4',</span>\n<span class=\"go\"> 'My image 5']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[contains(@href, \"image\")]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re_first</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'Name:\\s*(.*)'</span><span class=\"p\">)</span>\n<span class=\"go\">'My image 1'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'image1.html'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">extract_first</span><span class=\"p\">()</span>\n<span class=\"go\">'image1.html'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">extract</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'image1.html'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">extract</span><span class=\"p\">()</span>\n<span class=\"go\">'image1.html'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">divs</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">divs</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p'</span><span class=\"p\">):</span>  <span class=\"c1\"># this is wrong - gets all &lt;p&gt; from the whole document</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">())</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">divs</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'.//p'</span><span class=\"p\">):</span>  <span class=\"c1\"># extracts all &lt;p&gt; inside</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">())</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">divs</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'p'</span><span class=\"p\">):</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">())</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">*</span><span class=\"p\">[</span><span class=\"n\">contains</span><span class=\"p\">(</span><span class=\"n\">concat</span><span class=\"p\">(</span><span class=\"s1\">' '</span><span class=\"p\">,</span> <span class=\"n\">normalize</span><span class=\"o\">-</span><span class=\"n\">space</span><span class=\"p\">(</span><span class=\"nd\">@class</span><span class=\"p\">),</span> <span class=\"s1\">' '</span><span class=\"p\">),</span> <span class=\"s1\">' someclass '</span><span class=\"p\">)]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s1\">'&lt;div class=\"hero shout\"&gt;&lt;time datetime=\"2014-07-23 19:00\"&gt;Special date&lt;/time&gt;&lt;/div&gt;'</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'.shout'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'./time/@datetime'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['2014-07-23 19:00']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s2\">\"\"\"</span>\n<span class=\"go\">....:     &lt;ul class=\"list\"&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;1&lt;/li&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;2&lt;/li&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;3&lt;/li&gt;</span>\n<span class=\"go\">....:     &lt;/ul&gt;</span>\n<span class=\"go\">....:     &lt;ul class=\"list\"&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;4&lt;/li&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;5&lt;/li&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;6&lt;/li&gt;</span>\n<span class=\"go\">....:     &lt;/ul&gt;\"\"\")</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xp</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xp</span><span class=\"p\">(</span><span class=\"s2\">\"//li[1]\"</span><span class=\"p\">)</span>\n<span class=\"go\">['&lt;li&gt;1&lt;/li&gt;', '&lt;li&gt;4&lt;/li&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xp</span><span class=\"p\">(</span><span class=\"s2\">\"(//li)[1]\"</span><span class=\"p\">)</span>\n<span class=\"go\">['&lt;li&gt;1&lt;/li&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xp</span><span class=\"p\">(</span><span class=\"s2\">\"//ul/li[1]\"</span><span class=\"p\">)</span>\n<span class=\"go\">['&lt;li&gt;1&lt;/li&gt;', '&lt;li&gt;4&lt;/li&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xp</span><span class=\"p\">(</span><span class=\"s2\">\"(//ul/li)[1]\"</span><span class=\"p\">)</span>\n<span class=\"go\">['&lt;li&gt;1&lt;/li&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s1\">'&lt;a href=\"#\"&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a//text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span> <span class=\"c1\"># take a peek at the node-set</span>\n<span class=\"go\">['Click here to go to the ', 'Next Page']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"string(//a[1]//text())\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span> <span class=\"c1\"># convert it to string</span>\n<span class=\"go\">['Click here to go to the ']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//a[1]\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span> <span class=\"c1\"># select the first node</span>\n<span class=\"go\">['&lt;a href=\"#\"&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"string(//a[1])\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span> <span class=\"c1\"># convert it to string</span>\n<span class=\"go\">['Click here to go to the Next Page']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//a[contains(.//text(), 'Next Page')]\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">[]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//a[contains(., 'Next Page')]\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['&lt;a href=\"#\"&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"c1\"># `$val` used in the expression, a `val` argument needs to be passed</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[@id=$val]/a/text()'</span><span class=\"p\">,</span> <span class=\"n\">val</span><span class=\"o\">=</span><span class=\"s1\">'images'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Name: My image 1 '</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[count(a)=$cnt]/@id'</span><span class=\"p\">,</span> <span class=\"n\">cnt</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'images'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy shell https://feeds.feedburner.com/PythonInsider\n</pre></div>", "<div class=\"highlight\"><pre><span></span>&lt;?xml <span class=\"nv\">version</span><span class=\"o\">=</span><span class=\"s2\">\"1.0\"</span> <span class=\"nv\">encoding</span><span class=\"o\">=</span><span class=\"s2\">\"UTF-8\"</span>?&gt;\n&lt;?xml-stylesheet ...\n&lt;feed <span class=\"nv\">xmlns</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.w3.org/2005/Atom\"</span>\n      xmlns:openSearch<span class=\"o\">=</span><span class=\"s2\">\"http://a9.com/-/spec/opensearchrss/1.0/\"</span>\n      xmlns:blogger<span class=\"o\">=</span><span class=\"s2\">\"http://schemas.google.com/blogger/2008\"</span>\n      xmlns:georss<span class=\"o\">=</span><span class=\"s2\">\"http://www.georss.org/georss\"</span>\n      xmlns:gd<span class=\"o\">=</span><span class=\"s2\">\"http://schemas.google.com/g/2005\"</span>\n      xmlns:thr<span class=\"o\">=</span><span class=\"s2\">\"http://purl.org/syndication/thread/1.0\"</span>\n      xmlns:feedburner<span class=\"o\">=</span><span class=\"s2\">\"http://rssnamespace.org/feedburner/ext/1.0\"</span>&gt;\n  ...\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//link\"</span><span class=\"p\">)</span>\n<span class=\"go\">[]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">remove_namespaces</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//link\"</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='//link' data='&lt;link rel=\"alternate\" type=\"text/html\" h'&gt;,</span>\n<span class=\"go\">    &lt;Selector xpath='//link' data='&lt;link rel=\"next\" type=\"application/atom+'&gt;,</span>\n<span class=\"go\">    ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"s2\">\"\"\"</span>\n<span class=\"gp\">... </span><span class=\"s2\">&lt;div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;ul&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-0\"&gt;&lt;a href=\"link1.html\"&gt;first item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-1\"&gt;&lt;a href=\"link2.html\"&gt;second item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-inactive\"&gt;&lt;a href=\"link3.html\"&gt;third item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-1\"&gt;&lt;a href=\"link4.html\"&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-0\"&gt;&lt;a href=\"link5.html\"&gt;fifth item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;/ul&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">&lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">\"\"\"</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">doc</span><span class=\"p\">,</span> <span class=\"nb\">type</span><span class=\"o\">=</span><span class=\"s2\">\"html\"</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//li//@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//li[re:test(@class, \"item-\\d$\")]//@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['link1.html', 'link2.html', 'link4.html', 'link5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"s2\">\"\"\"</span>\n<span class=\"gp\">... </span><span class=\"s2\">&lt;div itemscope itemtype=\"http://schema.org/Product\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;span itemprop=\"name\"&gt;Kenmore White 17\" Microwave&lt;/span&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;img src=\"kenmore-microwave-17in.jpg\" alt='Kenmore 17\" Microwave' /&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;div itemprop=\"aggregateRating\"</span>\n<span class=\"gp\">... </span><span class=\"s2\">    itemscope itemtype=\"http://schema.org/AggregateRating\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">   Rated &lt;span itemprop=\"ratingValue\"&gt;3.5&lt;/span&gt;/5</span>\n<span class=\"gp\">... </span><span class=\"s2\">   based on &lt;span itemprop=\"reviewCount\"&gt;11&lt;/span&gt; customer reviews</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;/div&gt;</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;div itemprop=\"offers\" itemscope itemtype=\"http://schema.org/Offer\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"price\"&gt;$55.00&lt;/span&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;link itemprop=\"availability\" href=\"http://schema.org/InStock\" /&gt;In stock</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;/div&gt;</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  Product description:</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;span itemprop=\"description\"&gt;0.7 cubic feet countertop microwave.</span>\n<span class=\"gp\">... </span><span class=\"s2\">  Has six preset cooking categories and convenience features like</span>\n<span class=\"gp\">... </span><span class=\"s2\">  Add-A-Minute and Child Lock.&lt;/span&gt;</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  Customer reviews:</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"name\"&gt;Not a happy camper&lt;/span&gt; -</span>\n<span class=\"gp\">... </span><span class=\"s2\">    by &lt;span itemprop=\"author\"&gt;Ellie&lt;/span&gt;,</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;meta itemprop=\"datePublished\" content=\"2011-04-01\"&gt;April 1, 2011</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;meta itemprop=\"worstRating\" content = \"1\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;span itemprop=\"ratingValue\"&gt;1&lt;/span&gt;/</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;span itemprop=\"bestRating\"&gt;5&lt;/span&gt;stars</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"description\"&gt;The lamp burned out and now I have to replace</span>\n<span class=\"gp\">... </span><span class=\"s2\">    it. &lt;/span&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;/div&gt;</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"name\"&gt;Value purchase&lt;/span&gt; -</span>\n<span class=\"gp\">... </span><span class=\"s2\">    by &lt;span itemprop=\"author\"&gt;Lucas&lt;/span&gt;,</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;meta itemprop=\"datePublished\" content=\"2011-03-25\"&gt;March 25, 2011</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;meta itemprop=\"worstRating\" content = \"1\"/&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;span itemprop=\"ratingValue\"&gt;4&lt;/span&gt;/</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;span itemprop=\"bestRating\"&gt;5&lt;/span&gt;stars</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"description\"&gt;Great microwave for the price. It is small and</span>\n<span class=\"gp\">... </span><span class=\"s2\">    fits in my apartment.&lt;/span&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  ...</span>\n<span class=\"gp\">... </span><span class=\"s2\">&lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">\"\"\"</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">doc</span><span class=\"p\">,</span> <span class=\"nb\">type</span><span class=\"o\">=</span><span class=\"s2\">\"html\"</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">scope</span> <span class=\"ow\">in</span> <span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[@itemscope]'</span><span class=\"p\">):</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"current scope:\"</span><span class=\"p\">,</span> <span class=\"n\">scope</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'@itemtype'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">())</span>\n<span class=\"gp\">... </span>    <span class=\"n\">props</span> <span class=\"o\">=</span> <span class=\"n\">scope</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'''</span>\n<span class=\"gp\">... </span><span class=\"s1\">                set:difference(./descendant::*/@itemprop,</span>\n<span class=\"gp\">... </span><span class=\"s1\">                               .//*[@itemscope]/*/@itemprop)'''</span><span class=\"p\">)</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"    properties: </span><span class=\"si\">{</span><span class=\"n\">props</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"\"</span><span class=\"p\">)</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Product']</span>\n<span class=\"go\">    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/AggregateRating']</span>\n<span class=\"go\">    properties: ['ratingValue', 'reviewCount']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Offer']</span>\n<span class=\"go\">    properties: ['price', 'availability']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Review']</span>\n<span class=\"go\">    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Rating']</span>\n<span class=\"go\">    properties: ['worstRating', 'ratingValue', 'bestRating']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Review']</span>\n<span class=\"go\">    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Rating']</span>\n<span class=\"go\">    properties: ['worstRating', 'ratingValue', 'bestRating']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">p</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"foo bar-baz\"</span><span class=\"p\">&gt;</span>First<span class=\"p\">&lt;/</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;</span><span class=\"nt\">p</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"foo\"</span><span class=\"p\">&gt;</span>Second<span class=\"p\">&lt;/</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;</span><span class=\"nt\">p</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"bar\"</span><span class=\"p\">&gt;</span>Third<span class=\"p\">&lt;/</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>Fourth<span class=\"p\">&lt;/</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[has-class(\"foo\")]'</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='//p[has-class(\"foo\")]' data='&lt;p class=\"foo bar-baz\"&gt;First&lt;/p&gt;'&gt;,</span>\n<span class=\"go\"> &lt;Selector xpath='//p[has-class(\"foo\")]' data='&lt;p class=\"foo\"&gt;Second&lt;/p&gt;'&gt;]</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[has-class(\"foo\", \"bar-baz\")]'</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='//p[has-class(\"foo\", \"bar-baz\")]' data='&lt;p class=\"foo bar-baz\"&gt;First&lt;/p&gt;'&gt;]</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[has-class(\"foo\", \"bar\")]'</span><span class=\"p\">)</span>\n<span class=\"go\">[]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[href=$url]'</span><span class=\"p\">,</span> <span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.example.com\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[href=$url]'</span><span class=\"p\">,</span> <span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.example.com\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">html_response</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//h1\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//h1\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>         <span class=\"c1\"># this includes the h1 tag</span>\n<span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//h1/text()\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>  <span class=\"c1\"># this excludes the h1 tag</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">node</span> <span class=\"ow\">in</span> <span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//p\"</span><span class=\"p\">):</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'class'</span><span class=\"p\">])</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">xml_response</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//product\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">register_namespace</span><span class=\"p\">(</span><span class=\"s2\">\"g\"</span><span class=\"p\">,</span> <span class=\"s2\">\"http://base.google.com/ns/1.0\"</span><span class=\"p\">)</span>\n<span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//g:price\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n</pre></div>"], "codes_text": [">>> response.selector.xpath('//span/text()').get()\n'good'\n", ">>> response.xpath('//span/text()').get()\n'good'\n>>> response.css('span::text').get()\n'good'\n", ">>> from scrapy.selector import Selector\n>>> body = '<html><body><span>good</span></body></html>'\n>>> Selector(text=body).xpath('//span/text()').get()\n'good'\n", ">>> from scrapy.selector import Selector\n>>> from scrapy.http import HtmlResponse\n>>> response = HtmlResponse(url='http://example.com', body=body)\n>>> Selector(response=response).xpath('//span/text()').get()\n'good'\n", "<!DOCTYPE html>\n\n<html>\n  <head>\n    <base href='http://example.com/' />\n    <title>Example website</title>\n  </head>\n  <body>\n    <div id='images'>\n      <a href='image1.html'>Name: My image 1 <br /><img src='image1_thumb.jpg' alt='image1'/></a>\n      <a href='image2.html'>Name: My image 2 <br /><img src='image2_thumb.jpg' alt='image2'/></a>\n      <a href='image3.html'>Name: My image 3 <br /><img src='image3_thumb.jpg' alt='image3'/></a>\n      <a href='image4.html'>Name: My image 4 <br /><img src='image4_thumb.jpg' alt='image4'/></a>\n      <a href='image5.html'>Name: My image 5 <br /><img src='image5_thumb.jpg' alt='image5'/></a>\n    </div>\n  </body>\n</html>\n", "scrapy shell https://docs.scrapy.org/en/latest/_static/selectors-sample1.html\n", ">>> response.xpath('//title/text()')\n[<Selector xpath='//title/text()' data='Example website'>]\n", ">>> response.xpath('//title/text()').getall()\n['Example website']\n>>> response.xpath('//title/text()').get()\n'Example website'\n", ">>> response.css('title::text').get()\n'Example website'\n", ">>> response.css('img').xpath('@src').getall()\n['image1_thumb.jpg',\n 'image2_thumb.jpg',\n 'image3_thumb.jpg',\n 'image4_thumb.jpg',\n 'image5_thumb.jpg']\n", ">>> response.xpath('//div[@id=\"images\"]/a/text()').get()\n'Name: My image 1 '\n", ">>> response.xpath('//div[@id=\"not-exists\"]/text()').get() is None\nTrue\n", ">>> response.xpath('//div[@id=\"not-exists\"]/text()').get(default='not-found')\n'not-found'\n", ">>> [img.attrib['src'] for img in response.css('img')]\n['image1_thumb.jpg',\n 'image2_thumb.jpg',\n 'image3_thumb.jpg',\n 'image4_thumb.jpg',\n 'image5_thumb.jpg']\n", ">>> response.css('img').attrib['src']\n'image1_thumb.jpg'\n", ">>> response.css('base').attrib['href']\n'http://example.com/'\n", ">>> response.xpath('//base/@href').get()\n'http://example.com/'\n", ">>> response.css('base::attr(href)').get()\n'http://example.com/'\n", ">>> response.css('base').attrib['href']\n'http://example.com/'\n", ">>> response.xpath('//a[contains(@href, \"image\")]/@href').getall()\n['image1.html',\n 'image2.html',\n 'image3.html',\n 'image4.html',\n 'image5.html']\n", ">>> response.css('a[href*=image]::attr(href)').getall()\n['image1.html',\n 'image2.html',\n 'image3.html',\n 'image4.html',\n 'image5.html']\n", ">>> response.xpath('//a[contains(@href, \"image\")]/img/@src').getall()\n['image1_thumb.jpg',\n 'image2_thumb.jpg',\n 'image3_thumb.jpg',\n 'image4_thumb.jpg',\n 'image5_thumb.jpg']\n", ">>> response.css('a[href*=image] img::attr(src)').getall()\n['image1_thumb.jpg',\n 'image2_thumb.jpg',\n 'image3_thumb.jpg',\n 'image4_thumb.jpg',\n 'image5_thumb.jpg']\n", ">>> response.css('title::text').get()\n'Example website'\n", ">>> response.css('#images *::text').getall()\n['\\n   ',\n 'Name: My image 1 ',\n '\\n   ',\n 'Name: My image 2 ',\n '\\n   ',\n 'Name: My image 3 ',\n '\\n   ',\n 'Name: My image 4 ',\n '\\n   ',\n 'Name: My image 5 ',\n '\\n  ']\n", ">>> response.css('img::text').getall()\n[]\n", ">>> response.css('img::text').get()\n>>> response.css('img::text').get(default='')\n''\n", ">>> response.css('a::attr(href)').getall()\n['image1.html',\n 'image2.html',\n 'image3.html',\n 'image4.html',\n 'image5.html']\n", ">>> links = response.xpath('//a[contains(@href, \"image\")]')\n>>> links.getall()\n['<a href=\"image1.html\">Name: My image 1 <br><img src=\"image1_thumb.jpg\"></a>',\n '<a href=\"image2.html\">Name: My image 2 <br><img src=\"image2_thumb.jpg\"></a>',\n '<a href=\"image3.html\">Name: My image 3 <br><img src=\"image3_thumb.jpg\"></a>',\n '<a href=\"image4.html\">Name: My image 4 <br><img src=\"image4_thumb.jpg\"></a>',\n '<a href=\"image5.html\">Name: My image 5 <br><img src=\"image5_thumb.jpg\"></a>']\n", ">>> for index, link in enumerate(links):\n...     href_xpath = link.xpath('@href').get()\n...     img_xpath = link.xpath('img/@src').get()\n...     print(f'Link number {index} points to url {href_xpath!r} and image {img_xpath!r}')\nLink number 0 points to url 'image1.html' and image 'image1_thumb.jpg'\nLink number 1 points to url 'image2.html' and image 'image2_thumb.jpg'\nLink number 2 points to url 'image3.html' and image 'image3_thumb.jpg'\nLink number 3 points to url 'image4.html' and image 'image4_thumb.jpg'\nLink number 4 points to url 'image5.html' and image 'image5_thumb.jpg'\n", ">>> response.xpath(\"//a/@href\").getall()\n['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']\n", ">>> response.css('a::attr(href)').getall()\n['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']\n", ">>> [a.attrib['href'] for a in response.css('a')]\n['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']\n", ">>> response.css('base').attrib\n{'href': 'http://example.com/'}\n>>> response.css('base').attrib['href']\n'http://example.com/'\n", ">>> response.css('foo').attrib\n{}\n", ">>> response.xpath('//a[contains(@href, \"image\")]/text()').re(r'Name:\\s*(.*)')\n['My image 1',\n 'My image 2',\n 'My image 3',\n 'My image 4',\n 'My image 5']\n", ">>> response.xpath('//a[contains(@href, \"image\")]/text()').re_first(r'Name:\\s*(.*)')\n'My image 1'\n", ">>> response.css('a::attr(href)').get()\n'image1.html'\n>>> response.css('a::attr(href)').extract_first()\n'image1.html'\n", ">>> response.css('a::attr(href)').getall()\n['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']\n>>> response.css('a::attr(href)').extract()\n['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']\n", ">>> response.css('a::attr(href)')[0].get()\n'image1.html'\n>>> response.css('a::attr(href)')[0].extract()\n'image1.html'\n", ">>> response.css('a::attr(href)')[0].getall()\n['image1.html']\n", ">>> divs = response.xpath('//div')\n", ">>> for p in divs.xpath('//p'):  # this is wrong - gets all <p> from the whole document\n...     print(p.get())\n", ">>> for p in divs.xpath('.//p'):  # extracts all <p> inside\n...     print(p.get())\n", ">>> for p in divs.xpath('p'):\n...     print(p.get())\n", "*[contains(concat(' ', normalize-space(@class), ' '), ' someclass ')]\n", ">>> from scrapy import Selector\n>>> sel = Selector(text='<div class=\"hero shout\"><time datetime=\"2014-07-23 19:00\">Special date</time></div>')\n>>> sel.css('.shout').xpath('./time/@datetime').getall()\n['2014-07-23 19:00']\n", ">>> from scrapy import Selector\n>>> sel = Selector(text=\"\"\"\n....:     <ul class=\"list\">\n....:         <li>1</li>\n....:         <li>2</li>\n....:         <li>3</li>\n....:     </ul>\n....:     <ul class=\"list\">\n....:         <li>4</li>\n....:         <li>5</li>\n....:         <li>6</li>\n....:     </ul>\"\"\")\n>>> xp = lambda x: sel.xpath(x).getall()\n", ">>> xp(\"//li[1]\")\n['<li>1</li>', '<li>4</li>']\n", ">>> xp(\"(//li)[1]\")\n['<li>1</li>']\n", ">>> xp(\"//ul/li[1]\")\n['<li>1</li>', '<li>4</li>']\n", ">>> xp(\"(//ul/li)[1]\")\n['<li>1</li>']\n", ">>> from scrapy import Selector\n>>> sel = Selector(text='<a href=\"#\">Click here to go to the <strong>Next Page</strong></a>')\n", ">>> sel.xpath('//a//text()').getall() # take a peek at the node-set\n['Click here to go to the ', 'Next Page']\n>>> sel.xpath(\"string(//a[1]//text())\").getall() # convert it to string\n['Click here to go to the ']\n", ">>> sel.xpath(\"//a[1]\").getall() # select the first node\n['<a href=\"#\">Click here to go to the <strong>Next Page</strong></a>']\n>>> sel.xpath(\"string(//a[1])\").getall() # convert it to string\n['Click here to go to the Next Page']\n", ">>> sel.xpath(\"//a[contains(.//text(), 'Next Page')]\").getall()\n[]\n", ">>> sel.xpath(\"//a[contains(., 'Next Page')]\").getall()\n['<a href=\"#\">Click here to go to the <strong>Next Page</strong></a>']\n", ">>> # `$val` used in the expression, a `val` argument needs to be passed\n>>> response.xpath('//div[@id=$val]/a/text()', val='images').get()\n'Name: My image 1 '\n", ">>> response.xpath('//div[count(a)=$cnt]/@id', cnt=5).get()\n'images'\n", "$ scrapy shell https://feeds.feedburner.com/PythonInsider\n", "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<?xml-stylesheet ...\n<feed xmlns=\"http://www.w3.org/2005/Atom\"\n      xmlns:openSearch=\"http://a9.com/-/spec/opensearchrss/1.0/\"\n      xmlns:blogger=\"http://schemas.google.com/blogger/2008\"\n      xmlns:georss=\"http://www.georss.org/georss\"\n      xmlns:gd=\"http://schemas.google.com/g/2005\"\n      xmlns:thr=\"http://purl.org/syndication/thread/1.0\"\n      xmlns:feedburner=\"http://rssnamespace.org/feedburner/ext/1.0\">\n  ...\n", ">>> response.xpath(\"//link\")\n[]\n", ">>> response.selector.remove_namespaces()\n>>> response.xpath(\"//link\")\n[<Selector xpath='//link' data='<link rel=\"alternate\" type=\"text/html\" h'>,\n    <Selector xpath='//link' data='<link rel=\"next\" type=\"application/atom+'>,\n    ...\n", ">>> from scrapy import Selector\n>>> doc = \"\"\"\n... <div>\n...     <ul>\n...         <li class=\"item-0\"><a href=\"link1.html\">first item</a></li>\n...         <li class=\"item-1\"><a href=\"link2.html\">second item</a></li>\n...         <li class=\"item-inactive\"><a href=\"link3.html\">third item</a></li>\n...         <li class=\"item-1\"><a href=\"link4.html\">fourth item</a></li>\n...         <li class=\"item-0\"><a href=\"link5.html\">fifth item</a></li>\n...     </ul>\n... </div>\n... \"\"\"\n>>> sel = Selector(text=doc, type=\"html\")\n>>> sel.xpath('//li//@href').getall()\n['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']\n>>> sel.xpath('//li[re:test(@class, \"item-\\d$\")]//@href').getall()\n['link1.html', 'link2.html', 'link4.html', 'link5.html']\n", ">>> doc = \"\"\"\n... <div itemscope itemtype=\"http://schema.org/Product\">\n...   <span itemprop=\"name\">Kenmore White 17\" Microwave</span>\n...   <img src=\"kenmore-microwave-17in.jpg\" alt='Kenmore 17\" Microwave' />\n...   <div itemprop=\"aggregateRating\"\n...     itemscope itemtype=\"http://schema.org/AggregateRating\">\n...    Rated <span itemprop=\"ratingValue\">3.5</span>/5\n...    based on <span itemprop=\"reviewCount\">11</span> customer reviews\n...   </div>\n...\n...   <div itemprop=\"offers\" itemscope itemtype=\"http://schema.org/Offer\">\n...     <span itemprop=\"price\">$55.00</span>\n...     <link itemprop=\"availability\" href=\"http://schema.org/InStock\" />In stock\n...   </div>\n...\n...   Product description:\n...   <span itemprop=\"description\">0.7 cubic feet countertop microwave.\n...   Has six preset cooking categories and convenience features like\n...   Add-A-Minute and Child Lock.</span>\n...\n...   Customer reviews:\n...\n...   <div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\">\n...     <span itemprop=\"name\">Not a happy camper</span> -\n...     by <span itemprop=\"author\">Ellie</span>,\n...     <meta itemprop=\"datePublished\" content=\"2011-04-01\">April 1, 2011\n...     <div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\">\n...       <meta itemprop=\"worstRating\" content = \"1\">\n...       <span itemprop=\"ratingValue\">1</span>/\n...       <span itemprop=\"bestRating\">5</span>stars\n...     </div>\n...     <span itemprop=\"description\">The lamp burned out and now I have to replace\n...     it. </span>\n...   </div>\n...\n...   <div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\">\n...     <span itemprop=\"name\">Value purchase</span> -\n...     by <span itemprop=\"author\">Lucas</span>,\n...     <meta itemprop=\"datePublished\" content=\"2011-03-25\">March 25, 2011\n...     <div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\">\n...       <meta itemprop=\"worstRating\" content = \"1\"/>\n...       <span itemprop=\"ratingValue\">4</span>/\n...       <span itemprop=\"bestRating\">5</span>stars\n...     </div>\n...     <span itemprop=\"description\">Great microwave for the price. It is small and\n...     fits in my apartment.</span>\n...   </div>\n...   ...\n... </div>\n... \"\"\"\n>>> sel = Selector(text=doc, type=\"html\")\n>>> for scope in sel.xpath('//div[@itemscope]'):\n...     print(\"current scope:\", scope.xpath('@itemtype').getall())\n...     props = scope.xpath('''\n...                 set:difference(./descendant::*/@itemprop,\n...                                .//*[@itemscope]/*/@itemprop)''')\n...     print(f\"    properties: {props.getall()}\")\n...     print(\"\")\n\ncurrent scope: ['http://schema.org/Product']\n    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']\n\ncurrent scope: ['http://schema.org/AggregateRating']\n    properties: ['ratingValue', 'reviewCount']\n\ncurrent scope: ['http://schema.org/Offer']\n    properties: ['price', 'availability']\n\ncurrent scope: ['http://schema.org/Review']\n    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']\n\ncurrent scope: ['http://schema.org/Rating']\n    properties: ['worstRating', 'ratingValue', 'bestRating']\n\ncurrent scope: ['http://schema.org/Review']\n    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']\n\ncurrent scope: ['http://schema.org/Rating']\n    properties: ['worstRating', 'ratingValue', 'bestRating']\n", "<p class=\"foo bar-baz\">First</p>\n<p class=\"foo\">Second</p>\n<p class=\"bar\">Third</p>\n<p>Fourth</p>\n", ">>> response.xpath('//p[has-class(\"foo\")]')\n[<Selector xpath='//p[has-class(\"foo\")]' data='<p class=\"foo bar-baz\">First</p>'>,\n <Selector xpath='//p[has-class(\"foo\")]' data='<p class=\"foo\">Second</p>'>]\n>>> response.xpath('//p[has-class(\"foo\", \"bar-baz\")]')\n[<Selector xpath='//p[has-class(\"foo\", \"bar-baz\")]' data='<p class=\"foo bar-baz\">First</p>'>]\n>>> response.xpath('//p[has-class(\"foo\", \"bar\")]')\n[]\n", "selector.xpath('//a[href=$url]', url=\"http://www.example.com\")\n", "selector.xpath('//a[href=$url]', url=\"http://www.example.com\")\n", "sel = Selector(html_response)\n", "sel.xpath(\"//h1\")\n", "sel.xpath(\"//h1\").getall()         # this includes the h1 tag\nsel.xpath(\"//h1/text()\").getall()  # this excludes the h1 tag\n", "for node in sel.xpath(\"//p\"):\n    print(node.attrib['class'])\n", "sel = Selector(xml_response)\n", "sel.xpath(\"//product\")\n", "sel.register_namespace(\"g\", \"http://base.google.com/ns/1.0\")\nsel.xpath(\"//g:price\").getall()\n"], "index": 76}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Using selectors", "header_href": "#using-selectors", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//span/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'good'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//span/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'good'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'good'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.selector</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">body</span> <span class=\"o\">=</span> <span class=\"s1\">'&lt;html&gt;&lt;body&gt;&lt;span&gt;good&lt;/span&gt;&lt;/body&gt;&lt;/html&gt;'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">body</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//span/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'good'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.selector</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.http</span> <span class=\"kn\">import</span> <span class=\"n\">HtmlResponse</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">HtmlResponse</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s1\">'http://example.com'</span><span class=\"p\">,</span> <span class=\"n\">body</span><span class=\"o\">=</span><span class=\"n\">body</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//span/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'good'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"cp\">&lt;!DOCTYPE html&gt;</span>\n\n<span class=\"p\">&lt;</span><span class=\"nt\">html</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">head</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">base</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'http://example.com/'</span> <span class=\"p\">/&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">title</span><span class=\"p\">&gt;</span>Example website<span class=\"p\">&lt;/</span><span class=\"nt\">title</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;/</span><span class=\"nt\">head</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">body</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">id</span><span class=\"o\">=</span><span class=\"s\">'images'</span><span class=\"p\">&gt;</span>\n      <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'image1.html'</span><span class=\"p\">&gt;</span>Name: My image 1 <span class=\"p\">&lt;</span><span class=\"nt\">br</span> <span class=\"p\">/&gt;&lt;</span><span class=\"nt\">img</span> <span class=\"na\">src</span><span class=\"o\">=</span><span class=\"s\">'image1_thumb.jpg'</span> <span class=\"na\">alt</span><span class=\"o\">=</span><span class=\"s\">'image1'</span><span class=\"p\">/&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n      <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'image2.html'</span><span class=\"p\">&gt;</span>Name: My image 2 <span class=\"p\">&lt;</span><span class=\"nt\">br</span> <span class=\"p\">/&gt;&lt;</span><span class=\"nt\">img</span> <span class=\"na\">src</span><span class=\"o\">=</span><span class=\"s\">'image2_thumb.jpg'</span> <span class=\"na\">alt</span><span class=\"o\">=</span><span class=\"s\">'image2'</span><span class=\"p\">/&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n      <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'image3.html'</span><span class=\"p\">&gt;</span>Name: My image 3 <span class=\"p\">&lt;</span><span class=\"nt\">br</span> <span class=\"p\">/&gt;&lt;</span><span class=\"nt\">img</span> <span class=\"na\">src</span><span class=\"o\">=</span><span class=\"s\">'image3_thumb.jpg'</span> <span class=\"na\">alt</span><span class=\"o\">=</span><span class=\"s\">'image3'</span><span class=\"p\">/&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n      <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'image4.html'</span><span class=\"p\">&gt;</span>Name: My image 4 <span class=\"p\">&lt;</span><span class=\"nt\">br</span> <span class=\"p\">/&gt;&lt;</span><span class=\"nt\">img</span> <span class=\"na\">src</span><span class=\"o\">=</span><span class=\"s\">'image4_thumb.jpg'</span> <span class=\"na\">alt</span><span class=\"o\">=</span><span class=\"s\">'image4'</span><span class=\"p\">/&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n      <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'image5.html'</span><span class=\"p\">&gt;</span>Name: My image 5 <span class=\"p\">&lt;</span><span class=\"nt\">br</span> <span class=\"p\">/&gt;&lt;</span><span class=\"nt\">img</span> <span class=\"na\">src</span><span class=\"o\">=</span><span class=\"s\">'image5_thumb.jpg'</span> <span class=\"na\">alt</span><span class=\"o\">=</span><span class=\"s\">'image5'</span><span class=\"p\">/&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;/</span><span class=\"nt\">body</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;/</span><span class=\"nt\">html</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>scrapy shell https://docs.scrapy.org/en/latest/_static/selectors-sample1.html\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='//title/text()' data='Example website'&gt;]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['Example website']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Example website'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Example website'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'@src'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1_thumb.jpg',</span>\n<span class=\"go\"> 'image2_thumb.jpg',</span>\n<span class=\"go\"> 'image3_thumb.jpg',</span>\n<span class=\"go\"> 'image4_thumb.jpg',</span>\n<span class=\"go\"> 'image5_thumb.jpg']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[@id=\"images\"]/a/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Name: My image 1 '</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[@id=\"not-exists\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span> <span class=\"ow\">is</span> <span class=\"kc\">None</span>\n<span class=\"go\">True</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[@id=\"not-exists\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">default</span><span class=\"o\">=</span><span class=\"s1\">'not-found'</span><span class=\"p\">)</span>\n<span class=\"go\">'not-found'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"p\">[</span><span class=\"n\">img</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'src'</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">img</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img'</span><span class=\"p\">)]</span>\n<span class=\"go\">['image1_thumb.jpg',</span>\n<span class=\"go\"> 'image2_thumb.jpg',</span>\n<span class=\"go\"> 'image3_thumb.jpg',</span>\n<span class=\"go\"> 'image4_thumb.jpg',</span>\n<span class=\"go\"> 'image5_thumb.jpg']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'src'</span><span class=\"p\">]</span>\n<span class=\"go\">'image1_thumb.jpg'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'base'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'href'</span><span class=\"p\">]</span>\n<span class=\"go\">'http://example.com/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//base/@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'http://example.com/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'base::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'http://example.com/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'base'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'href'</span><span class=\"p\">]</span>\n<span class=\"go\">'http://example.com/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[contains(@href, \"image\")]/@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html',</span>\n<span class=\"go\"> 'image2.html',</span>\n<span class=\"go\"> 'image3.html',</span>\n<span class=\"go\"> 'image4.html',</span>\n<span class=\"go\"> 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a[href*=image]::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html',</span>\n<span class=\"go\"> 'image2.html',</span>\n<span class=\"go\"> 'image3.html',</span>\n<span class=\"go\"> 'image4.html',</span>\n<span class=\"go\"> 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[contains(@href, \"image\")]/img/@src'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1_thumb.jpg',</span>\n<span class=\"go\"> 'image2_thumb.jpg',</span>\n<span class=\"go\"> 'image3_thumb.jpg',</span>\n<span class=\"go\"> 'image4_thumb.jpg',</span>\n<span class=\"go\"> 'image5_thumb.jpg']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a[href*=image] img::attr(src)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1_thumb.jpg',</span>\n<span class=\"go\"> 'image2_thumb.jpg',</span>\n<span class=\"go\"> 'image3_thumb.jpg',</span>\n<span class=\"go\"> 'image4_thumb.jpg',</span>\n<span class=\"go\"> 'image5_thumb.jpg']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Example website'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'#images *::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['\\n   ',</span>\n<span class=\"go\"> 'Name: My image 1 ',</span>\n<span class=\"go\"> '\\n   ',</span>\n<span class=\"go\"> 'Name: My image 2 ',</span>\n<span class=\"go\"> '\\n   ',</span>\n<span class=\"go\"> 'Name: My image 3 ',</span>\n<span class=\"go\"> '\\n   ',</span>\n<span class=\"go\"> 'Name: My image 4 ',</span>\n<span class=\"go\"> '\\n   ',</span>\n<span class=\"go\"> 'Name: My image 5 ',</span>\n<span class=\"go\"> '\\n  ']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">[]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">default</span><span class=\"o\">=</span><span class=\"s1\">''</span><span class=\"p\">)</span>\n<span class=\"go\">''</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html',</span>\n<span class=\"go\"> 'image2.html',</span>\n<span class=\"go\"> 'image3.html',</span>\n<span class=\"go\"> 'image4.html',</span>\n<span class=\"go\"> 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">links</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[contains(@href, \"image\")]'</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">links</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['&lt;a href=\"image1.html\"&gt;Name: My image 1 &lt;br&gt;&lt;img src=\"image1_thumb.jpg\"&gt;&lt;/a&gt;',</span>\n<span class=\"go\"> '&lt;a href=\"image2.html\"&gt;Name: My image 2 &lt;br&gt;&lt;img src=\"image2_thumb.jpg\"&gt;&lt;/a&gt;',</span>\n<span class=\"go\"> '&lt;a href=\"image3.html\"&gt;Name: My image 3 &lt;br&gt;&lt;img src=\"image3_thumb.jpg\"&gt;&lt;/a&gt;',</span>\n<span class=\"go\"> '&lt;a href=\"image4.html\"&gt;Name: My image 4 &lt;br&gt;&lt;img src=\"image4_thumb.jpg\"&gt;&lt;/a&gt;',</span>\n<span class=\"go\"> '&lt;a href=\"image5.html\"&gt;Name: My image 5 &lt;br&gt;&lt;img src=\"image5_thumb.jpg\"&gt;&lt;/a&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">index</span><span class=\"p\">,</span> <span class=\"n\">link</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">links</span><span class=\"p\">):</span>\n<span class=\"gp\">... </span>    <span class=\"n\">href_xpath</span> <span class=\"o\">=</span> <span class=\"n\">link</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"n\">img_xpath</span> <span class=\"o\">=</span> <span class=\"n\">link</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'img/@src'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'Link number </span><span class=\"si\">{</span><span class=\"n\">index</span><span class=\"si\">}</span><span class=\"s1\"> points to url </span><span class=\"si\">{</span><span class=\"n\">href_xpath</span><span class=\"si\">!r}</span><span class=\"s1\"> and image </span><span class=\"si\">{</span><span class=\"n\">img_xpath</span><span class=\"si\">!r}</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n<span class=\"go\">Link number 0 points to url 'image1.html' and image 'image1_thumb.jpg'</span>\n<span class=\"go\">Link number 1 points to url 'image2.html' and image 'image2_thumb.jpg'</span>\n<span class=\"go\">Link number 2 points to url 'image3.html' and image 'image3_thumb.jpg'</span>\n<span class=\"go\">Link number 3 points to url 'image4.html' and image 'image4_thumb.jpg'</span>\n<span class=\"go\">Link number 4 points to url 'image5.html' and image 'image5_thumb.jpg'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//a/@href\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"p\">[</span><span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'href'</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a'</span><span class=\"p\">)]</span>\n<span class=\"go\">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'base'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span>\n<span class=\"go\">{'href': 'http://example.com/'}</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'base'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'href'</span><span class=\"p\">]</span>\n<span class=\"go\">'http://example.com/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'foo'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span>\n<span class=\"go\">{}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[contains(@href, \"image\")]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'Name:\\s*(.*)'</span><span class=\"p\">)</span>\n<span class=\"go\">['My image 1',</span>\n<span class=\"go\"> 'My image 2',</span>\n<span class=\"go\"> 'My image 3',</span>\n<span class=\"go\"> 'My image 4',</span>\n<span class=\"go\"> 'My image 5']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[contains(@href, \"image\")]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re_first</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'Name:\\s*(.*)'</span><span class=\"p\">)</span>\n<span class=\"go\">'My image 1'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'image1.html'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">extract_first</span><span class=\"p\">()</span>\n<span class=\"go\">'image1.html'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">extract</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'image1.html'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">extract</span><span class=\"p\">()</span>\n<span class=\"go\">'image1.html'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html']</span>\n</pre></div>"], "codes_text": [">>> response.selector.xpath('//span/text()').get()\n'good'\n", ">>> response.xpath('//span/text()').get()\n'good'\n>>> response.css('span::text').get()\n'good'\n", ">>> from scrapy.selector import Selector\n>>> body = '<html><body><span>good</span></body></html>'\n>>> Selector(text=body).xpath('//span/text()').get()\n'good'\n", ">>> from scrapy.selector import Selector\n>>> from scrapy.http import HtmlResponse\n>>> response = HtmlResponse(url='http://example.com', body=body)\n>>> Selector(response=response).xpath('//span/text()').get()\n'good'\n", "<!DOCTYPE html>\n\n<html>\n  <head>\n    <base href='http://example.com/' />\n    <title>Example website</title>\n  </head>\n  <body>\n    <div id='images'>\n      <a href='image1.html'>Name: My image 1 <br /><img src='image1_thumb.jpg' alt='image1'/></a>\n      <a href='image2.html'>Name: My image 2 <br /><img src='image2_thumb.jpg' alt='image2'/></a>\n      <a href='image3.html'>Name: My image 3 <br /><img src='image3_thumb.jpg' alt='image3'/></a>\n      <a href='image4.html'>Name: My image 4 <br /><img src='image4_thumb.jpg' alt='image4'/></a>\n      <a href='image5.html'>Name: My image 5 <br /><img src='image5_thumb.jpg' alt='image5'/></a>\n    </div>\n  </body>\n</html>\n", "scrapy shell https://docs.scrapy.org/en/latest/_static/selectors-sample1.html\n", ">>> response.xpath('//title/text()')\n[<Selector xpath='//title/text()' data='Example website'>]\n", ">>> response.xpath('//title/text()').getall()\n['Example website']\n>>> response.xpath('//title/text()').get()\n'Example website'\n", ">>> response.css('title::text').get()\n'Example website'\n", ">>> response.css('img').xpath('@src').getall()\n['image1_thumb.jpg',\n 'image2_thumb.jpg',\n 'image3_thumb.jpg',\n 'image4_thumb.jpg',\n 'image5_thumb.jpg']\n", ">>> response.xpath('//div[@id=\"images\"]/a/text()').get()\n'Name: My image 1 '\n", ">>> response.xpath('//div[@id=\"not-exists\"]/text()').get() is None\nTrue\n", ">>> response.xpath('//div[@id=\"not-exists\"]/text()').get(default='not-found')\n'not-found'\n", ">>> [img.attrib['src'] for img in response.css('img')]\n['image1_thumb.jpg',\n 'image2_thumb.jpg',\n 'image3_thumb.jpg',\n 'image4_thumb.jpg',\n 'image5_thumb.jpg']\n", ">>> response.css('img').attrib['src']\n'image1_thumb.jpg'\n", ">>> response.css('base').attrib['href']\n'http://example.com/'\n", ">>> response.xpath('//base/@href').get()\n'http://example.com/'\n", ">>> response.css('base::attr(href)').get()\n'http://example.com/'\n", ">>> response.css('base').attrib['href']\n'http://example.com/'\n", ">>> response.xpath('//a[contains(@href, \"image\")]/@href').getall()\n['image1.html',\n 'image2.html',\n 'image3.html',\n 'image4.html',\n 'image5.html']\n", ">>> response.css('a[href*=image]::attr(href)').getall()\n['image1.html',\n 'image2.html',\n 'image3.html',\n 'image4.html',\n 'image5.html']\n", ">>> response.xpath('//a[contains(@href, \"image\")]/img/@src').getall()\n['image1_thumb.jpg',\n 'image2_thumb.jpg',\n 'image3_thumb.jpg',\n 'image4_thumb.jpg',\n 'image5_thumb.jpg']\n", ">>> response.css('a[href*=image] img::attr(src)').getall()\n['image1_thumb.jpg',\n 'image2_thumb.jpg',\n 'image3_thumb.jpg',\n 'image4_thumb.jpg',\n 'image5_thumb.jpg']\n", ">>> response.css('title::text').get()\n'Example website'\n", ">>> response.css('#images *::text').getall()\n['\\n   ',\n 'Name: My image 1 ',\n '\\n   ',\n 'Name: My image 2 ',\n '\\n   ',\n 'Name: My image 3 ',\n '\\n   ',\n 'Name: My image 4 ',\n '\\n   ',\n 'Name: My image 5 ',\n '\\n  ']\n", ">>> response.css('img::text').getall()\n[]\n", ">>> response.css('img::text').get()\n>>> response.css('img::text').get(default='')\n''\n", ">>> response.css('a::attr(href)').getall()\n['image1.html',\n 'image2.html',\n 'image3.html',\n 'image4.html',\n 'image5.html']\n", ">>> links = response.xpath('//a[contains(@href, \"image\")]')\n>>> links.getall()\n['<a href=\"image1.html\">Name: My image 1 <br><img src=\"image1_thumb.jpg\"></a>',\n '<a href=\"image2.html\">Name: My image 2 <br><img src=\"image2_thumb.jpg\"></a>',\n '<a href=\"image3.html\">Name: My image 3 <br><img src=\"image3_thumb.jpg\"></a>',\n '<a href=\"image4.html\">Name: My image 4 <br><img src=\"image4_thumb.jpg\"></a>',\n '<a href=\"image5.html\">Name: My image 5 <br><img src=\"image5_thumb.jpg\"></a>']\n", ">>> for index, link in enumerate(links):\n...     href_xpath = link.xpath('@href').get()\n...     img_xpath = link.xpath('img/@src').get()\n...     print(f'Link number {index} points to url {href_xpath!r} and image {img_xpath!r}')\nLink number 0 points to url 'image1.html' and image 'image1_thumb.jpg'\nLink number 1 points to url 'image2.html' and image 'image2_thumb.jpg'\nLink number 2 points to url 'image3.html' and image 'image3_thumb.jpg'\nLink number 3 points to url 'image4.html' and image 'image4_thumb.jpg'\nLink number 4 points to url 'image5.html' and image 'image5_thumb.jpg'\n", ">>> response.xpath(\"//a/@href\").getall()\n['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']\n", ">>> response.css('a::attr(href)').getall()\n['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']\n", ">>> [a.attrib['href'] for a in response.css('a')]\n['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']\n", ">>> response.css('base').attrib\n{'href': 'http://example.com/'}\n>>> response.css('base').attrib['href']\n'http://example.com/'\n", ">>> response.css('foo').attrib\n{}\n", ">>> response.xpath('//a[contains(@href, \"image\")]/text()').re(r'Name:\\s*(.*)')\n['My image 1',\n 'My image 2',\n 'My image 3',\n 'My image 4',\n 'My image 5']\n", ">>> response.xpath('//a[contains(@href, \"image\")]/text()').re_first(r'Name:\\s*(.*)')\n'My image 1'\n", ">>> response.css('a::attr(href)').get()\n'image1.html'\n>>> response.css('a::attr(href)').extract_first()\n'image1.html'\n", ">>> response.css('a::attr(href)').getall()\n['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']\n>>> response.css('a::attr(href)').extract()\n['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']\n", ">>> response.css('a::attr(href)')[0].get()\n'image1.html'\n>>> response.css('a::attr(href)')[0].extract()\n'image1.html'\n", ">>> response.css('a::attr(href)')[0].getall()\n['image1.html']\n"], "index": 41}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Constructing selectors", "header_href": "#constructing-selectors", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//span/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'good'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//span/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'good'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'good'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.selector</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">body</span> <span class=\"o\">=</span> <span class=\"s1\">'&lt;html&gt;&lt;body&gt;&lt;span&gt;good&lt;/span&gt;&lt;/body&gt;&lt;/html&gt;'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">body</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//span/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'good'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.selector</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.http</span> <span class=\"kn\">import</span> <span class=\"n\">HtmlResponse</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">HtmlResponse</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s1\">'http://example.com'</span><span class=\"p\">,</span> <span class=\"n\">body</span><span class=\"o\">=</span><span class=\"n\">body</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//span/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'good'</span>\n</pre></div>"], "codes_text": [">>> response.selector.xpath('//span/text()').get()\n'good'\n", ">>> response.xpath('//span/text()').get()\n'good'\n>>> response.css('span::text').get()\n'good'\n", ">>> from scrapy.selector import Selector\n>>> body = '<html><body><span>good</span></body></html>'\n>>> Selector(text=body).xpath('//span/text()').get()\n'good'\n", ">>> from scrapy.selector import Selector\n>>> from scrapy.http import HtmlResponse\n>>> response = HtmlResponse(url='http://example.com', body=body)\n>>> Selector(response=response).xpath('//span/text()').get()\n'good'\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Using selectors", "header_href": "#id1", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"cp\">&lt;!DOCTYPE html&gt;</span>\n\n<span class=\"p\">&lt;</span><span class=\"nt\">html</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">head</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">base</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'http://example.com/'</span> <span class=\"p\">/&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">title</span><span class=\"p\">&gt;</span>Example website<span class=\"p\">&lt;/</span><span class=\"nt\">title</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;/</span><span class=\"nt\">head</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">body</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">id</span><span class=\"o\">=</span><span class=\"s\">'images'</span><span class=\"p\">&gt;</span>\n      <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'image1.html'</span><span class=\"p\">&gt;</span>Name: My image 1 <span class=\"p\">&lt;</span><span class=\"nt\">br</span> <span class=\"p\">/&gt;&lt;</span><span class=\"nt\">img</span> <span class=\"na\">src</span><span class=\"o\">=</span><span class=\"s\">'image1_thumb.jpg'</span> <span class=\"na\">alt</span><span class=\"o\">=</span><span class=\"s\">'image1'</span><span class=\"p\">/&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n      <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'image2.html'</span><span class=\"p\">&gt;</span>Name: My image 2 <span class=\"p\">&lt;</span><span class=\"nt\">br</span> <span class=\"p\">/&gt;&lt;</span><span class=\"nt\">img</span> <span class=\"na\">src</span><span class=\"o\">=</span><span class=\"s\">'image2_thumb.jpg'</span> <span class=\"na\">alt</span><span class=\"o\">=</span><span class=\"s\">'image2'</span><span class=\"p\">/&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n      <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'image3.html'</span><span class=\"p\">&gt;</span>Name: My image 3 <span class=\"p\">&lt;</span><span class=\"nt\">br</span> <span class=\"p\">/&gt;&lt;</span><span class=\"nt\">img</span> <span class=\"na\">src</span><span class=\"o\">=</span><span class=\"s\">'image3_thumb.jpg'</span> <span class=\"na\">alt</span><span class=\"o\">=</span><span class=\"s\">'image3'</span><span class=\"p\">/&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n      <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'image4.html'</span><span class=\"p\">&gt;</span>Name: My image 4 <span class=\"p\">&lt;</span><span class=\"nt\">br</span> <span class=\"p\">/&gt;&lt;</span><span class=\"nt\">img</span> <span class=\"na\">src</span><span class=\"o\">=</span><span class=\"s\">'image4_thumb.jpg'</span> <span class=\"na\">alt</span><span class=\"o\">=</span><span class=\"s\">'image4'</span><span class=\"p\">/&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n      <span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">'image5.html'</span><span class=\"p\">&gt;</span>Name: My image 5 <span class=\"p\">&lt;</span><span class=\"nt\">br</span> <span class=\"p\">/&gt;&lt;</span><span class=\"nt\">img</span> <span class=\"na\">src</span><span class=\"o\">=</span><span class=\"s\">'image5_thumb.jpg'</span> <span class=\"na\">alt</span><span class=\"o\">=</span><span class=\"s\">'image5'</span><span class=\"p\">/&gt;&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;/</span><span class=\"nt\">body</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;/</span><span class=\"nt\">html</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>scrapy shell https://docs.scrapy.org/en/latest/_static/selectors-sample1.html\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='//title/text()' data='Example website'&gt;]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['Example website']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Example website'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Example website'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'@src'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1_thumb.jpg',</span>\n<span class=\"go\"> 'image2_thumb.jpg',</span>\n<span class=\"go\"> 'image3_thumb.jpg',</span>\n<span class=\"go\"> 'image4_thumb.jpg',</span>\n<span class=\"go\"> 'image5_thumb.jpg']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[@id=\"images\"]/a/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Name: My image 1 '</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[@id=\"not-exists\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span> <span class=\"ow\">is</span> <span class=\"kc\">None</span>\n<span class=\"go\">True</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[@id=\"not-exists\"]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">default</span><span class=\"o\">=</span><span class=\"s1\">'not-found'</span><span class=\"p\">)</span>\n<span class=\"go\">'not-found'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"p\">[</span><span class=\"n\">img</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'src'</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">img</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img'</span><span class=\"p\">)]</span>\n<span class=\"go\">['image1_thumb.jpg',</span>\n<span class=\"go\"> 'image2_thumb.jpg',</span>\n<span class=\"go\"> 'image3_thumb.jpg',</span>\n<span class=\"go\"> 'image4_thumb.jpg',</span>\n<span class=\"go\"> 'image5_thumb.jpg']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'src'</span><span class=\"p\">]</span>\n<span class=\"go\">'image1_thumb.jpg'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'base'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'href'</span><span class=\"p\">]</span>\n<span class=\"go\">'http://example.com/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//base/@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'http://example.com/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'base::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'http://example.com/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'base'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'href'</span><span class=\"p\">]</span>\n<span class=\"go\">'http://example.com/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[contains(@href, \"image\")]/@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html',</span>\n<span class=\"go\"> 'image2.html',</span>\n<span class=\"go\"> 'image3.html',</span>\n<span class=\"go\"> 'image4.html',</span>\n<span class=\"go\"> 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a[href*=image]::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html',</span>\n<span class=\"go\"> 'image2.html',</span>\n<span class=\"go\"> 'image3.html',</span>\n<span class=\"go\"> 'image4.html',</span>\n<span class=\"go\"> 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[contains(@href, \"image\")]/img/@src'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1_thumb.jpg',</span>\n<span class=\"go\"> 'image2_thumb.jpg',</span>\n<span class=\"go\"> 'image3_thumb.jpg',</span>\n<span class=\"go\"> 'image4_thumb.jpg',</span>\n<span class=\"go\"> 'image5_thumb.jpg']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a[href*=image] img::attr(src)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1_thumb.jpg',</span>\n<span class=\"go\"> 'image2_thumb.jpg',</span>\n<span class=\"go\"> 'image3_thumb.jpg',</span>\n<span class=\"go\"> 'image4_thumb.jpg',</span>\n<span class=\"go\"> 'image5_thumb.jpg']</span>\n</pre></div>"], "codes_text": ["<!DOCTYPE html>\n\n<html>\n  <head>\n    <base href='http://example.com/' />\n    <title>Example website</title>\n  </head>\n  <body>\n    <div id='images'>\n      <a href='image1.html'>Name: My image 1 <br /><img src='image1_thumb.jpg' alt='image1'/></a>\n      <a href='image2.html'>Name: My image 2 <br /><img src='image2_thumb.jpg' alt='image2'/></a>\n      <a href='image3.html'>Name: My image 3 <br /><img src='image3_thumb.jpg' alt='image3'/></a>\n      <a href='image4.html'>Name: My image 4 <br /><img src='image4_thumb.jpg' alt='image4'/></a>\n      <a href='image5.html'>Name: My image 5 <br /><img src='image5_thumb.jpg' alt='image5'/></a>\n    </div>\n  </body>\n</html>\n", "scrapy shell https://docs.scrapy.org/en/latest/_static/selectors-sample1.html\n", ">>> response.xpath('//title/text()')\n[<Selector xpath='//title/text()' data='Example website'>]\n", ">>> response.xpath('//title/text()').getall()\n['Example website']\n>>> response.xpath('//title/text()').get()\n'Example website'\n", ">>> response.css('title::text').get()\n'Example website'\n", ">>> response.css('img').xpath('@src').getall()\n['image1_thumb.jpg',\n 'image2_thumb.jpg',\n 'image3_thumb.jpg',\n 'image4_thumb.jpg',\n 'image5_thumb.jpg']\n", ">>> response.xpath('//div[@id=\"images\"]/a/text()').get()\n'Name: My image 1 '\n", ">>> response.xpath('//div[@id=\"not-exists\"]/text()').get() is None\nTrue\n", ">>> response.xpath('//div[@id=\"not-exists\"]/text()').get(default='not-found')\n'not-found'\n", ">>> [img.attrib['src'] for img in response.css('img')]\n['image1_thumb.jpg',\n 'image2_thumb.jpg',\n 'image3_thumb.jpg',\n 'image4_thumb.jpg',\n 'image5_thumb.jpg']\n", ">>> response.css('img').attrib['src']\n'image1_thumb.jpg'\n", ">>> response.css('base').attrib['href']\n'http://example.com/'\n", ">>> response.xpath('//base/@href').get()\n'http://example.com/'\n", ">>> response.css('base::attr(href)').get()\n'http://example.com/'\n", ">>> response.css('base').attrib['href']\n'http://example.com/'\n", ">>> response.xpath('//a[contains(@href, \"image\")]/@href').getall()\n['image1.html',\n 'image2.html',\n 'image3.html',\n 'image4.html',\n 'image5.html']\n", ">>> response.css('a[href*=image]::attr(href)').getall()\n['image1.html',\n 'image2.html',\n 'image3.html',\n 'image4.html',\n 'image5.html']\n", ">>> response.xpath('//a[contains(@href, \"image\")]/img/@src').getall()\n['image1_thumb.jpg',\n 'image2_thumb.jpg',\n 'image3_thumb.jpg',\n 'image4_thumb.jpg',\n 'image5_thumb.jpg']\n", ">>> response.css('a[href*=image] img::attr(src)').getall()\n['image1_thumb.jpg',\n 'image2_thumb.jpg',\n 'image3_thumb.jpg',\n 'image4_thumb.jpg',\n 'image5_thumb.jpg']\n"], "index": 19}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Extensions to CSS Selectors", "header_href": "#extensions-to-css-selectors", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'title::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Example website'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'#images *::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['\\n   ',</span>\n<span class=\"go\"> 'Name: My image 1 ',</span>\n<span class=\"go\"> '\\n   ',</span>\n<span class=\"go\"> 'Name: My image 2 ',</span>\n<span class=\"go\"> '\\n   ',</span>\n<span class=\"go\"> 'Name: My image 3 ',</span>\n<span class=\"go\"> '\\n   ',</span>\n<span class=\"go\"> 'Name: My image 4 ',</span>\n<span class=\"go\"> '\\n   ',</span>\n<span class=\"go\"> 'Name: My image 5 ',</span>\n<span class=\"go\"> '\\n  ']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">[]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'img::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">default</span><span class=\"o\">=</span><span class=\"s1\">''</span><span class=\"p\">)</span>\n<span class=\"go\">''</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html',</span>\n<span class=\"go\"> 'image2.html',</span>\n<span class=\"go\"> 'image3.html',</span>\n<span class=\"go\"> 'image4.html',</span>\n<span class=\"go\"> 'image5.html']</span>\n</pre></div>"], "codes_text": [">>> response.css('title::text').get()\n'Example website'\n", ">>> response.css('#images *::text').getall()\n['\\n   ',\n 'Name: My image 1 ',\n '\\n   ',\n 'Name: My image 2 ',\n '\\n   ',\n 'Name: My image 3 ',\n '\\n   ',\n 'Name: My image 4 ',\n '\\n   ',\n 'Name: My image 5 ',\n '\\n  ']\n", ">>> response.css('img::text').getall()\n[]\n", ">>> response.css('img::text').get()\n>>> response.css('img::text').get(default='')\n''\n", ">>> response.css('a::attr(href)').getall()\n['image1.html',\n 'image2.html',\n 'image3.html',\n 'image4.html',\n 'image5.html']\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Nesting selectors", "header_href": "#nesting-selectors", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">links</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[contains(@href, \"image\")]'</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">links</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['&lt;a href=\"image1.html\"&gt;Name: My image 1 &lt;br&gt;&lt;img src=\"image1_thumb.jpg\"&gt;&lt;/a&gt;',</span>\n<span class=\"go\"> '&lt;a href=\"image2.html\"&gt;Name: My image 2 &lt;br&gt;&lt;img src=\"image2_thumb.jpg\"&gt;&lt;/a&gt;',</span>\n<span class=\"go\"> '&lt;a href=\"image3.html\"&gt;Name: My image 3 &lt;br&gt;&lt;img src=\"image3_thumb.jpg\"&gt;&lt;/a&gt;',</span>\n<span class=\"go\"> '&lt;a href=\"image4.html\"&gt;Name: My image 4 &lt;br&gt;&lt;img src=\"image4_thumb.jpg\"&gt;&lt;/a&gt;',</span>\n<span class=\"go\"> '&lt;a href=\"image5.html\"&gt;Name: My image 5 &lt;br&gt;&lt;img src=\"image5_thumb.jpg\"&gt;&lt;/a&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">index</span><span class=\"p\">,</span> <span class=\"n\">link</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">links</span><span class=\"p\">):</span>\n<span class=\"gp\">... </span>    <span class=\"n\">href_xpath</span> <span class=\"o\">=</span> <span class=\"n\">link</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"n\">img_xpath</span> <span class=\"o\">=</span> <span class=\"n\">link</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'img/@src'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'Link number </span><span class=\"si\">{</span><span class=\"n\">index</span><span class=\"si\">}</span><span class=\"s1\"> points to url </span><span class=\"si\">{</span><span class=\"n\">href_xpath</span><span class=\"si\">!r}</span><span class=\"s1\"> and image </span><span class=\"si\">{</span><span class=\"n\">img_xpath</span><span class=\"si\">!r}</span><span class=\"s1\">'</span><span class=\"p\">)</span>\n<span class=\"go\">Link number 0 points to url 'image1.html' and image 'image1_thumb.jpg'</span>\n<span class=\"go\">Link number 1 points to url 'image2.html' and image 'image2_thumb.jpg'</span>\n<span class=\"go\">Link number 2 points to url 'image3.html' and image 'image3_thumb.jpg'</span>\n<span class=\"go\">Link number 3 points to url 'image4.html' and image 'image4_thumb.jpg'</span>\n<span class=\"go\">Link number 4 points to url 'image5.html' and image 'image5_thumb.jpg'</span>\n</pre></div>"], "codes_text": [">>> links = response.xpath('//a[contains(@href, \"image\")]')\n>>> links.getall()\n['<a href=\"image1.html\">Name: My image 1 <br><img src=\"image1_thumb.jpg\"></a>',\n '<a href=\"image2.html\">Name: My image 2 <br><img src=\"image2_thumb.jpg\"></a>',\n '<a href=\"image3.html\">Name: My image 3 <br><img src=\"image3_thumb.jpg\"></a>',\n '<a href=\"image4.html\">Name: My image 4 <br><img src=\"image4_thumb.jpg\"></a>',\n '<a href=\"image5.html\">Name: My image 5 <br><img src=\"image5_thumb.jpg\"></a>']\n", ">>> for index, link in enumerate(links):\n...     href_xpath = link.xpath('@href').get()\n...     img_xpath = link.xpath('img/@src').get()\n...     print(f'Link number {index} points to url {href_xpath!r} and image {img_xpath!r}')\nLink number 0 points to url 'image1.html' and image 'image1_thumb.jpg'\nLink number 1 points to url 'image2.html' and image 'image2_thumb.jpg'\nLink number 2 points to url 'image3.html' and image 'image3_thumb.jpg'\nLink number 3 points to url 'image4.html' and image 'image4_thumb.jpg'\nLink number 4 points to url 'image5.html' and image 'image5_thumb.jpg'\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Selecting element attributes", "header_href": "#selecting-element-attributes", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//a/@href\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"p\">[</span><span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'href'</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a'</span><span class=\"p\">)]</span>\n<span class=\"go\">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'base'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span>\n<span class=\"go\">{'href': 'http://example.com/'}</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'base'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'href'</span><span class=\"p\">]</span>\n<span class=\"go\">'http://example.com/'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'foo'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">attrib</span>\n<span class=\"go\">{}</span>\n</pre></div>"], "codes_text": [">>> response.xpath(\"//a/@href\").getall()\n['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']\n", ">>> response.css('a::attr(href)').getall()\n['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']\n", ">>> [a.attrib['href'] for a in response.css('a')]\n['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']\n", ">>> response.css('base').attrib\n{'href': 'http://example.com/'}\n>>> response.css('base').attrib['href']\n'http://example.com/'\n", ">>> response.css('foo').attrib\n{}\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Using selectors with regular expressions", "header_href": "#using-selectors-with-regular-expressions", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[contains(@href, \"image\")]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'Name:\\s*(.*)'</span><span class=\"p\">)</span>\n<span class=\"go\">['My image 1',</span>\n<span class=\"go\"> 'My image 2',</span>\n<span class=\"go\"> 'My image 3',</span>\n<span class=\"go\"> 'My image 4',</span>\n<span class=\"go\"> 'My image 5']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[contains(@href, \"image\")]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re_first</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'Name:\\s*(.*)'</span><span class=\"p\">)</span>\n<span class=\"go\">'My image 1'</span>\n</pre></div>"], "codes_text": [">>> response.xpath('//a[contains(@href, \"image\")]/text()').re(r'Name:\\s*(.*)')\n['My image 1',\n 'My image 2',\n 'My image 3',\n 'My image 4',\n 'My image 5']\n", ">>> response.xpath('//a[contains(@href, \"image\")]/text()').re_first(r'Name:\\s*(.*)')\n'My image 1'\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "extract() and extract_first()", "header_href": "#extract-and-extract-first", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'image1.html'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">extract_first</span><span class=\"p\">()</span>\n<span class=\"go\">'image1.html'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">extract</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'image1.html'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">extract</span><span class=\"p\">()</span>\n<span class=\"go\">'image1.html'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'a::attr(href)'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['image1.html']</span>\n</pre></div>"], "codes_text": [">>> response.css('a::attr(href)').get()\n'image1.html'\n>>> response.css('a::attr(href)').extract_first()\n'image1.html'\n", ">>> response.css('a::attr(href)').getall()\n['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']\n>>> response.css('a::attr(href)').extract()\n['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']\n", ">>> response.css('a::attr(href)')[0].get()\n'image1.html'\n>>> response.css('a::attr(href)')[0].extract()\n'image1.html'\n", ">>> response.css('a::attr(href)')[0].getall()\n['image1.html']\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Working with XPaths", "header_href": "#working-with-xpaths", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">divs</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">divs</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p'</span><span class=\"p\">):</span>  <span class=\"c1\"># this is wrong - gets all &lt;p&gt; from the whole document</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">())</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">divs</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'.//p'</span><span class=\"p\">):</span>  <span class=\"c1\"># extracts all &lt;p&gt; inside</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">())</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">divs</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'p'</span><span class=\"p\">):</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">())</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">*</span><span class=\"p\">[</span><span class=\"n\">contains</span><span class=\"p\">(</span><span class=\"n\">concat</span><span class=\"p\">(</span><span class=\"s1\">' '</span><span class=\"p\">,</span> <span class=\"n\">normalize</span><span class=\"o\">-</span><span class=\"n\">space</span><span class=\"p\">(</span><span class=\"nd\">@class</span><span class=\"p\">),</span> <span class=\"s1\">' '</span><span class=\"p\">),</span> <span class=\"s1\">' someclass '</span><span class=\"p\">)]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s1\">'&lt;div class=\"hero shout\"&gt;&lt;time datetime=\"2014-07-23 19:00\"&gt;Special date&lt;/time&gt;&lt;/div&gt;'</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'.shout'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'./time/@datetime'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['2014-07-23 19:00']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s2\">\"\"\"</span>\n<span class=\"go\">....:     &lt;ul class=\"list\"&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;1&lt;/li&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;2&lt;/li&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;3&lt;/li&gt;</span>\n<span class=\"go\">....:     &lt;/ul&gt;</span>\n<span class=\"go\">....:     &lt;ul class=\"list\"&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;4&lt;/li&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;5&lt;/li&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;6&lt;/li&gt;</span>\n<span class=\"go\">....:     &lt;/ul&gt;\"\"\")</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xp</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xp</span><span class=\"p\">(</span><span class=\"s2\">\"//li[1]\"</span><span class=\"p\">)</span>\n<span class=\"go\">['&lt;li&gt;1&lt;/li&gt;', '&lt;li&gt;4&lt;/li&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xp</span><span class=\"p\">(</span><span class=\"s2\">\"(//li)[1]\"</span><span class=\"p\">)</span>\n<span class=\"go\">['&lt;li&gt;1&lt;/li&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xp</span><span class=\"p\">(</span><span class=\"s2\">\"//ul/li[1]\"</span><span class=\"p\">)</span>\n<span class=\"go\">['&lt;li&gt;1&lt;/li&gt;', '&lt;li&gt;4&lt;/li&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xp</span><span class=\"p\">(</span><span class=\"s2\">\"(//ul/li)[1]\"</span><span class=\"p\">)</span>\n<span class=\"go\">['&lt;li&gt;1&lt;/li&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s1\">'&lt;a href=\"#\"&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a//text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span> <span class=\"c1\"># take a peek at the node-set</span>\n<span class=\"go\">['Click here to go to the ', 'Next Page']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"string(//a[1]//text())\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span> <span class=\"c1\"># convert it to string</span>\n<span class=\"go\">['Click here to go to the ']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//a[1]\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span> <span class=\"c1\"># select the first node</span>\n<span class=\"go\">['&lt;a href=\"#\"&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"string(//a[1])\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span> <span class=\"c1\"># convert it to string</span>\n<span class=\"go\">['Click here to go to the Next Page']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//a[contains(.//text(), 'Next Page')]\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">[]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//a[contains(., 'Next Page')]\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['&lt;a href=\"#\"&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"c1\"># `$val` used in the expression, a `val` argument needs to be passed</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[@id=$val]/a/text()'</span><span class=\"p\">,</span> <span class=\"n\">val</span><span class=\"o\">=</span><span class=\"s1\">'images'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Name: My image 1 '</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[count(a)=$cnt]/@id'</span><span class=\"p\">,</span> <span class=\"n\">cnt</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'images'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy shell https://feeds.feedburner.com/PythonInsider\n</pre></div>", "<div class=\"highlight\"><pre><span></span>&lt;?xml <span class=\"nv\">version</span><span class=\"o\">=</span><span class=\"s2\">\"1.0\"</span> <span class=\"nv\">encoding</span><span class=\"o\">=</span><span class=\"s2\">\"UTF-8\"</span>?&gt;\n&lt;?xml-stylesheet ...\n&lt;feed <span class=\"nv\">xmlns</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.w3.org/2005/Atom\"</span>\n      xmlns:openSearch<span class=\"o\">=</span><span class=\"s2\">\"http://a9.com/-/spec/opensearchrss/1.0/\"</span>\n      xmlns:blogger<span class=\"o\">=</span><span class=\"s2\">\"http://schemas.google.com/blogger/2008\"</span>\n      xmlns:georss<span class=\"o\">=</span><span class=\"s2\">\"http://www.georss.org/georss\"</span>\n      xmlns:gd<span class=\"o\">=</span><span class=\"s2\">\"http://schemas.google.com/g/2005\"</span>\n      xmlns:thr<span class=\"o\">=</span><span class=\"s2\">\"http://purl.org/syndication/thread/1.0\"</span>\n      xmlns:feedburner<span class=\"o\">=</span><span class=\"s2\">\"http://rssnamespace.org/feedburner/ext/1.0\"</span>&gt;\n  ...\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//link\"</span><span class=\"p\">)</span>\n<span class=\"go\">[]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">remove_namespaces</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//link\"</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='//link' data='&lt;link rel=\"alternate\" type=\"text/html\" h'&gt;,</span>\n<span class=\"go\">    &lt;Selector xpath='//link' data='&lt;link rel=\"next\" type=\"application/atom+'&gt;,</span>\n<span class=\"go\">    ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"s2\">\"\"\"</span>\n<span class=\"gp\">... </span><span class=\"s2\">&lt;div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;ul&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-0\"&gt;&lt;a href=\"link1.html\"&gt;first item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-1\"&gt;&lt;a href=\"link2.html\"&gt;second item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-inactive\"&gt;&lt;a href=\"link3.html\"&gt;third item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-1\"&gt;&lt;a href=\"link4.html\"&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-0\"&gt;&lt;a href=\"link5.html\"&gt;fifth item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;/ul&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">&lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">\"\"\"</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">doc</span><span class=\"p\">,</span> <span class=\"nb\">type</span><span class=\"o\">=</span><span class=\"s2\">\"html\"</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//li//@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//li[re:test(@class, \"item-\\d$\")]//@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['link1.html', 'link2.html', 'link4.html', 'link5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"s2\">\"\"\"</span>\n<span class=\"gp\">... </span><span class=\"s2\">&lt;div itemscope itemtype=\"http://schema.org/Product\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;span itemprop=\"name\"&gt;Kenmore White 17\" Microwave&lt;/span&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;img src=\"kenmore-microwave-17in.jpg\" alt='Kenmore 17\" Microwave' /&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;div itemprop=\"aggregateRating\"</span>\n<span class=\"gp\">... </span><span class=\"s2\">    itemscope itemtype=\"http://schema.org/AggregateRating\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">   Rated &lt;span itemprop=\"ratingValue\"&gt;3.5&lt;/span&gt;/5</span>\n<span class=\"gp\">... </span><span class=\"s2\">   based on &lt;span itemprop=\"reviewCount\"&gt;11&lt;/span&gt; customer reviews</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;/div&gt;</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;div itemprop=\"offers\" itemscope itemtype=\"http://schema.org/Offer\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"price\"&gt;$55.00&lt;/span&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;link itemprop=\"availability\" href=\"http://schema.org/InStock\" /&gt;In stock</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;/div&gt;</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  Product description:</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;span itemprop=\"description\"&gt;0.7 cubic feet countertop microwave.</span>\n<span class=\"gp\">... </span><span class=\"s2\">  Has six preset cooking categories and convenience features like</span>\n<span class=\"gp\">... </span><span class=\"s2\">  Add-A-Minute and Child Lock.&lt;/span&gt;</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  Customer reviews:</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"name\"&gt;Not a happy camper&lt;/span&gt; -</span>\n<span class=\"gp\">... </span><span class=\"s2\">    by &lt;span itemprop=\"author\"&gt;Ellie&lt;/span&gt;,</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;meta itemprop=\"datePublished\" content=\"2011-04-01\"&gt;April 1, 2011</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;meta itemprop=\"worstRating\" content = \"1\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;span itemprop=\"ratingValue\"&gt;1&lt;/span&gt;/</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;span itemprop=\"bestRating\"&gt;5&lt;/span&gt;stars</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"description\"&gt;The lamp burned out and now I have to replace</span>\n<span class=\"gp\">... </span><span class=\"s2\">    it. &lt;/span&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;/div&gt;</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"name\"&gt;Value purchase&lt;/span&gt; -</span>\n<span class=\"gp\">... </span><span class=\"s2\">    by &lt;span itemprop=\"author\"&gt;Lucas&lt;/span&gt;,</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;meta itemprop=\"datePublished\" content=\"2011-03-25\"&gt;March 25, 2011</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;meta itemprop=\"worstRating\" content = \"1\"/&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;span itemprop=\"ratingValue\"&gt;4&lt;/span&gt;/</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;span itemprop=\"bestRating\"&gt;5&lt;/span&gt;stars</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"description\"&gt;Great microwave for the price. It is small and</span>\n<span class=\"gp\">... </span><span class=\"s2\">    fits in my apartment.&lt;/span&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  ...</span>\n<span class=\"gp\">... </span><span class=\"s2\">&lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">\"\"\"</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">doc</span><span class=\"p\">,</span> <span class=\"nb\">type</span><span class=\"o\">=</span><span class=\"s2\">\"html\"</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">scope</span> <span class=\"ow\">in</span> <span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[@itemscope]'</span><span class=\"p\">):</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"current scope:\"</span><span class=\"p\">,</span> <span class=\"n\">scope</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'@itemtype'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">())</span>\n<span class=\"gp\">... </span>    <span class=\"n\">props</span> <span class=\"o\">=</span> <span class=\"n\">scope</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'''</span>\n<span class=\"gp\">... </span><span class=\"s1\">                set:difference(./descendant::*/@itemprop,</span>\n<span class=\"gp\">... </span><span class=\"s1\">                               .//*[@itemscope]/*/@itemprop)'''</span><span class=\"p\">)</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"    properties: </span><span class=\"si\">{</span><span class=\"n\">props</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"\"</span><span class=\"p\">)</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Product']</span>\n<span class=\"go\">    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/AggregateRating']</span>\n<span class=\"go\">    properties: ['ratingValue', 'reviewCount']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Offer']</span>\n<span class=\"go\">    properties: ['price', 'availability']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Review']</span>\n<span class=\"go\">    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Rating']</span>\n<span class=\"go\">    properties: ['worstRating', 'ratingValue', 'bestRating']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Review']</span>\n<span class=\"go\">    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Rating']</span>\n<span class=\"go\">    properties: ['worstRating', 'ratingValue', 'bestRating']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">p</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"foo bar-baz\"</span><span class=\"p\">&gt;</span>First<span class=\"p\">&lt;/</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;</span><span class=\"nt\">p</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"foo\"</span><span class=\"p\">&gt;</span>Second<span class=\"p\">&lt;/</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;</span><span class=\"nt\">p</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"bar\"</span><span class=\"p\">&gt;</span>Third<span class=\"p\">&lt;/</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>Fourth<span class=\"p\">&lt;/</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[has-class(\"foo\")]'</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='//p[has-class(\"foo\")]' data='&lt;p class=\"foo bar-baz\"&gt;First&lt;/p&gt;'&gt;,</span>\n<span class=\"go\"> &lt;Selector xpath='//p[has-class(\"foo\")]' data='&lt;p class=\"foo\"&gt;Second&lt;/p&gt;'&gt;]</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[has-class(\"foo\", \"bar-baz\")]'</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='//p[has-class(\"foo\", \"bar-baz\")]' data='&lt;p class=\"foo bar-baz\"&gt;First&lt;/p&gt;'&gt;]</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[has-class(\"foo\", \"bar\")]'</span><span class=\"p\">)</span>\n<span class=\"go\">[]</span>\n</pre></div>"], "codes_text": [">>> divs = response.xpath('//div')\n", ">>> for p in divs.xpath('//p'):  # this is wrong - gets all <p> from the whole document\n...     print(p.get())\n", ">>> for p in divs.xpath('.//p'):  # extracts all <p> inside\n...     print(p.get())\n", ">>> for p in divs.xpath('p'):\n...     print(p.get())\n", "*[contains(concat(' ', normalize-space(@class), ' '), ' someclass ')]\n", ">>> from scrapy import Selector\n>>> sel = Selector(text='<div class=\"hero shout\"><time datetime=\"2014-07-23 19:00\">Special date</time></div>')\n>>> sel.css('.shout').xpath('./time/@datetime').getall()\n['2014-07-23 19:00']\n", ">>> from scrapy import Selector\n>>> sel = Selector(text=\"\"\"\n....:     <ul class=\"list\">\n....:         <li>1</li>\n....:         <li>2</li>\n....:         <li>3</li>\n....:     </ul>\n....:     <ul class=\"list\">\n....:         <li>4</li>\n....:         <li>5</li>\n....:         <li>6</li>\n....:     </ul>\"\"\")\n>>> xp = lambda x: sel.xpath(x).getall()\n", ">>> xp(\"//li[1]\")\n['<li>1</li>', '<li>4</li>']\n", ">>> xp(\"(//li)[1]\")\n['<li>1</li>']\n", ">>> xp(\"//ul/li[1]\")\n['<li>1</li>', '<li>4</li>']\n", ">>> xp(\"(//ul/li)[1]\")\n['<li>1</li>']\n", ">>> from scrapy import Selector\n>>> sel = Selector(text='<a href=\"#\">Click here to go to the <strong>Next Page</strong></a>')\n", ">>> sel.xpath('//a//text()').getall() # take a peek at the node-set\n['Click here to go to the ', 'Next Page']\n>>> sel.xpath(\"string(//a[1]//text())\").getall() # convert it to string\n['Click here to go to the ']\n", ">>> sel.xpath(\"//a[1]\").getall() # select the first node\n['<a href=\"#\">Click here to go to the <strong>Next Page</strong></a>']\n>>> sel.xpath(\"string(//a[1])\").getall() # convert it to string\n['Click here to go to the Next Page']\n", ">>> sel.xpath(\"//a[contains(.//text(), 'Next Page')]\").getall()\n[]\n", ">>> sel.xpath(\"//a[contains(., 'Next Page')]\").getall()\n['<a href=\"#\">Click here to go to the <strong>Next Page</strong></a>']\n", ">>> # `$val` used in the expression, a `val` argument needs to be passed\n>>> response.xpath('//div[@id=$val]/a/text()', val='images').get()\n'Name: My image 1 '\n", ">>> response.xpath('//div[count(a)=$cnt]/@id', cnt=5).get()\n'images'\n", "$ scrapy shell https://feeds.feedburner.com/PythonInsider\n", "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<?xml-stylesheet ...\n<feed xmlns=\"http://www.w3.org/2005/Atom\"\n      xmlns:openSearch=\"http://a9.com/-/spec/opensearchrss/1.0/\"\n      xmlns:blogger=\"http://schemas.google.com/blogger/2008\"\n      xmlns:georss=\"http://www.georss.org/georss\"\n      xmlns:gd=\"http://schemas.google.com/g/2005\"\n      xmlns:thr=\"http://purl.org/syndication/thread/1.0\"\n      xmlns:feedburner=\"http://rssnamespace.org/feedburner/ext/1.0\">\n  ...\n", ">>> response.xpath(\"//link\")\n[]\n", ">>> response.selector.remove_namespaces()\n>>> response.xpath(\"//link\")\n[<Selector xpath='//link' data='<link rel=\"alternate\" type=\"text/html\" h'>,\n    <Selector xpath='//link' data='<link rel=\"next\" type=\"application/atom+'>,\n    ...\n", ">>> from scrapy import Selector\n>>> doc = \"\"\"\n... <div>\n...     <ul>\n...         <li class=\"item-0\"><a href=\"link1.html\">first item</a></li>\n...         <li class=\"item-1\"><a href=\"link2.html\">second item</a></li>\n...         <li class=\"item-inactive\"><a href=\"link3.html\">third item</a></li>\n...         <li class=\"item-1\"><a href=\"link4.html\">fourth item</a></li>\n...         <li class=\"item-0\"><a href=\"link5.html\">fifth item</a></li>\n...     </ul>\n... </div>\n... \"\"\"\n>>> sel = Selector(text=doc, type=\"html\")\n>>> sel.xpath('//li//@href').getall()\n['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']\n>>> sel.xpath('//li[re:test(@class, \"item-\\d$\")]//@href').getall()\n['link1.html', 'link2.html', 'link4.html', 'link5.html']\n", ">>> doc = \"\"\"\n... <div itemscope itemtype=\"http://schema.org/Product\">\n...   <span itemprop=\"name\">Kenmore White 17\" Microwave</span>\n...   <img src=\"kenmore-microwave-17in.jpg\" alt='Kenmore 17\" Microwave' />\n...   <div itemprop=\"aggregateRating\"\n...     itemscope itemtype=\"http://schema.org/AggregateRating\">\n...    Rated <span itemprop=\"ratingValue\">3.5</span>/5\n...    based on <span itemprop=\"reviewCount\">11</span> customer reviews\n...   </div>\n...\n...   <div itemprop=\"offers\" itemscope itemtype=\"http://schema.org/Offer\">\n...     <span itemprop=\"price\">$55.00</span>\n...     <link itemprop=\"availability\" href=\"http://schema.org/InStock\" />In stock\n...   </div>\n...\n...   Product description:\n...   <span itemprop=\"description\">0.7 cubic feet countertop microwave.\n...   Has six preset cooking categories and convenience features like\n...   Add-A-Minute and Child Lock.</span>\n...\n...   Customer reviews:\n...\n...   <div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\">\n...     <span itemprop=\"name\">Not a happy camper</span> -\n...     by <span itemprop=\"author\">Ellie</span>,\n...     <meta itemprop=\"datePublished\" content=\"2011-04-01\">April 1, 2011\n...     <div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\">\n...       <meta itemprop=\"worstRating\" content = \"1\">\n...       <span itemprop=\"ratingValue\">1</span>/\n...       <span itemprop=\"bestRating\">5</span>stars\n...     </div>\n...     <span itemprop=\"description\">The lamp burned out and now I have to replace\n...     it. </span>\n...   </div>\n...\n...   <div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\">\n...     <span itemprop=\"name\">Value purchase</span> -\n...     by <span itemprop=\"author\">Lucas</span>,\n...     <meta itemprop=\"datePublished\" content=\"2011-03-25\">March 25, 2011\n...     <div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\">\n...       <meta itemprop=\"worstRating\" content = \"1\"/>\n...       <span itemprop=\"ratingValue\">4</span>/\n...       <span itemprop=\"bestRating\">5</span>stars\n...     </div>\n...     <span itemprop=\"description\">Great microwave for the price. It is small and\n...     fits in my apartment.</span>\n...   </div>\n...   ...\n... </div>\n... \"\"\"\n>>> sel = Selector(text=doc, type=\"html\")\n>>> for scope in sel.xpath('//div[@itemscope]'):\n...     print(\"current scope:\", scope.xpath('@itemtype').getall())\n...     props = scope.xpath('''\n...                 set:difference(./descendant::*/@itemprop,\n...                                .//*[@itemscope]/*/@itemprop)''')\n...     print(f\"    properties: {props.getall()}\")\n...     print(\"\")\n\ncurrent scope: ['http://schema.org/Product']\n    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']\n\ncurrent scope: ['http://schema.org/AggregateRating']\n    properties: ['ratingValue', 'reviewCount']\n\ncurrent scope: ['http://schema.org/Offer']\n    properties: ['price', 'availability']\n\ncurrent scope: ['http://schema.org/Review']\n    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']\n\ncurrent scope: ['http://schema.org/Rating']\n    properties: ['worstRating', 'ratingValue', 'bestRating']\n\ncurrent scope: ['http://schema.org/Review']\n    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']\n\ncurrent scope: ['http://schema.org/Rating']\n    properties: ['worstRating', 'ratingValue', 'bestRating']\n", "<p class=\"foo bar-baz\">First</p>\n<p class=\"foo\">Second</p>\n<p class=\"bar\">Third</p>\n<p>Fourth</p>\n", ">>> response.xpath('//p[has-class(\"foo\")]')\n[<Selector xpath='//p[has-class(\"foo\")]' data='<p class=\"foo bar-baz\">First</p>'>,\n <Selector xpath='//p[has-class(\"foo\")]' data='<p class=\"foo\">Second</p>'>]\n>>> response.xpath('//p[has-class(\"foo\", \"bar-baz\")]')\n[<Selector xpath='//p[has-class(\"foo\", \"bar-baz\")]' data='<p class=\"foo bar-baz\">First</p>'>]\n>>> response.xpath('//p[has-class(\"foo\", \"bar\")]')\n[]\n"], "index": 26}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Working with relative XPaths", "header_href": "#working-with-relative-xpaths", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">divs</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">divs</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p'</span><span class=\"p\">):</span>  <span class=\"c1\"># this is wrong - gets all &lt;p&gt; from the whole document</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">())</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">divs</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'.//p'</span><span class=\"p\">):</span>  <span class=\"c1\"># extracts all &lt;p&gt; inside</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">())</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">divs</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'p'</span><span class=\"p\">):</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">())</span>\n</pre></div>"], "codes_text": [">>> divs = response.xpath('//div')\n", ">>> for p in divs.xpath('//p'):  # this is wrong - gets all <p> from the whole document\n...     print(p.get())\n", ">>> for p in divs.xpath('.//p'):  # extracts all <p> inside\n...     print(p.get())\n", ">>> for p in divs.xpath('p'):\n...     print(p.get())\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "When querying by class, consider using CSS", "header_href": "#when-querying-by-class-consider-using-css", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"o\">*</span><span class=\"p\">[</span><span class=\"n\">contains</span><span class=\"p\">(</span><span class=\"n\">concat</span><span class=\"p\">(</span><span class=\"s1\">' '</span><span class=\"p\">,</span> <span class=\"n\">normalize</span><span class=\"o\">-</span><span class=\"n\">space</span><span class=\"p\">(</span><span class=\"nd\">@class</span><span class=\"p\">),</span> <span class=\"s1\">' '</span><span class=\"p\">),</span> <span class=\"s1\">' someclass '</span><span class=\"p\">)]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s1\">'&lt;div class=\"hero shout\"&gt;&lt;time datetime=\"2014-07-23 19:00\"&gt;Special date&lt;/time&gt;&lt;/div&gt;'</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'.shout'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'./time/@datetime'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['2014-07-23 19:00']</span>\n</pre></div>"], "codes_text": ["*[contains(concat(' ', normalize-space(@class), ' '), ' someclass ')]\n", ">>> from scrapy import Selector\n>>> sel = Selector(text='<div class=\"hero shout\"><time datetime=\"2014-07-23 19:00\">Special date</time></div>')\n>>> sel.css('.shout').xpath('./time/@datetime').getall()\n['2014-07-23 19:00']\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Beware of the difference between //node[1] and (//node)[1]", "header_href": "#beware-of-the-difference-between-node-1-and-node-1", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s2\">\"\"\"</span>\n<span class=\"go\">....:     &lt;ul class=\"list\"&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;1&lt;/li&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;2&lt;/li&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;3&lt;/li&gt;</span>\n<span class=\"go\">....:     &lt;/ul&gt;</span>\n<span class=\"go\">....:     &lt;ul class=\"list\"&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;4&lt;/li&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;5&lt;/li&gt;</span>\n<span class=\"go\">....:         &lt;li&gt;6&lt;/li&gt;</span>\n<span class=\"go\">....:     &lt;/ul&gt;\"\"\")</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xp</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xp</span><span class=\"p\">(</span><span class=\"s2\">\"//li[1]\"</span><span class=\"p\">)</span>\n<span class=\"go\">['&lt;li&gt;1&lt;/li&gt;', '&lt;li&gt;4&lt;/li&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xp</span><span class=\"p\">(</span><span class=\"s2\">\"(//li)[1]\"</span><span class=\"p\">)</span>\n<span class=\"go\">['&lt;li&gt;1&lt;/li&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xp</span><span class=\"p\">(</span><span class=\"s2\">\"//ul/li[1]\"</span><span class=\"p\">)</span>\n<span class=\"go\">['&lt;li&gt;1&lt;/li&gt;', '&lt;li&gt;4&lt;/li&gt;']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xp</span><span class=\"p\">(</span><span class=\"s2\">\"(//ul/li)[1]\"</span><span class=\"p\">)</span>\n<span class=\"go\">['&lt;li&gt;1&lt;/li&gt;']</span>\n</pre></div>"], "codes_text": [">>> from scrapy import Selector\n>>> sel = Selector(text=\"\"\"\n....:     <ul class=\"list\">\n....:         <li>1</li>\n....:         <li>2</li>\n....:         <li>3</li>\n....:     </ul>\n....:     <ul class=\"list\">\n....:         <li>4</li>\n....:         <li>5</li>\n....:         <li>6</li>\n....:     </ul>\"\"\")\n>>> xp = lambda x: sel.xpath(x).getall()\n", ">>> xp(\"//li[1]\")\n['<li>1</li>', '<li>4</li>']\n", ">>> xp(\"(//li)[1]\")\n['<li>1</li>']\n", ">>> xp(\"//ul/li[1]\")\n['<li>1</li>', '<li>4</li>']\n", ">>> xp(\"(//ul/li)[1]\")\n['<li>1</li>']\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Using text nodes in a condition", "header_href": "#using-text-nodes-in-a-condition", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"s1\">'&lt;a href=\"#\"&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a//text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span> <span class=\"c1\"># take a peek at the node-set</span>\n<span class=\"go\">['Click here to go to the ', 'Next Page']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"string(//a[1]//text())\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span> <span class=\"c1\"># convert it to string</span>\n<span class=\"go\">['Click here to go to the ']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//a[1]\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span> <span class=\"c1\"># select the first node</span>\n<span class=\"go\">['&lt;a href=\"#\"&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"string(//a[1])\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span> <span class=\"c1\"># convert it to string</span>\n<span class=\"go\">['Click here to go to the Next Page']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//a[contains(.//text(), 'Next Page')]\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">[]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//a[contains(., 'Next Page')]\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['&lt;a href=\"#\"&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;']</span>\n</pre></div>"], "codes_text": [">>> from scrapy import Selector\n>>> sel = Selector(text='<a href=\"#\">Click here to go to the <strong>Next Page</strong></a>')\n", ">>> sel.xpath('//a//text()').getall() # take a peek at the node-set\n['Click here to go to the ', 'Next Page']\n>>> sel.xpath(\"string(//a[1]//text())\").getall() # convert it to string\n['Click here to go to the ']\n", ">>> sel.xpath(\"//a[1]\").getall() # select the first node\n['<a href=\"#\">Click here to go to the <strong>Next Page</strong></a>']\n>>> sel.xpath(\"string(//a[1])\").getall() # convert it to string\n['Click here to go to the Next Page']\n", ">>> sel.xpath(\"//a[contains(.//text(), 'Next Page')]\").getall()\n[]\n", ">>> sel.xpath(\"//a[contains(., 'Next Page')]\").getall()\n['<a href=\"#\">Click here to go to the <strong>Next Page</strong></a>']\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Variables in XPath expressions", "header_href": "#variables-in-xpath-expressions", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"c1\"># `$val` used in the expression, a `val` argument needs to be passed</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[@id=$val]/a/text()'</span><span class=\"p\">,</span> <span class=\"n\">val</span><span class=\"o\">=</span><span class=\"s1\">'images'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Name: My image 1 '</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[count(a)=$cnt]/@id'</span><span class=\"p\">,</span> <span class=\"n\">cnt</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'images'</span>\n</pre></div>"], "codes_text": [">>> # `$val` used in the expression, a `val` argument needs to be passed\n>>> response.xpath('//div[@id=$val]/a/text()', val='images').get()\n'Name: My image 1 '\n", ">>> response.xpath('//div[count(a)=$cnt]/@id', cnt=5).get()\n'images'\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Removing namespaces", "header_href": "#removing-namespaces", "codes": ["<div class=\"highlight\"><pre><span></span>$ scrapy shell https://feeds.feedburner.com/PythonInsider\n</pre></div>", "<div class=\"highlight\"><pre><span></span>&lt;?xml <span class=\"nv\">version</span><span class=\"o\">=</span><span class=\"s2\">\"1.0\"</span> <span class=\"nv\">encoding</span><span class=\"o\">=</span><span class=\"s2\">\"UTF-8\"</span>?&gt;\n&lt;?xml-stylesheet ...\n&lt;feed <span class=\"nv\">xmlns</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.w3.org/2005/Atom\"</span>\n      xmlns:openSearch<span class=\"o\">=</span><span class=\"s2\">\"http://a9.com/-/spec/opensearchrss/1.0/\"</span>\n      xmlns:blogger<span class=\"o\">=</span><span class=\"s2\">\"http://schemas.google.com/blogger/2008\"</span>\n      xmlns:georss<span class=\"o\">=</span><span class=\"s2\">\"http://www.georss.org/georss\"</span>\n      xmlns:gd<span class=\"o\">=</span><span class=\"s2\">\"http://schemas.google.com/g/2005\"</span>\n      xmlns:thr<span class=\"o\">=</span><span class=\"s2\">\"http://purl.org/syndication/thread/1.0\"</span>\n      xmlns:feedburner<span class=\"o\">=</span><span class=\"s2\">\"http://rssnamespace.org/feedburner/ext/1.0\"</span>&gt;\n  ...\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//link\"</span><span class=\"p\">)</span>\n<span class=\"go\">[]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">remove_namespaces</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//link\"</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='//link' data='&lt;link rel=\"alternate\" type=\"text/html\" h'&gt;,</span>\n<span class=\"go\">    &lt;Selector xpath='//link' data='&lt;link rel=\"next\" type=\"application/atom+'&gt;,</span>\n<span class=\"go\">    ...</span>\n</pre></div>"], "codes_text": ["$ scrapy shell https://feeds.feedburner.com/PythonInsider\n", "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<?xml-stylesheet ...\n<feed xmlns=\"http://www.w3.org/2005/Atom\"\n      xmlns:openSearch=\"http://a9.com/-/spec/opensearchrss/1.0/\"\n      xmlns:blogger=\"http://schemas.google.com/blogger/2008\"\n      xmlns:georss=\"http://www.georss.org/georss\"\n      xmlns:gd=\"http://schemas.google.com/g/2005\"\n      xmlns:thr=\"http://purl.org/syndication/thread/1.0\"\n      xmlns:feedburner=\"http://rssnamespace.org/feedburner/ext/1.0\">\n  ...\n", ">>> response.xpath(\"//link\")\n[]\n", ">>> response.selector.remove_namespaces()\n>>> response.xpath(\"//link\")\n[<Selector xpath='//link' data='<link rel=\"alternate\" type=\"text/html\" h'>,\n    <Selector xpath='//link' data='<link rel=\"next\" type=\"application/atom+'>,\n    ...\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Using EXSLT extensions", "header_href": "#using-exslt-extensions", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"s2\">\"\"\"</span>\n<span class=\"gp\">... </span><span class=\"s2\">&lt;div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;ul&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-0\"&gt;&lt;a href=\"link1.html\"&gt;first item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-1\"&gt;&lt;a href=\"link2.html\"&gt;second item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-inactive\"&gt;&lt;a href=\"link3.html\"&gt;third item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-1\"&gt;&lt;a href=\"link4.html\"&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-0\"&gt;&lt;a href=\"link5.html\"&gt;fifth item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;/ul&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">&lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">\"\"\"</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">doc</span><span class=\"p\">,</span> <span class=\"nb\">type</span><span class=\"o\">=</span><span class=\"s2\">\"html\"</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//li//@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//li[re:test(@class, \"item-\\d$\")]//@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['link1.html', 'link2.html', 'link4.html', 'link5.html']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"s2\">\"\"\"</span>\n<span class=\"gp\">... </span><span class=\"s2\">&lt;div itemscope itemtype=\"http://schema.org/Product\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;span itemprop=\"name\"&gt;Kenmore White 17\" Microwave&lt;/span&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;img src=\"kenmore-microwave-17in.jpg\" alt='Kenmore 17\" Microwave' /&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;div itemprop=\"aggregateRating\"</span>\n<span class=\"gp\">... </span><span class=\"s2\">    itemscope itemtype=\"http://schema.org/AggregateRating\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">   Rated &lt;span itemprop=\"ratingValue\"&gt;3.5&lt;/span&gt;/5</span>\n<span class=\"gp\">... </span><span class=\"s2\">   based on &lt;span itemprop=\"reviewCount\"&gt;11&lt;/span&gt; customer reviews</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;/div&gt;</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;div itemprop=\"offers\" itemscope itemtype=\"http://schema.org/Offer\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"price\"&gt;$55.00&lt;/span&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;link itemprop=\"availability\" href=\"http://schema.org/InStock\" /&gt;In stock</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;/div&gt;</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  Product description:</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;span itemprop=\"description\"&gt;0.7 cubic feet countertop microwave.</span>\n<span class=\"gp\">... </span><span class=\"s2\">  Has six preset cooking categories and convenience features like</span>\n<span class=\"gp\">... </span><span class=\"s2\">  Add-A-Minute and Child Lock.&lt;/span&gt;</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  Customer reviews:</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"name\"&gt;Not a happy camper&lt;/span&gt; -</span>\n<span class=\"gp\">... </span><span class=\"s2\">    by &lt;span itemprop=\"author\"&gt;Ellie&lt;/span&gt;,</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;meta itemprop=\"datePublished\" content=\"2011-04-01\"&gt;April 1, 2011</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;meta itemprop=\"worstRating\" content = \"1\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;span itemprop=\"ratingValue\"&gt;1&lt;/span&gt;/</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;span itemprop=\"bestRating\"&gt;5&lt;/span&gt;stars</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"description\"&gt;The lamp burned out and now I have to replace</span>\n<span class=\"gp\">... </span><span class=\"s2\">    it. &lt;/span&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;/div&gt;</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"name\"&gt;Value purchase&lt;/span&gt; -</span>\n<span class=\"gp\">... </span><span class=\"s2\">    by &lt;span itemprop=\"author\"&gt;Lucas&lt;/span&gt;,</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;meta itemprop=\"datePublished\" content=\"2011-03-25\"&gt;March 25, 2011</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;meta itemprop=\"worstRating\" content = \"1\"/&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;span itemprop=\"ratingValue\"&gt;4&lt;/span&gt;/</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;span itemprop=\"bestRating\"&gt;5&lt;/span&gt;stars</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"description\"&gt;Great microwave for the price. It is small and</span>\n<span class=\"gp\">... </span><span class=\"s2\">    fits in my apartment.&lt;/span&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  ...</span>\n<span class=\"gp\">... </span><span class=\"s2\">&lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">\"\"\"</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">doc</span><span class=\"p\">,</span> <span class=\"nb\">type</span><span class=\"o\">=</span><span class=\"s2\">\"html\"</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">scope</span> <span class=\"ow\">in</span> <span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[@itemscope]'</span><span class=\"p\">):</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"current scope:\"</span><span class=\"p\">,</span> <span class=\"n\">scope</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'@itemtype'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">())</span>\n<span class=\"gp\">... </span>    <span class=\"n\">props</span> <span class=\"o\">=</span> <span class=\"n\">scope</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'''</span>\n<span class=\"gp\">... </span><span class=\"s1\">                set:difference(./descendant::*/@itemprop,</span>\n<span class=\"gp\">... </span><span class=\"s1\">                               .//*[@itemscope]/*/@itemprop)'''</span><span class=\"p\">)</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"    properties: </span><span class=\"si\">{</span><span class=\"n\">props</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"\"</span><span class=\"p\">)</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Product']</span>\n<span class=\"go\">    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/AggregateRating']</span>\n<span class=\"go\">    properties: ['ratingValue', 'reviewCount']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Offer']</span>\n<span class=\"go\">    properties: ['price', 'availability']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Review']</span>\n<span class=\"go\">    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Rating']</span>\n<span class=\"go\">    properties: ['worstRating', 'ratingValue', 'bestRating']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Review']</span>\n<span class=\"go\">    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Rating']</span>\n<span class=\"go\">    properties: ['worstRating', 'ratingValue', 'bestRating']</span>\n</pre></div>"], "codes_text": [">>> from scrapy import Selector\n>>> doc = \"\"\"\n... <div>\n...     <ul>\n...         <li class=\"item-0\"><a href=\"link1.html\">first item</a></li>\n...         <li class=\"item-1\"><a href=\"link2.html\">second item</a></li>\n...         <li class=\"item-inactive\"><a href=\"link3.html\">third item</a></li>\n...         <li class=\"item-1\"><a href=\"link4.html\">fourth item</a></li>\n...         <li class=\"item-0\"><a href=\"link5.html\">fifth item</a></li>\n...     </ul>\n... </div>\n... \"\"\"\n>>> sel = Selector(text=doc, type=\"html\")\n>>> sel.xpath('//li//@href').getall()\n['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']\n>>> sel.xpath('//li[re:test(@class, \"item-\\d$\")]//@href').getall()\n['link1.html', 'link2.html', 'link4.html', 'link5.html']\n", ">>> doc = \"\"\"\n... <div itemscope itemtype=\"http://schema.org/Product\">\n...   <span itemprop=\"name\">Kenmore White 17\" Microwave</span>\n...   <img src=\"kenmore-microwave-17in.jpg\" alt='Kenmore 17\" Microwave' />\n...   <div itemprop=\"aggregateRating\"\n...     itemscope itemtype=\"http://schema.org/AggregateRating\">\n...    Rated <span itemprop=\"ratingValue\">3.5</span>/5\n...    based on <span itemprop=\"reviewCount\">11</span> customer reviews\n...   </div>\n...\n...   <div itemprop=\"offers\" itemscope itemtype=\"http://schema.org/Offer\">\n...     <span itemprop=\"price\">$55.00</span>\n...     <link itemprop=\"availability\" href=\"http://schema.org/InStock\" />In stock\n...   </div>\n...\n...   Product description:\n...   <span itemprop=\"description\">0.7 cubic feet countertop microwave.\n...   Has six preset cooking categories and convenience features like\n...   Add-A-Minute and Child Lock.</span>\n...\n...   Customer reviews:\n...\n...   <div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\">\n...     <span itemprop=\"name\">Not a happy camper</span> -\n...     by <span itemprop=\"author\">Ellie</span>,\n...     <meta itemprop=\"datePublished\" content=\"2011-04-01\">April 1, 2011\n...     <div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\">\n...       <meta itemprop=\"worstRating\" content = \"1\">\n...       <span itemprop=\"ratingValue\">1</span>/\n...       <span itemprop=\"bestRating\">5</span>stars\n...     </div>\n...     <span itemprop=\"description\">The lamp burned out and now I have to replace\n...     it. </span>\n...   </div>\n...\n...   <div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\">\n...     <span itemprop=\"name\">Value purchase</span> -\n...     by <span itemprop=\"author\">Lucas</span>,\n...     <meta itemprop=\"datePublished\" content=\"2011-03-25\">March 25, 2011\n...     <div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\">\n...       <meta itemprop=\"worstRating\" content = \"1\"/>\n...       <span itemprop=\"ratingValue\">4</span>/\n...       <span itemprop=\"bestRating\">5</span>stars\n...     </div>\n...     <span itemprop=\"description\">Great microwave for the price. It is small and\n...     fits in my apartment.</span>\n...   </div>\n...   ...\n... </div>\n... \"\"\"\n>>> sel = Selector(text=doc, type=\"html\")\n>>> for scope in sel.xpath('//div[@itemscope]'):\n...     print(\"current scope:\", scope.xpath('@itemtype').getall())\n...     props = scope.xpath('''\n...                 set:difference(./descendant::*/@itemprop,\n...                                .//*[@itemscope]/*/@itemprop)''')\n...     print(f\"    properties: {props.getall()}\")\n...     print(\"\")\n\ncurrent scope: ['http://schema.org/Product']\n    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']\n\ncurrent scope: ['http://schema.org/AggregateRating']\n    properties: ['ratingValue', 'reviewCount']\n\ncurrent scope: ['http://schema.org/Offer']\n    properties: ['price', 'availability']\n\ncurrent scope: ['http://schema.org/Review']\n    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']\n\ncurrent scope: ['http://schema.org/Rating']\n    properties: ['worstRating', 'ratingValue', 'bestRating']\n\ncurrent scope: ['http://schema.org/Review']\n    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']\n\ncurrent scope: ['http://schema.org/Rating']\n    properties: ['worstRating', 'ratingValue', 'bestRating']\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Regular expressions", "header_href": "#regular-expressions", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"s2\">\"\"\"</span>\n<span class=\"gp\">... </span><span class=\"s2\">&lt;div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;ul&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-0\"&gt;&lt;a href=\"link1.html\"&gt;first item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-1\"&gt;&lt;a href=\"link2.html\"&gt;second item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-inactive\"&gt;&lt;a href=\"link3.html\"&gt;third item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-1\"&gt;&lt;a href=\"link4.html\"&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">        &lt;li class=\"item-0\"&gt;&lt;a href=\"link5.html\"&gt;fifth item&lt;/a&gt;&lt;/li&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;/ul&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">&lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">\"\"\"</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">doc</span><span class=\"p\">,</span> <span class=\"nb\">type</span><span class=\"o\">=</span><span class=\"s2\">\"html\"</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//li//@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//li[re:test(@class, \"item-\\d$\")]//@href'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['link1.html', 'link2.html', 'link4.html', 'link5.html']</span>\n</pre></div>"], "codes_text": [">>> from scrapy import Selector\n>>> doc = \"\"\"\n... <div>\n...     <ul>\n...         <li class=\"item-0\"><a href=\"link1.html\">first item</a></li>\n...         <li class=\"item-1\"><a href=\"link2.html\">second item</a></li>\n...         <li class=\"item-inactive\"><a href=\"link3.html\">third item</a></li>\n...         <li class=\"item-1\"><a href=\"link4.html\">fourth item</a></li>\n...         <li class=\"item-0\"><a href=\"link5.html\">fifth item</a></li>\n...     </ul>\n... </div>\n... \"\"\"\n>>> sel = Selector(text=doc, type=\"html\")\n>>> sel.xpath('//li//@href').getall()\n['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']\n>>> sel.xpath('//li[re:test(@class, \"item-\\d$\")]//@href').getall()\n['link1.html', 'link2.html', 'link4.html', 'link5.html']\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Set operations", "header_href": "#set-operations", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"s2\">\"\"\"</span>\n<span class=\"gp\">... </span><span class=\"s2\">&lt;div itemscope itemtype=\"http://schema.org/Product\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;span itemprop=\"name\"&gt;Kenmore White 17\" Microwave&lt;/span&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;img src=\"kenmore-microwave-17in.jpg\" alt='Kenmore 17\" Microwave' /&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;div itemprop=\"aggregateRating\"</span>\n<span class=\"gp\">... </span><span class=\"s2\">    itemscope itemtype=\"http://schema.org/AggregateRating\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">   Rated &lt;span itemprop=\"ratingValue\"&gt;3.5&lt;/span&gt;/5</span>\n<span class=\"gp\">... </span><span class=\"s2\">   based on &lt;span itemprop=\"reviewCount\"&gt;11&lt;/span&gt; customer reviews</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;/div&gt;</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;div itemprop=\"offers\" itemscope itemtype=\"http://schema.org/Offer\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"price\"&gt;$55.00&lt;/span&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;link itemprop=\"availability\" href=\"http://schema.org/InStock\" /&gt;In stock</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;/div&gt;</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  Product description:</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;span itemprop=\"description\"&gt;0.7 cubic feet countertop microwave.</span>\n<span class=\"gp\">... </span><span class=\"s2\">  Has six preset cooking categories and convenience features like</span>\n<span class=\"gp\">... </span><span class=\"s2\">  Add-A-Minute and Child Lock.&lt;/span&gt;</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  Customer reviews:</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"name\"&gt;Not a happy camper&lt;/span&gt; -</span>\n<span class=\"gp\">... </span><span class=\"s2\">    by &lt;span itemprop=\"author\"&gt;Ellie&lt;/span&gt;,</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;meta itemprop=\"datePublished\" content=\"2011-04-01\"&gt;April 1, 2011</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;meta itemprop=\"worstRating\" content = \"1\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;span itemprop=\"ratingValue\"&gt;1&lt;/span&gt;/</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;span itemprop=\"bestRating\"&gt;5&lt;/span&gt;stars</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"description\"&gt;The lamp burned out and now I have to replace</span>\n<span class=\"gp\">... </span><span class=\"s2\">    it. &lt;/span&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;/div&gt;</span>\n<span class=\"gp\">...</span><span class=\"s2\"></span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"name\"&gt;Value purchase&lt;/span&gt; -</span>\n<span class=\"gp\">... </span><span class=\"s2\">    by &lt;span itemprop=\"author\"&gt;Lucas&lt;/span&gt;,</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;meta itemprop=\"datePublished\" content=\"2011-03-25\"&gt;March 25, 2011</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\"&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;meta itemprop=\"worstRating\" content = \"1\"/&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;span itemprop=\"ratingValue\"&gt;4&lt;/span&gt;/</span>\n<span class=\"gp\">... </span><span class=\"s2\">      &lt;span itemprop=\"bestRating\"&gt;5&lt;/span&gt;stars</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">    &lt;span itemprop=\"description\"&gt;Great microwave for the price. It is small and</span>\n<span class=\"gp\">... </span><span class=\"s2\">    fits in my apartment.&lt;/span&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  &lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">  ...</span>\n<span class=\"gp\">... </span><span class=\"s2\">&lt;/div&gt;</span>\n<span class=\"gp\">... </span><span class=\"s2\">\"\"\"</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">doc</span><span class=\"p\">,</span> <span class=\"nb\">type</span><span class=\"o\">=</span><span class=\"s2\">\"html\"</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">for</span> <span class=\"n\">scope</span> <span class=\"ow\">in</span> <span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//div[@itemscope]'</span><span class=\"p\">):</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"current scope:\"</span><span class=\"p\">,</span> <span class=\"n\">scope</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'@itemtype'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">())</span>\n<span class=\"gp\">... </span>    <span class=\"n\">props</span> <span class=\"o\">=</span> <span class=\"n\">scope</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'''</span>\n<span class=\"gp\">... </span><span class=\"s1\">                set:difference(./descendant::*/@itemprop,</span>\n<span class=\"gp\">... </span><span class=\"s1\">                               .//*[@itemscope]/*/@itemprop)'''</span><span class=\"p\">)</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"    properties: </span><span class=\"si\">{</span><span class=\"n\">props</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n<span class=\"gp\">... </span>    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"\"</span><span class=\"p\">)</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Product']</span>\n<span class=\"go\">    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/AggregateRating']</span>\n<span class=\"go\">    properties: ['ratingValue', 'reviewCount']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Offer']</span>\n<span class=\"go\">    properties: ['price', 'availability']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Review']</span>\n<span class=\"go\">    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Rating']</span>\n<span class=\"go\">    properties: ['worstRating', 'ratingValue', 'bestRating']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Review']</span>\n<span class=\"go\">    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']</span>\n\n<span class=\"go\">current scope: ['http://schema.org/Rating']</span>\n<span class=\"go\">    properties: ['worstRating', 'ratingValue', 'bestRating']</span>\n</pre></div>"], "codes_text": [">>> doc = \"\"\"\n... <div itemscope itemtype=\"http://schema.org/Product\">\n...   <span itemprop=\"name\">Kenmore White 17\" Microwave</span>\n...   <img src=\"kenmore-microwave-17in.jpg\" alt='Kenmore 17\" Microwave' />\n...   <div itemprop=\"aggregateRating\"\n...     itemscope itemtype=\"http://schema.org/AggregateRating\">\n...    Rated <span itemprop=\"ratingValue\">3.5</span>/5\n...    based on <span itemprop=\"reviewCount\">11</span> customer reviews\n...   </div>\n...\n...   <div itemprop=\"offers\" itemscope itemtype=\"http://schema.org/Offer\">\n...     <span itemprop=\"price\">$55.00</span>\n...     <link itemprop=\"availability\" href=\"http://schema.org/InStock\" />In stock\n...   </div>\n...\n...   Product description:\n...   <span itemprop=\"description\">0.7 cubic feet countertop microwave.\n...   Has six preset cooking categories and convenience features like\n...   Add-A-Minute and Child Lock.</span>\n...\n...   Customer reviews:\n...\n...   <div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\">\n...     <span itemprop=\"name\">Not a happy camper</span> -\n...     by <span itemprop=\"author\">Ellie</span>,\n...     <meta itemprop=\"datePublished\" content=\"2011-04-01\">April 1, 2011\n...     <div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\">\n...       <meta itemprop=\"worstRating\" content = \"1\">\n...       <span itemprop=\"ratingValue\">1</span>/\n...       <span itemprop=\"bestRating\">5</span>stars\n...     </div>\n...     <span itemprop=\"description\">The lamp burned out and now I have to replace\n...     it. </span>\n...   </div>\n...\n...   <div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\">\n...     <span itemprop=\"name\">Value purchase</span> -\n...     by <span itemprop=\"author\">Lucas</span>,\n...     <meta itemprop=\"datePublished\" content=\"2011-03-25\">March 25, 2011\n...     <div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\">\n...       <meta itemprop=\"worstRating\" content = \"1\"/>\n...       <span itemprop=\"ratingValue\">4</span>/\n...       <span itemprop=\"bestRating\">5</span>stars\n...     </div>\n...     <span itemprop=\"description\">Great microwave for the price. It is small and\n...     fits in my apartment.</span>\n...   </div>\n...   ...\n... </div>\n... \"\"\"\n>>> sel = Selector(text=doc, type=\"html\")\n>>> for scope in sel.xpath('//div[@itemscope]'):\n...     print(\"current scope:\", scope.xpath('@itemtype').getall())\n...     props = scope.xpath('''\n...                 set:difference(./descendant::*/@itemprop,\n...                                .//*[@itemscope]/*/@itemprop)''')\n...     print(f\"    properties: {props.getall()}\")\n...     print(\"\")\n\ncurrent scope: ['http://schema.org/Product']\n    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']\n\ncurrent scope: ['http://schema.org/AggregateRating']\n    properties: ['ratingValue', 'reviewCount']\n\ncurrent scope: ['http://schema.org/Offer']\n    properties: ['price', 'availability']\n\ncurrent scope: ['http://schema.org/Review']\n    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']\n\ncurrent scope: ['http://schema.org/Rating']\n    properties: ['worstRating', 'ratingValue', 'bestRating']\n\ncurrent scope: ['http://schema.org/Review']\n    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']\n\ncurrent scope: ['http://schema.org/Rating']\n    properties: ['worstRating', 'ratingValue', 'bestRating']\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Other XPath extensions", "header_href": "#other-xpath-extensions", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">p</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"foo bar-baz\"</span><span class=\"p\">&gt;</span>First<span class=\"p\">&lt;/</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;</span><span class=\"nt\">p</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"foo\"</span><span class=\"p\">&gt;</span>Second<span class=\"p\">&lt;/</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;</span><span class=\"nt\">p</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"bar\"</span><span class=\"p\">&gt;</span>Third<span class=\"p\">&lt;/</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>Fourth<span class=\"p\">&lt;/</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[has-class(\"foo\")]'</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='//p[has-class(\"foo\")]' data='&lt;p class=\"foo bar-baz\"&gt;First&lt;/p&gt;'&gt;,</span>\n<span class=\"go\"> &lt;Selector xpath='//p[has-class(\"foo\")]' data='&lt;p class=\"foo\"&gt;Second&lt;/p&gt;'&gt;]</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[has-class(\"foo\", \"bar-baz\")]'</span><span class=\"p\">)</span>\n<span class=\"go\">[&lt;Selector xpath='//p[has-class(\"foo\", \"bar-baz\")]' data='&lt;p class=\"foo bar-baz\"&gt;First&lt;/p&gt;'&gt;]</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[has-class(\"foo\", \"bar\")]'</span><span class=\"p\">)</span>\n<span class=\"go\">[]</span>\n</pre></div>"], "codes_text": ["<p class=\"foo bar-baz\">First</p>\n<p class=\"foo\">Second</p>\n<p class=\"bar\">Third</p>\n<p>Fourth</p>\n", ">>> response.xpath('//p[has-class(\"foo\")]')\n[<Selector xpath='//p[has-class(\"foo\")]' data='<p class=\"foo bar-baz\">First</p>'>,\n <Selector xpath='//p[has-class(\"foo\")]' data='<p class=\"foo\">Second</p>'>]\n>>> response.xpath('//p[has-class(\"foo\", \"bar-baz\")]')\n[<Selector xpath='//p[has-class(\"foo\", \"bar-baz\")]' data='<p class=\"foo bar-baz\">First</p>'>]\n>>> response.xpath('//p[has-class(\"foo\", \"bar\")]')\n[]\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Built-in Selectors reference", "header_href": "#module-scrapy.selector", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[href=$url]'</span><span class=\"p\">,</span> <span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.example.com\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[href=$url]'</span><span class=\"p\">,</span> <span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.example.com\"</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["selector.xpath('//a[href=$url]', url=\"http://www.example.com\")\n", "selector.xpath('//a[href=$url]', url=\"http://www.example.com\")\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Selector objects", "header_href": "#selector-objects", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[href=$url]'</span><span class=\"p\">,</span> <span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.example.com\"</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["selector.xpath('//a[href=$url]', url=\"http://www.example.com\")\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "SelectorList objects", "header_href": "#selectorlist-objects", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a[href=$url]'</span><span class=\"p\">,</span> <span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.example.com\"</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["selector.xpath('//a[href=$url]', url=\"http://www.example.com\")\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Examples", "header_href": "#examples", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">html_response</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//h1\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//h1\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>         <span class=\"c1\"># this includes the h1 tag</span>\n<span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//h1/text()\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>  <span class=\"c1\"># this excludes the h1 tag</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">node</span> <span class=\"ow\">in</span> <span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//p\"</span><span class=\"p\">):</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'class'</span><span class=\"p\">])</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">xml_response</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//product\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">register_namespace</span><span class=\"p\">(</span><span class=\"s2\">\"g\"</span><span class=\"p\">,</span> <span class=\"s2\">\"http://base.google.com/ns/1.0\"</span><span class=\"p\">)</span>\n<span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//g:price\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n</pre></div>"], "codes_text": ["sel = Selector(html_response)\n", "sel.xpath(\"//h1\")\n", "sel.xpath(\"//h1\").getall()         # this includes the h1 tag\nsel.xpath(\"//h1/text()\").getall()  # this excludes the h1 tag\n", "for node in sel.xpath(\"//p\"):\n    print(node.attrib['class'])\n", "sel = Selector(xml_response)\n", "sel.xpath(\"//product\")\n", "sel.register_namespace(\"g\", \"http://base.google.com/ns/1.0\")\nsel.xpath(\"//g:price\").getall()\n"], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Selector examples on HTML response", "header_href": "#selector-examples-on-html-response", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">html_response</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//h1\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//h1\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>         <span class=\"c1\"># this includes the h1 tag</span>\n<span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//h1/text()\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>  <span class=\"c1\"># this excludes the h1 tag</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">node</span> <span class=\"ow\">in</span> <span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//p\"</span><span class=\"p\">):</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">'class'</span><span class=\"p\">])</span>\n</pre></div>"], "codes_text": ["sel = Selector(html_response)\n", "sel.xpath(\"//h1\")\n", "sel.xpath(\"//h1\").getall()         # this includes the h1 tag\nsel.xpath(\"//h1/text()\").getall()  # this excludes the h1 tag\n", "for node in sel.xpath(\"//p\"):\n    print(node.attrib['class'])\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/selectors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Selector examples on XML response", "header_href": "#selector-examples-on-xml-response", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">xml_response</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//product\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">register_namespace</span><span class=\"p\">(</span><span class=\"s2\">\"g\"</span><span class=\"p\">,</span> <span class=\"s2\">\"http://base.google.com/ns/1.0\"</span><span class=\"p\">)</span>\n<span class=\"n\">sel</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s2\">\"//g:price\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n</pre></div>"], "codes_text": ["sel = Selector(xml_response)\n", "sel.xpath(\"//product\")\n", "sel.register_namespace(\"g\", \"http://base.google.com/ns/1.0\")\nsel.xpath(\"//g:price\").getall()\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Items", "header_href": "#module-scrapy.item", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.item</span> <span class=\"kn\">import</span> <span class=\"n\">Item</span><span class=\"p\">,</span> <span class=\"n\">Field</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">CustomItem</span><span class=\"p\">(</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"n\">one_field</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">another_field</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">dataclasses</span> <span class=\"kn\">import</span> <span class=\"n\">dataclass</span>\n\n<span class=\"nd\">@dataclass</span>\n<span class=\"k\">class</span> <span class=\"nc\">CustomItem</span><span class=\"p\">:</span>\n    <span class=\"n\">one_field</span><span class=\"p\">:</span> <span class=\"nb\">str</span>\n    <span class=\"n\">another_field</span><span class=\"p\">:</span> <span class=\"nb\">int</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">attr</span>\n\n<span class=\"nd\">@attr</span><span class=\"o\">.</span><span class=\"n\">s</span>\n<span class=\"k\">class</span> <span class=\"nc\">CustomItem</span><span class=\"p\">:</span>\n    <span class=\"n\">one_field</span> <span class=\"o\">=</span> <span class=\"n\">attr</span><span class=\"o\">.</span><span class=\"n\">ib</span><span class=\"p\">()</span>\n    <span class=\"n\">another_field</span> <span class=\"o\">=</span> <span class=\"n\">attr</span><span class=\"o\">.</span><span class=\"n\">ib</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">Product</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">price</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">stock</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">tags</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">last_updated</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">(</span><span class=\"n\">serializer</span><span class=\"o\">=</span><span class=\"nb\">str</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span> <span class=\"o\">=</span> <span class=\"n\">Product</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'Desktop PC'</span><span class=\"p\">,</span> <span class=\"n\">price</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">product</span><span class=\"p\">)</span>\n<span class=\"go\">Product(name='Desktop PC', price=1000)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span>\n<span class=\"go\">Desktop PC</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">)</span>\n<span class=\"go\">Desktop PC</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'price'</span><span class=\"p\">]</span>\n<span class=\"go\">1000</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'last_updated'</span><span class=\"p\">]</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">KeyError</span>: <span class=\"n\">'last_updated'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'last_updated'</span><span class=\"p\">,</span> <span class=\"s1\">'not set'</span><span class=\"p\">)</span>\n<span class=\"go\">not set</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'lala'</span><span class=\"p\">]</span> <span class=\"c1\"># getting unknown field</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">KeyError</span>: <span class=\"n\">'lala'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'lala'</span><span class=\"p\">,</span> <span class=\"s1\">'unknown field'</span><span class=\"p\">)</span>\n<span class=\"go\">'unknown field'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"s1\">'name'</span> <span class=\"ow\">in</span> <span class=\"n\">product</span>  <span class=\"c1\"># is name field populated?</span>\n<span class=\"go\">True</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"s1\">'last_updated'</span> <span class=\"ow\">in</span> <span class=\"n\">product</span>  <span class=\"c1\"># is last_updated populated?</span>\n<span class=\"go\">False</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"s1\">'last_updated'</span> <span class=\"ow\">in</span> <span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">fields</span>  <span class=\"c1\"># is last_updated a declared field?</span>\n<span class=\"go\">True</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"s1\">'lala'</span> <span class=\"ow\">in</span> <span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">fields</span>  <span class=\"c1\"># is lala a declared field?</span>\n<span class=\"go\">False</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'last_updated'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'today'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'last_updated'</span><span class=\"p\">]</span>\n<span class=\"go\">today</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'lala'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'test'</span> <span class=\"c1\"># setting unknown field</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">KeyError</span>: <span class=\"n\">'Product does not support field: lala'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">keys</span><span class=\"p\">()</span>\n<span class=\"go\">['price', 'name']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">()</span>\n<span class=\"go\">[('price', 1000), ('name', 'Desktop PC')]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">product</span><span class=\"p\">)</span> <span class=\"c1\"># create a dict from all populated values</span>\n<span class=\"go\">{'price': 1000, 'name': 'Desktop PC'}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">Product</span><span class=\"p\">({</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'Laptop PC'</span><span class=\"p\">,</span> <span class=\"s1\">'price'</span><span class=\"p\">:</span> <span class=\"mi\">1500</span><span class=\"p\">})</span>\n<span class=\"go\">Product(price=1500, name='Laptop PC')</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">Product</span><span class=\"p\">({</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'Laptop PC'</span><span class=\"p\">,</span> <span class=\"s1\">'lala'</span><span class=\"p\">:</span> <span class=\"mi\">1500</span><span class=\"p\">})</span> <span class=\"c1\"># warning: unknown field in dict</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">KeyError</span>: <span class=\"n\">'Product does not support field: lala'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">DiscountedProduct</span><span class=\"p\">(</span><span class=\"n\">Product</span><span class=\"p\">):</span>\n    <span class=\"n\">discount_percent</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">(</span><span class=\"n\">serializer</span><span class=\"o\">=</span><span class=\"nb\">str</span><span class=\"p\">)</span>\n    <span class=\"n\">discount_expiration_date</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">SpecificProduct</span><span class=\"p\">(</span><span class=\"n\">Product</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">(</span><span class=\"n\">Product</span><span class=\"o\">.</span><span class=\"n\">fields</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">],</span> <span class=\"n\">serializer</span><span class=\"o\">=</span><span class=\"n\">my_serializer</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["from scrapy.item import Item, Field\n\nclass CustomItem(Item):\n    one_field = Field()\n    another_field = Field()\n", "from dataclasses import dataclass\n\n@dataclass\nclass CustomItem:\n    one_field: str\n    another_field: int\n", "import attr\n\n@attr.s\nclass CustomItem:\n    one_field = attr.ib()\n    another_field = attr.ib()\n", "import scrapy\n\nclass Product(scrapy.Item):\n    name = scrapy.Field()\n    price = scrapy.Field()\n    stock = scrapy.Field()\n    tags = scrapy.Field()\n    last_updated = scrapy.Field(serializer=str)\n", ">>> product = Product(name='Desktop PC', price=1000)\n>>> print(product)\nProduct(name='Desktop PC', price=1000)\n", ">>> product['name']\nDesktop PC\n>>> product.get('name')\nDesktop PC\n", ">>> product['price']\n1000\n", ">>> product['last_updated']\nTraceback (most recent call last):\n    ...\nKeyError: 'last_updated'\n", ">>> product.get('last_updated', 'not set')\nnot set\n", ">>> product['lala'] # getting unknown field\nTraceback (most recent call last):\n    ...\nKeyError: 'lala'\n", ">>> product.get('lala', 'unknown field')\n'unknown field'\n", ">>> 'name' in product  # is name field populated?\nTrue\n", ">>> 'last_updated' in product  # is last_updated populated?\nFalse\n", ">>> 'last_updated' in product.fields  # is last_updated a declared field?\nTrue\n", ">>> 'lala' in product.fields  # is lala a declared field?\nFalse\n", ">>> product['last_updated'] = 'today'\n>>> product['last_updated']\ntoday\n", ">>> product['lala'] = 'test' # setting unknown field\nTraceback (most recent call last):\n    ...\nKeyError: 'Product does not support field: lala'\n", ">>> product.keys()\n['price', 'name']\n", ">>> product.items()\n[('price', 1000), ('name', 'Desktop PC')]\n", ">>> dict(product) # create a dict from all populated values\n{'price': 1000, 'name': 'Desktop PC'}\n", ">>> Product({'name': 'Laptop PC', 'price': 1500})\nProduct(price=1500, name='Laptop PC')\n", ">>> Product({'name': 'Laptop PC', 'lala': 1500}) # warning: unknown field in dict\nTraceback (most recent call last):\n    ...\nKeyError: 'Product does not support field: lala'\n", "class DiscountedProduct(Product):\n    discount_percent = scrapy.Field(serializer=str)\n    discount_expiration_date = scrapy.Field()\n", "class SpecificProduct(Product):\n    name = scrapy.Field(Product.fields['name'], serializer=my_serializer)\n"], "index": 24}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Item Types", "header_href": "#item-types", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.item</span> <span class=\"kn\">import</span> <span class=\"n\">Item</span><span class=\"p\">,</span> <span class=\"n\">Field</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">CustomItem</span><span class=\"p\">(</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"n\">one_field</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">another_field</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">dataclasses</span> <span class=\"kn\">import</span> <span class=\"n\">dataclass</span>\n\n<span class=\"nd\">@dataclass</span>\n<span class=\"k\">class</span> <span class=\"nc\">CustomItem</span><span class=\"p\">:</span>\n    <span class=\"n\">one_field</span><span class=\"p\">:</span> <span class=\"nb\">str</span>\n    <span class=\"n\">another_field</span><span class=\"p\">:</span> <span class=\"nb\">int</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">attr</span>\n\n<span class=\"nd\">@attr</span><span class=\"o\">.</span><span class=\"n\">s</span>\n<span class=\"k\">class</span> <span class=\"nc\">CustomItem</span><span class=\"p\">:</span>\n    <span class=\"n\">one_field</span> <span class=\"o\">=</span> <span class=\"n\">attr</span><span class=\"o\">.</span><span class=\"n\">ib</span><span class=\"p\">()</span>\n    <span class=\"n\">another_field</span> <span class=\"o\">=</span> <span class=\"n\">attr</span><span class=\"o\">.</span><span class=\"n\">ib</span><span class=\"p\">()</span>\n</pre></div>"], "codes_text": ["from scrapy.item import Item, Field\n\nclass CustomItem(Item):\n    one_field = Field()\n    another_field = Field()\n", "from dataclasses import dataclass\n\n@dataclass\nclass CustomItem:\n    one_field: str\n    another_field: int\n", "import attr\n\n@attr.s\nclass CustomItem:\n    one_field = attr.ib()\n    another_field = attr.ib()\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Dictionaries", "header_href": "#dictionaries", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Item objects", "header_href": "#item-objects", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.item</span> <span class=\"kn\">import</span> <span class=\"n\">Item</span><span class=\"p\">,</span> <span class=\"n\">Field</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">CustomItem</span><span class=\"p\">(</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"n\">one_field</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">another_field</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">()</span>\n</pre></div>"], "codes_text": ["from scrapy.item import Item, Field\n\nclass CustomItem(Item):\n    one_field = Field()\n    another_field = Field()\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Dataclass objects", "header_href": "#dataclass-objects", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">dataclasses</span> <span class=\"kn\">import</span> <span class=\"n\">dataclass</span>\n\n<span class=\"nd\">@dataclass</span>\n<span class=\"k\">class</span> <span class=\"nc\">CustomItem</span><span class=\"p\">:</span>\n    <span class=\"n\">one_field</span><span class=\"p\">:</span> <span class=\"nb\">str</span>\n    <span class=\"n\">another_field</span><span class=\"p\">:</span> <span class=\"nb\">int</span>\n</pre></div>"], "codes_text": ["from dataclasses import dataclass\n\n@dataclass\nclass CustomItem:\n    one_field: str\n    another_field: int\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "attr.s objects", "header_href": "#attr-s-objects", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">attr</span>\n\n<span class=\"nd\">@attr</span><span class=\"o\">.</span><span class=\"n\">s</span>\n<span class=\"k\">class</span> <span class=\"nc\">CustomItem</span><span class=\"p\">:</span>\n    <span class=\"n\">one_field</span> <span class=\"o\">=</span> <span class=\"n\">attr</span><span class=\"o\">.</span><span class=\"n\">ib</span><span class=\"p\">()</span>\n    <span class=\"n\">another_field</span> <span class=\"o\">=</span> <span class=\"n\">attr</span><span class=\"o\">.</span><span class=\"n\">ib</span><span class=\"p\">()</span>\n</pre></div>"], "codes_text": ["import attr\n\n@attr.s\nclass CustomItem:\n    one_field = attr.ib()\n    another_field = attr.ib()\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Working with Item objects", "header_href": "#working-with-item-objects", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">Product</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">price</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">stock</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">tags</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">last_updated</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">(</span><span class=\"n\">serializer</span><span class=\"o\">=</span><span class=\"nb\">str</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span> <span class=\"o\">=</span> <span class=\"n\">Product</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'Desktop PC'</span><span class=\"p\">,</span> <span class=\"n\">price</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">product</span><span class=\"p\">)</span>\n<span class=\"go\">Product(name='Desktop PC', price=1000)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span>\n<span class=\"go\">Desktop PC</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">)</span>\n<span class=\"go\">Desktop PC</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'price'</span><span class=\"p\">]</span>\n<span class=\"go\">1000</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'last_updated'</span><span class=\"p\">]</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">KeyError</span>: <span class=\"n\">'last_updated'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'last_updated'</span><span class=\"p\">,</span> <span class=\"s1\">'not set'</span><span class=\"p\">)</span>\n<span class=\"go\">not set</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'lala'</span><span class=\"p\">]</span> <span class=\"c1\"># getting unknown field</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">KeyError</span>: <span class=\"n\">'lala'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'lala'</span><span class=\"p\">,</span> <span class=\"s1\">'unknown field'</span><span class=\"p\">)</span>\n<span class=\"go\">'unknown field'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"s1\">'name'</span> <span class=\"ow\">in</span> <span class=\"n\">product</span>  <span class=\"c1\"># is name field populated?</span>\n<span class=\"go\">True</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"s1\">'last_updated'</span> <span class=\"ow\">in</span> <span class=\"n\">product</span>  <span class=\"c1\"># is last_updated populated?</span>\n<span class=\"go\">False</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"s1\">'last_updated'</span> <span class=\"ow\">in</span> <span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">fields</span>  <span class=\"c1\"># is last_updated a declared field?</span>\n<span class=\"go\">True</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"s1\">'lala'</span> <span class=\"ow\">in</span> <span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">fields</span>  <span class=\"c1\"># is lala a declared field?</span>\n<span class=\"go\">False</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'last_updated'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'today'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'last_updated'</span><span class=\"p\">]</span>\n<span class=\"go\">today</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'lala'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'test'</span> <span class=\"c1\"># setting unknown field</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">KeyError</span>: <span class=\"n\">'Product does not support field: lala'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">keys</span><span class=\"p\">()</span>\n<span class=\"go\">['price', 'name']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">()</span>\n<span class=\"go\">[('price', 1000), ('name', 'Desktop PC')]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">product</span><span class=\"p\">)</span> <span class=\"c1\"># create a dict from all populated values</span>\n<span class=\"go\">{'price': 1000, 'name': 'Desktop PC'}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">Product</span><span class=\"p\">({</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'Laptop PC'</span><span class=\"p\">,</span> <span class=\"s1\">'price'</span><span class=\"p\">:</span> <span class=\"mi\">1500</span><span class=\"p\">})</span>\n<span class=\"go\">Product(price=1500, name='Laptop PC')</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">Product</span><span class=\"p\">({</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'Laptop PC'</span><span class=\"p\">,</span> <span class=\"s1\">'lala'</span><span class=\"p\">:</span> <span class=\"mi\">1500</span><span class=\"p\">})</span> <span class=\"c1\"># warning: unknown field in dict</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">KeyError</span>: <span class=\"n\">'Product does not support field: lala'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">DiscountedProduct</span><span class=\"p\">(</span><span class=\"n\">Product</span><span class=\"p\">):</span>\n    <span class=\"n\">discount_percent</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">(</span><span class=\"n\">serializer</span><span class=\"o\">=</span><span class=\"nb\">str</span><span class=\"p\">)</span>\n    <span class=\"n\">discount_expiration_date</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">SpecificProduct</span><span class=\"p\">(</span><span class=\"n\">Product</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">(</span><span class=\"n\">Product</span><span class=\"o\">.</span><span class=\"n\">fields</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">],</span> <span class=\"n\">serializer</span><span class=\"o\">=</span><span class=\"n\">my_serializer</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import scrapy\n\nclass Product(scrapy.Item):\n    name = scrapy.Field()\n    price = scrapy.Field()\n    stock = scrapy.Field()\n    tags = scrapy.Field()\n    last_updated = scrapy.Field(serializer=str)\n", ">>> product = Product(name='Desktop PC', price=1000)\n>>> print(product)\nProduct(name='Desktop PC', price=1000)\n", ">>> product['name']\nDesktop PC\n>>> product.get('name')\nDesktop PC\n", ">>> product['price']\n1000\n", ">>> product['last_updated']\nTraceback (most recent call last):\n    ...\nKeyError: 'last_updated'\n", ">>> product.get('last_updated', 'not set')\nnot set\n", ">>> product['lala'] # getting unknown field\nTraceback (most recent call last):\n    ...\nKeyError: 'lala'\n", ">>> product.get('lala', 'unknown field')\n'unknown field'\n", ">>> 'name' in product  # is name field populated?\nTrue\n", ">>> 'last_updated' in product  # is last_updated populated?\nFalse\n", ">>> 'last_updated' in product.fields  # is last_updated a declared field?\nTrue\n", ">>> 'lala' in product.fields  # is lala a declared field?\nFalse\n", ">>> product['last_updated'] = 'today'\n>>> product['last_updated']\ntoday\n", ">>> product['lala'] = 'test' # setting unknown field\nTraceback (most recent call last):\n    ...\nKeyError: 'Product does not support field: lala'\n", ">>> product.keys()\n['price', 'name']\n", ">>> product.items()\n[('price', 1000), ('name', 'Desktop PC')]\n", ">>> dict(product) # create a dict from all populated values\n{'price': 1000, 'name': 'Desktop PC'}\n", ">>> Product({'name': 'Laptop PC', 'price': 1500})\nProduct(price=1500, name='Laptop PC')\n", ">>> Product({'name': 'Laptop PC', 'lala': 1500}) # warning: unknown field in dict\nTraceback (most recent call last):\n    ...\nKeyError: 'Product does not support field: lala'\n", "class DiscountedProduct(Product):\n    discount_percent = scrapy.Field(serializer=str)\n    discount_expiration_date = scrapy.Field()\n", "class SpecificProduct(Product):\n    name = scrapy.Field(Product.fields['name'], serializer=my_serializer)\n"], "index": 21}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Declaring Item subclasses", "header_href": "#declaring-item-subclasses", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">Product</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">price</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">stock</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">tags</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">last_updated</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">(</span><span class=\"n\">serializer</span><span class=\"o\">=</span><span class=\"nb\">str</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import scrapy\n\nclass Product(scrapy.Item):\n    name = scrapy.Field()\n    price = scrapy.Field()\n    stock = scrapy.Field()\n    tags = scrapy.Field()\n    last_updated = scrapy.Field(serializer=str)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Declaring fields", "header_href": "#declaring-fields", "codes": [], "codes_text": [], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Working with Item objects", "header_href": "#id3", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span> <span class=\"o\">=</span> <span class=\"n\">Product</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'Desktop PC'</span><span class=\"p\">,</span> <span class=\"n\">price</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">product</span><span class=\"p\">)</span>\n<span class=\"go\">Product(name='Desktop PC', price=1000)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span>\n<span class=\"go\">Desktop PC</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">)</span>\n<span class=\"go\">Desktop PC</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'price'</span><span class=\"p\">]</span>\n<span class=\"go\">1000</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'last_updated'</span><span class=\"p\">]</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">KeyError</span>: <span class=\"n\">'last_updated'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'last_updated'</span><span class=\"p\">,</span> <span class=\"s1\">'not set'</span><span class=\"p\">)</span>\n<span class=\"go\">not set</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'lala'</span><span class=\"p\">]</span> <span class=\"c1\"># getting unknown field</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">KeyError</span>: <span class=\"n\">'lala'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'lala'</span><span class=\"p\">,</span> <span class=\"s1\">'unknown field'</span><span class=\"p\">)</span>\n<span class=\"go\">'unknown field'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"s1\">'name'</span> <span class=\"ow\">in</span> <span class=\"n\">product</span>  <span class=\"c1\"># is name field populated?</span>\n<span class=\"go\">True</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"s1\">'last_updated'</span> <span class=\"ow\">in</span> <span class=\"n\">product</span>  <span class=\"c1\"># is last_updated populated?</span>\n<span class=\"go\">False</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"s1\">'last_updated'</span> <span class=\"ow\">in</span> <span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">fields</span>  <span class=\"c1\"># is last_updated a declared field?</span>\n<span class=\"go\">True</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"s1\">'lala'</span> <span class=\"ow\">in</span> <span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">fields</span>  <span class=\"c1\"># is lala a declared field?</span>\n<span class=\"go\">False</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'last_updated'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'today'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'last_updated'</span><span class=\"p\">]</span>\n<span class=\"go\">today</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'lala'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'test'</span> <span class=\"c1\"># setting unknown field</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">KeyError</span>: <span class=\"n\">'Product does not support field: lala'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">keys</span><span class=\"p\">()</span>\n<span class=\"go\">['price', 'name']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">()</span>\n<span class=\"go\">[('price', 1000), ('name', 'Desktop PC')]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">product</span><span class=\"p\">)</span> <span class=\"c1\"># create a dict from all populated values</span>\n<span class=\"go\">{'price': 1000, 'name': 'Desktop PC'}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">Product</span><span class=\"p\">({</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'Laptop PC'</span><span class=\"p\">,</span> <span class=\"s1\">'price'</span><span class=\"p\">:</span> <span class=\"mi\">1500</span><span class=\"p\">})</span>\n<span class=\"go\">Product(price=1500, name='Laptop PC')</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">Product</span><span class=\"p\">({</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'Laptop PC'</span><span class=\"p\">,</span> <span class=\"s1\">'lala'</span><span class=\"p\">:</span> <span class=\"mi\">1500</span><span class=\"p\">})</span> <span class=\"c1\"># warning: unknown field in dict</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">KeyError</span>: <span class=\"n\">'Product does not support field: lala'</span>\n</pre></div>"], "codes_text": [">>> product = Product(name='Desktop PC', price=1000)\n>>> print(product)\nProduct(name='Desktop PC', price=1000)\n", ">>> product['name']\nDesktop PC\n>>> product.get('name')\nDesktop PC\n", ">>> product['price']\n1000\n", ">>> product['last_updated']\nTraceback (most recent call last):\n    ...\nKeyError: 'last_updated'\n", ">>> product.get('last_updated', 'not set')\nnot set\n", ">>> product['lala'] # getting unknown field\nTraceback (most recent call last):\n    ...\nKeyError: 'lala'\n", ">>> product.get('lala', 'unknown field')\n'unknown field'\n", ">>> 'name' in product  # is name field populated?\nTrue\n", ">>> 'last_updated' in product  # is last_updated populated?\nFalse\n", ">>> 'last_updated' in product.fields  # is last_updated a declared field?\nTrue\n", ">>> 'lala' in product.fields  # is lala a declared field?\nFalse\n", ">>> product['last_updated'] = 'today'\n>>> product['last_updated']\ntoday\n", ">>> product['lala'] = 'test' # setting unknown field\nTraceback (most recent call last):\n    ...\nKeyError: 'Product does not support field: lala'\n", ">>> product.keys()\n['price', 'name']\n", ">>> product.items()\n[('price', 1000), ('name', 'Desktop PC')]\n", ">>> dict(product) # create a dict from all populated values\n{'price': 1000, 'name': 'Desktop PC'}\n", ">>> Product({'name': 'Laptop PC', 'price': 1500})\nProduct(price=1500, name='Laptop PC')\n", ">>> Product({'name': 'Laptop PC', 'lala': 1500}) # warning: unknown field in dict\nTraceback (most recent call last):\n    ...\nKeyError: 'Product does not support field: lala'\n"], "index": 18}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Creating items", "header_href": "#creating-items", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span> <span class=\"o\">=</span> <span class=\"n\">Product</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'Desktop PC'</span><span class=\"p\">,</span> <span class=\"n\">price</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">product</span><span class=\"p\">)</span>\n<span class=\"go\">Product(name='Desktop PC', price=1000)</span>\n</pre></div>"], "codes_text": [">>> product = Product(name='Desktop PC', price=1000)\n>>> print(product)\nProduct(name='Desktop PC', price=1000)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Getting field values", "header_href": "#getting-field-values", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span>\n<span class=\"go\">Desktop PC</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">)</span>\n<span class=\"go\">Desktop PC</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'price'</span><span class=\"p\">]</span>\n<span class=\"go\">1000</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'last_updated'</span><span class=\"p\">]</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">KeyError</span>: <span class=\"n\">'last_updated'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'last_updated'</span><span class=\"p\">,</span> <span class=\"s1\">'not set'</span><span class=\"p\">)</span>\n<span class=\"go\">not set</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'lala'</span><span class=\"p\">]</span> <span class=\"c1\"># getting unknown field</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">KeyError</span>: <span class=\"n\">'lala'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'lala'</span><span class=\"p\">,</span> <span class=\"s1\">'unknown field'</span><span class=\"p\">)</span>\n<span class=\"go\">'unknown field'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"s1\">'name'</span> <span class=\"ow\">in</span> <span class=\"n\">product</span>  <span class=\"c1\"># is name field populated?</span>\n<span class=\"go\">True</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"s1\">'last_updated'</span> <span class=\"ow\">in</span> <span class=\"n\">product</span>  <span class=\"c1\"># is last_updated populated?</span>\n<span class=\"go\">False</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"s1\">'last_updated'</span> <span class=\"ow\">in</span> <span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">fields</span>  <span class=\"c1\"># is last_updated a declared field?</span>\n<span class=\"go\">True</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"s1\">'lala'</span> <span class=\"ow\">in</span> <span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">fields</span>  <span class=\"c1\"># is lala a declared field?</span>\n<span class=\"go\">False</span>\n</pre></div>"], "codes_text": [">>> product['name']\nDesktop PC\n>>> product.get('name')\nDesktop PC\n", ">>> product['price']\n1000\n", ">>> product['last_updated']\nTraceback (most recent call last):\n    ...\nKeyError: 'last_updated'\n", ">>> product.get('last_updated', 'not set')\nnot set\n", ">>> product['lala'] # getting unknown field\nTraceback (most recent call last):\n    ...\nKeyError: 'lala'\n", ">>> product.get('lala', 'unknown field')\n'unknown field'\n", ">>> 'name' in product  # is name field populated?\nTrue\n", ">>> 'last_updated' in product  # is last_updated populated?\nFalse\n", ">>> 'last_updated' in product.fields  # is last_updated a declared field?\nTrue\n", ">>> 'lala' in product.fields  # is lala a declared field?\nFalse\n"], "index": 10}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Setting field values", "header_href": "#setting-field-values", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'last_updated'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'today'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'last_updated'</span><span class=\"p\">]</span>\n<span class=\"go\">today</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"p\">[</span><span class=\"s1\">'lala'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'test'</span> <span class=\"c1\"># setting unknown field</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">KeyError</span>: <span class=\"n\">'Product does not support field: lala'</span>\n</pre></div>"], "codes_text": [">>> product['last_updated'] = 'today'\n>>> product['last_updated']\ntoday\n", ">>> product['lala'] = 'test' # setting unknown field\nTraceback (most recent call last):\n    ...\nKeyError: 'Product does not support field: lala'\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Accessing all populated values", "header_href": "#accessing-all-populated-values", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">keys</span><span class=\"p\">()</span>\n<span class=\"go\">['price', 'name']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">product</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">()</span>\n<span class=\"go\">[('price', 1000), ('name', 'Desktop PC')]</span>\n</pre></div>"], "codes_text": [">>> product.keys()\n['price', 'name']\n", ">>> product.items()\n[('price', 1000), ('name', 'Desktop PC')]\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Copying items", "header_href": "#copying-items", "codes": [], "codes_text": [], "index": 15}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Other common tasks", "header_href": "#other-common-tasks", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">product</span><span class=\"p\">)</span> <span class=\"c1\"># create a dict from all populated values</span>\n<span class=\"go\">{'price': 1000, 'name': 'Desktop PC'}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">Product</span><span class=\"p\">({</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'Laptop PC'</span><span class=\"p\">,</span> <span class=\"s1\">'price'</span><span class=\"p\">:</span> <span class=\"mi\">1500</span><span class=\"p\">})</span>\n<span class=\"go\">Product(price=1500, name='Laptop PC')</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">Product</span><span class=\"p\">({</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'Laptop PC'</span><span class=\"p\">,</span> <span class=\"s1\">'lala'</span><span class=\"p\">:</span> <span class=\"mi\">1500</span><span class=\"p\">})</span> <span class=\"c1\"># warning: unknown field in dict</span>\n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">KeyError</span>: <span class=\"n\">'Product does not support field: lala'</span>\n</pre></div>"], "codes_text": [">>> dict(product) # create a dict from all populated values\n{'price': 1000, 'name': 'Desktop PC'}\n", ">>> Product({'name': 'Laptop PC', 'price': 1500})\nProduct(price=1500, name='Laptop PC')\n", ">>> Product({'name': 'Laptop PC', 'lala': 1500}) # warning: unknown field in dict\nTraceback (most recent call last):\n    ...\nKeyError: 'Product does not support field: lala'\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Extending Item subclasses", "header_href": "#extending-item-subclasses", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">DiscountedProduct</span><span class=\"p\">(</span><span class=\"n\">Product</span><span class=\"p\">):</span>\n    <span class=\"n\">discount_percent</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">(</span><span class=\"n\">serializer</span><span class=\"o\">=</span><span class=\"nb\">str</span><span class=\"p\">)</span>\n    <span class=\"n\">discount_expiration_date</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">SpecificProduct</span><span class=\"p\">(</span><span class=\"n\">Product</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">(</span><span class=\"n\">Product</span><span class=\"o\">.</span><span class=\"n\">fields</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">],</span> <span class=\"n\">serializer</span><span class=\"o\">=</span><span class=\"n\">my_serializer</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["class DiscountedProduct(Product):\n    discount_percent = scrapy.Field(serializer=str)\n    discount_expiration_date = scrapy.Field()\n", "class SpecificProduct(Product):\n    name = scrapy.Field(Product.fields['name'], serializer=my_serializer)\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Supporting All Item Types", "header_href": "#supporting-all-item-types", "codes": [], "codes_text": [], "index": 18}
{"url": "https://docs.scrapy.org/en/latest/topics/items.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Other classes related to items", "header_href": "#other-classes-related-to-items", "codes": [], "codes_text": [], "index": 19}
{"url": "https://docs.scrapy.org/en/latest/topics/loaders.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Item Loaders", "header_href": "#module-scrapy.loader", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.loader</span> <span class=\"kn\">import</span> <span class=\"n\">ItemLoader</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.items</span> <span class=\"kn\">import</span> <span class=\"n\">Product</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"n\">l</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"o\">=</span><span class=\"n\">Product</span><span class=\"p\">(),</span> <span class=\"n\">response</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"p\">)</span>\n    <span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'//div[@class=\"product_name\"]'</span><span class=\"p\">)</span>\n    <span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'//div[@class=\"product_title\"]'</span><span class=\"p\">)</span>\n    <span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'price'</span><span class=\"p\">,</span> <span class=\"s1\">'//p[@id=\"price\"]'</span><span class=\"p\">)</span>\n    <span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_css</span><span class=\"p\">(</span><span class=\"s1\">'stock'</span><span class=\"p\">,</span> <span class=\"s1\">'p#stock'</span><span class=\"p\">)</span>\n    <span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"s1\">'last_updated'</span><span class=\"p\">,</span> <span class=\"s1\">'today'</span><span class=\"p\">)</span> <span class=\"c1\"># you can also use literal values</span>\n    <span class=\"k\">return</span> <span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">load_item</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">dataclasses</span> <span class=\"kn\">import</span> <span class=\"n\">dataclass</span><span class=\"p\">,</span> <span class=\"n\">field</span>\n<span class=\"kn\">from</span> <span class=\"nn\">typing</span> <span class=\"kn\">import</span> <span class=\"n\">Optional</span>\n\n<span class=\"nd\">@dataclass</span>\n<span class=\"k\">class</span> <span class=\"nc\">InventoryItem</span><span class=\"p\">:</span>\n    <span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">field</span><span class=\"p\">(</span><span class=\"n\">default</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n    <span class=\"n\">price</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">field</span><span class=\"p\">(</span><span class=\"n\">default</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n    <span class=\"n\">stock</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">field</span><span class=\"p\">(</span><span class=\"n\">default</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">l</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">Product</span><span class=\"p\">(),</span> <span class=\"n\">some_selector</span><span class=\"p\">)</span>\n<span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"n\">xpath1</span><span class=\"p\">)</span> <span class=\"c1\"># (1)</span>\n<span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"n\">xpath2</span><span class=\"p\">)</span> <span class=\"c1\"># (2)</span>\n<span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_css</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"n\">css</span><span class=\"p\">)</span> <span class=\"c1\"># (3)</span>\n<span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'test'</span><span class=\"p\">)</span> <span class=\"c1\"># (4)</span>\n<span class=\"k\">return</span> <span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">load_item</span><span class=\"p\">()</span> <span class=\"c1\"># (5)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemloaders.processors</span> <span class=\"kn\">import</span> <span class=\"n\">TakeFirst</span><span class=\"p\">,</span> <span class=\"n\">MapCompose</span><span class=\"p\">,</span> <span class=\"n\">Join</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.loader</span> <span class=\"kn\">import</span> <span class=\"n\">ItemLoader</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">ProductLoader</span><span class=\"p\">(</span><span class=\"n\">ItemLoader</span><span class=\"p\">):</span>\n\n    <span class=\"n\">default_output_processor</span> <span class=\"o\">=</span> <span class=\"n\">TakeFirst</span><span class=\"p\">()</span>\n\n    <span class=\"n\">name_in</span> <span class=\"o\">=</span> <span class=\"n\">MapCompose</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">)</span>\n    <span class=\"n\">name_out</span> <span class=\"o\">=</span> <span class=\"n\">Join</span><span class=\"p\">()</span>\n\n    <span class=\"n\">price_in</span> <span class=\"o\">=</span> <span class=\"n\">MapCompose</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"o\">.</span><span class=\"n\">strip</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">itemloaders.processors</span> <span class=\"kn\">import</span> <span class=\"n\">Join</span><span class=\"p\">,</span> <span class=\"n\">MapCompose</span><span class=\"p\">,</span> <span class=\"n\">TakeFirst</span>\n<span class=\"kn\">from</span> <span class=\"nn\">w3lib.html</span> <span class=\"kn\">import</span> <span class=\"n\">remove_tags</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">filter_price</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"n\">value</span><span class=\"o\">.</span><span class=\"n\">isdigit</span><span class=\"p\">():</span>\n        <span class=\"k\">return</span> <span class=\"n\">value</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">Product</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">(</span>\n        <span class=\"n\">input_processor</span><span class=\"o\">=</span><span class=\"n\">MapCompose</span><span class=\"p\">(</span><span class=\"n\">remove_tags</span><span class=\"p\">),</span>\n        <span class=\"n\">output_processor</span><span class=\"o\">=</span><span class=\"n\">Join</span><span class=\"p\">(),</span>\n    <span class=\"p\">)</span>\n    <span class=\"n\">price</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">(</span>\n        <span class=\"n\">input_processor</span><span class=\"o\">=</span><span class=\"n\">MapCompose</span><span class=\"p\">(</span><span class=\"n\">remove_tags</span><span class=\"p\">,</span> <span class=\"n\">filter_price</span><span class=\"p\">),</span>\n        <span class=\"n\">output_processor</span><span class=\"o\">=</span><span class=\"n\">TakeFirst</span><span class=\"p\">(),</span>\n    <span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.loader</span> <span class=\"kn\">import</span> <span class=\"n\">ItemLoader</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">il</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"o\">=</span><span class=\"n\">Product</span><span class=\"p\">())</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">il</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">'Welcome to my'</span><span class=\"p\">,</span> <span class=\"s1\">'&lt;strong&gt;website&lt;/strong&gt;'</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">il</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"s1\">'price'</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">'&amp;euro;'</span><span class=\"p\">,</span> <span class=\"s1\">'&lt;span&gt;1000&lt;/span&gt;'</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">il</span><span class=\"o\">.</span><span class=\"n\">load_item</span><span class=\"p\">()</span>\n<span class=\"go\">{'name': 'Welcome to my website', 'price': '1000'}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse_length</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"n\">loader_context</span><span class=\"p\">):</span>\n    <span class=\"n\">unit</span> <span class=\"o\">=</span> <span class=\"n\">loader_context</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'unit'</span><span class=\"p\">,</span> <span class=\"s1\">'m'</span><span class=\"p\">)</span>\n    <span class=\"c1\"># ... length parsing code goes here ...</span>\n    <span class=\"k\">return</span> <span class=\"n\">parsed_length</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">product</span><span class=\"p\">)</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">context</span><span class=\"p\">[</span><span class=\"s1\">'unit'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'cm'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">product</span><span class=\"p\">,</span> <span class=\"n\">unit</span><span class=\"o\">=</span><span class=\"s1\">'cm'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">ProductLoader</span><span class=\"p\">(</span><span class=\"n\">ItemLoader</span><span class=\"p\">):</span>\n    <span class=\"n\">length_out</span> <span class=\"o\">=</span> <span class=\"n\">MapCompose</span><span class=\"p\">(</span><span class=\"n\">parse_length</span><span class=\"p\">,</span> <span class=\"n\">unit</span><span class=\"o\">=</span><span class=\"s1\">'cm'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># HTML snippet: &lt;p class=\"product-name\"&gt;Color TV&lt;/p&gt;</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_css</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'p.product-name'</span><span class=\"p\">)</span>\n<span class=\"c1\"># HTML snippet: &lt;p id=\"price\"&gt;the price is $1200&lt;/p&gt;</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_css</span><span class=\"p\">(</span><span class=\"s1\">'price'</span><span class=\"p\">,</span> <span class=\"s1\">'p#price'</span><span class=\"p\">,</span> <span class=\"n\">re</span><span class=\"o\">=</span><span class=\"s1\">'the price is (.*)'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'Color TV'</span><span class=\"p\">)</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"s1\">'colours'</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">'white'</span><span class=\"p\">,</span> <span class=\"s1\">'blue'</span><span class=\"p\">])</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"s1\">'length'</span><span class=\"p\">,</span> <span class=\"s1\">'100'</span><span class=\"p\">)</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'name: foo'</span><span class=\"p\">,</span> <span class=\"n\">TakeFirst</span><span class=\"p\">(),</span> <span class=\"n\">re</span><span class=\"o\">=</span><span class=\"s1\">'name: (.+)'</span><span class=\"p\">)</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"p\">{</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'foo'</span><span class=\"p\">,</span> <span class=\"s1\">'sex'</span><span class=\"p\">:</span> <span class=\"s1\">'male'</span><span class=\"p\">})</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># HTML snippet: &lt;p class=\"product-name\"&gt;Color TV&lt;/p&gt;</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'//p[@class=\"product-name\"]'</span><span class=\"p\">)</span>\n<span class=\"c1\"># HTML snippet: &lt;p id=\"price\"&gt;the price is $1200&lt;/p&gt;</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'price'</span><span class=\"p\">,</span> <span class=\"s1\">'//p[@id=\"price\"]'</span><span class=\"p\">,</span> <span class=\"n\">re</span><span class=\"o\">=</span><span class=\"s1\">'the price is (.*)'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># HTML snippet: &lt;p class=\"product-name\"&gt;Color TV&lt;/p&gt;</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">get_css</span><span class=\"p\">(</span><span class=\"s1\">'p.product-name'</span><span class=\"p\">)</span>\n<span class=\"c1\"># HTML snippet: &lt;p id=\"price\"&gt;the price is $1200&lt;/p&gt;</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">get_css</span><span class=\"p\">(</span><span class=\"s1\">'p#price'</span><span class=\"p\">,</span> <span class=\"n\">TakeFirst</span><span class=\"p\">(),</span> <span class=\"n\">re</span><span class=\"o\">=</span><span class=\"s1\">'the price is (.*)'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">itemloaders</span> <span class=\"kn\">import</span> <span class=\"n\">ItemLoader</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">itemloaders.processors</span> <span class=\"kn\">import</span> <span class=\"n\">TakeFirst</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">get_value</span><span class=\"p\">(</span><span class=\"s1\">'name: foo'</span><span class=\"p\">,</span> <span class=\"n\">TakeFirst</span><span class=\"p\">(),</span> <span class=\"nb\">str</span><span class=\"o\">.</span><span class=\"n\">upper</span><span class=\"p\">,</span> <span class=\"n\">re</span><span class=\"o\">=</span><span class=\"s1\">'name: (.+)'</span><span class=\"p\">)</span>\n<span class=\"go\">'FOO'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># HTML snippet: &lt;p class=\"product-name\"&gt;Color TV&lt;/p&gt;</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">get_xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[@class=\"product-name\"]'</span><span class=\"p\">)</span>\n<span class=\"c1\"># HTML snippet: &lt;p id=\"price\"&gt;the price is $1200&lt;/p&gt;</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">get_xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[@id=\"price\"]'</span><span class=\"p\">,</span> <span class=\"n\">TakeFirst</span><span class=\"p\">(),</span> <span class=\"n\">re</span><span class=\"o\">=</span><span class=\"s1\">'the price is (.*)'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">footer</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">a</span> <span class=\"n\">class</span><span class=\"o\">=</span><span class=\"s2\">\"social\"</span> <span class=\"n\">href</span><span class=\"o\">=</span><span class=\"s2\">\"https://facebook.com/whatever\"</span><span class=\"o\">&gt;</span><span class=\"n\">Like</span> <span class=\"n\">Us</span><span class=\"o\">&lt;/</span><span class=\"n\">a</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">a</span> <span class=\"n\">class</span><span class=\"o\">=</span><span class=\"s2\">\"social\"</span> <span class=\"n\">href</span><span class=\"o\">=</span><span class=\"s2\">\"https://twitter.com/whatever\"</span><span class=\"o\">&gt;</span><span class=\"n\">Follow</span> <span class=\"n\">Us</span><span class=\"o\">&lt;/</span><span class=\"n\">a</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">a</span> <span class=\"n\">class</span><span class=\"o\">=</span><span class=\"s2\">\"email\"</span> <span class=\"n\">href</span><span class=\"o\">=</span><span class=\"s2\">\"mailto:whatever@example.com\"</span><span class=\"o\">&gt;</span><span class=\"n\">Email</span> <span class=\"n\">Us</span><span class=\"o\">&lt;/</span><span class=\"n\">a</span><span class=\"o\">&gt;</span>\n<span class=\"o\">&lt;/</span><span class=\"n\">footer</span><span class=\"o\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"o\">=</span><span class=\"n\">Item</span><span class=\"p\">())</span>\n<span class=\"c1\"># load stuff not in the footer</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'social'</span><span class=\"p\">,</span> <span class=\"s1\">'//footer/a[@class = \"social\"]/@href'</span><span class=\"p\">)</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'email'</span><span class=\"p\">,</span> <span class=\"s1\">'//footer/a[@class = \"email\"]/@href'</span><span class=\"p\">)</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">load_item</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"o\">=</span><span class=\"n\">Item</span><span class=\"p\">())</span>\n<span class=\"c1\"># load stuff not in the footer</span>\n<span class=\"n\">footer_loader</span> <span class=\"o\">=</span> <span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">nested_xpath</span><span class=\"p\">(</span><span class=\"s1\">'//footer'</span><span class=\"p\">)</span>\n<span class=\"n\">footer_loader</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'social'</span><span class=\"p\">,</span> <span class=\"s1\">'a[@class = \"social\"]/@href'</span><span class=\"p\">)</span>\n<span class=\"n\">footer_loader</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'email'</span><span class=\"p\">,</span> <span class=\"s1\">'a[@class = \"email\"]/@href'</span><span class=\"p\">)</span>\n<span class=\"c1\"># no need to call footer_loader.load_item()</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">load_item</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemloaders.processors</span> <span class=\"kn\">import</span> <span class=\"n\">MapCompose</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.ItemLoaders</span> <span class=\"kn\">import</span> <span class=\"n\">ProductLoader</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">strip_dashes</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">strip</span><span class=\"p\">(</span><span class=\"s1\">'-'</span><span class=\"p\">)</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">SiteSpecificLoader</span><span class=\"p\">(</span><span class=\"n\">ProductLoader</span><span class=\"p\">):</span>\n    <span class=\"n\">name_in</span> <span class=\"o\">=</span> <span class=\"n\">MapCompose</span><span class=\"p\">(</span><span class=\"n\">strip_dashes</span><span class=\"p\">,</span> <span class=\"n\">ProductLoader</span><span class=\"o\">.</span><span class=\"n\">name_in</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemloaders.processors</span> <span class=\"kn\">import</span> <span class=\"n\">MapCompose</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.ItemLoaders</span> <span class=\"kn\">import</span> <span class=\"n\">ProductLoader</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.utils.xml</span> <span class=\"kn\">import</span> <span class=\"n\">remove_cdata</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">XmlProductLoader</span><span class=\"p\">(</span><span class=\"n\">ProductLoader</span><span class=\"p\">):</span>\n    <span class=\"n\">name_in</span> <span class=\"o\">=</span> <span class=\"n\">MapCompose</span><span class=\"p\">(</span><span class=\"n\">remove_cdata</span><span class=\"p\">,</span> <span class=\"n\">ProductLoader</span><span class=\"o\">.</span><span class=\"n\">name_in</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["from scrapy.loader import ItemLoader\nfrom myproject.items import Product\n\ndef parse(self, response):\n    l = ItemLoader(item=Product(), response=response)\n    l.add_xpath('name', '//div[@class=\"product_name\"]')\n    l.add_xpath('name', '//div[@class=\"product_title\"]')\n    l.add_xpath('price', '//p[@id=\"price\"]')\n    l.add_css('stock', 'p#stock')\n    l.add_value('last_updated', 'today') # you can also use literal values\n    return l.load_item()\n", "from dataclasses import dataclass, field\nfrom typing import Optional\n\n@dataclass\nclass InventoryItem:\n    name: Optional[str] = field(default=None)\n    price: Optional[float] = field(default=None)\n    stock: Optional[int] = field(default=None)\n", "l = ItemLoader(Product(), some_selector)\nl.add_xpath('name', xpath1) # (1)\nl.add_xpath('name', xpath2) # (2)\nl.add_css('name', css) # (3)\nl.add_value('name', 'test') # (4)\nreturn l.load_item() # (5)\n", "from itemloaders.processors import TakeFirst, MapCompose, Join\nfrom scrapy.loader import ItemLoader\n\nclass ProductLoader(ItemLoader):\n\n    default_output_processor = TakeFirst()\n\n    name_in = MapCompose(str.title)\n    name_out = Join()\n\n    price_in = MapCompose(str.strip)\n\n    # ...\n", "import scrapy\nfrom itemloaders.processors import Join, MapCompose, TakeFirst\nfrom w3lib.html import remove_tags\n\ndef filter_price(value):\n    if value.isdigit():\n        return value\n\nclass Product(scrapy.Item):\n    name = scrapy.Field(\n        input_processor=MapCompose(remove_tags),\n        output_processor=Join(),\n    )\n    price = scrapy.Field(\n        input_processor=MapCompose(remove_tags, filter_price),\n        output_processor=TakeFirst(),\n    )\n", ">>> from scrapy.loader import ItemLoader\n>>> il = ItemLoader(item=Product())\n>>> il.add_value('name', ['Welcome to my', '<strong>website</strong>'])\n>>> il.add_value('price', ['€', '<span>1000</span>'])\n>>> il.load_item()\n{'name': 'Welcome to my website', 'price': '1000'}\n", "def parse_length(text, loader_context):\n    unit = loader_context.get('unit', 'm')\n    # ... length parsing code goes here ...\n    return parsed_length\n", "loader = ItemLoader(product)\nloader.context['unit'] = 'cm'\n", "loader = ItemLoader(product, unit='cm')\n", "class ProductLoader(ItemLoader):\n    length_out = MapCompose(parse_length, unit='cm')\n", "# HTML snippet: <p class=\"product-name\">Color TV</p>\nloader.add_css('name', 'p.product-name')\n# HTML snippet: <p id=\"price\">the price is $1200</p>\nloader.add_css('price', 'p#price', re='the price is (.*)')\n", "loader.add_value('name', 'Color TV')\nloader.add_value('colours', ['white', 'blue'])\nloader.add_value('length', '100')\nloader.add_value('name', 'name: foo', TakeFirst(), re='name: (.+)')\nloader.add_value(None, {'name': 'foo', 'sex': 'male'})\n", "# HTML snippet: <p class=\"product-name\">Color TV</p>\nloader.add_xpath('name', '//p[@class=\"product-name\"]')\n# HTML snippet: <p id=\"price\">the price is $1200</p>\nloader.add_xpath('price', '//p[@id=\"price\"]', re='the price is (.*)')\n", "# HTML snippet: <p class=\"product-name\">Color TV</p>\nloader.get_css('p.product-name')\n# HTML snippet: <p id=\"price\">the price is $1200</p>\nloader.get_css('p#price', TakeFirst(), re='the price is (.*)')\n", ">>> from itemloaders import ItemLoader\n>>> from itemloaders.processors import TakeFirst\n>>> loader = ItemLoader()\n>>> loader.get_value('name: foo', TakeFirst(), str.upper, re='name: (.+)')\n'FOO'\n", "# HTML snippet: <p class=\"product-name\">Color TV</p>\nloader.get_xpath('//p[@class=\"product-name\"]')\n# HTML snippet: <p id=\"price\">the price is $1200</p>\nloader.get_xpath('//p[@id=\"price\"]', TakeFirst(), re='the price is (.*)')\n", "<footer>\n    <a class=\"social\" href=\"https://facebook.com/whatever\">Like Us</a>\n    <a class=\"social\" href=\"https://twitter.com/whatever\">Follow Us</a>\n    <a class=\"email\" href=\"mailto:whatever@example.com\">Email Us</a>\n</footer>\n", "loader = ItemLoader(item=Item())\n# load stuff not in the footer\nloader.add_xpath('social', '//footer/a[@class = \"social\"]/@href')\nloader.add_xpath('email', '//footer/a[@class = \"email\"]/@href')\nloader.load_item()\n", "loader = ItemLoader(item=Item())\n# load stuff not in the footer\nfooter_loader = loader.nested_xpath('//footer')\nfooter_loader.add_xpath('social', 'a[@class = \"social\"]/@href')\nfooter_loader.add_xpath('email', 'a[@class = \"email\"]/@href')\n# no need to call footer_loader.load_item()\nloader.load_item()\n", "from itemloaders.processors import MapCompose\nfrom myproject.ItemLoaders import ProductLoader\n\ndef strip_dashes(x):\n    return x.strip('-')\n\nclass SiteSpecificLoader(ProductLoader):\n    name_in = MapCompose(strip_dashes, ProductLoader.name_in)\n", "from itemloaders.processors import MapCompose\nfrom myproject.ItemLoaders import ProductLoader\nfrom myproject.utils.xml import remove_cdata\n\nclass XmlProductLoader(ProductLoader):\n    name_in = MapCompose(remove_cdata, ProductLoader.name_in)\n"], "index": 21}
{"url": "https://docs.scrapy.org/en/latest/topics/loaders.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Using Item Loaders to populate items", "header_href": "#using-item-loaders-to-populate-items", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.loader</span> <span class=\"kn\">import</span> <span class=\"n\">ItemLoader</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.items</span> <span class=\"kn\">import</span> <span class=\"n\">Product</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"n\">l</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"o\">=</span><span class=\"n\">Product</span><span class=\"p\">(),</span> <span class=\"n\">response</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"p\">)</span>\n    <span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'//div[@class=\"product_name\"]'</span><span class=\"p\">)</span>\n    <span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'//div[@class=\"product_title\"]'</span><span class=\"p\">)</span>\n    <span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'price'</span><span class=\"p\">,</span> <span class=\"s1\">'//p[@id=\"price\"]'</span><span class=\"p\">)</span>\n    <span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_css</span><span class=\"p\">(</span><span class=\"s1\">'stock'</span><span class=\"p\">,</span> <span class=\"s1\">'p#stock'</span><span class=\"p\">)</span>\n    <span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"s1\">'last_updated'</span><span class=\"p\">,</span> <span class=\"s1\">'today'</span><span class=\"p\">)</span> <span class=\"c1\"># you can also use literal values</span>\n    <span class=\"k\">return</span> <span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">load_item</span><span class=\"p\">()</span>\n</pre></div>"], "codes_text": ["from scrapy.loader import ItemLoader\nfrom myproject.items import Product\n\ndef parse(self, response):\n    l = ItemLoader(item=Product(), response=response)\n    l.add_xpath('name', '//div[@class=\"product_name\"]')\n    l.add_xpath('name', '//div[@class=\"product_title\"]')\n    l.add_xpath('price', '//p[@id=\"price\"]')\n    l.add_css('stock', 'p#stock')\n    l.add_value('last_updated', 'today') # you can also use literal values\n    return l.load_item()\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/loaders.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Working with dataclass items", "header_href": "#working-with-dataclass-items", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">dataclasses</span> <span class=\"kn\">import</span> <span class=\"n\">dataclass</span><span class=\"p\">,</span> <span class=\"n\">field</span>\n<span class=\"kn\">from</span> <span class=\"nn\">typing</span> <span class=\"kn\">import</span> <span class=\"n\">Optional</span>\n\n<span class=\"nd\">@dataclass</span>\n<span class=\"k\">class</span> <span class=\"nc\">InventoryItem</span><span class=\"p\">:</span>\n    <span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">field</span><span class=\"p\">(</span><span class=\"n\">default</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n    <span class=\"n\">price</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">field</span><span class=\"p\">(</span><span class=\"n\">default</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n    <span class=\"n\">stock</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">field</span><span class=\"p\">(</span><span class=\"n\">default</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["from dataclasses import dataclass, field\nfrom typing import Optional\n\n@dataclass\nclass InventoryItem:\n    name: Optional[str] = field(default=None)\n    price: Optional[float] = field(default=None)\n    stock: Optional[int] = field(default=None)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/loaders.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Input and Output processors", "header_href": "#input-and-output-processors", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">l</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">Product</span><span class=\"p\">(),</span> <span class=\"n\">some_selector</span><span class=\"p\">)</span>\n<span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"n\">xpath1</span><span class=\"p\">)</span> <span class=\"c1\"># (1)</span>\n<span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"n\">xpath2</span><span class=\"p\">)</span> <span class=\"c1\"># (2)</span>\n<span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_css</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"n\">css</span><span class=\"p\">)</span> <span class=\"c1\"># (3)</span>\n<span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'test'</span><span class=\"p\">)</span> <span class=\"c1\"># (4)</span>\n<span class=\"k\">return</span> <span class=\"n\">l</span><span class=\"o\">.</span><span class=\"n\">load_item</span><span class=\"p\">()</span> <span class=\"c1\"># (5)</span>\n</pre></div>"], "codes_text": ["l = ItemLoader(Product(), some_selector)\nl.add_xpath('name', xpath1) # (1)\nl.add_xpath('name', xpath2) # (2)\nl.add_css('name', css) # (3)\nl.add_value('name', 'test') # (4)\nreturn l.load_item() # (5)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/loaders.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Declaring Item Loaders", "header_href": "#declaring-item-loaders", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemloaders.processors</span> <span class=\"kn\">import</span> <span class=\"n\">TakeFirst</span><span class=\"p\">,</span> <span class=\"n\">MapCompose</span><span class=\"p\">,</span> <span class=\"n\">Join</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.loader</span> <span class=\"kn\">import</span> <span class=\"n\">ItemLoader</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">ProductLoader</span><span class=\"p\">(</span><span class=\"n\">ItemLoader</span><span class=\"p\">):</span>\n\n    <span class=\"n\">default_output_processor</span> <span class=\"o\">=</span> <span class=\"n\">TakeFirst</span><span class=\"p\">()</span>\n\n    <span class=\"n\">name_in</span> <span class=\"o\">=</span> <span class=\"n\">MapCompose</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">)</span>\n    <span class=\"n\">name_out</span> <span class=\"o\">=</span> <span class=\"n\">Join</span><span class=\"p\">()</span>\n\n    <span class=\"n\">price_in</span> <span class=\"o\">=</span> <span class=\"n\">MapCompose</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"o\">.</span><span class=\"n\">strip</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># ...</span>\n</pre></div>"], "codes_text": ["from itemloaders.processors import TakeFirst, MapCompose, Join\nfrom scrapy.loader import ItemLoader\n\nclass ProductLoader(ItemLoader):\n\n    default_output_processor = TakeFirst()\n\n    name_in = MapCompose(str.title)\n    name_out = Join()\n\n    price_in = MapCompose(str.strip)\n\n    # ...\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/loaders.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Declaring Input and Output Processors", "header_href": "#declaring-input-and-output-processors", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">itemloaders.processors</span> <span class=\"kn\">import</span> <span class=\"n\">Join</span><span class=\"p\">,</span> <span class=\"n\">MapCompose</span><span class=\"p\">,</span> <span class=\"n\">TakeFirst</span>\n<span class=\"kn\">from</span> <span class=\"nn\">w3lib.html</span> <span class=\"kn\">import</span> <span class=\"n\">remove_tags</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">filter_price</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"n\">value</span><span class=\"o\">.</span><span class=\"n\">isdigit</span><span class=\"p\">():</span>\n        <span class=\"k\">return</span> <span class=\"n\">value</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">Product</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">(</span>\n        <span class=\"n\">input_processor</span><span class=\"o\">=</span><span class=\"n\">MapCompose</span><span class=\"p\">(</span><span class=\"n\">remove_tags</span><span class=\"p\">),</span>\n        <span class=\"n\">output_processor</span><span class=\"o\">=</span><span class=\"n\">Join</span><span class=\"p\">(),</span>\n    <span class=\"p\">)</span>\n    <span class=\"n\">price</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">(</span>\n        <span class=\"n\">input_processor</span><span class=\"o\">=</span><span class=\"n\">MapCompose</span><span class=\"p\">(</span><span class=\"n\">remove_tags</span><span class=\"p\">,</span> <span class=\"n\">filter_price</span><span class=\"p\">),</span>\n        <span class=\"n\">output_processor</span><span class=\"o\">=</span><span class=\"n\">TakeFirst</span><span class=\"p\">(),</span>\n    <span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.loader</span> <span class=\"kn\">import</span> <span class=\"n\">ItemLoader</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">il</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"o\">=</span><span class=\"n\">Product</span><span class=\"p\">())</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">il</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">'Welcome to my'</span><span class=\"p\">,</span> <span class=\"s1\">'&lt;strong&gt;website&lt;/strong&gt;'</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">il</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"s1\">'price'</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">'&amp;euro;'</span><span class=\"p\">,</span> <span class=\"s1\">'&lt;span&gt;1000&lt;/span&gt;'</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">il</span><span class=\"o\">.</span><span class=\"n\">load_item</span><span class=\"p\">()</span>\n<span class=\"go\">{'name': 'Welcome to my website', 'price': '1000'}</span>\n</pre></div>"], "codes_text": ["import scrapy\nfrom itemloaders.processors import Join, MapCompose, TakeFirst\nfrom w3lib.html import remove_tags\n\ndef filter_price(value):\n    if value.isdigit():\n        return value\n\nclass Product(scrapy.Item):\n    name = scrapy.Field(\n        input_processor=MapCompose(remove_tags),\n        output_processor=Join(),\n    )\n    price = scrapy.Field(\n        input_processor=MapCompose(remove_tags, filter_price),\n        output_processor=TakeFirst(),\n    )\n", ">>> from scrapy.loader import ItemLoader\n>>> il = ItemLoader(item=Product())\n>>> il.add_value('name', ['Welcome to my', '<strong>website</strong>'])\n>>> il.add_value('price', ['€', '<span>1000</span>'])\n>>> il.load_item()\n{'name': 'Welcome to my website', 'price': '1000'}\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/loaders.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Item Loader Context", "header_href": "#item-loader-context", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse_length</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"n\">loader_context</span><span class=\"p\">):</span>\n    <span class=\"n\">unit</span> <span class=\"o\">=</span> <span class=\"n\">loader_context</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'unit'</span><span class=\"p\">,</span> <span class=\"s1\">'m'</span><span class=\"p\">)</span>\n    <span class=\"c1\"># ... length parsing code goes here ...</span>\n    <span class=\"k\">return</span> <span class=\"n\">parsed_length</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">product</span><span class=\"p\">)</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">context</span><span class=\"p\">[</span><span class=\"s1\">'unit'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'cm'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">product</span><span class=\"p\">,</span> <span class=\"n\">unit</span><span class=\"o\">=</span><span class=\"s1\">'cm'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">ProductLoader</span><span class=\"p\">(</span><span class=\"n\">ItemLoader</span><span class=\"p\">):</span>\n    <span class=\"n\">length_out</span> <span class=\"o\">=</span> <span class=\"n\">MapCompose</span><span class=\"p\">(</span><span class=\"n\">parse_length</span><span class=\"p\">,</span> <span class=\"n\">unit</span><span class=\"o\">=</span><span class=\"s1\">'cm'</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["def parse_length(text, loader_context):\n    unit = loader_context.get('unit', 'm')\n    # ... length parsing code goes here ...\n    return parsed_length\n", "loader = ItemLoader(product)\nloader.context['unit'] = 'cm'\n", "loader = ItemLoader(product, unit='cm')\n", "class ProductLoader(ItemLoader):\n    length_out = MapCompose(parse_length, unit='cm')\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/loaders.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "ItemLoader objects", "header_href": "#itemloader-objects", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"c1\"># HTML snippet: &lt;p class=\"product-name\"&gt;Color TV&lt;/p&gt;</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_css</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'p.product-name'</span><span class=\"p\">)</span>\n<span class=\"c1\"># HTML snippet: &lt;p id=\"price\"&gt;the price is $1200&lt;/p&gt;</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_css</span><span class=\"p\">(</span><span class=\"s1\">'price'</span><span class=\"p\">,</span> <span class=\"s1\">'p#price'</span><span class=\"p\">,</span> <span class=\"n\">re</span><span class=\"o\">=</span><span class=\"s1\">'the price is (.*)'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'Color TV'</span><span class=\"p\">)</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"s1\">'colours'</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">'white'</span><span class=\"p\">,</span> <span class=\"s1\">'blue'</span><span class=\"p\">])</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"s1\">'length'</span><span class=\"p\">,</span> <span class=\"s1\">'100'</span><span class=\"p\">)</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'name: foo'</span><span class=\"p\">,</span> <span class=\"n\">TakeFirst</span><span class=\"p\">(),</span> <span class=\"n\">re</span><span class=\"o\">=</span><span class=\"s1\">'name: (.+)'</span><span class=\"p\">)</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_value</span><span class=\"p\">(</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"p\">{</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'foo'</span><span class=\"p\">,</span> <span class=\"s1\">'sex'</span><span class=\"p\">:</span> <span class=\"s1\">'male'</span><span class=\"p\">})</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># HTML snippet: &lt;p class=\"product-name\"&gt;Color TV&lt;/p&gt;</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'//p[@class=\"product-name\"]'</span><span class=\"p\">)</span>\n<span class=\"c1\"># HTML snippet: &lt;p id=\"price\"&gt;the price is $1200&lt;/p&gt;</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'price'</span><span class=\"p\">,</span> <span class=\"s1\">'//p[@id=\"price\"]'</span><span class=\"p\">,</span> <span class=\"n\">re</span><span class=\"o\">=</span><span class=\"s1\">'the price is (.*)'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># HTML snippet: &lt;p class=\"product-name\"&gt;Color TV&lt;/p&gt;</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">get_css</span><span class=\"p\">(</span><span class=\"s1\">'p.product-name'</span><span class=\"p\">)</span>\n<span class=\"c1\"># HTML snippet: &lt;p id=\"price\"&gt;the price is $1200&lt;/p&gt;</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">get_css</span><span class=\"p\">(</span><span class=\"s1\">'p#price'</span><span class=\"p\">,</span> <span class=\"n\">TakeFirst</span><span class=\"p\">(),</span> <span class=\"n\">re</span><span class=\"o\">=</span><span class=\"s1\">'the price is (.*)'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">itemloaders</span> <span class=\"kn\">import</span> <span class=\"n\">ItemLoader</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">itemloaders.processors</span> <span class=\"kn\">import</span> <span class=\"n\">TakeFirst</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">get_value</span><span class=\"p\">(</span><span class=\"s1\">'name: foo'</span><span class=\"p\">,</span> <span class=\"n\">TakeFirst</span><span class=\"p\">(),</span> <span class=\"nb\">str</span><span class=\"o\">.</span><span class=\"n\">upper</span><span class=\"p\">,</span> <span class=\"n\">re</span><span class=\"o\">=</span><span class=\"s1\">'name: (.+)'</span><span class=\"p\">)</span>\n<span class=\"go\">'FOO'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># HTML snippet: &lt;p class=\"product-name\"&gt;Color TV&lt;/p&gt;</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">get_xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[@class=\"product-name\"]'</span><span class=\"p\">)</span>\n<span class=\"c1\"># HTML snippet: &lt;p id=\"price\"&gt;the price is $1200&lt;/p&gt;</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">get_xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p[@id=\"price\"]'</span><span class=\"p\">,</span> <span class=\"n\">TakeFirst</span><span class=\"p\">(),</span> <span class=\"n\">re</span><span class=\"o\">=</span><span class=\"s1\">'the price is (.*)'</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["# HTML snippet: <p class=\"product-name\">Color TV</p>\nloader.add_css('name', 'p.product-name')\n# HTML snippet: <p id=\"price\">the price is $1200</p>\nloader.add_css('price', 'p#price', re='the price is (.*)')\n", "loader.add_value('name', 'Color TV')\nloader.add_value('colours', ['white', 'blue'])\nloader.add_value('length', '100')\nloader.add_value('name', 'name: foo', TakeFirst(), re='name: (.+)')\nloader.add_value(None, {'name': 'foo', 'sex': 'male'})\n", "# HTML snippet: <p class=\"product-name\">Color TV</p>\nloader.add_xpath('name', '//p[@class=\"product-name\"]')\n# HTML snippet: <p id=\"price\">the price is $1200</p>\nloader.add_xpath('price', '//p[@id=\"price\"]', re='the price is (.*)')\n", "# HTML snippet: <p class=\"product-name\">Color TV</p>\nloader.get_css('p.product-name')\n# HTML snippet: <p id=\"price\">the price is $1200</p>\nloader.get_css('p#price', TakeFirst(), re='the price is (.*)')\n", ">>> from itemloaders import ItemLoader\n>>> from itemloaders.processors import TakeFirst\n>>> loader = ItemLoader()\n>>> loader.get_value('name: foo', TakeFirst(), str.upper, re='name: (.+)')\n'FOO'\n", "# HTML snippet: <p class=\"product-name\">Color TV</p>\nloader.get_xpath('//p[@class=\"product-name\"]')\n# HTML snippet: <p id=\"price\">the price is $1200</p>\nloader.get_xpath('//p[@id=\"price\"]', TakeFirst(), re='the price is (.*)')\n"], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/loaders.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Nested Loaders", "header_href": "#nested-loaders", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">footer</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">a</span> <span class=\"n\">class</span><span class=\"o\">=</span><span class=\"s2\">\"social\"</span> <span class=\"n\">href</span><span class=\"o\">=</span><span class=\"s2\">\"https://facebook.com/whatever\"</span><span class=\"o\">&gt;</span><span class=\"n\">Like</span> <span class=\"n\">Us</span><span class=\"o\">&lt;/</span><span class=\"n\">a</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">a</span> <span class=\"n\">class</span><span class=\"o\">=</span><span class=\"s2\">\"social\"</span> <span class=\"n\">href</span><span class=\"o\">=</span><span class=\"s2\">\"https://twitter.com/whatever\"</span><span class=\"o\">&gt;</span><span class=\"n\">Follow</span> <span class=\"n\">Us</span><span class=\"o\">&lt;/</span><span class=\"n\">a</span><span class=\"o\">&gt;</span>\n    <span class=\"o\">&lt;</span><span class=\"n\">a</span> <span class=\"n\">class</span><span class=\"o\">=</span><span class=\"s2\">\"email\"</span> <span class=\"n\">href</span><span class=\"o\">=</span><span class=\"s2\">\"mailto:whatever@example.com\"</span><span class=\"o\">&gt;</span><span class=\"n\">Email</span> <span class=\"n\">Us</span><span class=\"o\">&lt;/</span><span class=\"n\">a</span><span class=\"o\">&gt;</span>\n<span class=\"o\">&lt;/</span><span class=\"n\">footer</span><span class=\"o\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"o\">=</span><span class=\"n\">Item</span><span class=\"p\">())</span>\n<span class=\"c1\"># load stuff not in the footer</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'social'</span><span class=\"p\">,</span> <span class=\"s1\">'//footer/a[@class = \"social\"]/@href'</span><span class=\"p\">)</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'email'</span><span class=\"p\">,</span> <span class=\"s1\">'//footer/a[@class = \"email\"]/@href'</span><span class=\"p\">)</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">load_item</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"o\">=</span><span class=\"n\">Item</span><span class=\"p\">())</span>\n<span class=\"c1\"># load stuff not in the footer</span>\n<span class=\"n\">footer_loader</span> <span class=\"o\">=</span> <span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">nested_xpath</span><span class=\"p\">(</span><span class=\"s1\">'//footer'</span><span class=\"p\">)</span>\n<span class=\"n\">footer_loader</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'social'</span><span class=\"p\">,</span> <span class=\"s1\">'a[@class = \"social\"]/@href'</span><span class=\"p\">)</span>\n<span class=\"n\">footer_loader</span><span class=\"o\">.</span><span class=\"n\">add_xpath</span><span class=\"p\">(</span><span class=\"s1\">'email'</span><span class=\"p\">,</span> <span class=\"s1\">'a[@class = \"email\"]/@href'</span><span class=\"p\">)</span>\n<span class=\"c1\"># no need to call footer_loader.load_item()</span>\n<span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">load_item</span><span class=\"p\">()</span>\n</pre></div>"], "codes_text": ["<footer>\n    <a class=\"social\" href=\"https://facebook.com/whatever\">Like Us</a>\n    <a class=\"social\" href=\"https://twitter.com/whatever\">Follow Us</a>\n    <a class=\"email\" href=\"mailto:whatever@example.com\">Email Us</a>\n</footer>\n", "loader = ItemLoader(item=Item())\n# load stuff not in the footer\nloader.add_xpath('social', '//footer/a[@class = \"social\"]/@href')\nloader.add_xpath('email', '//footer/a[@class = \"email\"]/@href')\nloader.load_item()\n", "loader = ItemLoader(item=Item())\n# load stuff not in the footer\nfooter_loader = loader.nested_xpath('//footer')\nfooter_loader.add_xpath('social', 'a[@class = \"social\"]/@href')\nfooter_loader.add_xpath('email', 'a[@class = \"email\"]/@href')\n# no need to call footer_loader.load_item()\nloader.load_item()\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/loaders.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Reusing and extending Item Loaders", "header_href": "#reusing-and-extending-item-loaders", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemloaders.processors</span> <span class=\"kn\">import</span> <span class=\"n\">MapCompose</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.ItemLoaders</span> <span class=\"kn\">import</span> <span class=\"n\">ProductLoader</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">strip_dashes</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">strip</span><span class=\"p\">(</span><span class=\"s1\">'-'</span><span class=\"p\">)</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">SiteSpecificLoader</span><span class=\"p\">(</span><span class=\"n\">ProductLoader</span><span class=\"p\">):</span>\n    <span class=\"n\">name_in</span> <span class=\"o\">=</span> <span class=\"n\">MapCompose</span><span class=\"p\">(</span><span class=\"n\">strip_dashes</span><span class=\"p\">,</span> <span class=\"n\">ProductLoader</span><span class=\"o\">.</span><span class=\"n\">name_in</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemloaders.processors</span> <span class=\"kn\">import</span> <span class=\"n\">MapCompose</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.ItemLoaders</span> <span class=\"kn\">import</span> <span class=\"n\">ProductLoader</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.utils.xml</span> <span class=\"kn\">import</span> <span class=\"n\">remove_cdata</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">XmlProductLoader</span><span class=\"p\">(</span><span class=\"n\">ProductLoader</span><span class=\"p\">):</span>\n    <span class=\"n\">name_in</span> <span class=\"o\">=</span> <span class=\"n\">MapCompose</span><span class=\"p\">(</span><span class=\"n\">remove_cdata</span><span class=\"p\">,</span> <span class=\"n\">ProductLoader</span><span class=\"o\">.</span><span class=\"n\">name_in</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["from itemloaders.processors import MapCompose\nfrom myproject.ItemLoaders import ProductLoader\n\ndef strip_dashes(x):\n    return x.strip('-')\n\nclass SiteSpecificLoader(ProductLoader):\n    name_in = MapCompose(strip_dashes, ProductLoader.name_in)\n", "from itemloaders.processors import MapCompose\nfrom myproject.ItemLoaders import ProductLoader\nfrom myproject.utils.xml import remove_cdata\n\nclass XmlProductLoader(ProductLoader):\n    name_in = MapCompose(remove_cdata, ProductLoader.name_in)\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/shell.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Scrapy shell", "header_href": "#scrapy-shell", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">[</span><span class=\"n\">settings</span><span class=\"p\">]</span>\n<span class=\"n\">shell</span> <span class=\"o\">=</span> <span class=\"n\">bpython</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"o\">&lt;</span><span class=\"n\">url</span><span class=\"o\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># UNIX-style</span>\n<span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"o\">./</span><span class=\"n\">path</span><span class=\"o\">/</span><span class=\"n\">to</span><span class=\"o\">/</span><span class=\"n\">file</span><span class=\"o\">.</span><span class=\"n\">html</span>\n<span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"o\">../</span><span class=\"n\">other</span><span class=\"o\">/</span><span class=\"n\">path</span><span class=\"o\">/</span><span class=\"n\">to</span><span class=\"o\">/</span><span class=\"n\">file</span><span class=\"o\">.</span><span class=\"n\">html</span>\n<span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"o\">/</span><span class=\"n\">absolute</span><span class=\"o\">/</span><span class=\"n\">path</span><span class=\"o\">/</span><span class=\"n\">to</span><span class=\"o\">/</span><span class=\"n\">file</span><span class=\"o\">.</span><span class=\"n\">html</span>\n\n<span class=\"c1\"># File URI</span>\n<span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"n\">file</span><span class=\"p\">:</span><span class=\"o\">///</span><span class=\"n\">absolute</span><span class=\"o\">/</span><span class=\"n\">path</span><span class=\"o\">/</span><span class=\"n\">to</span><span class=\"o\">/</span><span class=\"n\">file</span><span class=\"o\">.</span><span class=\"n\">html</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy shell index.html\n[ ... scrapy shell starts ... ]\n[ ... traceback ... ]\ntwisted.internet.error.DNSLookupError: DNS lookup failed:\naddress 'index.html' not found: [Errno -5] No address associated with hostname.\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"s1\">'https://scrapy.org'</span> <span class=\"o\">--</span><span class=\"n\">nolog</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"s2\">\"https://scrapy.org\"</span> <span class=\"o\">--</span><span class=\"n\">nolog</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span> <span class=\"n\">Available</span> <span class=\"n\">Scrapy</span> <span class=\"n\">objects</span><span class=\"p\">:</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">scrapy</span>     <span class=\"n\">scrapy</span> <span class=\"n\">module</span> <span class=\"p\">(</span><span class=\"n\">contains</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">,</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Selector</span><span class=\"p\">,</span> <span class=\"n\">etc</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">crawler</span>    <span class=\"o\">&lt;</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">Crawler</span> <span class=\"nb\">object</span> <span class=\"n\">at</span> <span class=\"mh\">0x7f07395dd690</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">item</span>       <span class=\"p\">{}</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">request</span>    <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">org</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">response</span>   <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">org</span><span class=\"o\">/&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">settings</span>   <span class=\"o\">&lt;</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">Settings</span> <span class=\"nb\">object</span> <span class=\"n\">at</span> <span class=\"mh\">0x7f07395dd710</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">spider</span>     <span class=\"o\">&lt;</span><span class=\"n\">DefaultSpider</span> <span class=\"s1\">'default'</span> <span class=\"n\">at</span> <span class=\"mh\">0x7f0735891690</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span> <span class=\"n\">Useful</span> <span class=\"n\">shortcuts</span><span class=\"p\">:</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">fetch</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">[,</span> <span class=\"n\">redirect</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">])</span> <span class=\"n\">Fetch</span> <span class=\"n\">URL</span> <span class=\"ow\">and</span> <span class=\"n\">update</span> <span class=\"n\">local</span> <span class=\"n\">objects</span> <span class=\"p\">(</span><span class=\"n\">by</span> <span class=\"n\">default</span><span class=\"p\">,</span> <span class=\"n\">redirects</span> <span class=\"n\">are</span> <span class=\"n\">followed</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">fetch</span><span class=\"p\">(</span><span class=\"n\">req</span><span class=\"p\">)</span>                  <span class=\"n\">Fetch</span> <span class=\"n\">a</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span> <span class=\"ow\">and</span> <span class=\"n\">update</span> <span class=\"n\">local</span> <span class=\"n\">objects</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">shelp</span><span class=\"p\">()</span>           <span class=\"n\">Shell</span> <span class=\"n\">help</span> <span class=\"p\">(</span><span class=\"nb\">print</span> <span class=\"n\">this</span> <span class=\"n\">help</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">view</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">)</span>    <span class=\"n\">View</span> <span class=\"n\">response</span> <span class=\"ow\">in</span> <span class=\"n\">a</span> <span class=\"n\">browser</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Scrapy | A Fast and Powerful Scraping and Web Crawling Framework'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">fetch</span><span class=\"p\">(</span><span class=\"s2\">\"https://old.reddit.com/\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'reddit: the front page of the internet'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"n\">method</span><span class=\"o\">=</span><span class=\"s2\">\"POST\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">fetch</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">status</span>\n<span class=\"go\">404</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">pprint</span> <span class=\"kn\">import</span> <span class=\"n\">pprint</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">pprint</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">headers</span><span class=\"p\">)</span>\n<span class=\"go\">{'Accept-Ranges': ['bytes'],</span>\n<span class=\"go\"> 'Cache-Control': ['max-age=0, must-revalidate'],</span>\n<span class=\"go\"> 'Content-Type': ['text/html; charset=UTF-8'],</span>\n<span class=\"go\"> 'Date': ['Thu, 08 Dec 2016 16:21:19 GMT'],</span>\n<span class=\"go\"> 'Server': ['snooserv'],</span>\n<span class=\"go\"> 'Set-Cookie': ['loid=KqNLou0V9SKMX4qb4n; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',</span>\n<span class=\"go\">                'loidcreated=2016-12-08T16%3A21%3A19.445Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',</span>\n<span class=\"go\">                'loid=vi0ZVe4NkxNWdlH7r7; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',</span>\n<span class=\"go\">                'loidcreated=2016-12-08T16%3A21%3A19.459Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure'],</span>\n<span class=\"go\"> 'Vary': ['accept-encoding'],</span>\n<span class=\"go\"> 'Via': ['1.1 varnish'],</span>\n<span class=\"go\"> 'X-Cache': ['MISS'],</span>\n<span class=\"go\"> 'X-Cache-Hits': ['0'],</span>\n<span class=\"go\"> 'X-Content-Type-Options': ['nosniff'],</span>\n<span class=\"go\"> 'X-Frame-Options': ['SAMEORIGIN'],</span>\n<span class=\"go\"> 'X-Moose': ['majestic'],</span>\n<span class=\"go\"> 'X-Served-By': ['cache-cdg8730-CDG'],</span>\n<span class=\"go\"> 'X-Timer': ['S1481214079.394283,VS0,VE159'],</span>\n<span class=\"go\"> 'X-Ua-Compatible': ['IE=edge'],</span>\n<span class=\"go\"> 'X-Xss-Protection': ['1; mode=block']}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"myspider\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s2\">\"http://example.com\"</span><span class=\"p\">,</span>\n        <span class=\"s2\">\"http://example.org\"</span><span class=\"p\">,</span>\n        <span class=\"s2\">\"http://example.net\"</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"c1\"># We want to inspect one specific response.</span>\n        <span class=\"k\">if</span> <span class=\"s2\">\".org\"</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">:</span>\n            <span class=\"kn\">from</span> <span class=\"nn\">scrapy.shell</span> <span class=\"kn\">import</span> <span class=\"n\">inspect_response</span>\n            <span class=\"n\">inspect_response</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># Rest of parsing code.</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">2014</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">23</span> <span class=\"mi\">17</span><span class=\"p\">:</span><span class=\"mi\">48</span><span class=\"p\">:</span><span class=\"mi\">31</span><span class=\"o\">-</span><span class=\"mi\">0400</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"mi\">2014</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">23</span> <span class=\"mi\">17</span><span class=\"p\">:</span><span class=\"mi\">48</span><span class=\"p\">:</span><span class=\"mi\">31</span><span class=\"o\">-</span><span class=\"mi\">0400</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">org</span><span class=\"o\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span> <span class=\"n\">Available</span> <span class=\"n\">Scrapy</span> <span class=\"n\">objects</span><span class=\"p\">:</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">crawler</span>    <span class=\"o\">&lt;</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">Crawler</span> <span class=\"nb\">object</span> <span class=\"n\">at</span> <span class=\"mh\">0x1e16b50</span><span class=\"o\">&gt;</span>\n<span class=\"o\">...</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span>\n<span class=\"s1\">'http://example.org'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//h1[@class=\"fn\"]'</span><span class=\"p\">)</span>\n<span class=\"go\">[]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">)</span>\n<span class=\"go\">True</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"o\">^</span><span class=\"n\">D</span>\n<span class=\"go\">2014-01-23 17:50:03-0400 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://example.net&gt; (referer: None)</span>\n<span class=\"gp\">...</span>\n</pre></div>"], "codes_text": ["[settings]\nshell = bpython\n", "scrapy shell <url>\n", "# UNIX-style\nscrapy shell ./path/to/file.html\nscrapy shell ../other/path/to/file.html\nscrapy shell /absolute/path/to/file.html\n\n# File URI\nscrapy shell file:///absolute/path/to/file.html\n", "$ scrapy shell index.html\n[ ... scrapy shell starts ... ]\n[ ... traceback ... ]\ntwisted.internet.error.DNSLookupError: DNS lookup failed:\naddress 'index.html' not found: [Errno -5] No address associated with hostname.\n", "scrapy shell 'https://scrapy.org' --nolog\n", "scrapy shell \"https://scrapy.org\" --nolog\n", "[s] Available Scrapy objects:\n[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)\n[s]   crawler    <scrapy.crawler.Crawler object at 0x7f07395dd690>\n[s]   item       {}\n[s]   request    <GET https://scrapy.org>\n[s]   response   <200 https://scrapy.org/>\n[s]   settings   <scrapy.settings.Settings object at 0x7f07395dd710>\n[s]   spider     <DefaultSpider 'default' at 0x7f0735891690>\n[s] Useful shortcuts:\n[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)\n[s]   fetch(req)                  Fetch a scrapy.Request and update local objects\n[s]   shelp()           Shell help (print this help)\n[s]   view(response)    View response in a browser\n\n>>>\n", ">>> response.xpath('//title/text()').get()\n'Scrapy | A Fast and Powerful Scraping and Web Crawling Framework'\n", ">>> fetch(\"https://old.reddit.com/\")\n", ">>> response.xpath('//title/text()').get()\n'reddit: the front page of the internet'\n", ">>> request = request.replace(method=\"POST\")\n", ">>> fetch(request)\n", ">>> response.status\n404\n", ">>> from pprint import pprint\n", ">>> pprint(response.headers)\n{'Accept-Ranges': ['bytes'],\n 'Cache-Control': ['max-age=0, must-revalidate'],\n 'Content-Type': ['text/html; charset=UTF-8'],\n 'Date': ['Thu, 08 Dec 2016 16:21:19 GMT'],\n 'Server': ['snooserv'],\n 'Set-Cookie': ['loid=KqNLou0V9SKMX4qb4n; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',\n                'loidcreated=2016-12-08T16:21:19.445Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',\n                'loid=vi0ZVe4NkxNWdlH7r7; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',\n                'loidcreated=2016-12-08T16:21:19.459Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure'],\n 'Vary': ['accept-encoding'],\n 'Via': ['1.1 varnish'],\n 'X-Cache': ['MISS'],\n 'X-Cache-Hits': ['0'],\n 'X-Content-Type-Options': ['nosniff'],\n 'X-Frame-Options': ['SAMEORIGIN'],\n 'X-Moose': ['majestic'],\n 'X-Served-By': ['cache-cdg8730-CDG'],\n 'X-Timer': ['S1481214079.394283,VS0,VE159'],\n 'X-Ua-Compatible': ['IE=edge'],\n 'X-Xss-Protection': ['1; mode=block']}\n", "import scrapy\n\n\nclass MySpider(scrapy.Spider):\n    name = \"myspider\"\n    start_urls = [\n        \"http://example.com\",\n        \"http://example.org\",\n        \"http://example.net\",\n    ]\n\n    def parse(self, response):\n        # We want to inspect one specific response.\n        if \".org\" in response.url:\n            from scrapy.shell import inspect_response\n            inspect_response(response, self)\n\n        # Rest of parsing code.\n", "2014-01-23 17:48:31-0400 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://example.com> (referer: None)\n2014-01-23 17:48:31-0400 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://example.org> (referer: None)\n[s] Available Scrapy objects:\n[s]   crawler    <scrapy.crawler.Crawler object at 0x1e16b50>\n...\n\n>>> response.url\n'http://example.org'\n", ">>> response.xpath('//h1[@class=\"fn\"]')\n[]\n", ">>> view(response)\nTrue\n", ">>> ^D\n2014-01-23 17:50:03-0400 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://example.net> (referer: None)\n...\n"], "index": 20}
{"url": "https://docs.scrapy.org/en/latest/topics/shell.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Configuring the shell", "header_href": "#configuring-the-shell", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">[</span><span class=\"n\">settings</span><span class=\"p\">]</span>\n<span class=\"n\">shell</span> <span class=\"o\">=</span> <span class=\"n\">bpython</span>\n</pre></div>"], "codes_text": ["[settings]\nshell = bpython\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/shell.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Launch the shell", "header_href": "#launch-the-shell", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"o\">&lt;</span><span class=\"n\">url</span><span class=\"o\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># UNIX-style</span>\n<span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"o\">./</span><span class=\"n\">path</span><span class=\"o\">/</span><span class=\"n\">to</span><span class=\"o\">/</span><span class=\"n\">file</span><span class=\"o\">.</span><span class=\"n\">html</span>\n<span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"o\">../</span><span class=\"n\">other</span><span class=\"o\">/</span><span class=\"n\">path</span><span class=\"o\">/</span><span class=\"n\">to</span><span class=\"o\">/</span><span class=\"n\">file</span><span class=\"o\">.</span><span class=\"n\">html</span>\n<span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"o\">/</span><span class=\"n\">absolute</span><span class=\"o\">/</span><span class=\"n\">path</span><span class=\"o\">/</span><span class=\"n\">to</span><span class=\"o\">/</span><span class=\"n\">file</span><span class=\"o\">.</span><span class=\"n\">html</span>\n\n<span class=\"c1\"># File URI</span>\n<span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"n\">file</span><span class=\"p\">:</span><span class=\"o\">///</span><span class=\"n\">absolute</span><span class=\"o\">/</span><span class=\"n\">path</span><span class=\"o\">/</span><span class=\"n\">to</span><span class=\"o\">/</span><span class=\"n\">file</span><span class=\"o\">.</span><span class=\"n\">html</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy shell index.html\n[ ... scrapy shell starts ... ]\n[ ... traceback ... ]\ntwisted.internet.error.DNSLookupError: DNS lookup failed:\naddress 'index.html' not found: [Errno -5] No address associated with hostname.\n</pre></div>"], "codes_text": ["scrapy shell <url>\n", "# UNIX-style\nscrapy shell ./path/to/file.html\nscrapy shell ../other/path/to/file.html\nscrapy shell /absolute/path/to/file.html\n\n# File URI\nscrapy shell file:///absolute/path/to/file.html\n", "$ scrapy shell index.html\n[ ... scrapy shell starts ... ]\n[ ... traceback ... ]\ntwisted.internet.error.DNSLookupError: DNS lookup failed:\naddress 'index.html' not found: [Errno -5] No address associated with hostname.\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/shell.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Using the shell", "header_href": "#using-the-shell", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/shell.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Available Shortcuts", "header_href": "#available-shortcuts", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/shell.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Available Scrapy objects", "header_href": "#available-scrapy-objects", "codes": [], "codes_text": [], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/shell.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Example of shell session", "header_href": "#example-of-shell-session", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"s1\">'https://scrapy.org'</span> <span class=\"o\">--</span><span class=\"n\">nolog</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">shell</span> <span class=\"s2\">\"https://scrapy.org\"</span> <span class=\"o\">--</span><span class=\"n\">nolog</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span> <span class=\"n\">Available</span> <span class=\"n\">Scrapy</span> <span class=\"n\">objects</span><span class=\"p\">:</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">scrapy</span>     <span class=\"n\">scrapy</span> <span class=\"n\">module</span> <span class=\"p\">(</span><span class=\"n\">contains</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">,</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Selector</span><span class=\"p\">,</span> <span class=\"n\">etc</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">crawler</span>    <span class=\"o\">&lt;</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">Crawler</span> <span class=\"nb\">object</span> <span class=\"n\">at</span> <span class=\"mh\">0x7f07395dd690</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">item</span>       <span class=\"p\">{}</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">request</span>    <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">org</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">response</span>   <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">org</span><span class=\"o\">/&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">settings</span>   <span class=\"o\">&lt;</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">Settings</span> <span class=\"nb\">object</span> <span class=\"n\">at</span> <span class=\"mh\">0x7f07395dd710</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">spider</span>     <span class=\"o\">&lt;</span><span class=\"n\">DefaultSpider</span> <span class=\"s1\">'default'</span> <span class=\"n\">at</span> <span class=\"mh\">0x7f0735891690</span><span class=\"o\">&gt;</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span> <span class=\"n\">Useful</span> <span class=\"n\">shortcuts</span><span class=\"p\">:</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">fetch</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">[,</span> <span class=\"n\">redirect</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">])</span> <span class=\"n\">Fetch</span> <span class=\"n\">URL</span> <span class=\"ow\">and</span> <span class=\"n\">update</span> <span class=\"n\">local</span> <span class=\"n\">objects</span> <span class=\"p\">(</span><span class=\"n\">by</span> <span class=\"n\">default</span><span class=\"p\">,</span> <span class=\"n\">redirects</span> <span class=\"n\">are</span> <span class=\"n\">followed</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">fetch</span><span class=\"p\">(</span><span class=\"n\">req</span><span class=\"p\">)</span>                  <span class=\"n\">Fetch</span> <span class=\"n\">a</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span> <span class=\"ow\">and</span> <span class=\"n\">update</span> <span class=\"n\">local</span> <span class=\"n\">objects</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">shelp</span><span class=\"p\">()</span>           <span class=\"n\">Shell</span> <span class=\"n\">help</span> <span class=\"p\">(</span><span class=\"nb\">print</span> <span class=\"n\">this</span> <span class=\"n\">help</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">view</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">)</span>    <span class=\"n\">View</span> <span class=\"n\">response</span> <span class=\"ow\">in</span> <span class=\"n\">a</span> <span class=\"n\">browser</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'Scrapy | A Fast and Powerful Scraping and Web Crawling Framework'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">fetch</span><span class=\"p\">(</span><span class=\"s2\">\"https://old.reddit.com/\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//title/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'reddit: the front page of the internet'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"n\">method</span><span class=\"o\">=</span><span class=\"s2\">\"POST\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">fetch</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">status</span>\n<span class=\"go\">404</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">pprint</span> <span class=\"kn\">import</span> <span class=\"n\">pprint</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">pprint</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">headers</span><span class=\"p\">)</span>\n<span class=\"go\">{'Accept-Ranges': ['bytes'],</span>\n<span class=\"go\"> 'Cache-Control': ['max-age=0, must-revalidate'],</span>\n<span class=\"go\"> 'Content-Type': ['text/html; charset=UTF-8'],</span>\n<span class=\"go\"> 'Date': ['Thu, 08 Dec 2016 16:21:19 GMT'],</span>\n<span class=\"go\"> 'Server': ['snooserv'],</span>\n<span class=\"go\"> 'Set-Cookie': ['loid=KqNLou0V9SKMX4qb4n; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',</span>\n<span class=\"go\">                'loidcreated=2016-12-08T16%3A21%3A19.445Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',</span>\n<span class=\"go\">                'loid=vi0ZVe4NkxNWdlH7r7; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',</span>\n<span class=\"go\">                'loidcreated=2016-12-08T16%3A21%3A19.459Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure'],</span>\n<span class=\"go\"> 'Vary': ['accept-encoding'],</span>\n<span class=\"go\"> 'Via': ['1.1 varnish'],</span>\n<span class=\"go\"> 'X-Cache': ['MISS'],</span>\n<span class=\"go\"> 'X-Cache-Hits': ['0'],</span>\n<span class=\"go\"> 'X-Content-Type-Options': ['nosniff'],</span>\n<span class=\"go\"> 'X-Frame-Options': ['SAMEORIGIN'],</span>\n<span class=\"go\"> 'X-Moose': ['majestic'],</span>\n<span class=\"go\"> 'X-Served-By': ['cache-cdg8730-CDG'],</span>\n<span class=\"go\"> 'X-Timer': ['S1481214079.394283,VS0,VE159'],</span>\n<span class=\"go\"> 'X-Ua-Compatible': ['IE=edge'],</span>\n<span class=\"go\"> 'X-Xss-Protection': ['1; mode=block']}</span>\n</pre></div>"], "codes_text": ["scrapy shell 'https://scrapy.org' --nolog\n", "scrapy shell \"https://scrapy.org\" --nolog\n", "[s] Available Scrapy objects:\n[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)\n[s]   crawler    <scrapy.crawler.Crawler object at 0x7f07395dd690>\n[s]   item       {}\n[s]   request    <GET https://scrapy.org>\n[s]   response   <200 https://scrapy.org/>\n[s]   settings   <scrapy.settings.Settings object at 0x7f07395dd710>\n[s]   spider     <DefaultSpider 'default' at 0x7f0735891690>\n[s] Useful shortcuts:\n[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)\n[s]   fetch(req)                  Fetch a scrapy.Request and update local objects\n[s]   shelp()           Shell help (print this help)\n[s]   view(response)    View response in a browser\n\n>>>\n", ">>> response.xpath('//title/text()').get()\n'Scrapy | A Fast and Powerful Scraping and Web Crawling Framework'\n", ">>> fetch(\"https://old.reddit.com/\")\n", ">>> response.xpath('//title/text()').get()\n'reddit: the front page of the internet'\n", ">>> request = request.replace(method=\"POST\")\n", ">>> fetch(request)\n", ">>> response.status\n404\n", ">>> from pprint import pprint\n", ">>> pprint(response.headers)\n{'Accept-Ranges': ['bytes'],\n 'Cache-Control': ['max-age=0, must-revalidate'],\n 'Content-Type': ['text/html; charset=UTF-8'],\n 'Date': ['Thu, 08 Dec 2016 16:21:19 GMT'],\n 'Server': ['snooserv'],\n 'Set-Cookie': ['loid=KqNLou0V9SKMX4qb4n; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',\n                'loidcreated=2016-12-08T16:21:19.445Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',\n                'loid=vi0ZVe4NkxNWdlH7r7; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',\n                'loidcreated=2016-12-08T16:21:19.459Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure'],\n 'Vary': ['accept-encoding'],\n 'Via': ['1.1 varnish'],\n 'X-Cache': ['MISS'],\n 'X-Cache-Hits': ['0'],\n 'X-Content-Type-Options': ['nosniff'],\n 'X-Frame-Options': ['SAMEORIGIN'],\n 'X-Moose': ['majestic'],\n 'X-Served-By': ['cache-cdg8730-CDG'],\n 'X-Timer': ['S1481214079.394283,VS0,VE159'],\n 'X-Ua-Compatible': ['IE=edge'],\n 'X-Xss-Protection': ['1; mode=block']}\n"], "index": 11}
{"url": "https://docs.scrapy.org/en/latest/topics/shell.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Invoking the shell from spiders to inspect responses", "header_href": "#invoking-the-shell-from-spiders-to-inspect-responses", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"myspider\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s2\">\"http://example.com\"</span><span class=\"p\">,</span>\n        <span class=\"s2\">\"http://example.org\"</span><span class=\"p\">,</span>\n        <span class=\"s2\">\"http://example.net\"</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"c1\"># We want to inspect one specific response.</span>\n        <span class=\"k\">if</span> <span class=\"s2\">\".org\"</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">:</span>\n            <span class=\"kn\">from</span> <span class=\"nn\">scrapy.shell</span> <span class=\"kn\">import</span> <span class=\"n\">inspect_response</span>\n            <span class=\"n\">inspect_response</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># Rest of parsing code.</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">2014</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">23</span> <span class=\"mi\">17</span><span class=\"p\">:</span><span class=\"mi\">48</span><span class=\"p\">:</span><span class=\"mi\">31</span><span class=\"o\">-</span><span class=\"mi\">0400</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"mi\">2014</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">23</span> <span class=\"mi\">17</span><span class=\"p\">:</span><span class=\"mi\">48</span><span class=\"p\">:</span><span class=\"mi\">31</span><span class=\"o\">-</span><span class=\"mi\">0400</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">org</span><span class=\"o\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span> <span class=\"n\">Available</span> <span class=\"n\">Scrapy</span> <span class=\"n\">objects</span><span class=\"p\">:</span>\n<span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]</span>   <span class=\"n\">crawler</span>    <span class=\"o\">&lt;</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">Crawler</span> <span class=\"nb\">object</span> <span class=\"n\">at</span> <span class=\"mh\">0x1e16b50</span><span class=\"o\">&gt;</span>\n<span class=\"o\">...</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span>\n<span class=\"s1\">'http://example.org'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//h1[@class=\"fn\"]'</span><span class=\"p\">)</span>\n<span class=\"go\">[]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">)</span>\n<span class=\"go\">True</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"o\">^</span><span class=\"n\">D</span>\n<span class=\"go\">2014-01-23 17:50:03-0400 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://example.net&gt; (referer: None)</span>\n<span class=\"gp\">...</span>\n</pre></div>"], "codes_text": ["import scrapy\n\n\nclass MySpider(scrapy.Spider):\n    name = \"myspider\"\n    start_urls = [\n        \"http://example.com\",\n        \"http://example.org\",\n        \"http://example.net\",\n    ]\n\n    def parse(self, response):\n        # We want to inspect one specific response.\n        if \".org\" in response.url:\n            from scrapy.shell import inspect_response\n            inspect_response(response, self)\n\n        # Rest of parsing code.\n", "2014-01-23 17:48:31-0400 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://example.com> (referer: None)\n2014-01-23 17:48:31-0400 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://example.org> (referer: None)\n[s] Available Scrapy objects:\n[s]   crawler    <scrapy.crawler.Crawler object at 0x1e16b50>\n...\n\n>>> response.url\n'http://example.org'\n", ">>> response.xpath('//h1[@class=\"fn\"]')\n[]\n", ">>> view(response)\nTrue\n", ">>> ^D\n2014-01-23 17:50:03-0400 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://example.net> (referer: None)\n...\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/item-pipeline.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Item Pipeline", "header_href": "#item-pipeline", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">DropItem</span>\n<span class=\"k\">class</span> <span class=\"nc\">PricePipeline</span><span class=\"p\">:</span>\n\n    <span class=\"n\">vat_factor</span> <span class=\"o\">=</span> <span class=\"mf\">1.15</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"k\">if</span> <span class=\"n\">adapter</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'price'</span><span class=\"p\">):</span>\n            <span class=\"k\">if</span> <span class=\"n\">adapter</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'price_excludes_vat'</span><span class=\"p\">):</span>\n                <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'price'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'price'</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">vat_factor</span>\n            <span class=\"k\">return</span> <span class=\"n\">item</span>\n        <span class=\"k\">else</span><span class=\"p\">:</span>\n            <span class=\"k\">raise</span> <span class=\"n\">DropItem</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"Missing price in </span><span class=\"si\">{</span><span class=\"n\">item</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">json</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">JsonWriterPipeline</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">open_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">file</span> <span class=\"o\">=</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s1\">'items.jsonl'</span><span class=\"p\">,</span> <span class=\"s1\">'w'</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">close_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">file</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">line</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">dumps</span><span class=\"p\">(</span><span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">asdict</span><span class=\"p\">())</span> <span class=\"o\">+</span> <span class=\"s2\">\"</span><span class=\"se\">\\n</span><span class=\"s2\">\"</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">file</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">line</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">pymongo</span>\n<span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MongoPipeline</span><span class=\"p\">:</span>\n\n    <span class=\"n\">collection_name</span> <span class=\"o\">=</span> <span class=\"s1\">'scrapy_items'</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">mongo_uri</span><span class=\"p\">,</span> <span class=\"n\">mongo_db</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">mongo_uri</span> <span class=\"o\">=</span> <span class=\"n\">mongo_uri</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">mongo_db</span> <span class=\"o\">=</span> <span class=\"n\">mongo_db</span>\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">from_crawler</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">crawler</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"bp\">cls</span><span class=\"p\">(</span>\n            <span class=\"n\">mongo_uri</span><span class=\"o\">=</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'MONGO_URI'</span><span class=\"p\">),</span>\n            <span class=\"n\">mongo_db</span><span class=\"o\">=</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'MONGO_DATABASE'</span><span class=\"p\">,</span> <span class=\"s1\">'items'</span><span class=\"p\">)</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">open_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">pymongo</span><span class=\"o\">.</span><span class=\"n\">MongoClient</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">mongo_uri</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">db</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">client</span><span class=\"p\">[</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">mongo_db</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">close_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">db</span><span class=\"p\">[</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">collection_name</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">insert_one</span><span class=\"p\">(</span><span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">asdict</span><span class=\"p\">())</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">hashlib</span>\n<span class=\"kn\">from</span> <span class=\"nn\">urllib.parse</span> <span class=\"kn\">import</span> <span class=\"n\">quote</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.defer</span> <span class=\"kn\">import</span> <span class=\"n\">maybe_deferred_to_future</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">ScreenshotPipeline</span><span class=\"p\">:</span>\n    <span class=\"sd\">\"\"\"Pipeline that uses Splash to render screenshot of</span>\n<span class=\"sd\">    every Scrapy item.\"\"\"</span>\n\n    <span class=\"n\">SPLASH_URL</span> <span class=\"o\">=</span> <span class=\"s2\">\"http://localhost:8050/render.png?url=</span><span class=\"si\">{}</span><span class=\"s2\">\"</span>\n\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"n\">encoded_item_url</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"p\">(</span><span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s2\">\"url\"</span><span class=\"p\">])</span>\n        <span class=\"n\">screenshot_url</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">SPLASH_URL</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">encoded_item_url</span><span class=\"p\">)</span>\n        <span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">screenshot_url</span><span class=\"p\">)</span>\n        <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">maybe_deferred_to_future</span><span class=\"p\">(</span><span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"o\">.</span><span class=\"n\">download</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">))</span>\n\n        <span class=\"k\">if</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">status</span> <span class=\"o\">!=</span> <span class=\"mi\">200</span><span class=\"p\">:</span>\n            <span class=\"c1\"># Error happened, return item.</span>\n            <span class=\"k\">return</span> <span class=\"n\">item</span>\n\n        <span class=\"c1\"># Save screenshot to file, filename will be hash of url.</span>\n        <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s2\">\"url\"</span><span class=\"p\">]</span>\n        <span class=\"n\">url_hash</span> <span class=\"o\">=</span> <span class=\"n\">hashlib</span><span class=\"o\">.</span><span class=\"n\">md5</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">(</span><span class=\"s2\">\"utf8\"</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">hexdigest</span><span class=\"p\">()</span>\n        <span class=\"n\">filename</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s2\">\"</span><span class=\"si\">{</span><span class=\"n\">url_hash</span><span class=\"si\">}</span><span class=\"s2\">.png\"</span>\n        <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span> <span class=\"s2\">\"wb\"</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n            <span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># Store filename in item.</span>\n        <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s2\">\"screenshot_filename\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">filename</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">DropItem</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">DuplicatesPipeline</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ids_seen</span> <span class=\"o\">=</span> <span class=\"nb\">set</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"k\">if</span> <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ids_seen</span><span class=\"p\">:</span>\n            <span class=\"k\">raise</span> <span class=\"n\">DropItem</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"Duplicate item found: </span><span class=\"si\">{</span><span class=\"n\">item</span><span class=\"si\">!r}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n        <span class=\"k\">else</span><span class=\"p\">:</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ids_seen</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">])</span>\n            <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">ITEM_PIPELINES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'myproject.pipelines.PricePipeline'</span><span class=\"p\">:</span> <span class=\"mi\">300</span><span class=\"p\">,</span>\n    <span class=\"s1\">'myproject.pipelines.JsonWriterPipeline'</span><span class=\"p\">:</span> <span class=\"mi\">800</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["from itemadapter import ItemAdapter\nfrom scrapy.exceptions import DropItem\nclass PricePipeline:\n\n    vat_factor = 1.15\n\n    def process_item(self, item, spider):\n        adapter = ItemAdapter(item)\n        if adapter.get('price'):\n            if adapter.get('price_excludes_vat'):\n                adapter['price'] = adapter['price'] * self.vat_factor\n            return item\n        else:\n            raise DropItem(f\"Missing price in {item}\")\n", "import json\n\nfrom itemadapter import ItemAdapter\n\nclass JsonWriterPipeline:\n\n    def open_spider(self, spider):\n        self.file = open('items.jsonl', 'w')\n\n    def close_spider(self, spider):\n        self.file.close()\n\n    def process_item(self, item, spider):\n        line = json.dumps(ItemAdapter(item).asdict()) + \"\\n\"\n        self.file.write(line)\n        return item\n", "import pymongo\nfrom itemadapter import ItemAdapter\n\nclass MongoPipeline:\n\n    collection_name = 'scrapy_items'\n\n    def __init__(self, mongo_uri, mongo_db):\n        self.mongo_uri = mongo_uri\n        self.mongo_db = mongo_db\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        return cls(\n            mongo_uri=crawler.settings.get('MONGO_URI'),\n            mongo_db=crawler.settings.get('MONGO_DATABASE', 'items')\n        )\n\n    def open_spider(self, spider):\n        self.client = pymongo.MongoClient(self.mongo_uri)\n        self.db = self.client[self.mongo_db]\n\n    def close_spider(self, spider):\n        self.client.close()\n\n    def process_item(self, item, spider):\n        self.db[self.collection_name].insert_one(ItemAdapter(item).asdict())\n        return item\n", "import hashlib\nfrom urllib.parse import quote\n\nimport scrapy\nfrom itemadapter import ItemAdapter\nfrom scrapy.utils.defer import maybe_deferred_to_future\n\n\nclass ScreenshotPipeline:\n    \"\"\"Pipeline that uses Splash to render screenshot of\n    every Scrapy item.\"\"\"\n\n    SPLASH_URL = \"http://localhost:8050/render.png?url={}\"\n\n    async def process_item(self, item, spider):\n        adapter = ItemAdapter(item)\n        encoded_item_url = quote(adapter[\"url\"])\n        screenshot_url = self.SPLASH_URL.format(encoded_item_url)\n        request = scrapy.Request(screenshot_url)\n        response = await maybe_deferred_to_future(spider.crawler.engine.download(request, spider))\n\n        if response.status != 200:\n            # Error happened, return item.\n            return item\n\n        # Save screenshot to file, filename will be hash of url.\n        url = adapter[\"url\"]\n        url_hash = hashlib.md5(url.encode(\"utf8\")).hexdigest()\n        filename = f\"{url_hash}.png\"\n        with open(filename, \"wb\") as f:\n            f.write(response.body)\n\n        # Store filename in item.\n        adapter[\"screenshot_filename\"] = filename\n        return item\n", "from itemadapter import ItemAdapter\nfrom scrapy.exceptions import DropItem\n\nclass DuplicatesPipeline:\n\n    def __init__(self):\n        self.ids_seen = set()\n\n    def process_item(self, item, spider):\n        adapter = ItemAdapter(item)\n        if adapter['id'] in self.ids_seen:\n            raise DropItem(f\"Duplicate item found: {item!r}\")\n        else:\n            self.ids_seen.add(adapter['id'])\n            return item\n", "ITEM_PIPELINES = {\n    'myproject.pipelines.PricePipeline': 300,\n    'myproject.pipelines.JsonWriterPipeline': 800,\n}\n"], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/item-pipeline.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Writing your own item pipeline", "header_href": "#writing-your-own-item-pipeline", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/item-pipeline.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Item pipeline example", "header_href": "#item-pipeline-example", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">DropItem</span>\n<span class=\"k\">class</span> <span class=\"nc\">PricePipeline</span><span class=\"p\">:</span>\n\n    <span class=\"n\">vat_factor</span> <span class=\"o\">=</span> <span class=\"mf\">1.15</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"k\">if</span> <span class=\"n\">adapter</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'price'</span><span class=\"p\">):</span>\n            <span class=\"k\">if</span> <span class=\"n\">adapter</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'price_excludes_vat'</span><span class=\"p\">):</span>\n                <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'price'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'price'</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">vat_factor</span>\n            <span class=\"k\">return</span> <span class=\"n\">item</span>\n        <span class=\"k\">else</span><span class=\"p\">:</span>\n            <span class=\"k\">raise</span> <span class=\"n\">DropItem</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"Missing price in </span><span class=\"si\">{</span><span class=\"n\">item</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">json</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">JsonWriterPipeline</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">open_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">file</span> <span class=\"o\">=</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s1\">'items.jsonl'</span><span class=\"p\">,</span> <span class=\"s1\">'w'</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">close_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">file</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">line</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">dumps</span><span class=\"p\">(</span><span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">asdict</span><span class=\"p\">())</span> <span class=\"o\">+</span> <span class=\"s2\">\"</span><span class=\"se\">\\n</span><span class=\"s2\">\"</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">file</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">line</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">pymongo</span>\n<span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MongoPipeline</span><span class=\"p\">:</span>\n\n    <span class=\"n\">collection_name</span> <span class=\"o\">=</span> <span class=\"s1\">'scrapy_items'</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">mongo_uri</span><span class=\"p\">,</span> <span class=\"n\">mongo_db</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">mongo_uri</span> <span class=\"o\">=</span> <span class=\"n\">mongo_uri</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">mongo_db</span> <span class=\"o\">=</span> <span class=\"n\">mongo_db</span>\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">from_crawler</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">crawler</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"bp\">cls</span><span class=\"p\">(</span>\n            <span class=\"n\">mongo_uri</span><span class=\"o\">=</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'MONGO_URI'</span><span class=\"p\">),</span>\n            <span class=\"n\">mongo_db</span><span class=\"o\">=</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'MONGO_DATABASE'</span><span class=\"p\">,</span> <span class=\"s1\">'items'</span><span class=\"p\">)</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">open_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">pymongo</span><span class=\"o\">.</span><span class=\"n\">MongoClient</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">mongo_uri</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">db</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">client</span><span class=\"p\">[</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">mongo_db</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">close_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">db</span><span class=\"p\">[</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">collection_name</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">insert_one</span><span class=\"p\">(</span><span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">asdict</span><span class=\"p\">())</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">hashlib</span>\n<span class=\"kn\">from</span> <span class=\"nn\">urllib.parse</span> <span class=\"kn\">import</span> <span class=\"n\">quote</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.defer</span> <span class=\"kn\">import</span> <span class=\"n\">maybe_deferred_to_future</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">ScreenshotPipeline</span><span class=\"p\">:</span>\n    <span class=\"sd\">\"\"\"Pipeline that uses Splash to render screenshot of</span>\n<span class=\"sd\">    every Scrapy item.\"\"\"</span>\n\n    <span class=\"n\">SPLASH_URL</span> <span class=\"o\">=</span> <span class=\"s2\">\"http://localhost:8050/render.png?url=</span><span class=\"si\">{}</span><span class=\"s2\">\"</span>\n\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"n\">encoded_item_url</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"p\">(</span><span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s2\">\"url\"</span><span class=\"p\">])</span>\n        <span class=\"n\">screenshot_url</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">SPLASH_URL</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">encoded_item_url</span><span class=\"p\">)</span>\n        <span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">screenshot_url</span><span class=\"p\">)</span>\n        <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">maybe_deferred_to_future</span><span class=\"p\">(</span><span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"o\">.</span><span class=\"n\">download</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">))</span>\n\n        <span class=\"k\">if</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">status</span> <span class=\"o\">!=</span> <span class=\"mi\">200</span><span class=\"p\">:</span>\n            <span class=\"c1\"># Error happened, return item.</span>\n            <span class=\"k\">return</span> <span class=\"n\">item</span>\n\n        <span class=\"c1\"># Save screenshot to file, filename will be hash of url.</span>\n        <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s2\">\"url\"</span><span class=\"p\">]</span>\n        <span class=\"n\">url_hash</span> <span class=\"o\">=</span> <span class=\"n\">hashlib</span><span class=\"o\">.</span><span class=\"n\">md5</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">(</span><span class=\"s2\">\"utf8\"</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">hexdigest</span><span class=\"p\">()</span>\n        <span class=\"n\">filename</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s2\">\"</span><span class=\"si\">{</span><span class=\"n\">url_hash</span><span class=\"si\">}</span><span class=\"s2\">.png\"</span>\n        <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span> <span class=\"s2\">\"wb\"</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n            <span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># Store filename in item.</span>\n        <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s2\">\"screenshot_filename\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">filename</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">DropItem</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">DuplicatesPipeline</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ids_seen</span> <span class=\"o\">=</span> <span class=\"nb\">set</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"k\">if</span> <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ids_seen</span><span class=\"p\">:</span>\n            <span class=\"k\">raise</span> <span class=\"n\">DropItem</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"Duplicate item found: </span><span class=\"si\">{</span><span class=\"n\">item</span><span class=\"si\">!r}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n        <span class=\"k\">else</span><span class=\"p\">:</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ids_seen</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">])</span>\n            <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>"], "codes_text": ["from itemadapter import ItemAdapter\nfrom scrapy.exceptions import DropItem\nclass PricePipeline:\n\n    vat_factor = 1.15\n\n    def process_item(self, item, spider):\n        adapter = ItemAdapter(item)\n        if adapter.get('price'):\n            if adapter.get('price_excludes_vat'):\n                adapter['price'] = adapter['price'] * self.vat_factor\n            return item\n        else:\n            raise DropItem(f\"Missing price in {item}\")\n", "import json\n\nfrom itemadapter import ItemAdapter\n\nclass JsonWriterPipeline:\n\n    def open_spider(self, spider):\n        self.file = open('items.jsonl', 'w')\n\n    def close_spider(self, spider):\n        self.file.close()\n\n    def process_item(self, item, spider):\n        line = json.dumps(ItemAdapter(item).asdict()) + \"\\n\"\n        self.file.write(line)\n        return item\n", "import pymongo\nfrom itemadapter import ItemAdapter\n\nclass MongoPipeline:\n\n    collection_name = 'scrapy_items'\n\n    def __init__(self, mongo_uri, mongo_db):\n        self.mongo_uri = mongo_uri\n        self.mongo_db = mongo_db\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        return cls(\n            mongo_uri=crawler.settings.get('MONGO_URI'),\n            mongo_db=crawler.settings.get('MONGO_DATABASE', 'items')\n        )\n\n    def open_spider(self, spider):\n        self.client = pymongo.MongoClient(self.mongo_uri)\n        self.db = self.client[self.mongo_db]\n\n    def close_spider(self, spider):\n        self.client.close()\n\n    def process_item(self, item, spider):\n        self.db[self.collection_name].insert_one(ItemAdapter(item).asdict())\n        return item\n", "import hashlib\nfrom urllib.parse import quote\n\nimport scrapy\nfrom itemadapter import ItemAdapter\nfrom scrapy.utils.defer import maybe_deferred_to_future\n\n\nclass ScreenshotPipeline:\n    \"\"\"Pipeline that uses Splash to render screenshot of\n    every Scrapy item.\"\"\"\n\n    SPLASH_URL = \"http://localhost:8050/render.png?url={}\"\n\n    async def process_item(self, item, spider):\n        adapter = ItemAdapter(item)\n        encoded_item_url = quote(adapter[\"url\"])\n        screenshot_url = self.SPLASH_URL.format(encoded_item_url)\n        request = scrapy.Request(screenshot_url)\n        response = await maybe_deferred_to_future(spider.crawler.engine.download(request, spider))\n\n        if response.status != 200:\n            # Error happened, return item.\n            return item\n\n        # Save screenshot to file, filename will be hash of url.\n        url = adapter[\"url\"]\n        url_hash = hashlib.md5(url.encode(\"utf8\")).hexdigest()\n        filename = f\"{url_hash}.png\"\n        with open(filename, \"wb\") as f:\n            f.write(response.body)\n\n        # Store filename in item.\n        adapter[\"screenshot_filename\"] = filename\n        return item\n", "from itemadapter import ItemAdapter\nfrom scrapy.exceptions import DropItem\n\nclass DuplicatesPipeline:\n\n    def __init__(self):\n        self.ids_seen = set()\n\n    def process_item(self, item, spider):\n        adapter = ItemAdapter(item)\n        if adapter['id'] in self.ids_seen:\n            raise DropItem(f\"Duplicate item found: {item!r}\")\n        else:\n            self.ids_seen.add(adapter['id'])\n            return item\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/item-pipeline.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Price validation and dropping items with no prices", "header_href": "#price-validation-and-dropping-items-with-no-prices", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">DropItem</span>\n<span class=\"k\">class</span> <span class=\"nc\">PricePipeline</span><span class=\"p\">:</span>\n\n    <span class=\"n\">vat_factor</span> <span class=\"o\">=</span> <span class=\"mf\">1.15</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"k\">if</span> <span class=\"n\">adapter</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'price'</span><span class=\"p\">):</span>\n            <span class=\"k\">if</span> <span class=\"n\">adapter</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'price_excludes_vat'</span><span class=\"p\">):</span>\n                <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'price'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'price'</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">vat_factor</span>\n            <span class=\"k\">return</span> <span class=\"n\">item</span>\n        <span class=\"k\">else</span><span class=\"p\">:</span>\n            <span class=\"k\">raise</span> <span class=\"n\">DropItem</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"Missing price in </span><span class=\"si\">{</span><span class=\"n\">item</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["from itemadapter import ItemAdapter\nfrom scrapy.exceptions import DropItem\nclass PricePipeline:\n\n    vat_factor = 1.15\n\n    def process_item(self, item, spider):\n        adapter = ItemAdapter(item)\n        if adapter.get('price'):\n            if adapter.get('price_excludes_vat'):\n                adapter['price'] = adapter['price'] * self.vat_factor\n            return item\n        else:\n            raise DropItem(f\"Missing price in {item}\")\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/item-pipeline.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Write items to a JSON lines file", "header_href": "#write-items-to-a-json-lines-file", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">json</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">JsonWriterPipeline</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">open_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">file</span> <span class=\"o\">=</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s1\">'items.jsonl'</span><span class=\"p\">,</span> <span class=\"s1\">'w'</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">close_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">file</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">line</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">dumps</span><span class=\"p\">(</span><span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">asdict</span><span class=\"p\">())</span> <span class=\"o\">+</span> <span class=\"s2\">\"</span><span class=\"se\">\\n</span><span class=\"s2\">\"</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">file</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">line</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>"], "codes_text": ["import json\n\nfrom itemadapter import ItemAdapter\n\nclass JsonWriterPipeline:\n\n    def open_spider(self, spider):\n        self.file = open('items.jsonl', 'w')\n\n    def close_spider(self, spider):\n        self.file.close()\n\n    def process_item(self, item, spider):\n        line = json.dumps(ItemAdapter(item).asdict()) + \"\\n\"\n        self.file.write(line)\n        return item\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/item-pipeline.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Write items to MongoDB", "header_href": "#write-items-to-mongodb", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">pymongo</span>\n<span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MongoPipeline</span><span class=\"p\">:</span>\n\n    <span class=\"n\">collection_name</span> <span class=\"o\">=</span> <span class=\"s1\">'scrapy_items'</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">mongo_uri</span><span class=\"p\">,</span> <span class=\"n\">mongo_db</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">mongo_uri</span> <span class=\"o\">=</span> <span class=\"n\">mongo_uri</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">mongo_db</span> <span class=\"o\">=</span> <span class=\"n\">mongo_db</span>\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">from_crawler</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">crawler</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"bp\">cls</span><span class=\"p\">(</span>\n            <span class=\"n\">mongo_uri</span><span class=\"o\">=</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'MONGO_URI'</span><span class=\"p\">),</span>\n            <span class=\"n\">mongo_db</span><span class=\"o\">=</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'MONGO_DATABASE'</span><span class=\"p\">,</span> <span class=\"s1\">'items'</span><span class=\"p\">)</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">open_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">pymongo</span><span class=\"o\">.</span><span class=\"n\">MongoClient</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">mongo_uri</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">db</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">client</span><span class=\"p\">[</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">mongo_db</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">close_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">db</span><span class=\"p\">[</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">collection_name</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">insert_one</span><span class=\"p\">(</span><span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">asdict</span><span class=\"p\">())</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>"], "codes_text": ["import pymongo\nfrom itemadapter import ItemAdapter\n\nclass MongoPipeline:\n\n    collection_name = 'scrapy_items'\n\n    def __init__(self, mongo_uri, mongo_db):\n        self.mongo_uri = mongo_uri\n        self.mongo_db = mongo_db\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        return cls(\n            mongo_uri=crawler.settings.get('MONGO_URI'),\n            mongo_db=crawler.settings.get('MONGO_DATABASE', 'items')\n        )\n\n    def open_spider(self, spider):\n        self.client = pymongo.MongoClient(self.mongo_uri)\n        self.db = self.client[self.mongo_db]\n\n    def close_spider(self, spider):\n        self.client.close()\n\n    def process_item(self, item, spider):\n        self.db[self.collection_name].insert_one(ItemAdapter(item).asdict())\n        return item\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/item-pipeline.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Take screenshot of item", "header_href": "#take-screenshot-of-item", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">hashlib</span>\n<span class=\"kn\">from</span> <span class=\"nn\">urllib.parse</span> <span class=\"kn\">import</span> <span class=\"n\">quote</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.defer</span> <span class=\"kn\">import</span> <span class=\"n\">maybe_deferred_to_future</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">ScreenshotPipeline</span><span class=\"p\">:</span>\n    <span class=\"sd\">\"\"\"Pipeline that uses Splash to render screenshot of</span>\n<span class=\"sd\">    every Scrapy item.\"\"\"</span>\n\n    <span class=\"n\">SPLASH_URL</span> <span class=\"o\">=</span> <span class=\"s2\">\"http://localhost:8050/render.png?url=</span><span class=\"si\">{}</span><span class=\"s2\">\"</span>\n\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"n\">encoded_item_url</span> <span class=\"o\">=</span> <span class=\"n\">quote</span><span class=\"p\">(</span><span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s2\">\"url\"</span><span class=\"p\">])</span>\n        <span class=\"n\">screenshot_url</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">SPLASH_URL</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">encoded_item_url</span><span class=\"p\">)</span>\n        <span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">screenshot_url</span><span class=\"p\">)</span>\n        <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">maybe_deferred_to_future</span><span class=\"p\">(</span><span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"o\">.</span><span class=\"n\">download</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">))</span>\n\n        <span class=\"k\">if</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">status</span> <span class=\"o\">!=</span> <span class=\"mi\">200</span><span class=\"p\">:</span>\n            <span class=\"c1\"># Error happened, return item.</span>\n            <span class=\"k\">return</span> <span class=\"n\">item</span>\n\n        <span class=\"c1\"># Save screenshot to file, filename will be hash of url.</span>\n        <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s2\">\"url\"</span><span class=\"p\">]</span>\n        <span class=\"n\">url_hash</span> <span class=\"o\">=</span> <span class=\"n\">hashlib</span><span class=\"o\">.</span><span class=\"n\">md5</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">(</span><span class=\"s2\">\"utf8\"</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">hexdigest</span><span class=\"p\">()</span>\n        <span class=\"n\">filename</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s2\">\"</span><span class=\"si\">{</span><span class=\"n\">url_hash</span><span class=\"si\">}</span><span class=\"s2\">.png\"</span>\n        <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span> <span class=\"s2\">\"wb\"</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n            <span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># Store filename in item.</span>\n        <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s2\">\"screenshot_filename\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">filename</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>"], "codes_text": ["import hashlib\nfrom urllib.parse import quote\n\nimport scrapy\nfrom itemadapter import ItemAdapter\nfrom scrapy.utils.defer import maybe_deferred_to_future\n\n\nclass ScreenshotPipeline:\n    \"\"\"Pipeline that uses Splash to render screenshot of\n    every Scrapy item.\"\"\"\n\n    SPLASH_URL = \"http://localhost:8050/render.png?url={}\"\n\n    async def process_item(self, item, spider):\n        adapter = ItemAdapter(item)\n        encoded_item_url = quote(adapter[\"url\"])\n        screenshot_url = self.SPLASH_URL.format(encoded_item_url)\n        request = scrapy.Request(screenshot_url)\n        response = await maybe_deferred_to_future(spider.crawler.engine.download(request, spider))\n\n        if response.status != 200:\n            # Error happened, return item.\n            return item\n\n        # Save screenshot to file, filename will be hash of url.\n        url = adapter[\"url\"]\n        url_hash = hashlib.md5(url.encode(\"utf8\")).hexdigest()\n        filename = f\"{url_hash}.png\"\n        with open(filename, \"wb\") as f:\n            f.write(response.body)\n\n        # Store filename in item.\n        adapter[\"screenshot_filename\"] = filename\n        return item\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/item-pipeline.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Duplicates filter", "header_href": "#duplicates-filter", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">DropItem</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">DuplicatesPipeline</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ids_seen</span> <span class=\"o\">=</span> <span class=\"nb\">set</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"k\">if</span> <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">]</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ids_seen</span><span class=\"p\">:</span>\n            <span class=\"k\">raise</span> <span class=\"n\">DropItem</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"Duplicate item found: </span><span class=\"si\">{</span><span class=\"n\">item</span><span class=\"si\">!r}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n        <span class=\"k\">else</span><span class=\"p\">:</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ids_seen</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">])</span>\n            <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>"], "codes_text": ["from itemadapter import ItemAdapter\nfrom scrapy.exceptions import DropItem\n\nclass DuplicatesPipeline:\n\n    def __init__(self):\n        self.ids_seen = set()\n\n    def process_item(self, item, spider):\n        adapter = ItemAdapter(item)\n        if adapter['id'] in self.ids_seen:\n            raise DropItem(f\"Duplicate item found: {item!r}\")\n        else:\n            self.ids_seen.add(adapter['id'])\n            return item\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/item-pipeline.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Activating an Item Pipeline component", "header_href": "#activating-an-item-pipeline-component", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">ITEM_PIPELINES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'myproject.pipelines.PricePipeline'</span><span class=\"p\">:</span> <span class=\"mi\">300</span><span class=\"p\">,</span>\n    <span class=\"s1\">'myproject.pipelines.JsonWriterPipeline'</span><span class=\"p\">:</span> <span class=\"mi\">800</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["ITEM_PIPELINES = {\n    'myproject.pipelines.PricePipeline': 300,\n    'myproject.pipelines.JsonWriterPipeline': 800,\n}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Feed exports", "header_href": "#feed-exports", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MyCustomFilter</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">feed_options</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">feed_options</span> <span class=\"o\">=</span> <span class=\"n\">feed_options</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">accepts</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"s2\">\"field1\"</span> <span class=\"ow\">in</span> <span class=\"n\">item</span> <span class=\"ow\">and</span> <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s2\">\"field1\"</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"s2\">\"expected_data\"</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"kc\">True</span>\n        <span class=\"k\">return</span> <span class=\"kc\">False</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'items.json'</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n        <span class=\"s1\">'format'</span><span class=\"p\">:</span> <span class=\"s1\">'json'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'encoding'</span><span class=\"p\">:</span> <span class=\"s1\">'utf8'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'store_empty'</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n        <span class=\"s1\">'item_classes'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">MyItemClass1</span><span class=\"p\">,</span> <span class=\"s1\">'myproject.items.MyItemClass2'</span><span class=\"p\">],</span>\n        <span class=\"s1\">'fields'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n        <span class=\"s1\">'indent'</span><span class=\"p\">:</span> <span class=\"mi\">4</span><span class=\"p\">,</span>\n        <span class=\"s1\">'item_export_kwargs'</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n           <span class=\"s1\">'export_empty_fields'</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n        <span class=\"p\">},</span>\n    <span class=\"p\">},</span>\n    <span class=\"s1\">'/home/user/documents/items.xml'</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n        <span class=\"s1\">'format'</span><span class=\"p\">:</span> <span class=\"s1\">'xml'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'fields'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'price'</span><span class=\"p\">],</span>\n        <span class=\"s1\">'item_filter'</span><span class=\"p\">:</span> <span class=\"n\">MyCustomFilter1</span><span class=\"p\">,</span>\n        <span class=\"s1\">'encoding'</span><span class=\"p\">:</span> <span class=\"s1\">'latin1'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'indent'</span><span class=\"p\">:</span> <span class=\"mi\">8</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n    <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span><span class=\"p\">(</span><span class=\"s1\">'items.csv.gz'</span><span class=\"p\">):</span> <span class=\"p\">{</span>\n        <span class=\"s1\">'format'</span><span class=\"p\">:</span> <span class=\"s1\">'csv'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'fields'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'price'</span><span class=\"p\">,</span> <span class=\"s1\">'name'</span><span class=\"p\">],</span>\n        <span class=\"s1\">'item_filter'</span><span class=\"p\">:</span> <span class=\"s1\">'myproject.filters.MyCustomFilter2'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'postprocessing'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">MyPlugin1</span><span class=\"p\">,</span> <span class=\"s1\">'scrapy.extensions.postprocessing.GzipPlugin'</span><span class=\"p\">],</span>\n        <span class=\"s1\">'gzip_compresslevel'</span><span class=\"p\">:</span> <span class=\"mi\">5</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">''</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.extensions.feedexport.FileFeedStorage'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'file'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.extensions.feedexport.FileFeedStorage'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'stdout'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.extensions.feedexport.StdoutFeedStorage'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'s3'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.extensions.feedexport.S3FeedStorage'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'ftp'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.extensions.feedexport.FTPFeedStorage'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">FEED_STORAGES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'ftp'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'json'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.JsonItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'jsonlines'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.JsonLinesItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'jsonl'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.JsonLinesItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'jl'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.JsonLinesItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'csv'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.CsvItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'xml'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.XmlItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'marshal'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.MarshalItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'pickle'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.PickleItemExporter'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">FEED_EXPORTERS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'csv'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">FEED_EXPORT_BATCH_ITEM_COUNT</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">spidername</span> <span class=\"o\">-</span><span class=\"n\">o</span> <span class=\"s2\">\"dirname/</span><span class=\"si\">%(batch_id)d</span><span class=\"s2\">-filename</span><span class=\"si\">%(batch_time)s</span><span class=\"s2\">.json\"</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">-&gt;</span><span class=\"n\">projectname</span>\n<span class=\"o\">--&gt;</span><span class=\"n\">dirname</span>\n<span class=\"o\">---&gt;</span><span class=\"mi\">1</span><span class=\"o\">-</span><span class=\"n\">filename2020</span><span class=\"o\">-</span><span class=\"mi\">03</span><span class=\"o\">-</span><span class=\"mi\">28</span><span class=\"n\">T14</span><span class=\"o\">-</span><span class=\"mi\">45</span><span class=\"o\">-</span><span class=\"mf\">08.237134</span><span class=\"o\">.</span><span class=\"n\">json</span>\n<span class=\"o\">---&gt;</span><span class=\"mi\">2</span><span class=\"o\">-</span><span class=\"n\">filename2020</span><span class=\"o\">-</span><span class=\"mi\">03</span><span class=\"o\">-</span><span class=\"mi\">28</span><span class=\"n\">T14</span><span class=\"o\">-</span><span class=\"mi\">45</span><span class=\"o\">-</span><span class=\"mf\">09.148903</span><span class=\"o\">.</span><span class=\"n\">json</span>\n<span class=\"o\">---&gt;</span><span class=\"mi\">3</span><span class=\"o\">-</span><span class=\"n\">filename2020</span><span class=\"o\">-</span><span class=\"mi\">03</span><span class=\"o\">-</span><span class=\"mi\">28</span><span class=\"n\">T14</span><span class=\"o\">-</span><span class=\"mi\">45</span><span class=\"o\">-</span><span class=\"mf\">10.046092</span><span class=\"o\">.</span><span class=\"n\">json</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># myproject/utils.py</span>\n<span class=\"k\">def</span> <span class=\"nf\">uri_params</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"o\">**</span><span class=\"n\">params</span><span class=\"p\">,</span> <span class=\"s1\">'spider_name'</span><span class=\"p\">:</span> <span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># myproject/settings.py</span>\n<span class=\"n\">FEED_URI_PARAMS</span> <span class=\"o\">=</span> <span class=\"s1\">'myproject.utils.uri_params'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"o\">&lt;</span><span class=\"n\">spider_name</span><span class=\"o\">&gt;</span> <span class=\"o\">-</span><span class=\"n\">o</span> <span class=\"s2\">\"</span><span class=\"si\">%(spider_name)s</span><span class=\"s2\">.jsonl\"</span>\n</pre></div>"], "codes_text": ["class MyCustomFilter:\n\n    def __init__(self, feed_options):\n        self.feed_options = feed_options\n\n    def accepts(self, item):\n        if \"field1\" in item and item[\"field1\"] == \"expected_data\":\n            return True\n        return False\n", "{\n    'items.json': {\n        'format': 'json',\n        'encoding': 'utf8',\n        'store_empty': False,\n        'item_classes': [MyItemClass1, 'myproject.items.MyItemClass2'],\n        'fields': None,\n        'indent': 4,\n        'item_export_kwargs': {\n           'export_empty_fields': True,\n        },\n    },\n    '/home/user/documents/items.xml': {\n        'format': 'xml',\n        'fields': ['name', 'price'],\n        'item_filter': MyCustomFilter1,\n        'encoding': 'latin1',\n        'indent': 8,\n    },\n    pathlib.Path('items.csv.gz'): {\n        'format': 'csv',\n        'fields': ['price', 'name'],\n        'item_filter': 'myproject.filters.MyCustomFilter2',\n        'postprocessing': [MyPlugin1, 'scrapy.extensions.postprocessing.GzipPlugin'],\n        'gzip_compresslevel': 5,\n    },\n}\n", "{\n    '': 'scrapy.extensions.feedexport.FileFeedStorage',\n    'file': 'scrapy.extensions.feedexport.FileFeedStorage',\n    'stdout': 'scrapy.extensions.feedexport.StdoutFeedStorage',\n    's3': 'scrapy.extensions.feedexport.S3FeedStorage',\n    'ftp': 'scrapy.extensions.feedexport.FTPFeedStorage',\n}\n", "FEED_STORAGES = {\n    'ftp': None,\n}\n", "{\n    'json': 'scrapy.exporters.JsonItemExporter',\n    'jsonlines': 'scrapy.exporters.JsonLinesItemExporter',\n    'jsonl': 'scrapy.exporters.JsonLinesItemExporter',\n    'jl': 'scrapy.exporters.JsonLinesItemExporter',\n    'csv': 'scrapy.exporters.CsvItemExporter',\n    'xml': 'scrapy.exporters.XmlItemExporter',\n    'marshal': 'scrapy.exporters.MarshalItemExporter',\n    'pickle': 'scrapy.exporters.PickleItemExporter',\n}\n", "FEED_EXPORTERS = {\n    'csv': None,\n}\n", "FEED_EXPORT_BATCH_ITEM_COUNT = 100\n", "scrapy crawl spidername -o \"dirname/%(batch_id)d-filename%(batch_time)s.json\"\n", "->projectname\n-->dirname\n--->1-filename2020-03-28T14-45-08.237134.json\n--->2-filename2020-03-28T14-45-09.148903.json\n--->3-filename2020-03-28T14-45-10.046092.json\n", "# myproject/utils.py\ndef uri_params(params, spider):\n    return {**params, 'spider_name': spider.name}\n", "# myproject/settings.py\nFEED_URI_PARAMS = 'myproject.utils.uri_params'\n", "scrapy crawl <spider_name> -o \"%(spider_name)s.jsonl\"\n"], "index": 12}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Serialization formats", "header_href": "#serialization-formats", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "JSON", "header_href": "#json", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "JSON lines", "header_href": "#json-lines", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "CSV", "header_href": "#csv", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "XML", "header_href": "#xml", "codes": [], "codes_text": [], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Pickle", "header_href": "#pickle", "codes": [], "codes_text": [], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Marshal", "header_href": "#marshal", "codes": [], "codes_text": [], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Storages", "header_href": "#storages", "codes": [], "codes_text": [], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Storage URI parameters", "header_href": "#storage-uri-parameters", "codes": [], "codes_text": [], "index": 10}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Storage backends", "header_href": "#storage-backends", "codes": [], "codes_text": [], "index": 11}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Local filesystem", "header_href": "#local-filesystem", "codes": [], "codes_text": [], "index": 12}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FTP", "header_href": "#ftp", "codes": [], "codes_text": [], "index": 13}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "S3", "header_href": "#s3", "codes": [], "codes_text": [], "index": 14}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Google Cloud Storage (GCS)", "header_href": "#google-cloud-storage-gcs", "codes": [], "codes_text": [], "index": 15}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Standard output", "header_href": "#standard-output", "codes": [], "codes_text": [], "index": 16}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Delayed file delivery", "header_href": "#delayed-file-delivery", "codes": [], "codes_text": [], "index": 17}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Item filtering", "header_href": "#item-filtering", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MyCustomFilter</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">feed_options</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">feed_options</span> <span class=\"o\">=</span> <span class=\"n\">feed_options</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">accepts</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"s2\">\"field1\"</span> <span class=\"ow\">in</span> <span class=\"n\">item</span> <span class=\"ow\">and</span> <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s2\">\"field1\"</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"s2\">\"expected_data\"</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"kc\">True</span>\n        <span class=\"k\">return</span> <span class=\"kc\">False</span>\n</pre></div>"], "codes_text": ["class MyCustomFilter:\n\n    def __init__(self, feed_options):\n        self.feed_options = feed_options\n\n    def accepts(self, item):\n        if \"field1\" in item and item[\"field1\"] == \"expected_data\":\n            return True\n        return False\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "ItemFilter", "header_href": "#itemfilter", "codes": [], "codes_text": [], "index": 19}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Post-Processing", "header_href": "#post-processing", "codes": [], "codes_text": [], "index": 20}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Built-in Plugins", "header_href": "#built-in-plugins", "codes": [], "codes_text": [], "index": 21}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Custom Plugins", "header_href": "#custom-plugins", "codes": [], "codes_text": [], "index": 22}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Settings", "header_href": "#settings", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'items.json'</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n        <span class=\"s1\">'format'</span><span class=\"p\">:</span> <span class=\"s1\">'json'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'encoding'</span><span class=\"p\">:</span> <span class=\"s1\">'utf8'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'store_empty'</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n        <span class=\"s1\">'item_classes'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">MyItemClass1</span><span class=\"p\">,</span> <span class=\"s1\">'myproject.items.MyItemClass2'</span><span class=\"p\">],</span>\n        <span class=\"s1\">'fields'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n        <span class=\"s1\">'indent'</span><span class=\"p\">:</span> <span class=\"mi\">4</span><span class=\"p\">,</span>\n        <span class=\"s1\">'item_export_kwargs'</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n           <span class=\"s1\">'export_empty_fields'</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n        <span class=\"p\">},</span>\n    <span class=\"p\">},</span>\n    <span class=\"s1\">'/home/user/documents/items.xml'</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n        <span class=\"s1\">'format'</span><span class=\"p\">:</span> <span class=\"s1\">'xml'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'fields'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'price'</span><span class=\"p\">],</span>\n        <span class=\"s1\">'item_filter'</span><span class=\"p\">:</span> <span class=\"n\">MyCustomFilter1</span><span class=\"p\">,</span>\n        <span class=\"s1\">'encoding'</span><span class=\"p\">:</span> <span class=\"s1\">'latin1'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'indent'</span><span class=\"p\">:</span> <span class=\"mi\">8</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n    <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span><span class=\"p\">(</span><span class=\"s1\">'items.csv.gz'</span><span class=\"p\">):</span> <span class=\"p\">{</span>\n        <span class=\"s1\">'format'</span><span class=\"p\">:</span> <span class=\"s1\">'csv'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'fields'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'price'</span><span class=\"p\">,</span> <span class=\"s1\">'name'</span><span class=\"p\">],</span>\n        <span class=\"s1\">'item_filter'</span><span class=\"p\">:</span> <span class=\"s1\">'myproject.filters.MyCustomFilter2'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'postprocessing'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">MyPlugin1</span><span class=\"p\">,</span> <span class=\"s1\">'scrapy.extensions.postprocessing.GzipPlugin'</span><span class=\"p\">],</span>\n        <span class=\"s1\">'gzip_compresslevel'</span><span class=\"p\">:</span> <span class=\"mi\">5</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">''</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.extensions.feedexport.FileFeedStorage'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'file'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.extensions.feedexport.FileFeedStorage'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'stdout'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.extensions.feedexport.StdoutFeedStorage'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'s3'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.extensions.feedexport.S3FeedStorage'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'ftp'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.extensions.feedexport.FTPFeedStorage'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">FEED_STORAGES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'ftp'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'json'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.JsonItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'jsonlines'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.JsonLinesItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'jsonl'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.JsonLinesItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'jl'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.JsonLinesItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'csv'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.CsvItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'xml'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.XmlItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'marshal'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.MarshalItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'pickle'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.PickleItemExporter'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">FEED_EXPORTERS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'csv'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">FEED_EXPORT_BATCH_ITEM_COUNT</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">spidername</span> <span class=\"o\">-</span><span class=\"n\">o</span> <span class=\"s2\">\"dirname/</span><span class=\"si\">%(batch_id)d</span><span class=\"s2\">-filename</span><span class=\"si\">%(batch_time)s</span><span class=\"s2\">.json\"</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">-&gt;</span><span class=\"n\">projectname</span>\n<span class=\"o\">--&gt;</span><span class=\"n\">dirname</span>\n<span class=\"o\">---&gt;</span><span class=\"mi\">1</span><span class=\"o\">-</span><span class=\"n\">filename2020</span><span class=\"o\">-</span><span class=\"mi\">03</span><span class=\"o\">-</span><span class=\"mi\">28</span><span class=\"n\">T14</span><span class=\"o\">-</span><span class=\"mi\">45</span><span class=\"o\">-</span><span class=\"mf\">08.237134</span><span class=\"o\">.</span><span class=\"n\">json</span>\n<span class=\"o\">---&gt;</span><span class=\"mi\">2</span><span class=\"o\">-</span><span class=\"n\">filename2020</span><span class=\"o\">-</span><span class=\"mi\">03</span><span class=\"o\">-</span><span class=\"mi\">28</span><span class=\"n\">T14</span><span class=\"o\">-</span><span class=\"mi\">45</span><span class=\"o\">-</span><span class=\"mf\">09.148903</span><span class=\"o\">.</span><span class=\"n\">json</span>\n<span class=\"o\">---&gt;</span><span class=\"mi\">3</span><span class=\"o\">-</span><span class=\"n\">filename2020</span><span class=\"o\">-</span><span class=\"mi\">03</span><span class=\"o\">-</span><span class=\"mi\">28</span><span class=\"n\">T14</span><span class=\"o\">-</span><span class=\"mi\">45</span><span class=\"o\">-</span><span class=\"mf\">10.046092</span><span class=\"o\">.</span><span class=\"n\">json</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># myproject/utils.py</span>\n<span class=\"k\">def</span> <span class=\"nf\">uri_params</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"o\">**</span><span class=\"n\">params</span><span class=\"p\">,</span> <span class=\"s1\">'spider_name'</span><span class=\"p\">:</span> <span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># myproject/settings.py</span>\n<span class=\"n\">FEED_URI_PARAMS</span> <span class=\"o\">=</span> <span class=\"s1\">'myproject.utils.uri_params'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"o\">&lt;</span><span class=\"n\">spider_name</span><span class=\"o\">&gt;</span> <span class=\"o\">-</span><span class=\"n\">o</span> <span class=\"s2\">\"</span><span class=\"si\">%(spider_name)s</span><span class=\"s2\">.jsonl\"</span>\n</pre></div>"], "codes_text": ["{\n    'items.json': {\n        'format': 'json',\n        'encoding': 'utf8',\n        'store_empty': False,\n        'item_classes': [MyItemClass1, 'myproject.items.MyItemClass2'],\n        'fields': None,\n        'indent': 4,\n        'item_export_kwargs': {\n           'export_empty_fields': True,\n        },\n    },\n    '/home/user/documents/items.xml': {\n        'format': 'xml',\n        'fields': ['name', 'price'],\n        'item_filter': MyCustomFilter1,\n        'encoding': 'latin1',\n        'indent': 8,\n    },\n    pathlib.Path('items.csv.gz'): {\n        'format': 'csv',\n        'fields': ['price', 'name'],\n        'item_filter': 'myproject.filters.MyCustomFilter2',\n        'postprocessing': [MyPlugin1, 'scrapy.extensions.postprocessing.GzipPlugin'],\n        'gzip_compresslevel': 5,\n    },\n}\n", "{\n    '': 'scrapy.extensions.feedexport.FileFeedStorage',\n    'file': 'scrapy.extensions.feedexport.FileFeedStorage',\n    'stdout': 'scrapy.extensions.feedexport.StdoutFeedStorage',\n    's3': 'scrapy.extensions.feedexport.S3FeedStorage',\n    'ftp': 'scrapy.extensions.feedexport.FTPFeedStorage',\n}\n", "FEED_STORAGES = {\n    'ftp': None,\n}\n", "{\n    'json': 'scrapy.exporters.JsonItemExporter',\n    'jsonlines': 'scrapy.exporters.JsonLinesItemExporter',\n    'jsonl': 'scrapy.exporters.JsonLinesItemExporter',\n    'jl': 'scrapy.exporters.JsonLinesItemExporter',\n    'csv': 'scrapy.exporters.CsvItemExporter',\n    'xml': 'scrapy.exporters.XmlItemExporter',\n    'marshal': 'scrapy.exporters.MarshalItemExporter',\n    'pickle': 'scrapy.exporters.PickleItemExporter',\n}\n", "FEED_EXPORTERS = {\n    'csv': None,\n}\n", "FEED_EXPORT_BATCH_ITEM_COUNT = 100\n", "scrapy crawl spidername -o \"dirname/%(batch_id)d-filename%(batch_time)s.json\"\n", "->projectname\n-->dirname\n--->1-filename2020-03-28T14-45-08.237134.json\n--->2-filename2020-03-28T14-45-09.148903.json\n--->3-filename2020-03-28T14-45-10.046092.json\n", "# myproject/utils.py\ndef uri_params(params, spider):\n    return {**params, 'spider_name': spider.name}\n", "# myproject/settings.py\nFEED_URI_PARAMS = 'myproject.utils.uri_params'\n", "scrapy crawl <spider_name> -o \"%(spider_name)s.jsonl\"\n"], "index": 11}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FEEDS", "header_href": "#feeds", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'items.json'</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n        <span class=\"s1\">'format'</span><span class=\"p\">:</span> <span class=\"s1\">'json'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'encoding'</span><span class=\"p\">:</span> <span class=\"s1\">'utf8'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'store_empty'</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n        <span class=\"s1\">'item_classes'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">MyItemClass1</span><span class=\"p\">,</span> <span class=\"s1\">'myproject.items.MyItemClass2'</span><span class=\"p\">],</span>\n        <span class=\"s1\">'fields'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n        <span class=\"s1\">'indent'</span><span class=\"p\">:</span> <span class=\"mi\">4</span><span class=\"p\">,</span>\n        <span class=\"s1\">'item_export_kwargs'</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n           <span class=\"s1\">'export_empty_fields'</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n        <span class=\"p\">},</span>\n    <span class=\"p\">},</span>\n    <span class=\"s1\">'/home/user/documents/items.xml'</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n        <span class=\"s1\">'format'</span><span class=\"p\">:</span> <span class=\"s1\">'xml'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'fields'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'price'</span><span class=\"p\">],</span>\n        <span class=\"s1\">'item_filter'</span><span class=\"p\">:</span> <span class=\"n\">MyCustomFilter1</span><span class=\"p\">,</span>\n        <span class=\"s1\">'encoding'</span><span class=\"p\">:</span> <span class=\"s1\">'latin1'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'indent'</span><span class=\"p\">:</span> <span class=\"mi\">8</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n    <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span><span class=\"p\">(</span><span class=\"s1\">'items.csv.gz'</span><span class=\"p\">):</span> <span class=\"p\">{</span>\n        <span class=\"s1\">'format'</span><span class=\"p\">:</span> <span class=\"s1\">'csv'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'fields'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'price'</span><span class=\"p\">,</span> <span class=\"s1\">'name'</span><span class=\"p\">],</span>\n        <span class=\"s1\">'item_filter'</span><span class=\"p\">:</span> <span class=\"s1\">'myproject.filters.MyCustomFilter2'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'postprocessing'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">MyPlugin1</span><span class=\"p\">,</span> <span class=\"s1\">'scrapy.extensions.postprocessing.GzipPlugin'</span><span class=\"p\">],</span>\n        <span class=\"s1\">'gzip_compresslevel'</span><span class=\"p\">:</span> <span class=\"mi\">5</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["{\n    'items.json': {\n        'format': 'json',\n        'encoding': 'utf8',\n        'store_empty': False,\n        'item_classes': [MyItemClass1, 'myproject.items.MyItemClass2'],\n        'fields': None,\n        'indent': 4,\n        'item_export_kwargs': {\n           'export_empty_fields': True,\n        },\n    },\n    '/home/user/documents/items.xml': {\n        'format': 'xml',\n        'fields': ['name', 'price'],\n        'item_filter': MyCustomFilter1,\n        'encoding': 'latin1',\n        'indent': 8,\n    },\n    pathlib.Path('items.csv.gz'): {\n        'format': 'csv',\n        'fields': ['price', 'name'],\n        'item_filter': 'myproject.filters.MyCustomFilter2',\n        'postprocessing': [MyPlugin1, 'scrapy.extensions.postprocessing.GzipPlugin'],\n        'gzip_compresslevel': 5,\n    },\n}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FEED_EXPORT_ENCODING", "header_href": "#feed-export-encoding", "codes": [], "codes_text": [], "index": 25}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FEED_EXPORT_FIELDS", "header_href": "#feed-export-fields", "codes": [], "codes_text": [], "index": 26}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FEED_EXPORT_INDENT", "header_href": "#feed-export-indent", "codes": [], "codes_text": [], "index": 27}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FEED_STORE_EMPTY", "header_href": "#feed-store-empty", "codes": [], "codes_text": [], "index": 28}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FEED_STORAGES", "header_href": "#feed-storages", "codes": [], "codes_text": [], "index": 29}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FEED_STORAGE_FTP_ACTIVE", "header_href": "#feed-storage-ftp-active", "codes": [], "codes_text": [], "index": 30}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FEED_STORAGE_S3_ACL", "header_href": "#feed-storage-s3-acl", "codes": [], "codes_text": [], "index": 31}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FEED_STORAGES_BASE", "header_href": "#feed-storages-base", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">''</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.extensions.feedexport.FileFeedStorage'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'file'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.extensions.feedexport.FileFeedStorage'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'stdout'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.extensions.feedexport.StdoutFeedStorage'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'s3'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.extensions.feedexport.S3FeedStorage'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'ftp'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.extensions.feedexport.FTPFeedStorage'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">FEED_STORAGES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'ftp'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["{\n    '': 'scrapy.extensions.feedexport.FileFeedStorage',\n    'file': 'scrapy.extensions.feedexport.FileFeedStorage',\n    'stdout': 'scrapy.extensions.feedexport.StdoutFeedStorage',\n    's3': 'scrapy.extensions.feedexport.S3FeedStorage',\n    'ftp': 'scrapy.extensions.feedexport.FTPFeedStorage',\n}\n", "FEED_STORAGES = {\n    'ftp': None,\n}\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FEED_EXPORTERS", "header_href": "#feed-exporters", "codes": [], "codes_text": [], "index": 33}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FEED_EXPORTERS_BASE", "header_href": "#feed-exporters-base", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'json'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.JsonItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'jsonlines'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.JsonLinesItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'jsonl'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.JsonLinesItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'jl'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.JsonLinesItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'csv'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.CsvItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'xml'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.XmlItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'marshal'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.MarshalItemExporter'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'pickle'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.exporters.PickleItemExporter'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">FEED_EXPORTERS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'csv'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["{\n    'json': 'scrapy.exporters.JsonItemExporter',\n    'jsonlines': 'scrapy.exporters.JsonLinesItemExporter',\n    'jsonl': 'scrapy.exporters.JsonLinesItemExporter',\n    'jl': 'scrapy.exporters.JsonLinesItemExporter',\n    'csv': 'scrapy.exporters.CsvItemExporter',\n    'xml': 'scrapy.exporters.XmlItemExporter',\n    'marshal': 'scrapy.exporters.MarshalItemExporter',\n    'pickle': 'scrapy.exporters.PickleItemExporter',\n}\n", "FEED_EXPORTERS = {\n    'csv': None,\n}\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FEED_EXPORT_BATCH_ITEM_COUNT", "header_href": "#feed-export-batch-item-count", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">FEED_EXPORT_BATCH_ITEM_COUNT</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">spidername</span> <span class=\"o\">-</span><span class=\"n\">o</span> <span class=\"s2\">\"dirname/</span><span class=\"si\">%(batch_id)d</span><span class=\"s2\">-filename</span><span class=\"si\">%(batch_time)s</span><span class=\"s2\">.json\"</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">-&gt;</span><span class=\"n\">projectname</span>\n<span class=\"o\">--&gt;</span><span class=\"n\">dirname</span>\n<span class=\"o\">---&gt;</span><span class=\"mi\">1</span><span class=\"o\">-</span><span class=\"n\">filename2020</span><span class=\"o\">-</span><span class=\"mi\">03</span><span class=\"o\">-</span><span class=\"mi\">28</span><span class=\"n\">T14</span><span class=\"o\">-</span><span class=\"mi\">45</span><span class=\"o\">-</span><span class=\"mf\">08.237134</span><span class=\"o\">.</span><span class=\"n\">json</span>\n<span class=\"o\">---&gt;</span><span class=\"mi\">2</span><span class=\"o\">-</span><span class=\"n\">filename2020</span><span class=\"o\">-</span><span class=\"mi\">03</span><span class=\"o\">-</span><span class=\"mi\">28</span><span class=\"n\">T14</span><span class=\"o\">-</span><span class=\"mi\">45</span><span class=\"o\">-</span><span class=\"mf\">09.148903</span><span class=\"o\">.</span><span class=\"n\">json</span>\n<span class=\"o\">---&gt;</span><span class=\"mi\">3</span><span class=\"o\">-</span><span class=\"n\">filename2020</span><span class=\"o\">-</span><span class=\"mi\">03</span><span class=\"o\">-</span><span class=\"mi\">28</span><span class=\"n\">T14</span><span class=\"o\">-</span><span class=\"mi\">45</span><span class=\"o\">-</span><span class=\"mf\">10.046092</span><span class=\"o\">.</span><span class=\"n\">json</span>\n</pre></div>"], "codes_text": ["FEED_EXPORT_BATCH_ITEM_COUNT = 100\n", "scrapy crawl spidername -o \"dirname/%(batch_id)d-filename%(batch_time)s.json\"\n", "->projectname\n-->dirname\n--->1-filename2020-03-28T14-45-08.237134.json\n--->2-filename2020-03-28T14-45-09.148903.json\n--->3-filename2020-03-28T14-45-10.046092.json\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/feed-exports.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FEED_URI_PARAMS", "header_href": "#feed-uri-params", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"c1\"># myproject/utils.py</span>\n<span class=\"k\">def</span> <span class=\"nf\">uri_params</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"o\">**</span><span class=\"n\">params</span><span class=\"p\">,</span> <span class=\"s1\">'spider_name'</span><span class=\"p\">:</span> <span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># myproject/settings.py</span>\n<span class=\"n\">FEED_URI_PARAMS</span> <span class=\"o\">=</span> <span class=\"s1\">'myproject.utils.uri_params'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"o\">&lt;</span><span class=\"n\">spider_name</span><span class=\"o\">&gt;</span> <span class=\"o\">-</span><span class=\"n\">o</span> <span class=\"s2\">\"</span><span class=\"si\">%(spider_name)s</span><span class=\"s2\">.jsonl\"</span>\n</pre></div>"], "codes_text": ["# myproject/utils.py\ndef uri_params(params, spider):\n    return {**params, 'spider_name': spider.name}\n", "# myproject/settings.py\nFEED_URI_PARAMS = 'myproject.utils.uri_params'\n", "scrapy crawl <spider_name> -o \"%(spider_name)s.jsonl\"\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Requests and Responses", "header_href": "#module-scrapy.http", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">request_with_cookies</span> <span class=\"o\">=</span> <span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.example.com\"</span><span class=\"p\">,</span>\n                               <span class=\"n\">cookies</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'currency'</span><span class=\"p\">:</span> <span class=\"s1\">'USD'</span><span class=\"p\">,</span> <span class=\"s1\">'country'</span><span class=\"p\">:</span> <span class=\"s1\">'UY'</span><span class=\"p\">})</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">request_with_cookies</span> <span class=\"o\">=</span> <span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.example.com\"</span><span class=\"p\">,</span>\n                               <span class=\"n\">cookies</span><span class=\"o\">=</span><span class=\"p\">[{</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'currency'</span><span class=\"p\">,</span>\n                                        <span class=\"s1\">'value'</span><span class=\"p\">:</span> <span class=\"s1\">'USD'</span><span class=\"p\">,</span>\n                                        <span class=\"s1\">'domain'</span><span class=\"p\">:</span> <span class=\"s1\">'example.com'</span><span class=\"p\">,</span>\n                                        <span class=\"s1\">'path'</span><span class=\"p\">:</span> <span class=\"s1\">'/currency'</span><span class=\"p\">}])</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">Request</span><span class=\"p\">(</span>\n    <span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.example.com\"</span><span class=\"p\">,</span>\n    <span class=\"n\">cookies</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'currency'</span><span class=\"p\">:</span> <span class=\"s1\">'USD'</span><span class=\"p\">,</span> <span class=\"s1\">'country'</span><span class=\"p\">:</span> <span class=\"s1\">'UY'</span><span class=\"p\">},</span>\n    <span class=\"n\">meta</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'dont_merge_cookies'</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">},</span>\n<span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse_page1</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s2\">\"http://www.example.com/some_page.html\"</span><span class=\"p\">,</span>\n                          <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_page2</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">parse_page2</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"c1\"># this would log http://www.example.com/some_page.html</span>\n    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s2\">\"Visited </span><span class=\"si\">%s</span><span class=\"s2\">\"</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s1\">'http://www.example.com/index.html'</span><span class=\"p\">,</span>\n                             <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_page2</span><span class=\"p\">,</span>\n                             <span class=\"n\">cb_kwargs</span><span class=\"o\">=</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">main_url</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">))</span>\n    <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">cb_kwargs</span><span class=\"p\">[</span><span class=\"s1\">'foo'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'bar'</span>  <span class=\"c1\"># add more arguments for the callback</span>\n    <span class=\"k\">yield</span> <span class=\"n\">request</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">parse_page2</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">main_url</span><span class=\"p\">,</span> <span class=\"n\">foo</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"nb\">dict</span><span class=\"p\">(</span>\n        <span class=\"n\">main_url</span><span class=\"o\">=</span><span class=\"n\">main_url</span><span class=\"p\">,</span>\n        <span class=\"n\">other_url</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">,</span>\n        <span class=\"n\">foo</span><span class=\"o\">=</span><span class=\"n\">foo</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.spidermiddlewares.httperror</span> <span class=\"kn\">import</span> <span class=\"n\">HttpError</span>\n<span class=\"kn\">from</span> <span class=\"nn\">twisted.internet.error</span> <span class=\"kn\">import</span> <span class=\"n\">DNSLookupError</span>\n<span class=\"kn\">from</span> <span class=\"nn\">twisted.internet.error</span> <span class=\"kn\">import</span> <span class=\"ne\">TimeoutError</span><span class=\"p\">,</span> <span class=\"n\">TCPTimedOutError</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">ErrbackSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"errback_example\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s2\">\"http://www.httpbin.org/\"</span><span class=\"p\">,</span>              <span class=\"c1\"># HTTP 200 expected</span>\n        <span class=\"s2\">\"http://www.httpbin.org/status/404\"</span><span class=\"p\">,</span>    <span class=\"c1\"># Not found error</span>\n        <span class=\"s2\">\"http://www.httpbin.org/status/500\"</span><span class=\"p\">,</span>    <span class=\"c1\"># server issue</span>\n        <span class=\"s2\">\"http://www.httpbin.org:12345/\"</span><span class=\"p\">,</span>        <span class=\"c1\"># non-responding host, timeout expected</span>\n        <span class=\"s2\">\"https://example.invalid/\"</span><span class=\"p\">,</span>             <span class=\"c1\"># DNS error expected</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">u</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">start_urls</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">u</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_httpbin</span><span class=\"p\">,</span>\n                                    <span class=\"n\">errback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">errback_httpbin</span><span class=\"p\">,</span>\n                                    <span class=\"n\">dont_filter</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_httpbin</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Got successful response from </span><span class=\"si\">{}</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">))</span>\n        <span class=\"c1\"># do something useful here...</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">errback_httpbin</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">failure</span><span class=\"p\">):</span>\n        <span class=\"c1\"># log all failures</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"nb\">repr</span><span class=\"p\">(</span><span class=\"n\">failure</span><span class=\"p\">))</span>\n\n        <span class=\"c1\"># in case you want to do something special for some errors,</span>\n        <span class=\"c1\"># you may need the failure's type:</span>\n\n        <span class=\"k\">if</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">check</span><span class=\"p\">(</span><span class=\"n\">HttpError</span><span class=\"p\">):</span>\n            <span class=\"c1\"># these exceptions come from HttpError spider middleware</span>\n            <span class=\"c1\"># you can get the non-200 response</span>\n            <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">value</span><span class=\"o\">.</span><span class=\"n\">response</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"s1\">'HttpError on </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n\n        <span class=\"k\">elif</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">check</span><span class=\"p\">(</span><span class=\"n\">DNSLookupError</span><span class=\"p\">):</span>\n            <span class=\"c1\"># this is the original request</span>\n            <span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">request</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"s1\">'DNSLookupError on </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n\n        <span class=\"k\">elif</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">check</span><span class=\"p\">(</span><span class=\"ne\">TimeoutError</span><span class=\"p\">,</span> <span class=\"n\">TCPTimedOutError</span><span class=\"p\">):</span>\n            <span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">request</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"s1\">'TimeoutError on </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s1\">'http://www.example.com/index.html'</span><span class=\"p\">,</span>\n                             <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_page2</span><span class=\"p\">,</span>\n                             <span class=\"n\">errback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">errback_page2</span><span class=\"p\">,</span>\n                             <span class=\"n\">cb_kwargs</span><span class=\"o\">=</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">main_url</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">))</span>\n    <span class=\"k\">yield</span> <span class=\"n\">request</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">parse_page2</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">main_url</span><span class=\"p\">):</span>\n    <span class=\"k\">pass</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">errback_page2</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">failure</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"nb\">dict</span><span class=\"p\">(</span>\n        <span class=\"n\">main_url</span><span class=\"o\">=</span><span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">cb_kwargs</span><span class=\"p\">[</span><span class=\"s1\">'main_url'</span><span class=\"p\">],</span>\n    <span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># my_project/settings.py</span>\n<span class=\"n\">REQUEST_FINGERPRINTER_CLASS</span> <span class=\"o\">=</span> <span class=\"s1\">'my_project.utils.RequestFingerprinter'</span>\n\n<span class=\"c1\"># my_project/utils.py</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.request</span> <span class=\"kn\">import</span> <span class=\"n\">fingerprint</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RequestFingerprinter</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">fingerprint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">fingerprint</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"p\">,</span> <span class=\"n\">include_headers</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'X-ID'</span><span class=\"p\">])</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">hashlib</span> <span class=\"kn\">import</span> <span class=\"n\">sha1</span>\n<span class=\"kn\">from</span> <span class=\"nn\">weakref</span> <span class=\"kn\">import</span> <span class=\"n\">WeakKeyDictionary</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.python</span> <span class=\"kn\">import</span> <span class=\"n\">to_bytes</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RequestFingerprinter</span><span class=\"p\">:</span>\n\n    <span class=\"n\">cache</span> <span class=\"o\">=</span> <span class=\"n\">WeakKeyDictionary</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">fingerprint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">request</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">:</span>\n            <span class=\"n\">fp</span> <span class=\"o\">=</span> <span class=\"n\">sha1</span><span class=\"p\">()</span>\n            <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">to_bytes</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">))</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">[</span><span class=\"n\">request</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">digest</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">[</span><span class=\"n\">request</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.request</span> <span class=\"kn\">import</span> <span class=\"n\">fingerprint</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RequestFingerprinter</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">fingerprint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"s1\">'fingerprint'</span> <span class=\"ow\">in</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"p\">[</span><span class=\"s1\">'fingerprint'</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">fingerprint</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">hashlib</span> <span class=\"kn\">import</span> <span class=\"n\">sha1</span>\n<span class=\"kn\">from</span> <span class=\"nn\">weakref</span> <span class=\"kn\">import</span> <span class=\"n\">WeakKeyDictionary</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.python</span> <span class=\"kn\">import</span> <span class=\"n\">to_bytes</span>\n<span class=\"kn\">from</span> <span class=\"nn\">w3lib.url</span> <span class=\"kn\">import</span> <span class=\"n\">canonicalize_url</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RequestFingerprinter</span><span class=\"p\">:</span>\n\n    <span class=\"n\">cache</span> <span class=\"o\">=</span> <span class=\"n\">WeakKeyDictionary</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">fingerprint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">request</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">:</span>\n            <span class=\"n\">fp</span> <span class=\"o\">=</span> <span class=\"n\">sha1</span><span class=\"p\">()</span>\n            <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">to_bytes</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">method</span><span class=\"p\">))</span>\n            <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">to_bytes</span><span class=\"p\">(</span><span class=\"n\">canonicalize_url</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)))</span>\n            <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">body</span> <span class=\"ow\">or</span> <span class=\"sa\">b</span><span class=\"s1\">''</span><span class=\"p\">)</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">[</span><span class=\"n\">request</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">digest</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">[</span><span class=\"n\">request</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">/</span><span class=\"n\">home</span><span class=\"o\">/</span><span class=\"n\">user</span><span class=\"o\">/</span><span class=\"n\">project</span><span class=\"o\">/.</span><span class=\"n\">scrapy</span><span class=\"o\">/</span><span class=\"n\">httpcache</span><span class=\"o\">/</span><span class=\"n\">my_spider</span><span class=\"o\">/</span><span class=\"mi\">01</span><span class=\"o\">/</span><span class=\"mi\">0123456789</span><span class=\"n\">abcdef0123456789abcdef01234567</span><span class=\"o\">/</span><span class=\"n\">response_headers</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">StopSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"stop\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"https://docs.scrapy.org/en/latest/\"</span><span class=\"p\">]</span>\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">from_crawler</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">crawler</span><span class=\"p\">):</span>\n        <span class=\"n\">spider</span> <span class=\"o\">=</span> <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">from_crawler</span><span class=\"p\">(</span><span class=\"n\">crawler</span><span class=\"p\">)</span>\n        <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">on_bytes_received</span><span class=\"p\">,</span> <span class=\"n\">signal</span><span class=\"o\">=</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">bytes_received</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">spider</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"c1\"># 'last_chars' show that the full response was not downloaded</span>\n        <span class=\"k\">yield</span> <span class=\"p\">{</span><span class=\"s2\">\"len\"</span><span class=\"p\">:</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">),</span> <span class=\"s2\">\"last_chars\"</span><span class=\"p\">:</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">40</span><span class=\"p\">:]}</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">on_bytes_received</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"k\">raise</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">exceptions</span><span class=\"o\">.</span><span class=\"n\">StopDownload</span><span class=\"p\">(</span><span class=\"n\">fail</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">2020</span><span class=\"o\">-</span><span class=\"mi\">05</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">17</span><span class=\"p\">:</span><span class=\"mi\">26</span><span class=\"p\">:</span><span class=\"mi\">12</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Spider</span> <span class=\"n\">opened</span>\n<span class=\"mi\">2020</span><span class=\"o\">-</span><span class=\"mi\">05</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">17</span><span class=\"p\">:</span><span class=\"mi\">26</span><span class=\"p\">:</span><span class=\"mi\">12</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">logstats</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"mi\">0</span> <span class=\"n\">pages</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">pages</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">),</span> <span class=\"n\">scraped</span> <span class=\"mi\">0</span> <span class=\"n\">items</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">items</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">)</span>\n<span class=\"mi\">2020</span><span class=\"o\">-</span><span class=\"mi\">05</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">17</span><span class=\"p\">:</span><span class=\"mi\">26</span><span class=\"p\">:</span><span class=\"mi\">13</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">downloader</span><span class=\"o\">.</span><span class=\"n\">handlers</span><span class=\"o\">.</span><span class=\"n\">http11</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Download</span> <span class=\"n\">stopped</span> <span class=\"k\">for</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">docs</span><span class=\"o\">.</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">org</span><span class=\"o\">/</span><span class=\"n\">en</span><span class=\"o\">/</span><span class=\"n\">latest</span><span class=\"o\">/&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">signal</span> <span class=\"n\">handler</span> <span class=\"n\">StopSpider</span><span class=\"o\">.</span><span class=\"n\">on_bytes_received</span>\n<span class=\"mi\">2020</span><span class=\"o\">-</span><span class=\"mi\">05</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">17</span><span class=\"p\">:</span><span class=\"mi\">26</span><span class=\"p\">:</span><span class=\"mi\">13</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">docs</span><span class=\"o\">.</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">org</span><span class=\"o\">/</span><span class=\"n\">en</span><span class=\"o\">/</span><span class=\"n\">latest</span><span class=\"o\">/&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span> <span class=\"p\">[</span><span class=\"s1\">'download_stopped'</span><span class=\"p\">]</span>\n<span class=\"mi\">2020</span><span class=\"o\">-</span><span class=\"mi\">05</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">17</span><span class=\"p\">:</span><span class=\"mi\">26</span><span class=\"p\">:</span><span class=\"mi\">13</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">scraper</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Scraped</span> <span class=\"kn\">from</span> <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">docs</span><span class=\"o\">.</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">org</span><span class=\"o\">/</span><span class=\"n\">en</span><span class=\"o\">/</span><span class=\"n\">latest</span><span class=\"o\">/&gt;</span>\n<span class=\"p\">{</span><span class=\"s1\">'len'</span><span class=\"p\">:</span> <span class=\"mi\">279</span><span class=\"p\">,</span> <span class=\"s1\">'last_chars'</span><span class=\"p\">:</span> <span class=\"s1\">'dth, initial-scale=1.0\"&gt;</span><span class=\"se\">\\n</span><span class=\"s1\">  </span><span class=\"se\">\\n</span><span class=\"s1\">  &lt;title&gt;Scr'</span><span class=\"p\">}</span>\n<span class=\"mi\">2020</span><span class=\"o\">-</span><span class=\"mi\">05</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">17</span><span class=\"p\">:</span><span class=\"mi\">26</span><span class=\"p\">:</span><span class=\"mi\">13</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Closing</span> <span class=\"n\">spider</span> <span class=\"p\">(</span><span class=\"n\">finished</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"n\">FormRequest</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.example.com/post/action\"</span><span class=\"p\">,</span>\n                    <span class=\"n\">formdata</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'John Doe'</span><span class=\"p\">,</span> <span class=\"s1\">'age'</span><span class=\"p\">:</span> <span class=\"s1\">'27'</span><span class=\"p\">},</span>\n                    <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">after_post</span><span class=\"p\">)]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">authentication_failed</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"c1\"># TODO: Check the contents of the response and return True if it failed</span>\n    <span class=\"c1\"># or False if it succeeded.</span>\n    <span class=\"k\">pass</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">LoginSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/users/login.php'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">FormRequest</span><span class=\"o\">.</span><span class=\"n\">from_response</span><span class=\"p\">(</span>\n            <span class=\"n\">response</span><span class=\"p\">,</span>\n            <span class=\"n\">formdata</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'username'</span><span class=\"p\">:</span> <span class=\"s1\">'john'</span><span class=\"p\">,</span> <span class=\"s1\">'password'</span><span class=\"p\">:</span> <span class=\"s1\">'secret'</span><span class=\"p\">},</span>\n            <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">after_login</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">after_login</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">authentication_failed</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">):</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"s2\">\"Login failed\"</span><span class=\"p\">)</span>\n            <span class=\"k\">return</span>\n\n        <span class=\"c1\"># continue scraping with authenticated session...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'name1'</span><span class=\"p\">:</span> <span class=\"s1\">'value1'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'name2'</span><span class=\"p\">:</span> <span class=\"s1\">'value2'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n<span class=\"k\">yield</span> <span class=\"n\">JsonRequest</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s1\">'http://www.example.com/post/action'</span><span class=\"p\">,</span> <span class=\"n\">data</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">headers</span><span class=\"o\">.</span><span class=\"n\">getlist</span><span class=\"p\">(</span><span class=\"s1\">'Set-Cookie'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">urllib</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"o\">.</span><span class=\"n\">urljoin</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"sa\">b</span><span class=\"s1\">'body'</span><span class=\"p\">)</span>\n<span class=\"go\">\"b'body'\"</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'p'</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["request_with_cookies = Request(url=\"http://www.example.com\",\n                               cookies={'currency': 'USD', 'country': 'UY'})\n", "request_with_cookies = Request(url=\"http://www.example.com\",\n                               cookies=[{'name': 'currency',\n                                        'value': 'USD',\n                                        'domain': 'example.com',\n                                        'path': '/currency'}])\n", "Request(\n    url=\"http://www.example.com\",\n    cookies={'currency': 'USD', 'country': 'UY'},\n    meta={'dont_merge_cookies': True},\n)\n", "def parse_page1(self, response):\n    return scrapy.Request(\"http://www.example.com/some_page.html\",\n                          callback=self.parse_page2)\n\ndef parse_page2(self, response):\n    # this would log http://www.example.com/some_page.html\n    self.logger.info(\"Visited %s\", response.url)\n", "def parse(self, response):\n    request = scrapy.Request('http://www.example.com/index.html',\n                             callback=self.parse_page2,\n                             cb_kwargs=dict(main_url=response.url))\n    request.cb_kwargs['foo'] = 'bar'  # add more arguments for the callback\n    yield request\n\ndef parse_page2(self, response, main_url, foo):\n    yield dict(\n        main_url=main_url,\n        other_url=response.url,\n        foo=foo,\n    )\n", "import scrapy\n\nfrom scrapy.spidermiddlewares.httperror import HttpError\nfrom twisted.internet.error import DNSLookupError\nfrom twisted.internet.error import TimeoutError, TCPTimedOutError\n\nclass ErrbackSpider(scrapy.Spider):\n    name = \"errback_example\"\n    start_urls = [\n        \"http://www.httpbin.org/\",              # HTTP 200 expected\n        \"http://www.httpbin.org/status/404\",    # Not found error\n        \"http://www.httpbin.org/status/500\",    # server issue\n        \"http://www.httpbin.org:12345/\",        # non-responding host, timeout expected\n        \"https://example.invalid/\",             # DNS error expected\n    ]\n\n    def start_requests(self):\n        for u in self.start_urls:\n            yield scrapy.Request(u, callback=self.parse_httpbin,\n                                    errback=self.errback_httpbin,\n                                    dont_filter=True)\n\n    def parse_httpbin(self, response):\n        self.logger.info('Got successful response from {}'.format(response.url))\n        # do something useful here...\n\n    def errback_httpbin(self, failure):\n        # log all failures\n        self.logger.error(repr(failure))\n\n        # in case you want to do something special for some errors,\n        # you may need the failure's type:\n\n        if failure.check(HttpError):\n            # these exceptions come from HttpError spider middleware\n            # you can get the non-200 response\n            response = failure.value.response\n            self.logger.error('HttpError on %s', response.url)\n\n        elif failure.check(DNSLookupError):\n            # this is the original request\n            request = failure.request\n            self.logger.error('DNSLookupError on %s', request.url)\n\n        elif failure.check(TimeoutError, TCPTimedOutError):\n            request = failure.request\n            self.logger.error('TimeoutError on %s', request.url)\n", "def parse(self, response):\n    request = scrapy.Request('http://www.example.com/index.html',\n                             callback=self.parse_page2,\n                             errback=self.errback_page2,\n                             cb_kwargs=dict(main_url=response.url))\n    yield request\n\ndef parse_page2(self, response, main_url):\n    pass\n\ndef errback_page2(self, failure):\n    yield dict(\n        main_url=failure.request.cb_kwargs['main_url'],\n    )\n", "# my_project/settings.py\nREQUEST_FINGERPRINTER_CLASS = 'my_project.utils.RequestFingerprinter'\n\n# my_project/utils.py\nfrom scrapy.utils.request import fingerprint\n\nclass RequestFingerprinter:\n\n    def fingerprint(self, request):\n        return fingerprint(request, include_headers=['X-ID'])\n", "from hashlib import sha1\nfrom weakref import WeakKeyDictionary\n\nfrom scrapy.utils.python import to_bytes\n\nclass RequestFingerprinter:\n\n    cache = WeakKeyDictionary()\n\n    def fingerprint(self, request):\n        if request not in self.cache:\n            fp = sha1()\n            fp.update(to_bytes(request.url))\n            self.cache[request] = fp.digest()\n        return self.cache[request]\n", "from scrapy.utils.request import fingerprint\n\nclass RequestFingerprinter:\n\n    def fingerprint(self, request):\n        if 'fingerprint' in request.meta:\n            return request.meta['fingerprint']\n        return fingerprint(request)\n", "from hashlib import sha1\nfrom weakref import WeakKeyDictionary\n\nfrom scrapy.utils.python import to_bytes\nfrom w3lib.url import canonicalize_url\n\nclass RequestFingerprinter:\n\n    cache = WeakKeyDictionary()\n\n    def fingerprint(self, request):\n        if request not in self.cache:\n            fp = sha1()\n            fp.update(to_bytes(request.method))\n            fp.update(to_bytes(canonicalize_url(request.url)))\n            fp.update(request.body or b'')\n            self.cache[request] = fp.digest()\n        return self.cache[request]\n", "/home/user/project/.scrapy/httpcache/my_spider/01/0123456789abcdef0123456789abcdef01234567/response_headers\n", "import scrapy\n\n\nclass StopSpider(scrapy.Spider):\n    name = \"stop\"\n    start_urls = [\"https://docs.scrapy.org/en/latest/\"]\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        spider = super().from_crawler(crawler)\n        crawler.signals.connect(spider.on_bytes_received, signal=scrapy.signals.bytes_received)\n        return spider\n\n    def parse(self, response):\n        # 'last_chars' show that the full response was not downloaded\n        yield {\"len\": len(response.text), \"last_chars\": response.text[-40:]}\n\n    def on_bytes_received(self, data, request, spider):\n        raise scrapy.exceptions.StopDownload(fail=False)\n", "2020-05-19 17:26:12 [scrapy.core.engine] INFO: Spider opened\n2020-05-19 17:26:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n2020-05-19 17:26:13 [scrapy.core.downloader.handlers.http11] DEBUG: Download stopped for <GET https://docs.scrapy.org/en/latest/> from signal handler StopSpider.on_bytes_received\n2020-05-19 17:26:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://docs.scrapy.org/en/latest/> (referer: None) ['download_stopped']\n2020-05-19 17:26:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://docs.scrapy.org/en/latest/>\n{'len': 279, 'last_chars': 'dth, initial-scale=1.0\">\\n  \\n  <title>Scr'}\n2020-05-19 17:26:13 [scrapy.core.engine] INFO: Closing spider (finished)\n", "return [FormRequest(url=\"http://www.example.com/post/action\",\n                    formdata={'name': 'John Doe', 'age': '27'},\n                    callback=self.after_post)]\n", "import scrapy\n\ndef authentication_failed(response):\n    # TODO: Check the contents of the response and return True if it failed\n    # or False if it succeeded.\n    pass\n\nclass LoginSpider(scrapy.Spider):\n    name = 'example.com'\n    start_urls = ['http://www.example.com/users/login.php']\n\n    def parse(self, response):\n        return scrapy.FormRequest.from_response(\n            response,\n            formdata={'username': 'john', 'password': 'secret'},\n            callback=self.after_login\n        )\n\n    def after_login(self, response):\n        if authentication_failed(response):\n            self.logger.error(\"Login failed\")\n            return\n\n        # continue scraping with authenticated session...\n", "data = {\n    'name1': 'value1',\n    'name2': 'value2',\n}\nyield JsonRequest(url='http://www.example.com/post/action', data=data)\n", "response.headers.getlist('Set-Cookie')\n", "urllib.parse.urljoin(response.url, url)\n", ">>> str(b'body')\n\"b'body'\"\n", "response.xpath('//p')\n", "response.css('p')\n"], "index": 22}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Request objects", "header_href": "#request-objects", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">request_with_cookies</span> <span class=\"o\">=</span> <span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.example.com\"</span><span class=\"p\">,</span>\n                               <span class=\"n\">cookies</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'currency'</span><span class=\"p\">:</span> <span class=\"s1\">'USD'</span><span class=\"p\">,</span> <span class=\"s1\">'country'</span><span class=\"p\">:</span> <span class=\"s1\">'UY'</span><span class=\"p\">})</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">request_with_cookies</span> <span class=\"o\">=</span> <span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.example.com\"</span><span class=\"p\">,</span>\n                               <span class=\"n\">cookies</span><span class=\"o\">=</span><span class=\"p\">[{</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'currency'</span><span class=\"p\">,</span>\n                                        <span class=\"s1\">'value'</span><span class=\"p\">:</span> <span class=\"s1\">'USD'</span><span class=\"p\">,</span>\n                                        <span class=\"s1\">'domain'</span><span class=\"p\">:</span> <span class=\"s1\">'example.com'</span><span class=\"p\">,</span>\n                                        <span class=\"s1\">'path'</span><span class=\"p\">:</span> <span class=\"s1\">'/currency'</span><span class=\"p\">}])</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">Request</span><span class=\"p\">(</span>\n    <span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.example.com\"</span><span class=\"p\">,</span>\n    <span class=\"n\">cookies</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'currency'</span><span class=\"p\">:</span> <span class=\"s1\">'USD'</span><span class=\"p\">,</span> <span class=\"s1\">'country'</span><span class=\"p\">:</span> <span class=\"s1\">'UY'</span><span class=\"p\">},</span>\n    <span class=\"n\">meta</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'dont_merge_cookies'</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">},</span>\n<span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse_page1</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s2\">\"http://www.example.com/some_page.html\"</span><span class=\"p\">,</span>\n                          <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_page2</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">parse_page2</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"c1\"># this would log http://www.example.com/some_page.html</span>\n    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s2\">\"Visited </span><span class=\"si\">%s</span><span class=\"s2\">\"</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s1\">'http://www.example.com/index.html'</span><span class=\"p\">,</span>\n                             <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_page2</span><span class=\"p\">,</span>\n                             <span class=\"n\">cb_kwargs</span><span class=\"o\">=</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">main_url</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">))</span>\n    <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">cb_kwargs</span><span class=\"p\">[</span><span class=\"s1\">'foo'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'bar'</span>  <span class=\"c1\"># add more arguments for the callback</span>\n    <span class=\"k\">yield</span> <span class=\"n\">request</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">parse_page2</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">main_url</span><span class=\"p\">,</span> <span class=\"n\">foo</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"nb\">dict</span><span class=\"p\">(</span>\n        <span class=\"n\">main_url</span><span class=\"o\">=</span><span class=\"n\">main_url</span><span class=\"p\">,</span>\n        <span class=\"n\">other_url</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">,</span>\n        <span class=\"n\">foo</span><span class=\"o\">=</span><span class=\"n\">foo</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.spidermiddlewares.httperror</span> <span class=\"kn\">import</span> <span class=\"n\">HttpError</span>\n<span class=\"kn\">from</span> <span class=\"nn\">twisted.internet.error</span> <span class=\"kn\">import</span> <span class=\"n\">DNSLookupError</span>\n<span class=\"kn\">from</span> <span class=\"nn\">twisted.internet.error</span> <span class=\"kn\">import</span> <span class=\"ne\">TimeoutError</span><span class=\"p\">,</span> <span class=\"n\">TCPTimedOutError</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">ErrbackSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"errback_example\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s2\">\"http://www.httpbin.org/\"</span><span class=\"p\">,</span>              <span class=\"c1\"># HTTP 200 expected</span>\n        <span class=\"s2\">\"http://www.httpbin.org/status/404\"</span><span class=\"p\">,</span>    <span class=\"c1\"># Not found error</span>\n        <span class=\"s2\">\"http://www.httpbin.org/status/500\"</span><span class=\"p\">,</span>    <span class=\"c1\"># server issue</span>\n        <span class=\"s2\">\"http://www.httpbin.org:12345/\"</span><span class=\"p\">,</span>        <span class=\"c1\"># non-responding host, timeout expected</span>\n        <span class=\"s2\">\"https://example.invalid/\"</span><span class=\"p\">,</span>             <span class=\"c1\"># DNS error expected</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">u</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">start_urls</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">u</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_httpbin</span><span class=\"p\">,</span>\n                                    <span class=\"n\">errback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">errback_httpbin</span><span class=\"p\">,</span>\n                                    <span class=\"n\">dont_filter</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_httpbin</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Got successful response from </span><span class=\"si\">{}</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">))</span>\n        <span class=\"c1\"># do something useful here...</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">errback_httpbin</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">failure</span><span class=\"p\">):</span>\n        <span class=\"c1\"># log all failures</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"nb\">repr</span><span class=\"p\">(</span><span class=\"n\">failure</span><span class=\"p\">))</span>\n\n        <span class=\"c1\"># in case you want to do something special for some errors,</span>\n        <span class=\"c1\"># you may need the failure's type:</span>\n\n        <span class=\"k\">if</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">check</span><span class=\"p\">(</span><span class=\"n\">HttpError</span><span class=\"p\">):</span>\n            <span class=\"c1\"># these exceptions come from HttpError spider middleware</span>\n            <span class=\"c1\"># you can get the non-200 response</span>\n            <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">value</span><span class=\"o\">.</span><span class=\"n\">response</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"s1\">'HttpError on </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n\n        <span class=\"k\">elif</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">check</span><span class=\"p\">(</span><span class=\"n\">DNSLookupError</span><span class=\"p\">):</span>\n            <span class=\"c1\"># this is the original request</span>\n            <span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">request</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"s1\">'DNSLookupError on </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n\n        <span class=\"k\">elif</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">check</span><span class=\"p\">(</span><span class=\"ne\">TimeoutError</span><span class=\"p\">,</span> <span class=\"n\">TCPTimedOutError</span><span class=\"p\">):</span>\n            <span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">request</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"s1\">'TimeoutError on </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s1\">'http://www.example.com/index.html'</span><span class=\"p\">,</span>\n                             <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_page2</span><span class=\"p\">,</span>\n                             <span class=\"n\">errback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">errback_page2</span><span class=\"p\">,</span>\n                             <span class=\"n\">cb_kwargs</span><span class=\"o\">=</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">main_url</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">))</span>\n    <span class=\"k\">yield</span> <span class=\"n\">request</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">parse_page2</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">main_url</span><span class=\"p\">):</span>\n    <span class=\"k\">pass</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">errback_page2</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">failure</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"nb\">dict</span><span class=\"p\">(</span>\n        <span class=\"n\">main_url</span><span class=\"o\">=</span><span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">cb_kwargs</span><span class=\"p\">[</span><span class=\"s1\">'main_url'</span><span class=\"p\">],</span>\n    <span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># my_project/settings.py</span>\n<span class=\"n\">REQUEST_FINGERPRINTER_CLASS</span> <span class=\"o\">=</span> <span class=\"s1\">'my_project.utils.RequestFingerprinter'</span>\n\n<span class=\"c1\"># my_project/utils.py</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.request</span> <span class=\"kn\">import</span> <span class=\"n\">fingerprint</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RequestFingerprinter</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">fingerprint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">fingerprint</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"p\">,</span> <span class=\"n\">include_headers</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'X-ID'</span><span class=\"p\">])</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">hashlib</span> <span class=\"kn\">import</span> <span class=\"n\">sha1</span>\n<span class=\"kn\">from</span> <span class=\"nn\">weakref</span> <span class=\"kn\">import</span> <span class=\"n\">WeakKeyDictionary</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.python</span> <span class=\"kn\">import</span> <span class=\"n\">to_bytes</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RequestFingerprinter</span><span class=\"p\">:</span>\n\n    <span class=\"n\">cache</span> <span class=\"o\">=</span> <span class=\"n\">WeakKeyDictionary</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">fingerprint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">request</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">:</span>\n            <span class=\"n\">fp</span> <span class=\"o\">=</span> <span class=\"n\">sha1</span><span class=\"p\">()</span>\n            <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">to_bytes</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">))</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">[</span><span class=\"n\">request</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">digest</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">[</span><span class=\"n\">request</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.request</span> <span class=\"kn\">import</span> <span class=\"n\">fingerprint</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RequestFingerprinter</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">fingerprint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"s1\">'fingerprint'</span> <span class=\"ow\">in</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"p\">[</span><span class=\"s1\">'fingerprint'</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">fingerprint</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">hashlib</span> <span class=\"kn\">import</span> <span class=\"n\">sha1</span>\n<span class=\"kn\">from</span> <span class=\"nn\">weakref</span> <span class=\"kn\">import</span> <span class=\"n\">WeakKeyDictionary</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.python</span> <span class=\"kn\">import</span> <span class=\"n\">to_bytes</span>\n<span class=\"kn\">from</span> <span class=\"nn\">w3lib.url</span> <span class=\"kn\">import</span> <span class=\"n\">canonicalize_url</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RequestFingerprinter</span><span class=\"p\">:</span>\n\n    <span class=\"n\">cache</span> <span class=\"o\">=</span> <span class=\"n\">WeakKeyDictionary</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">fingerprint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">request</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">:</span>\n            <span class=\"n\">fp</span> <span class=\"o\">=</span> <span class=\"n\">sha1</span><span class=\"p\">()</span>\n            <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">to_bytes</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">method</span><span class=\"p\">))</span>\n            <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">to_bytes</span><span class=\"p\">(</span><span class=\"n\">canonicalize_url</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)))</span>\n            <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">body</span> <span class=\"ow\">or</span> <span class=\"sa\">b</span><span class=\"s1\">''</span><span class=\"p\">)</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">[</span><span class=\"n\">request</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">digest</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">[</span><span class=\"n\">request</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">/</span><span class=\"n\">home</span><span class=\"o\">/</span><span class=\"n\">user</span><span class=\"o\">/</span><span class=\"n\">project</span><span class=\"o\">/.</span><span class=\"n\">scrapy</span><span class=\"o\">/</span><span class=\"n\">httpcache</span><span class=\"o\">/</span><span class=\"n\">my_spider</span><span class=\"o\">/</span><span class=\"mi\">01</span><span class=\"o\">/</span><span class=\"mi\">0123456789</span><span class=\"n\">abcdef0123456789abcdef01234567</span><span class=\"o\">/</span><span class=\"n\">response_headers</span>\n</pre></div>"], "codes_text": ["request_with_cookies = Request(url=\"http://www.example.com\",\n                               cookies={'currency': 'USD', 'country': 'UY'})\n", "request_with_cookies = Request(url=\"http://www.example.com\",\n                               cookies=[{'name': 'currency',\n                                        'value': 'USD',\n                                        'domain': 'example.com',\n                                        'path': '/currency'}])\n", "Request(\n    url=\"http://www.example.com\",\n    cookies={'currency': 'USD', 'country': 'UY'},\n    meta={'dont_merge_cookies': True},\n)\n", "def parse_page1(self, response):\n    return scrapy.Request(\"http://www.example.com/some_page.html\",\n                          callback=self.parse_page2)\n\ndef parse_page2(self, response):\n    # this would log http://www.example.com/some_page.html\n    self.logger.info(\"Visited %s\", response.url)\n", "def parse(self, response):\n    request = scrapy.Request('http://www.example.com/index.html',\n                             callback=self.parse_page2,\n                             cb_kwargs=dict(main_url=response.url))\n    request.cb_kwargs['foo'] = 'bar'  # add more arguments for the callback\n    yield request\n\ndef parse_page2(self, response, main_url, foo):\n    yield dict(\n        main_url=main_url,\n        other_url=response.url,\n        foo=foo,\n    )\n", "import scrapy\n\nfrom scrapy.spidermiddlewares.httperror import HttpError\nfrom twisted.internet.error import DNSLookupError\nfrom twisted.internet.error import TimeoutError, TCPTimedOutError\n\nclass ErrbackSpider(scrapy.Spider):\n    name = \"errback_example\"\n    start_urls = [\n        \"http://www.httpbin.org/\",              # HTTP 200 expected\n        \"http://www.httpbin.org/status/404\",    # Not found error\n        \"http://www.httpbin.org/status/500\",    # server issue\n        \"http://www.httpbin.org:12345/\",        # non-responding host, timeout expected\n        \"https://example.invalid/\",             # DNS error expected\n    ]\n\n    def start_requests(self):\n        for u in self.start_urls:\n            yield scrapy.Request(u, callback=self.parse_httpbin,\n                                    errback=self.errback_httpbin,\n                                    dont_filter=True)\n\n    def parse_httpbin(self, response):\n        self.logger.info('Got successful response from {}'.format(response.url))\n        # do something useful here...\n\n    def errback_httpbin(self, failure):\n        # log all failures\n        self.logger.error(repr(failure))\n\n        # in case you want to do something special for some errors,\n        # you may need the failure's type:\n\n        if failure.check(HttpError):\n            # these exceptions come from HttpError spider middleware\n            # you can get the non-200 response\n            response = failure.value.response\n            self.logger.error('HttpError on %s', response.url)\n\n        elif failure.check(DNSLookupError):\n            # this is the original request\n            request = failure.request\n            self.logger.error('DNSLookupError on %s', request.url)\n\n        elif failure.check(TimeoutError, TCPTimedOutError):\n            request = failure.request\n            self.logger.error('TimeoutError on %s', request.url)\n", "def parse(self, response):\n    request = scrapy.Request('http://www.example.com/index.html',\n                             callback=self.parse_page2,\n                             errback=self.errback_page2,\n                             cb_kwargs=dict(main_url=response.url))\n    yield request\n\ndef parse_page2(self, response, main_url):\n    pass\n\ndef errback_page2(self, failure):\n    yield dict(\n        main_url=failure.request.cb_kwargs['main_url'],\n    )\n", "# my_project/settings.py\nREQUEST_FINGERPRINTER_CLASS = 'my_project.utils.RequestFingerprinter'\n\n# my_project/utils.py\nfrom scrapy.utils.request import fingerprint\n\nclass RequestFingerprinter:\n\n    def fingerprint(self, request):\n        return fingerprint(request, include_headers=['X-ID'])\n", "from hashlib import sha1\nfrom weakref import WeakKeyDictionary\n\nfrom scrapy.utils.python import to_bytes\n\nclass RequestFingerprinter:\n\n    cache = WeakKeyDictionary()\n\n    def fingerprint(self, request):\n        if request not in self.cache:\n            fp = sha1()\n            fp.update(to_bytes(request.url))\n            self.cache[request] = fp.digest()\n        return self.cache[request]\n", "from scrapy.utils.request import fingerprint\n\nclass RequestFingerprinter:\n\n    def fingerprint(self, request):\n        if 'fingerprint' in request.meta:\n            return request.meta['fingerprint']\n        return fingerprint(request)\n", "from hashlib import sha1\nfrom weakref import WeakKeyDictionary\n\nfrom scrapy.utils.python import to_bytes\nfrom w3lib.url import canonicalize_url\n\nclass RequestFingerprinter:\n\n    cache = WeakKeyDictionary()\n\n    def fingerprint(self, request):\n        if request not in self.cache:\n            fp = sha1()\n            fp.update(to_bytes(request.method))\n            fp.update(to_bytes(canonicalize_url(request.url)))\n            fp.update(request.body or b'')\n            self.cache[request] = fp.digest()\n        return self.cache[request]\n", "/home/user/project/.scrapy/httpcache/my_spider/01/0123456789abcdef0123456789abcdef01234567/response_headers\n"], "index": 12}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Other functions related to requests", "header_href": "#other-functions-related-to-requests", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Passing additional data to callback functions", "header_href": "#passing-additional-data-to-callback-functions", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse_page1</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s2\">\"http://www.example.com/some_page.html\"</span><span class=\"p\">,</span>\n                          <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_page2</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">parse_page2</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"c1\"># this would log http://www.example.com/some_page.html</span>\n    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s2\">\"Visited </span><span class=\"si\">%s</span><span class=\"s2\">\"</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s1\">'http://www.example.com/index.html'</span><span class=\"p\">,</span>\n                             <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_page2</span><span class=\"p\">,</span>\n                             <span class=\"n\">cb_kwargs</span><span class=\"o\">=</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">main_url</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">))</span>\n    <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">cb_kwargs</span><span class=\"p\">[</span><span class=\"s1\">'foo'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'bar'</span>  <span class=\"c1\"># add more arguments for the callback</span>\n    <span class=\"k\">yield</span> <span class=\"n\">request</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">parse_page2</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">main_url</span><span class=\"p\">,</span> <span class=\"n\">foo</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"nb\">dict</span><span class=\"p\">(</span>\n        <span class=\"n\">main_url</span><span class=\"o\">=</span><span class=\"n\">main_url</span><span class=\"p\">,</span>\n        <span class=\"n\">other_url</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">,</span>\n        <span class=\"n\">foo</span><span class=\"o\">=</span><span class=\"n\">foo</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["def parse_page1(self, response):\n    return scrapy.Request(\"http://www.example.com/some_page.html\",\n                          callback=self.parse_page2)\n\ndef parse_page2(self, response):\n    # this would log http://www.example.com/some_page.html\n    self.logger.info(\"Visited %s\", response.url)\n", "def parse(self, response):\n    request = scrapy.Request('http://www.example.com/index.html',\n                             callback=self.parse_page2,\n                             cb_kwargs=dict(main_url=response.url))\n    request.cb_kwargs['foo'] = 'bar'  # add more arguments for the callback\n    yield request\n\ndef parse_page2(self, response, main_url, foo):\n    yield dict(\n        main_url=main_url,\n        other_url=response.url,\n        foo=foo,\n    )\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Using errbacks to catch exceptions in request processing", "header_href": "#using-errbacks-to-catch-exceptions-in-request-processing", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.spidermiddlewares.httperror</span> <span class=\"kn\">import</span> <span class=\"n\">HttpError</span>\n<span class=\"kn\">from</span> <span class=\"nn\">twisted.internet.error</span> <span class=\"kn\">import</span> <span class=\"n\">DNSLookupError</span>\n<span class=\"kn\">from</span> <span class=\"nn\">twisted.internet.error</span> <span class=\"kn\">import</span> <span class=\"ne\">TimeoutError</span><span class=\"p\">,</span> <span class=\"n\">TCPTimedOutError</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">ErrbackSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"errback_example\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s2\">\"http://www.httpbin.org/\"</span><span class=\"p\">,</span>              <span class=\"c1\"># HTTP 200 expected</span>\n        <span class=\"s2\">\"http://www.httpbin.org/status/404\"</span><span class=\"p\">,</span>    <span class=\"c1\"># Not found error</span>\n        <span class=\"s2\">\"http://www.httpbin.org/status/500\"</span><span class=\"p\">,</span>    <span class=\"c1\"># server issue</span>\n        <span class=\"s2\">\"http://www.httpbin.org:12345/\"</span><span class=\"p\">,</span>        <span class=\"c1\"># non-responding host, timeout expected</span>\n        <span class=\"s2\">\"https://example.invalid/\"</span><span class=\"p\">,</span>             <span class=\"c1\"># DNS error expected</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">u</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">start_urls</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">u</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_httpbin</span><span class=\"p\">,</span>\n                                    <span class=\"n\">errback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">errback_httpbin</span><span class=\"p\">,</span>\n                                    <span class=\"n\">dont_filter</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_httpbin</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Got successful response from </span><span class=\"si\">{}</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">))</span>\n        <span class=\"c1\"># do something useful here...</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">errback_httpbin</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">failure</span><span class=\"p\">):</span>\n        <span class=\"c1\"># log all failures</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"nb\">repr</span><span class=\"p\">(</span><span class=\"n\">failure</span><span class=\"p\">))</span>\n\n        <span class=\"c1\"># in case you want to do something special for some errors,</span>\n        <span class=\"c1\"># you may need the failure's type:</span>\n\n        <span class=\"k\">if</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">check</span><span class=\"p\">(</span><span class=\"n\">HttpError</span><span class=\"p\">):</span>\n            <span class=\"c1\"># these exceptions come from HttpError spider middleware</span>\n            <span class=\"c1\"># you can get the non-200 response</span>\n            <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">value</span><span class=\"o\">.</span><span class=\"n\">response</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"s1\">'HttpError on </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n\n        <span class=\"k\">elif</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">check</span><span class=\"p\">(</span><span class=\"n\">DNSLookupError</span><span class=\"p\">):</span>\n            <span class=\"c1\"># this is the original request</span>\n            <span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">request</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"s1\">'DNSLookupError on </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n\n        <span class=\"k\">elif</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">check</span><span class=\"p\">(</span><span class=\"ne\">TimeoutError</span><span class=\"p\">,</span> <span class=\"n\">TCPTimedOutError</span><span class=\"p\">):</span>\n            <span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">request</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"s1\">'TimeoutError on </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import scrapy\n\nfrom scrapy.spidermiddlewares.httperror import HttpError\nfrom twisted.internet.error import DNSLookupError\nfrom twisted.internet.error import TimeoutError, TCPTimedOutError\n\nclass ErrbackSpider(scrapy.Spider):\n    name = \"errback_example\"\n    start_urls = [\n        \"http://www.httpbin.org/\",              # HTTP 200 expected\n        \"http://www.httpbin.org/status/404\",    # Not found error\n        \"http://www.httpbin.org/status/500\",    # server issue\n        \"http://www.httpbin.org:12345/\",        # non-responding host, timeout expected\n        \"https://example.invalid/\",             # DNS error expected\n    ]\n\n    def start_requests(self):\n        for u in self.start_urls:\n            yield scrapy.Request(u, callback=self.parse_httpbin,\n                                    errback=self.errback_httpbin,\n                                    dont_filter=True)\n\n    def parse_httpbin(self, response):\n        self.logger.info('Got successful response from {}'.format(response.url))\n        # do something useful here...\n\n    def errback_httpbin(self, failure):\n        # log all failures\n        self.logger.error(repr(failure))\n\n        # in case you want to do something special for some errors,\n        # you may need the failure's type:\n\n        if failure.check(HttpError):\n            # these exceptions come from HttpError spider middleware\n            # you can get the non-200 response\n            response = failure.value.response\n            self.logger.error('HttpError on %s', response.url)\n\n        elif failure.check(DNSLookupError):\n            # this is the original request\n            request = failure.request\n            self.logger.error('DNSLookupError on %s', request.url)\n\n        elif failure.check(TimeoutError, TCPTimedOutError):\n            request = failure.request\n            self.logger.error('TimeoutError on %s', request.url)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Accessing additional data in errback functions", "header_href": "#accessing-additional-data-in-errback-functions", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s1\">'http://www.example.com/index.html'</span><span class=\"p\">,</span>\n                             <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_page2</span><span class=\"p\">,</span>\n                             <span class=\"n\">errback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">errback_page2</span><span class=\"p\">,</span>\n                             <span class=\"n\">cb_kwargs</span><span class=\"o\">=</span><span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">main_url</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">))</span>\n    <span class=\"k\">yield</span> <span class=\"n\">request</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">parse_page2</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">main_url</span><span class=\"p\">):</span>\n    <span class=\"k\">pass</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">errback_page2</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">failure</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"nb\">dict</span><span class=\"p\">(</span>\n        <span class=\"n\">main_url</span><span class=\"o\">=</span><span class=\"n\">failure</span><span class=\"o\">.</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">cb_kwargs</span><span class=\"p\">[</span><span class=\"s1\">'main_url'</span><span class=\"p\">],</span>\n    <span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["def parse(self, response):\n    request = scrapy.Request('http://www.example.com/index.html',\n                             callback=self.parse_page2,\n                             errback=self.errback_page2,\n                             cb_kwargs=dict(main_url=response.url))\n    yield request\n\ndef parse_page2(self, response, main_url):\n    pass\n\ndef errback_page2(self, failure):\n    yield dict(\n        main_url=failure.request.cb_kwargs['main_url'],\n    )\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Request fingerprints", "header_href": "#request-fingerprints", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"c1\"># my_project/settings.py</span>\n<span class=\"n\">REQUEST_FINGERPRINTER_CLASS</span> <span class=\"o\">=</span> <span class=\"s1\">'my_project.utils.RequestFingerprinter'</span>\n\n<span class=\"c1\"># my_project/utils.py</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.request</span> <span class=\"kn\">import</span> <span class=\"n\">fingerprint</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RequestFingerprinter</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">fingerprint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">fingerprint</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"p\">,</span> <span class=\"n\">include_headers</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'X-ID'</span><span class=\"p\">])</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">hashlib</span> <span class=\"kn\">import</span> <span class=\"n\">sha1</span>\n<span class=\"kn\">from</span> <span class=\"nn\">weakref</span> <span class=\"kn\">import</span> <span class=\"n\">WeakKeyDictionary</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.python</span> <span class=\"kn\">import</span> <span class=\"n\">to_bytes</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RequestFingerprinter</span><span class=\"p\">:</span>\n\n    <span class=\"n\">cache</span> <span class=\"o\">=</span> <span class=\"n\">WeakKeyDictionary</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">fingerprint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">request</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">:</span>\n            <span class=\"n\">fp</span> <span class=\"o\">=</span> <span class=\"n\">sha1</span><span class=\"p\">()</span>\n            <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">to_bytes</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">))</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">[</span><span class=\"n\">request</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">digest</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">[</span><span class=\"n\">request</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.request</span> <span class=\"kn\">import</span> <span class=\"n\">fingerprint</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RequestFingerprinter</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">fingerprint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"s1\">'fingerprint'</span> <span class=\"ow\">in</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"p\">[</span><span class=\"s1\">'fingerprint'</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">fingerprint</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">hashlib</span> <span class=\"kn\">import</span> <span class=\"n\">sha1</span>\n<span class=\"kn\">from</span> <span class=\"nn\">weakref</span> <span class=\"kn\">import</span> <span class=\"n\">WeakKeyDictionary</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.python</span> <span class=\"kn\">import</span> <span class=\"n\">to_bytes</span>\n<span class=\"kn\">from</span> <span class=\"nn\">w3lib.url</span> <span class=\"kn\">import</span> <span class=\"n\">canonicalize_url</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RequestFingerprinter</span><span class=\"p\">:</span>\n\n    <span class=\"n\">cache</span> <span class=\"o\">=</span> <span class=\"n\">WeakKeyDictionary</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">fingerprint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">request</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">:</span>\n            <span class=\"n\">fp</span> <span class=\"o\">=</span> <span class=\"n\">sha1</span><span class=\"p\">()</span>\n            <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">to_bytes</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">method</span><span class=\"p\">))</span>\n            <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">to_bytes</span><span class=\"p\">(</span><span class=\"n\">canonicalize_url</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)))</span>\n            <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">body</span> <span class=\"ow\">or</span> <span class=\"sa\">b</span><span class=\"s1\">''</span><span class=\"p\">)</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">[</span><span class=\"n\">request</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">digest</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">[</span><span class=\"n\">request</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">/</span><span class=\"n\">home</span><span class=\"o\">/</span><span class=\"n\">user</span><span class=\"o\">/</span><span class=\"n\">project</span><span class=\"o\">/.</span><span class=\"n\">scrapy</span><span class=\"o\">/</span><span class=\"n\">httpcache</span><span class=\"o\">/</span><span class=\"n\">my_spider</span><span class=\"o\">/</span><span class=\"mi\">01</span><span class=\"o\">/</span><span class=\"mi\">0123456789</span><span class=\"n\">abcdef0123456789abcdef01234567</span><span class=\"o\">/</span><span class=\"n\">response_headers</span>\n</pre></div>"], "codes_text": ["# my_project/settings.py\nREQUEST_FINGERPRINTER_CLASS = 'my_project.utils.RequestFingerprinter'\n\n# my_project/utils.py\nfrom scrapy.utils.request import fingerprint\n\nclass RequestFingerprinter:\n\n    def fingerprint(self, request):\n        return fingerprint(request, include_headers=['X-ID'])\n", "from hashlib import sha1\nfrom weakref import WeakKeyDictionary\n\nfrom scrapy.utils.python import to_bytes\n\nclass RequestFingerprinter:\n\n    cache = WeakKeyDictionary()\n\n    def fingerprint(self, request):\n        if request not in self.cache:\n            fp = sha1()\n            fp.update(to_bytes(request.url))\n            self.cache[request] = fp.digest()\n        return self.cache[request]\n", "from scrapy.utils.request import fingerprint\n\nclass RequestFingerprinter:\n\n    def fingerprint(self, request):\n        if 'fingerprint' in request.meta:\n            return request.meta['fingerprint']\n        return fingerprint(request)\n", "from hashlib import sha1\nfrom weakref import WeakKeyDictionary\n\nfrom scrapy.utils.python import to_bytes\nfrom w3lib.url import canonicalize_url\n\nclass RequestFingerprinter:\n\n    cache = WeakKeyDictionary()\n\n    def fingerprint(self, request):\n        if request not in self.cache:\n            fp = sha1()\n            fp.update(to_bytes(request.method))\n            fp.update(to_bytes(canonicalize_url(request.url)))\n            fp.update(request.body or b'')\n            self.cache[request] = fp.digest()\n        return self.cache[request]\n", "/home/user/project/.scrapy/httpcache/my_spider/01/0123456789abcdef0123456789abcdef01234567/response_headers\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "REQUEST_FINGERPRINTER_CLASS", "header_href": "#request-fingerprinter-class", "codes": [], "codes_text": [], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "REQUEST_FINGERPRINTER_IMPLEMENTATION", "header_href": "#request-fingerprinter-implementation", "codes": [], "codes_text": [], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Writing your own request fingerprinter", "header_href": "#writing-your-own-request-fingerprinter", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"c1\"># my_project/settings.py</span>\n<span class=\"n\">REQUEST_FINGERPRINTER_CLASS</span> <span class=\"o\">=</span> <span class=\"s1\">'my_project.utils.RequestFingerprinter'</span>\n\n<span class=\"c1\"># my_project/utils.py</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.request</span> <span class=\"kn\">import</span> <span class=\"n\">fingerprint</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RequestFingerprinter</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">fingerprint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">fingerprint</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"p\">,</span> <span class=\"n\">include_headers</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'X-ID'</span><span class=\"p\">])</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">hashlib</span> <span class=\"kn\">import</span> <span class=\"n\">sha1</span>\n<span class=\"kn\">from</span> <span class=\"nn\">weakref</span> <span class=\"kn\">import</span> <span class=\"n\">WeakKeyDictionary</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.python</span> <span class=\"kn\">import</span> <span class=\"n\">to_bytes</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RequestFingerprinter</span><span class=\"p\">:</span>\n\n    <span class=\"n\">cache</span> <span class=\"o\">=</span> <span class=\"n\">WeakKeyDictionary</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">fingerprint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">request</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">:</span>\n            <span class=\"n\">fp</span> <span class=\"o\">=</span> <span class=\"n\">sha1</span><span class=\"p\">()</span>\n            <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">to_bytes</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">))</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">[</span><span class=\"n\">request</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">digest</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">[</span><span class=\"n\">request</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.request</span> <span class=\"kn\">import</span> <span class=\"n\">fingerprint</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RequestFingerprinter</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">fingerprint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"s1\">'fingerprint'</span> <span class=\"ow\">in</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"p\">[</span><span class=\"s1\">'fingerprint'</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">fingerprint</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">hashlib</span> <span class=\"kn\">import</span> <span class=\"n\">sha1</span>\n<span class=\"kn\">from</span> <span class=\"nn\">weakref</span> <span class=\"kn\">import</span> <span class=\"n\">WeakKeyDictionary</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.python</span> <span class=\"kn\">import</span> <span class=\"n\">to_bytes</span>\n<span class=\"kn\">from</span> <span class=\"nn\">w3lib.url</span> <span class=\"kn\">import</span> <span class=\"n\">canonicalize_url</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RequestFingerprinter</span><span class=\"p\">:</span>\n\n    <span class=\"n\">cache</span> <span class=\"o\">=</span> <span class=\"n\">WeakKeyDictionary</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">fingerprint</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">request</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">:</span>\n            <span class=\"n\">fp</span> <span class=\"o\">=</span> <span class=\"n\">sha1</span><span class=\"p\">()</span>\n            <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">to_bytes</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">method</span><span class=\"p\">))</span>\n            <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">to_bytes</span><span class=\"p\">(</span><span class=\"n\">canonicalize_url</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)))</span>\n            <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">body</span> <span class=\"ow\">or</span> <span class=\"sa\">b</span><span class=\"s1\">''</span><span class=\"p\">)</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">[</span><span class=\"n\">request</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">digest</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"p\">[</span><span class=\"n\">request</span><span class=\"p\">]</span>\n</pre></div>"], "codes_text": ["# my_project/settings.py\nREQUEST_FINGERPRINTER_CLASS = 'my_project.utils.RequestFingerprinter'\n\n# my_project/utils.py\nfrom scrapy.utils.request import fingerprint\n\nclass RequestFingerprinter:\n\n    def fingerprint(self, request):\n        return fingerprint(request, include_headers=['X-ID'])\n", "from hashlib import sha1\nfrom weakref import WeakKeyDictionary\n\nfrom scrapy.utils.python import to_bytes\n\nclass RequestFingerprinter:\n\n    cache = WeakKeyDictionary()\n\n    def fingerprint(self, request):\n        if request not in self.cache:\n            fp = sha1()\n            fp.update(to_bytes(request.url))\n            self.cache[request] = fp.digest()\n        return self.cache[request]\n", "from scrapy.utils.request import fingerprint\n\nclass RequestFingerprinter:\n\n    def fingerprint(self, request):\n        if 'fingerprint' in request.meta:\n            return request.meta['fingerprint']\n        return fingerprint(request)\n", "from hashlib import sha1\nfrom weakref import WeakKeyDictionary\n\nfrom scrapy.utils.python import to_bytes\nfrom w3lib.url import canonicalize_url\n\nclass RequestFingerprinter:\n\n    cache = WeakKeyDictionary()\n\n    def fingerprint(self, request):\n        if request not in self.cache:\n            fp = sha1()\n            fp.update(to_bytes(request.method))\n            fp.update(to_bytes(canonicalize_url(request.url)))\n            fp.update(request.body or b'')\n            self.cache[request] = fp.digest()\n        return self.cache[request]\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Request fingerprint restrictions", "header_href": "#request-fingerprint-restrictions", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"o\">/</span><span class=\"n\">home</span><span class=\"o\">/</span><span class=\"n\">user</span><span class=\"o\">/</span><span class=\"n\">project</span><span class=\"o\">/.</span><span class=\"n\">scrapy</span><span class=\"o\">/</span><span class=\"n\">httpcache</span><span class=\"o\">/</span><span class=\"n\">my_spider</span><span class=\"o\">/</span><span class=\"mi\">01</span><span class=\"o\">/</span><span class=\"mi\">0123456789</span><span class=\"n\">abcdef0123456789abcdef01234567</span><span class=\"o\">/</span><span class=\"n\">response_headers</span>\n</pre></div>"], "codes_text": ["/home/user/project/.scrapy/httpcache/my_spider/01/0123456789abcdef0123456789abcdef01234567/response_headers\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Request.meta special keys", "header_href": "#request-meta-special-keys", "codes": [], "codes_text": [], "index": 12}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "bindaddress", "header_href": "#bindaddress", "codes": [], "codes_text": [], "index": 13}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "download_timeout", "header_href": "#download-timeout", "codes": [], "codes_text": [], "index": 14}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "download_latency", "header_href": "#download-latency", "codes": [], "codes_text": [], "index": 15}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "download_fail_on_dataloss", "header_href": "#download-fail-on-dataloss", "codes": [], "codes_text": [], "index": 16}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "max_retry_times", "header_href": "#max-retry-times", "codes": [], "codes_text": [], "index": 17}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Stopping the download of a Response", "header_href": "#stopping-the-download-of-a-response", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">StopSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"stop\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"https://docs.scrapy.org/en/latest/\"</span><span class=\"p\">]</span>\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">from_crawler</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">crawler</span><span class=\"p\">):</span>\n        <span class=\"n\">spider</span> <span class=\"o\">=</span> <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">from_crawler</span><span class=\"p\">(</span><span class=\"n\">crawler</span><span class=\"p\">)</span>\n        <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">on_bytes_received</span><span class=\"p\">,</span> <span class=\"n\">signal</span><span class=\"o\">=</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">bytes_received</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">spider</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"c1\"># 'last_chars' show that the full response was not downloaded</span>\n        <span class=\"k\">yield</span> <span class=\"p\">{</span><span class=\"s2\">\"len\"</span><span class=\"p\">:</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">),</span> <span class=\"s2\">\"last_chars\"</span><span class=\"p\">:</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">40</span><span class=\"p\">:]}</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">on_bytes_received</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"k\">raise</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">exceptions</span><span class=\"o\">.</span><span class=\"n\">StopDownload</span><span class=\"p\">(</span><span class=\"n\">fail</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">2020</span><span class=\"o\">-</span><span class=\"mi\">05</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">17</span><span class=\"p\">:</span><span class=\"mi\">26</span><span class=\"p\">:</span><span class=\"mi\">12</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Spider</span> <span class=\"n\">opened</span>\n<span class=\"mi\">2020</span><span class=\"o\">-</span><span class=\"mi\">05</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">17</span><span class=\"p\">:</span><span class=\"mi\">26</span><span class=\"p\">:</span><span class=\"mi\">12</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">logstats</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"mi\">0</span> <span class=\"n\">pages</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">pages</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">),</span> <span class=\"n\">scraped</span> <span class=\"mi\">0</span> <span class=\"n\">items</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">items</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">)</span>\n<span class=\"mi\">2020</span><span class=\"o\">-</span><span class=\"mi\">05</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">17</span><span class=\"p\">:</span><span class=\"mi\">26</span><span class=\"p\">:</span><span class=\"mi\">13</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">downloader</span><span class=\"o\">.</span><span class=\"n\">handlers</span><span class=\"o\">.</span><span class=\"n\">http11</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Download</span> <span class=\"n\">stopped</span> <span class=\"k\">for</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">docs</span><span class=\"o\">.</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">org</span><span class=\"o\">/</span><span class=\"n\">en</span><span class=\"o\">/</span><span class=\"n\">latest</span><span class=\"o\">/&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">signal</span> <span class=\"n\">handler</span> <span class=\"n\">StopSpider</span><span class=\"o\">.</span><span class=\"n\">on_bytes_received</span>\n<span class=\"mi\">2020</span><span class=\"o\">-</span><span class=\"mi\">05</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">17</span><span class=\"p\">:</span><span class=\"mi\">26</span><span class=\"p\">:</span><span class=\"mi\">13</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">docs</span><span class=\"o\">.</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">org</span><span class=\"o\">/</span><span class=\"n\">en</span><span class=\"o\">/</span><span class=\"n\">latest</span><span class=\"o\">/&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span> <span class=\"p\">[</span><span class=\"s1\">'download_stopped'</span><span class=\"p\">]</span>\n<span class=\"mi\">2020</span><span class=\"o\">-</span><span class=\"mi\">05</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">17</span><span class=\"p\">:</span><span class=\"mi\">26</span><span class=\"p\">:</span><span class=\"mi\">13</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">scraper</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Scraped</span> <span class=\"kn\">from</span> <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">docs</span><span class=\"o\">.</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">org</span><span class=\"o\">/</span><span class=\"n\">en</span><span class=\"o\">/</span><span class=\"n\">latest</span><span class=\"o\">/&gt;</span>\n<span class=\"p\">{</span><span class=\"s1\">'len'</span><span class=\"p\">:</span> <span class=\"mi\">279</span><span class=\"p\">,</span> <span class=\"s1\">'last_chars'</span><span class=\"p\">:</span> <span class=\"s1\">'dth, initial-scale=1.0\"&gt;</span><span class=\"se\">\\n</span><span class=\"s1\">  </span><span class=\"se\">\\n</span><span class=\"s1\">  &lt;title&gt;Scr'</span><span class=\"p\">}</span>\n<span class=\"mi\">2020</span><span class=\"o\">-</span><span class=\"mi\">05</span><span class=\"o\">-</span><span class=\"mi\">19</span> <span class=\"mi\">17</span><span class=\"p\">:</span><span class=\"mi\">26</span><span class=\"p\">:</span><span class=\"mi\">13</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Closing</span> <span class=\"n\">spider</span> <span class=\"p\">(</span><span class=\"n\">finished</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import scrapy\n\n\nclass StopSpider(scrapy.Spider):\n    name = \"stop\"\n    start_urls = [\"https://docs.scrapy.org/en/latest/\"]\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        spider = super().from_crawler(crawler)\n        crawler.signals.connect(spider.on_bytes_received, signal=scrapy.signals.bytes_received)\n        return spider\n\n    def parse(self, response):\n        # 'last_chars' show that the full response was not downloaded\n        yield {\"len\": len(response.text), \"last_chars\": response.text[-40:]}\n\n    def on_bytes_received(self, data, request, spider):\n        raise scrapy.exceptions.StopDownload(fail=False)\n", "2020-05-19 17:26:12 [scrapy.core.engine] INFO: Spider opened\n2020-05-19 17:26:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n2020-05-19 17:26:13 [scrapy.core.downloader.handlers.http11] DEBUG: Download stopped for <GET https://docs.scrapy.org/en/latest/> from signal handler StopSpider.on_bytes_received\n2020-05-19 17:26:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://docs.scrapy.org/en/latest/> (referer: None) ['download_stopped']\n2020-05-19 17:26:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://docs.scrapy.org/en/latest/>\n{'len': 279, 'last_chars': 'dth, initial-scale=1.0\">\\n  \\n  <title>Scr'}\n2020-05-19 17:26:13 [scrapy.core.engine] INFO: Closing spider (finished)\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Request subclasses", "header_href": "#request-subclasses", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"n\">FormRequest</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.example.com/post/action\"</span><span class=\"p\">,</span>\n                    <span class=\"n\">formdata</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'John Doe'</span><span class=\"p\">,</span> <span class=\"s1\">'age'</span><span class=\"p\">:</span> <span class=\"s1\">'27'</span><span class=\"p\">},</span>\n                    <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">after_post</span><span class=\"p\">)]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">authentication_failed</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"c1\"># TODO: Check the contents of the response and return True if it failed</span>\n    <span class=\"c1\"># or False if it succeeded.</span>\n    <span class=\"k\">pass</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">LoginSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/users/login.php'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">FormRequest</span><span class=\"o\">.</span><span class=\"n\">from_response</span><span class=\"p\">(</span>\n            <span class=\"n\">response</span><span class=\"p\">,</span>\n            <span class=\"n\">formdata</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'username'</span><span class=\"p\">:</span> <span class=\"s1\">'john'</span><span class=\"p\">,</span> <span class=\"s1\">'password'</span><span class=\"p\">:</span> <span class=\"s1\">'secret'</span><span class=\"p\">},</span>\n            <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">after_login</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">after_login</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">authentication_failed</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">):</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"s2\">\"Login failed\"</span><span class=\"p\">)</span>\n            <span class=\"k\">return</span>\n\n        <span class=\"c1\"># continue scraping with authenticated session...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'name1'</span><span class=\"p\">:</span> <span class=\"s1\">'value1'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'name2'</span><span class=\"p\">:</span> <span class=\"s1\">'value2'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n<span class=\"k\">yield</span> <span class=\"n\">JsonRequest</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s1\">'http://www.example.com/post/action'</span><span class=\"p\">,</span> <span class=\"n\">data</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["return [FormRequest(url=\"http://www.example.com/post/action\",\n                    formdata={'name': 'John Doe', 'age': '27'},\n                    callback=self.after_post)]\n", "import scrapy\n\ndef authentication_failed(response):\n    # TODO: Check the contents of the response and return True if it failed\n    # or False if it succeeded.\n    pass\n\nclass LoginSpider(scrapy.Spider):\n    name = 'example.com'\n    start_urls = ['http://www.example.com/users/login.php']\n\n    def parse(self, response):\n        return scrapy.FormRequest.from_response(\n            response,\n            formdata={'username': 'john', 'password': 'secret'},\n            callback=self.after_login\n        )\n\n    def after_login(self, response):\n        if authentication_failed(response):\n            self.logger.error(\"Login failed\")\n            return\n\n        # continue scraping with authenticated session...\n", "data = {\n    'name1': 'value1',\n    'name2': 'value2',\n}\nyield JsonRequest(url='http://www.example.com/post/action', data=data)\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FormRequest objects", "header_href": "#formrequest-objects", "codes": [], "codes_text": [], "index": 20}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Request usage examples", "header_href": "#request-usage-examples", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"n\">FormRequest</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.example.com/post/action\"</span><span class=\"p\">,</span>\n                    <span class=\"n\">formdata</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'John Doe'</span><span class=\"p\">,</span> <span class=\"s1\">'age'</span><span class=\"p\">:</span> <span class=\"s1\">'27'</span><span class=\"p\">},</span>\n                    <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">after_post</span><span class=\"p\">)]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">authentication_failed</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"c1\"># TODO: Check the contents of the response and return True if it failed</span>\n    <span class=\"c1\"># or False if it succeeded.</span>\n    <span class=\"k\">pass</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">LoginSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/users/login.php'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">FormRequest</span><span class=\"o\">.</span><span class=\"n\">from_response</span><span class=\"p\">(</span>\n            <span class=\"n\">response</span><span class=\"p\">,</span>\n            <span class=\"n\">formdata</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'username'</span><span class=\"p\">:</span> <span class=\"s1\">'john'</span><span class=\"p\">,</span> <span class=\"s1\">'password'</span><span class=\"p\">:</span> <span class=\"s1\">'secret'</span><span class=\"p\">},</span>\n            <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">after_login</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">after_login</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">authentication_failed</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">):</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"s2\">\"Login failed\"</span><span class=\"p\">)</span>\n            <span class=\"k\">return</span>\n\n        <span class=\"c1\"># continue scraping with authenticated session...</span>\n</pre></div>"], "codes_text": ["return [FormRequest(url=\"http://www.example.com/post/action\",\n                    formdata={'name': 'John Doe', 'age': '27'},\n                    callback=self.after_post)]\n", "import scrapy\n\ndef authentication_failed(response):\n    # TODO: Check the contents of the response and return True if it failed\n    # or False if it succeeded.\n    pass\n\nclass LoginSpider(scrapy.Spider):\n    name = 'example.com'\n    start_urls = ['http://www.example.com/users/login.php']\n\n    def parse(self, response):\n        return scrapy.FormRequest.from_response(\n            response,\n            formdata={'username': 'john', 'password': 'secret'},\n            callback=self.after_login\n        )\n\n    def after_login(self, response):\n        if authentication_failed(response):\n            self.logger.error(\"Login failed\")\n            return\n\n        # continue scraping with authenticated session...\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Using FormRequest to send data via HTTP POST", "header_href": "#using-formrequest-to-send-data-via-http-post", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"n\">FormRequest</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://www.example.com/post/action\"</span><span class=\"p\">,</span>\n                    <span class=\"n\">formdata</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'John Doe'</span><span class=\"p\">,</span> <span class=\"s1\">'age'</span><span class=\"p\">:</span> <span class=\"s1\">'27'</span><span class=\"p\">},</span>\n                    <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">after_post</span><span class=\"p\">)]</span>\n</pre></div>"], "codes_text": ["return [FormRequest(url=\"http://www.example.com/post/action\",\n                    formdata={'name': 'John Doe', 'age': '27'},\n                    callback=self.after_post)]\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Using FormRequest.from_response() to simulate a user login", "header_href": "#using-formrequest-from-response-to-simulate-a-user-login", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">authentication_failed</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"c1\"># TODO: Check the contents of the response and return True if it failed</span>\n    <span class=\"c1\"># or False if it succeeded.</span>\n    <span class=\"k\">pass</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">LoginSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example.com'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://www.example.com/users/login.php'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">FormRequest</span><span class=\"o\">.</span><span class=\"n\">from_response</span><span class=\"p\">(</span>\n            <span class=\"n\">response</span><span class=\"p\">,</span>\n            <span class=\"n\">formdata</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'username'</span><span class=\"p\">:</span> <span class=\"s1\">'john'</span><span class=\"p\">,</span> <span class=\"s1\">'password'</span><span class=\"p\">:</span> <span class=\"s1\">'secret'</span><span class=\"p\">},</span>\n            <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">after_login</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">after_login</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">authentication_failed</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">):</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"s2\">\"Login failed\"</span><span class=\"p\">)</span>\n            <span class=\"k\">return</span>\n\n        <span class=\"c1\"># continue scraping with authenticated session...</span>\n</pre></div>"], "codes_text": ["import scrapy\n\ndef authentication_failed(response):\n    # TODO: Check the contents of the response and return True if it failed\n    # or False if it succeeded.\n    pass\n\nclass LoginSpider(scrapy.Spider):\n    name = 'example.com'\n    start_urls = ['http://www.example.com/users/login.php']\n\n    def parse(self, response):\n        return scrapy.FormRequest.from_response(\n            response,\n            formdata={'username': 'john', 'password': 'secret'},\n            callback=self.after_login\n        )\n\n    def after_login(self, response):\n        if authentication_failed(response):\n            self.logger.error(\"Login failed\")\n            return\n\n        # continue scraping with authenticated session...\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "JsonRequest", "header_href": "#jsonrequest", "codes": [], "codes_text": [], "index": 24}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "JsonRequest usage example", "header_href": "#jsonrequest-usage-example", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'name1'</span><span class=\"p\">:</span> <span class=\"s1\">'value1'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'name2'</span><span class=\"p\">:</span> <span class=\"s1\">'value2'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n<span class=\"k\">yield</span> <span class=\"n\">JsonRequest</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s1\">'http://www.example.com/post/action'</span><span class=\"p\">,</span> <span class=\"n\">data</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["data = {\n    'name1': 'value1',\n    'name2': 'value2',\n}\nyield JsonRequest(url='http://www.example.com/post/action', data=data)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Response objects", "header_href": "#response-objects", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">headers</span><span class=\"o\">.</span><span class=\"n\">getlist</span><span class=\"p\">(</span><span class=\"s1\">'Set-Cookie'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">urllib</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"o\">.</span><span class=\"n\">urljoin</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["response.headers.getlist('Set-Cookie')\n", "urllib.parse.urljoin(response.url, url)\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Response subclasses", "header_href": "#response-subclasses", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"sa\">b</span><span class=\"s1\">'body'</span><span class=\"p\">)</span>\n<span class=\"go\">\"b'body'\"</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'p'</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": [">>> str(b'body')\n\"b'body'\"\n", "response.xpath('//p')\n", "response.css('p')\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "TextResponse objects", "header_href": "#textresponse-objects", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"sa\">b</span><span class=\"s1\">'body'</span><span class=\"p\">)</span>\n<span class=\"go\">\"b'body'\"</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//p'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'p'</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": [">>> str(b'body')\n\"b'body'\"\n", "response.xpath('//p')\n", "response.css('p')\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "HtmlResponse objects", "header_href": "#htmlresponse-objects", "codes": [], "codes_text": [], "index": 29}
{"url": "https://docs.scrapy.org/en/latest/topics/request-response.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "XmlResponse objects", "header_href": "#xmlresponse-objects", "codes": [], "codes_text": [], "index": 30}
{"url": "https://docs.scrapy.org/en/latest/topics/link-extractors.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Link Extractors", "header_href": "#link-extractors", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"k\">for</span> <span class=\"n\">link</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">link_extractor</span><span class=\"o\">.</span><span class=\"n\">extract_links</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">yield</span> <span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">link</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.linkextractors</span> <span class=\"kn\">import</span> <span class=\"n\">LinkExtractor</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"javascript:goToPage('../other/page.html'); return false\"</span><span class=\"p\">&gt;</span>Link text<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">process_value</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">):</span>\n    <span class=\"n\">m</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"s2\">\"javascript:goToPage\\('(.*?)'\"</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">)</span>\n    <span class=\"k\">if</span> <span class=\"n\">m</span><span class=\"p\">:</span>\n        <span class=\"k\">return</span> <span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">group</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">a</span> <span class=\"n\">href</span><span class=\"o\">=</span><span class=\"s2\">\"https://example.com/nofollow.html#foo\"</span> <span class=\"n\">rel</span><span class=\"o\">=</span><span class=\"s2\">\"nofollow\"</span><span class=\"o\">&gt;</span><span class=\"n\">Dont</span> <span class=\"n\">follow</span> <span class=\"n\">this</span> <span class=\"n\">one</span><span class=\"o\">&lt;/</span><span class=\"n\">a</span><span class=\"o\">&gt;</span>\n</pre></div>"], "codes_text": ["def parse(self, response):\n    for link in self.link_extractor.extract_links(response):\n        yield Request(link.url, callback=self.parse)\n", "from scrapy.linkextractors import LinkExtractor\n", "<a href=\"javascript:goToPage('../other/page.html'); return false\">Link text</a>\n", "def process_value(value):\n    m = re.search(\"javascript:goToPage\\('(.*?)'\", value)\n    if m:\n        return m.group(1)\n", "<a href=\"https://example.com/nofollow.html#foo\" rel=\"nofollow\">Dont follow this one</a>\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/link-extractors.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Link extractor reference", "header_href": "#module-scrapy.linkextractors", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.linkextractors</span> <span class=\"kn\">import</span> <span class=\"n\">LinkExtractor</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"javascript:goToPage('../other/page.html'); return false\"</span><span class=\"p\">&gt;</span>Link text<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">process_value</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">):</span>\n    <span class=\"n\">m</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"s2\">\"javascript:goToPage\\('(.*?)'\"</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">)</span>\n    <span class=\"k\">if</span> <span class=\"n\">m</span><span class=\"p\">:</span>\n        <span class=\"k\">return</span> <span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">group</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">a</span> <span class=\"n\">href</span><span class=\"o\">=</span><span class=\"s2\">\"https://example.com/nofollow.html#foo\"</span> <span class=\"n\">rel</span><span class=\"o\">=</span><span class=\"s2\">\"nofollow\"</span><span class=\"o\">&gt;</span><span class=\"n\">Dont</span> <span class=\"n\">follow</span> <span class=\"n\">this</span> <span class=\"n\">one</span><span class=\"o\">&lt;/</span><span class=\"n\">a</span><span class=\"o\">&gt;</span>\n</pre></div>"], "codes_text": ["from scrapy.linkextractors import LinkExtractor\n", "<a href=\"javascript:goToPage('../other/page.html'); return false\">Link text</a>\n", "def process_value(value):\n    m = re.search(\"javascript:goToPage\\('(.*?)'\", value)\n    if m:\n        return m.group(1)\n", "<a href=\"https://example.com/nofollow.html#foo\" rel=\"nofollow\">Dont follow this one</a>\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/link-extractors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "LxmlLinkExtractor", "header_href": "#module-scrapy.linkextractors.lxmlhtml", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">a</span> <span class=\"na\">href</span><span class=\"o\">=</span><span class=\"s\">\"javascript:goToPage('../other/page.html'); return false\"</span><span class=\"p\">&gt;</span>Link text<span class=\"p\">&lt;/</span><span class=\"nt\">a</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">process_value</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">):</span>\n    <span class=\"n\">m</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"s2\">\"javascript:goToPage\\('(.*?)'\"</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">)</span>\n    <span class=\"k\">if</span> <span class=\"n\">m</span><span class=\"p\">:</span>\n        <span class=\"k\">return</span> <span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">group</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["<a href=\"javascript:goToPage('../other/page.html'); return false\">Link text</a>\n", "def process_value(value):\n    m = re.search(\"javascript:goToPage\\('(.*?)'\", value)\n    if m:\n        return m.group(1)\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/link-extractors.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Link", "header_href": "#module-scrapy.link", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">a</span> <span class=\"n\">href</span><span class=\"o\">=</span><span class=\"s2\">\"https://example.com/nofollow.html#foo\"</span> <span class=\"n\">rel</span><span class=\"o\">=</span><span class=\"s2\">\"nofollow\"</span><span class=\"o\">&gt;</span><span class=\"n\">Dont</span> <span class=\"n\">follow</span> <span class=\"n\">this</span> <span class=\"n\">one</span><span class=\"o\">&lt;/</span><span class=\"n\">a</span><span class=\"o\">&gt;</span>\n</pre></div>"], "codes_text": ["<a href=\"https://example.com/nofollow.html#foo\" rel=\"nofollow\">Dont follow this one</a>\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Settings", "header_href": "#settings", "codes": ["<div class=\"highlight\"><pre><span></span>scrapy crawl myspider -s <span class=\"nv\">LOG_FILE</span><span class=\"o\">=</span>scrapy.log\n</pre></div>", "<div class=\"highlight\"><pre><span></span>class MySpider<span class=\"o\">(</span>scrapy.Spider<span class=\"o\">)</span>:\n    <span class=\"nv\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n\n    <span class=\"nv\">custom_settings</span> <span class=\"o\">=</span> <span class=\"o\">{</span>\n        <span class=\"s1\">'SOME_SETTING'</span>: <span class=\"s1\">'some value'</span>,\n    <span class=\"o\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>from mybot.pipelines.validate import ValidateMyItem\n<span class=\"nv\">ITEM_PIPELINES</span> <span class=\"o\">=</span> <span class=\"o\">{</span>\n    <span class=\"c1\"># passing the classname...</span>\n    ValidateMyItem: <span class=\"m\">300</span>,\n    <span class=\"c1\"># ...equals passing the class path</span>\n    <span class=\"s1\">'mybot.pipelines.validate.ValidateMyItem'</span>: <span class=\"m\">300</span>,\n<span class=\"o\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://example.com'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"Existing settings: </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">attributes</span><span class=\"o\">.</span><span class=\"n\">keys</span><span class=\"p\">()</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MyExtension</span><span class=\"p\">:</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">log_is_enabled</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">log_is_enabled</span><span class=\"p\">:</span>\n            <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"log is enabled!\"</span><span class=\"p\">)</span>\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">from_crawler</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">crawler</span><span class=\"p\">):</span>\n        <span class=\"n\">settings</span> <span class=\"o\">=</span> <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">settings</span>\n        <span class=\"k\">return</span> <span class=\"bp\">cls</span><span class=\"p\">(</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">getbool</span><span class=\"p\">(</span><span class=\"s1\">'LOG_ENABLED'</span><span class=\"p\">))</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'Accept'</span><span class=\"p\">:</span> <span class=\"s1\">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'Accept-Language'</span><span class=\"p\">:</span> <span class=\"s1\">'en'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">priority</span> <span class=\"o\">=</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">priority</span> <span class=\"o\">-</span> <span class=\"p\">(</span> <span class=\"n\">depth</span> <span class=\"o\">*</span> <span class=\"n\">DEPTH_PRIORITY</span> <span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">100</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">300</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">350</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">400</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">500</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.retry.RetryMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">550</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">560</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">580</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">590</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">600</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.cookies.CookiesMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">700</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">750</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.stats.DownloaderStats'</span><span class=\"p\">:</span> <span class=\"mi\">850</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">900</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">DOWNLOAD_DELAY</span> <span class=\"o\">=</span> <span class=\"mf\">0.25</span>    <span class=\"c1\"># 250 ms of delay</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'data'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.datauri.DataURIDownloadHandler'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'file'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.file.FileDownloadHandler'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'http'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.http.HTTPDownloadHandler'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'https'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.http.HTTPDownloadHandler'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'s3'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.s3.S3DownloadHandler'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'ftp'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.ftp.FTPDownloadHandler'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">DOWNLOAD_HANDLERS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'ftp'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">DOWNLOAD_HANDLERS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'https'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.http2.H2DownloadHandler'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.extensions.corestats.CoreStats'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.telnet.TelnetConsole'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.memusage.MemoryUsage'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.memdebug.MemoryDebugger'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.closespider.CloseSpider'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.feedexport.FeedExporter'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.logstats.LogStats'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.spiderstate.SpiderState'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.throttle.AutoThrottle'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">ITEM_PIPELINES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'mybot.pipelines.validate.ValidateMyItem'</span><span class=\"p\">:</span> <span class=\"mi\">300</span><span class=\"p\">,</span>\n    <span class=\"s1\">'mybot.pipelines.validate.StoreMyItem'</span><span class=\"p\">:</span> <span class=\"mi\">800</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">MEMDEBUG_NOTIFY</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'user@example.com'</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">MEMUSAGE_NOTIFY_MAIL</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'user@example.com'</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">NEWSPIDER_MODULE</span> <span class=\"o\">=</span> <span class=\"s1\">'mybot.spiders_dev'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">1956</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">31</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"o\">+</span><span class=\"mi\">0800</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">scheduler</span><span class=\"p\">]</span> <span class=\"n\">ERROR</span><span class=\"p\">:</span> <span class=\"n\">Unable</span> <span class=\"n\">to</span> <span class=\"n\">serialize</span> <span class=\"n\">request</span><span class=\"p\">:</span>\n<span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">&gt;</span> <span class=\"o\">-</span> <span class=\"n\">reason</span><span class=\"p\">:</span> <span class=\"n\">cannot</span> <span class=\"n\">serialize</span> <span class=\"o\">&lt;</span><span class=\"n\">Request</span> <span class=\"n\">at</span> <span class=\"mh\">0x9a7c7ec</span><span class=\"o\">&gt;</span>\n<span class=\"p\">(</span><span class=\"nb\">type</span> <span class=\"n\">Request</span><span class=\"p\">)</span><span class=\"o\">&gt;</span> <span class=\"o\">-</span> <span class=\"n\">no</span> <span class=\"n\">more</span> <span class=\"n\">unserializable</span> <span class=\"n\">requests</span> <span class=\"n\">will</span> <span class=\"n\">be</span> <span class=\"n\">logged</span>\n<span class=\"p\">(</span><span class=\"n\">see</span> <span class=\"s1\">'scheduler/unserializable'</span> <span class=\"n\">stats</span> <span class=\"n\">counter</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.contracts.default.UrlContract'</span> <span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.contracts.default.ReturnsContract'</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.contracts.default.ScrapesContract'</span><span class=\"p\">:</span> <span class=\"mi\">3</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">SPIDER_CONTRACTS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.contracts.default.ScrapesContract'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">50</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">500</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.referer.RefererMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">700</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">800</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.depth.DepthMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">900</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">SPIDER_MODULES</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'mybot.spiders_prod'</span><span class=\"p\">,</span> <span class=\"s1\">'mybot.spiders_dev'</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">twisted.internet</span> <span class=\"kn\">import</span> <span class=\"n\">reactor</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'quotes'</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">timeout</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">kwargs</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"s1\">'timeout'</span><span class=\"p\">,</span> <span class=\"s1\">'60'</span><span class=\"p\">))</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">QuotesSpider</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">callLater</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">timeout</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">stop</span><span class=\"p\">)</span>\n\n        <span class=\"n\">urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://quotes.toscrape.com/page/1'</span><span class=\"p\">]</span>\n        <span class=\"k\">for</span> <span class=\"n\">url</span> <span class=\"ow\">in</span> <span class=\"n\">urls</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span><span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()}</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">stop</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"o\">.</span><span class=\"n\">close_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"s1\">'timeout'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'quotes'</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">timeout</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">kwargs</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"s1\">'timeout'</span><span class=\"p\">,</span> <span class=\"s1\">'60'</span><span class=\"p\">))</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">QuotesSpider</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"kn\">from</span> <span class=\"nn\">twisted.internet</span> <span class=\"kn\">import</span> <span class=\"n\">reactor</span>\n        <span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">callLater</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">timeout</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">stop</span><span class=\"p\">)</span>\n\n        <span class=\"n\">urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://quotes.toscrape.com/page/1'</span><span class=\"p\">]</span>\n        <span class=\"k\">for</span> <span class=\"n\">url</span> <span class=\"ow\">in</span> <span class=\"n\">urls</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span><span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()}</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">stop</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"o\">.</span><span class=\"n\">close_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"s1\">'timeout'</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["scrapy crawl myspider -s LOG_FILE=scrapy.log\n", "class MySpider(scrapy.Spider):\n    name = 'myspider'\n\n    custom_settings = {\n        'SOME_SETTING': 'some value',\n    }\n", "from mybot.pipelines.validate import ValidateMyItem\nITEM_PIPELINES = {\n    # passing the classname...\n    ValidateMyItem: 300,\n    # ...equals passing the class path\n    'mybot.pipelines.validate.ValidateMyItem': 300,\n}\n", "class MySpider(scrapy.Spider):\n    name = 'myspider'\n    start_urls = ['http://example.com']\n\n    def parse(self, response):\n        print(f\"Existing settings: {self.settings.attributes.keys()}\")\n", "class MyExtension:\n    def __init__(self, log_is_enabled=False):\n        if log_is_enabled:\n            print(\"log is enabled!\")\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        settings = crawler.settings\n        return cls(settings.getbool('LOG_ENABLED'))\n", "{\n    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n    'Accept-Language': 'en',\n}\n", "request.priority = request.priority - ( depth * DEPTH_PRIORITY )\n", "{\n    'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware': 100,\n    'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware': 300,\n    'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware': 350,\n    'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware': 400,\n    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': 500,\n    'scrapy.downloadermiddlewares.retry.RetryMiddleware': 550,\n    'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware': 560,\n    'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware': 580,\n    'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware': 590,\n    'scrapy.downloadermiddlewares.redirect.RedirectMiddleware': 600,\n    'scrapy.downloadermiddlewares.cookies.CookiesMiddleware': 700,\n    'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware': 750,\n    'scrapy.downloadermiddlewares.stats.DownloaderStats': 850,\n    'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware': 900,\n}\n", "DOWNLOAD_DELAY = 0.25    # 250 ms of delay\n", "{\n    'data': 'scrapy.core.downloader.handlers.datauri.DataURIDownloadHandler',\n    'file': 'scrapy.core.downloader.handlers.file.FileDownloadHandler',\n    'http': 'scrapy.core.downloader.handlers.http.HTTPDownloadHandler',\n    'https': 'scrapy.core.downloader.handlers.http.HTTPDownloadHandler',\n    's3': 'scrapy.core.downloader.handlers.s3.S3DownloadHandler',\n    'ftp': 'scrapy.core.downloader.handlers.ftp.FTPDownloadHandler',\n}\n", "DOWNLOAD_HANDLERS = {\n    'ftp': None,\n}\n", "DOWNLOAD_HANDLERS = {\n    'https': 'scrapy.core.downloader.handlers.http2.H2DownloadHandler',\n}\n", "{\n    'scrapy.extensions.corestats.CoreStats': 0,\n    'scrapy.extensions.telnet.TelnetConsole': 0,\n    'scrapy.extensions.memusage.MemoryUsage': 0,\n    'scrapy.extensions.memdebug.MemoryDebugger': 0,\n    'scrapy.extensions.closespider.CloseSpider': 0,\n    'scrapy.extensions.feedexport.FeedExporter': 0,\n    'scrapy.extensions.logstats.LogStats': 0,\n    'scrapy.extensions.spiderstate.SpiderState': 0,\n    'scrapy.extensions.throttle.AutoThrottle': 0,\n}\n", "ITEM_PIPELINES = {\n    'mybot.pipelines.validate.ValidateMyItem': 300,\n    'mybot.pipelines.validate.StoreMyItem': 800,\n}\n", "MEMDEBUG_NOTIFY = ['user@example.com']\n", "MEMUSAGE_NOTIFY_MAIL = ['user@example.com']\n", "NEWSPIDER_MODULE = 'mybot.spiders_dev'\n", "1956-01-31 00:00:00+0800 [scrapy.core.scheduler] ERROR: Unable to serialize request:\n<GET http://example.com> - reason: cannot serialize <Request at 0x9a7c7ec>\n(type Request)> - no more unserializable requests will be logged\n(see 'scheduler/unserializable' stats counter)\n", "{\n    'scrapy.contracts.default.UrlContract' : 1,\n    'scrapy.contracts.default.ReturnsContract': 2,\n    'scrapy.contracts.default.ScrapesContract': 3,\n}\n", "SPIDER_CONTRACTS = {\n    'scrapy.contracts.default.ScrapesContract': None,\n}\n", "{\n    'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware': 50,\n    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': 500,\n    'scrapy.spidermiddlewares.referer.RefererMiddleware': 700,\n    'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware': 800,\n    'scrapy.spidermiddlewares.depth.DepthMiddleware': 900,\n}\n", "SPIDER_MODULES = ['mybot.spiders_prod', 'mybot.spiders_dev']\n", "import scrapy\nfrom twisted.internet import reactor\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = 'quotes'\n\n    def __init__(self, *args, **kwargs):\n        self.timeout = int(kwargs.pop('timeout', '60'))\n        super(QuotesSpider, self).__init__(*args, **kwargs)\n\n    def start_requests(self):\n        reactor.callLater(self.timeout, self.stop)\n\n        urls = ['https://quotes.toscrape.com/page/1']\n        for url in urls:\n            yield scrapy.Request(url=url, callback=self.parse)\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {'text': quote.css('span.text::text').get()}\n\n    def stop(self):\n        self.crawler.engine.close_spider(self, 'timeout')\n", "import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = 'quotes'\n\n    def __init__(self, *args, **kwargs):\n        self.timeout = int(kwargs.pop('timeout', '60'))\n        super(QuotesSpider, self).__init__(*args, **kwargs)\n\n    def start_requests(self):\n        from twisted.internet import reactor\n        reactor.callLater(self.timeout, self.stop)\n\n        urls = ['https://quotes.toscrape.com/page/1']\n        for url in urls:\n            yield scrapy.Request(url=url, callback=self.parse)\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {'text': quote.css('span.text::text').get()}\n\n    def stop(self):\n        self.crawler.engine.close_spider(self, 'timeout')\n"], "index": 24}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Designating the settings", "header_href": "#designating-the-settings", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Populating the settings", "header_href": "#populating-the-settings", "codes": ["<div class=\"highlight\"><pre><span></span>scrapy crawl myspider -s <span class=\"nv\">LOG_FILE</span><span class=\"o\">=</span>scrapy.log\n</pre></div>", "<div class=\"highlight\"><pre><span></span>class MySpider<span class=\"o\">(</span>scrapy.Spider<span class=\"o\">)</span>:\n    <span class=\"nv\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n\n    <span class=\"nv\">custom_settings</span> <span class=\"o\">=</span> <span class=\"o\">{</span>\n        <span class=\"s1\">'SOME_SETTING'</span>: <span class=\"s1\">'some value'</span>,\n    <span class=\"o\">}</span>\n</pre></div>"], "codes_text": ["scrapy crawl myspider -s LOG_FILE=scrapy.log\n", "class MySpider(scrapy.Spider):\n    name = 'myspider'\n\n    custom_settings = {\n        'SOME_SETTING': 'some value',\n    }\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "1. Command line options", "header_href": "#command-line-options", "codes": ["<div class=\"highlight\"><pre><span></span>scrapy crawl myspider -s <span class=\"nv\">LOG_FILE</span><span class=\"o\">=</span>scrapy.log\n</pre></div>"], "codes_text": ["scrapy crawl myspider -s LOG_FILE=scrapy.log\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "2. Settings per-spider", "header_href": "#settings-per-spider", "codes": ["<div class=\"highlight\"><pre><span></span>class MySpider<span class=\"o\">(</span>scrapy.Spider<span class=\"o\">)</span>:\n    <span class=\"nv\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n\n    <span class=\"nv\">custom_settings</span> <span class=\"o\">=</span> <span class=\"o\">{</span>\n        <span class=\"s1\">'SOME_SETTING'</span>: <span class=\"s1\">'some value'</span>,\n    <span class=\"o\">}</span>\n</pre></div>"], "codes_text": ["class MySpider(scrapy.Spider):\n    name = 'myspider'\n\n    custom_settings = {\n        'SOME_SETTING': 'some value',\n    }\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "3. Project settings module", "header_href": "#project-settings-module", "codes": [], "codes_text": [], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "4. Default settings per-command", "header_href": "#default-settings-per-command", "codes": [], "codes_text": [], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "5. Default global settings", "header_href": "#default-global-settings", "codes": [], "codes_text": [], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Compatibility with pickle", "header_href": "#compatibility-with-pickle", "codes": [], "codes_text": [], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Import paths and classes", "header_href": "#import-paths-and-classes", "codes": ["<div class=\"highlight\"><pre><span></span>from mybot.pipelines.validate import ValidateMyItem\n<span class=\"nv\">ITEM_PIPELINES</span> <span class=\"o\">=</span> <span class=\"o\">{</span>\n    <span class=\"c1\"># passing the classname...</span>\n    ValidateMyItem: <span class=\"m\">300</span>,\n    <span class=\"c1\"># ...equals passing the class path</span>\n    <span class=\"s1\">'mybot.pipelines.validate.ValidateMyItem'</span>: <span class=\"m\">300</span>,\n<span class=\"o\">}</span>\n</pre></div>"], "codes_text": ["from mybot.pipelines.validate import ValidateMyItem\nITEM_PIPELINES = {\n    # passing the classname...\n    ValidateMyItem: 300,\n    # ...equals passing the class path\n    'mybot.pipelines.validate.ValidateMyItem': 300,\n}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "How to access settings", "header_href": "#how-to-access-settings", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://example.com'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"Existing settings: </span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">attributes</span><span class=\"o\">.</span><span class=\"n\">keys</span><span class=\"p\">()</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MyExtension</span><span class=\"p\">:</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">log_is_enabled</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">log_is_enabled</span><span class=\"p\">:</span>\n            <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"log is enabled!\"</span><span class=\"p\">)</span>\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">from_crawler</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">crawler</span><span class=\"p\">):</span>\n        <span class=\"n\">settings</span> <span class=\"o\">=</span> <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">settings</span>\n        <span class=\"k\">return</span> <span class=\"bp\">cls</span><span class=\"p\">(</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">getbool</span><span class=\"p\">(</span><span class=\"s1\">'LOG_ENABLED'</span><span class=\"p\">))</span>\n</pre></div>"], "codes_text": ["class MySpider(scrapy.Spider):\n    name = 'myspider'\n    start_urls = ['http://example.com']\n\n    def parse(self, response):\n        print(f\"Existing settings: {self.settings.attributes.keys()}\")\n", "class MyExtension:\n    def __init__(self, log_is_enabled=False):\n        if log_is_enabled:\n            print(\"log is enabled!\")\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        settings = crawler.settings\n        return cls(settings.getbool('LOG_ENABLED'))\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Rationale for setting names", "header_href": "#rationale-for-setting-names", "codes": [], "codes_text": [], "index": 12}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Built-in settings reference", "header_href": "#built-in-settings-reference", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'Accept'</span><span class=\"p\">:</span> <span class=\"s1\">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'Accept-Language'</span><span class=\"p\">:</span> <span class=\"s1\">'en'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">priority</span> <span class=\"o\">=</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">priority</span> <span class=\"o\">-</span> <span class=\"p\">(</span> <span class=\"n\">depth</span> <span class=\"o\">*</span> <span class=\"n\">DEPTH_PRIORITY</span> <span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">100</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">300</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">350</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">400</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">500</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.retry.RetryMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">550</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">560</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">580</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">590</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">600</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.cookies.CookiesMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">700</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">750</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.stats.DownloaderStats'</span><span class=\"p\">:</span> <span class=\"mi\">850</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">900</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">DOWNLOAD_DELAY</span> <span class=\"o\">=</span> <span class=\"mf\">0.25</span>    <span class=\"c1\"># 250 ms of delay</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'data'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.datauri.DataURIDownloadHandler'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'file'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.file.FileDownloadHandler'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'http'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.http.HTTPDownloadHandler'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'https'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.http.HTTPDownloadHandler'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'s3'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.s3.S3DownloadHandler'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'ftp'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.ftp.FTPDownloadHandler'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">DOWNLOAD_HANDLERS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'ftp'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">DOWNLOAD_HANDLERS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'https'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.http2.H2DownloadHandler'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.extensions.corestats.CoreStats'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.telnet.TelnetConsole'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.memusage.MemoryUsage'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.memdebug.MemoryDebugger'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.closespider.CloseSpider'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.feedexport.FeedExporter'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.logstats.LogStats'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.spiderstate.SpiderState'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.throttle.AutoThrottle'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">ITEM_PIPELINES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'mybot.pipelines.validate.ValidateMyItem'</span><span class=\"p\">:</span> <span class=\"mi\">300</span><span class=\"p\">,</span>\n    <span class=\"s1\">'mybot.pipelines.validate.StoreMyItem'</span><span class=\"p\">:</span> <span class=\"mi\">800</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">MEMDEBUG_NOTIFY</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'user@example.com'</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">MEMUSAGE_NOTIFY_MAIL</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'user@example.com'</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">NEWSPIDER_MODULE</span> <span class=\"o\">=</span> <span class=\"s1\">'mybot.spiders_dev'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">1956</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">31</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"o\">+</span><span class=\"mi\">0800</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">scheduler</span><span class=\"p\">]</span> <span class=\"n\">ERROR</span><span class=\"p\">:</span> <span class=\"n\">Unable</span> <span class=\"n\">to</span> <span class=\"n\">serialize</span> <span class=\"n\">request</span><span class=\"p\">:</span>\n<span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">&gt;</span> <span class=\"o\">-</span> <span class=\"n\">reason</span><span class=\"p\">:</span> <span class=\"n\">cannot</span> <span class=\"n\">serialize</span> <span class=\"o\">&lt;</span><span class=\"n\">Request</span> <span class=\"n\">at</span> <span class=\"mh\">0x9a7c7ec</span><span class=\"o\">&gt;</span>\n<span class=\"p\">(</span><span class=\"nb\">type</span> <span class=\"n\">Request</span><span class=\"p\">)</span><span class=\"o\">&gt;</span> <span class=\"o\">-</span> <span class=\"n\">no</span> <span class=\"n\">more</span> <span class=\"n\">unserializable</span> <span class=\"n\">requests</span> <span class=\"n\">will</span> <span class=\"n\">be</span> <span class=\"n\">logged</span>\n<span class=\"p\">(</span><span class=\"n\">see</span> <span class=\"s1\">'scheduler/unserializable'</span> <span class=\"n\">stats</span> <span class=\"n\">counter</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.contracts.default.UrlContract'</span> <span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.contracts.default.ReturnsContract'</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.contracts.default.ScrapesContract'</span><span class=\"p\">:</span> <span class=\"mi\">3</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">SPIDER_CONTRACTS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.contracts.default.ScrapesContract'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">50</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">500</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.referer.RefererMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">700</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">800</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.depth.DepthMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">900</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">SPIDER_MODULES</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'mybot.spiders_prod'</span><span class=\"p\">,</span> <span class=\"s1\">'mybot.spiders_dev'</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">twisted.internet</span> <span class=\"kn\">import</span> <span class=\"n\">reactor</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'quotes'</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">timeout</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">kwargs</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"s1\">'timeout'</span><span class=\"p\">,</span> <span class=\"s1\">'60'</span><span class=\"p\">))</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">QuotesSpider</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">callLater</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">timeout</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">stop</span><span class=\"p\">)</span>\n\n        <span class=\"n\">urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://quotes.toscrape.com/page/1'</span><span class=\"p\">]</span>\n        <span class=\"k\">for</span> <span class=\"n\">url</span> <span class=\"ow\">in</span> <span class=\"n\">urls</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span><span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()}</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">stop</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"o\">.</span><span class=\"n\">close_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"s1\">'timeout'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'quotes'</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">timeout</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">kwargs</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"s1\">'timeout'</span><span class=\"p\">,</span> <span class=\"s1\">'60'</span><span class=\"p\">))</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">QuotesSpider</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"kn\">from</span> <span class=\"nn\">twisted.internet</span> <span class=\"kn\">import</span> <span class=\"n\">reactor</span>\n        <span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">callLater</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">timeout</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">stop</span><span class=\"p\">)</span>\n\n        <span class=\"n\">urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://quotes.toscrape.com/page/1'</span><span class=\"p\">]</span>\n        <span class=\"k\">for</span> <span class=\"n\">url</span> <span class=\"ow\">in</span> <span class=\"n\">urls</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span><span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()}</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">stop</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"o\">.</span><span class=\"n\">close_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"s1\">'timeout'</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["{\n    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n    'Accept-Language': 'en',\n}\n", "request.priority = request.priority - ( depth * DEPTH_PRIORITY )\n", "{\n    'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware': 100,\n    'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware': 300,\n    'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware': 350,\n    'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware': 400,\n    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': 500,\n    'scrapy.downloadermiddlewares.retry.RetryMiddleware': 550,\n    'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware': 560,\n    'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware': 580,\n    'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware': 590,\n    'scrapy.downloadermiddlewares.redirect.RedirectMiddleware': 600,\n    'scrapy.downloadermiddlewares.cookies.CookiesMiddleware': 700,\n    'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware': 750,\n    'scrapy.downloadermiddlewares.stats.DownloaderStats': 850,\n    'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware': 900,\n}\n", "DOWNLOAD_DELAY = 0.25    # 250 ms of delay\n", "{\n    'data': 'scrapy.core.downloader.handlers.datauri.DataURIDownloadHandler',\n    'file': 'scrapy.core.downloader.handlers.file.FileDownloadHandler',\n    'http': 'scrapy.core.downloader.handlers.http.HTTPDownloadHandler',\n    'https': 'scrapy.core.downloader.handlers.http.HTTPDownloadHandler',\n    's3': 'scrapy.core.downloader.handlers.s3.S3DownloadHandler',\n    'ftp': 'scrapy.core.downloader.handlers.ftp.FTPDownloadHandler',\n}\n", "DOWNLOAD_HANDLERS = {\n    'ftp': None,\n}\n", "DOWNLOAD_HANDLERS = {\n    'https': 'scrapy.core.downloader.handlers.http2.H2DownloadHandler',\n}\n", "{\n    'scrapy.extensions.corestats.CoreStats': 0,\n    'scrapy.extensions.telnet.TelnetConsole': 0,\n    'scrapy.extensions.memusage.MemoryUsage': 0,\n    'scrapy.extensions.memdebug.MemoryDebugger': 0,\n    'scrapy.extensions.closespider.CloseSpider': 0,\n    'scrapy.extensions.feedexport.FeedExporter': 0,\n    'scrapy.extensions.logstats.LogStats': 0,\n    'scrapy.extensions.spiderstate.SpiderState': 0,\n    'scrapy.extensions.throttle.AutoThrottle': 0,\n}\n", "ITEM_PIPELINES = {\n    'mybot.pipelines.validate.ValidateMyItem': 300,\n    'mybot.pipelines.validate.StoreMyItem': 800,\n}\n", "MEMDEBUG_NOTIFY = ['user@example.com']\n", "MEMUSAGE_NOTIFY_MAIL = ['user@example.com']\n", "NEWSPIDER_MODULE = 'mybot.spiders_dev'\n", "1956-01-31 00:00:00+0800 [scrapy.core.scheduler] ERROR: Unable to serialize request:\n<GET http://example.com> - reason: cannot serialize <Request at 0x9a7c7ec>\n(type Request)> - no more unserializable requests will be logged\n(see 'scheduler/unserializable' stats counter)\n", "{\n    'scrapy.contracts.default.UrlContract' : 1,\n    'scrapy.contracts.default.ReturnsContract': 2,\n    'scrapy.contracts.default.ScrapesContract': 3,\n}\n", "SPIDER_CONTRACTS = {\n    'scrapy.contracts.default.ScrapesContract': None,\n}\n", "{\n    'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware': 50,\n    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': 500,\n    'scrapy.spidermiddlewares.referer.RefererMiddleware': 700,\n    'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware': 800,\n    'scrapy.spidermiddlewares.depth.DepthMiddleware': 900,\n}\n", "SPIDER_MODULES = ['mybot.spiders_prod', 'mybot.spiders_dev']\n", "import scrapy\nfrom twisted.internet import reactor\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = 'quotes'\n\n    def __init__(self, *args, **kwargs):\n        self.timeout = int(kwargs.pop('timeout', '60'))\n        super(QuotesSpider, self).__init__(*args, **kwargs)\n\n    def start_requests(self):\n        reactor.callLater(self.timeout, self.stop)\n\n        urls = ['https://quotes.toscrape.com/page/1']\n        for url in urls:\n            yield scrapy.Request(url=url, callback=self.parse)\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {'text': quote.css('span.text::text').get()}\n\n    def stop(self):\n        self.crawler.engine.close_spider(self, 'timeout')\n", "import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = 'quotes'\n\n    def __init__(self, *args, **kwargs):\n        self.timeout = int(kwargs.pop('timeout', '60'))\n        super(QuotesSpider, self).__init__(*args, **kwargs)\n\n    def start_requests(self):\n        from twisted.internet import reactor\n        reactor.callLater(self.timeout, self.stop)\n\n        urls = ['https://quotes.toscrape.com/page/1']\n        for url in urls:\n            yield scrapy.Request(url=url, callback=self.parse)\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {'text': quote.css('span.text::text').get()}\n\n    def stop(self):\n        self.crawler.engine.close_spider(self, 'timeout')\n"], "index": 19}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "AWS_ACCESS_KEY_ID", "header_href": "#aws-access-key-id", "codes": [], "codes_text": [], "index": 14}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "AWS_SECRET_ACCESS_KEY", "header_href": "#aws-secret-access-key", "codes": [], "codes_text": [], "index": 15}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "AWS_SESSION_TOKEN", "header_href": "#aws-session-token", "codes": [], "codes_text": [], "index": 16}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "AWS_ENDPOINT_URL", "header_href": "#aws-endpoint-url", "codes": [], "codes_text": [], "index": 17}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "AWS_USE_SSL", "header_href": "#aws-use-ssl", "codes": [], "codes_text": [], "index": 18}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "AWS_VERIFY", "header_href": "#aws-verify", "codes": [], "codes_text": [], "index": 19}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "AWS_REGION_NAME", "header_href": "#aws-region-name", "codes": [], "codes_text": [], "index": 20}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "ASYNCIO_EVENT_LOOP", "header_href": "#asyncio-event-loop", "codes": [], "codes_text": [], "index": 21}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "BOT_NAME", "header_href": "#bot-name", "codes": [], "codes_text": [], "index": 22}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "CONCURRENT_ITEMS", "header_href": "#concurrent-items", "codes": [], "codes_text": [], "index": 23}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "CONCURRENT_REQUESTS", "header_href": "#concurrent-requests", "codes": [], "codes_text": [], "index": 24}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "CONCURRENT_REQUESTS_PER_DOMAIN", "header_href": "#concurrent-requests-per-domain", "codes": [], "codes_text": [], "index": 25}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "CONCURRENT_REQUESTS_PER_IP", "header_href": "#concurrent-requests-per-ip", "codes": [], "codes_text": [], "index": 26}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DEFAULT_ITEM_CLASS", "header_href": "#default-item-class", "codes": [], "codes_text": [], "index": 27}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DEFAULT_REQUEST_HEADERS", "header_href": "#default-request-headers", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'Accept'</span><span class=\"p\">:</span> <span class=\"s1\">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'Accept-Language'</span><span class=\"p\">:</span> <span class=\"s1\">'en'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["{\n    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n    'Accept-Language': 'en',\n}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DEPTH_LIMIT", "header_href": "#depth-limit", "codes": [], "codes_text": [], "index": 29}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DEPTH_PRIORITY", "header_href": "#depth-priority", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">priority</span> <span class=\"o\">=</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">priority</span> <span class=\"o\">-</span> <span class=\"p\">(</span> <span class=\"n\">depth</span> <span class=\"o\">*</span> <span class=\"n\">DEPTH_PRIORITY</span> <span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["request.priority = request.priority - ( depth * DEPTH_PRIORITY )\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DEPTH_STATS_VERBOSE", "header_href": "#depth-stats-verbose", "codes": [], "codes_text": [], "index": 31}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DNSCACHE_ENABLED", "header_href": "#dnscache-enabled", "codes": [], "codes_text": [], "index": 32}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DNSCACHE_SIZE", "header_href": "#dnscache-size", "codes": [], "codes_text": [], "index": 33}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DNS_RESOLVER", "header_href": "#dns-resolver", "codes": [], "codes_text": [], "index": 34}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DNS_TIMEOUT", "header_href": "#dns-timeout", "codes": [], "codes_text": [], "index": 35}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DOWNLOADER", "header_href": "#downloader", "codes": [], "codes_text": [], "index": 36}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DOWNLOADER_HTTPCLIENTFACTORY", "header_href": "#downloader-httpclientfactory", "codes": [], "codes_text": [], "index": 37}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DOWNLOADER_CLIENTCONTEXTFACTORY", "header_href": "#downloader-clientcontextfactory", "codes": [], "codes_text": [], "index": 38}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DOWNLOADER_CLIENT_TLS_CIPHERS", "header_href": "#downloader-client-tls-ciphers", "codes": [], "codes_text": [], "index": 39}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DOWNLOADER_CLIENT_TLS_METHOD", "header_href": "#downloader-client-tls-method", "codes": [], "codes_text": [], "index": 40}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DOWNLOADER_CLIENT_TLS_VERBOSE_LOGGING", "header_href": "#downloader-client-tls-verbose-logging", "codes": [], "codes_text": [], "index": 41}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DOWNLOADER_MIDDLEWARES", "header_href": "#downloader-middlewares", "codes": [], "codes_text": [], "index": 42}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DOWNLOADER_MIDDLEWARES_BASE", "header_href": "#downloader-middlewares-base", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">100</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">300</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">350</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">400</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">500</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.retry.RetryMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">550</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">560</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">580</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">590</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">600</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.cookies.CookiesMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">700</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">750</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.stats.DownloaderStats'</span><span class=\"p\">:</span> <span class=\"mi\">850</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">900</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["{\n    'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware': 100,\n    'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware': 300,\n    'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware': 350,\n    'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware': 400,\n    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': 500,\n    'scrapy.downloadermiddlewares.retry.RetryMiddleware': 550,\n    'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware': 560,\n    'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware': 580,\n    'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware': 590,\n    'scrapy.downloadermiddlewares.redirect.RedirectMiddleware': 600,\n    'scrapy.downloadermiddlewares.cookies.CookiesMiddleware': 700,\n    'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware': 750,\n    'scrapy.downloadermiddlewares.stats.DownloaderStats': 850,\n    'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware': 900,\n}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DOWNLOADER_STATS", "header_href": "#downloader-stats", "codes": [], "codes_text": [], "index": 44}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DOWNLOAD_DELAY", "header_href": "#download-delay", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">DOWNLOAD_DELAY</span> <span class=\"o\">=</span> <span class=\"mf\">0.25</span>    <span class=\"c1\"># 250 ms of delay</span>\n</pre></div>"], "codes_text": ["DOWNLOAD_DELAY = 0.25    # 250 ms of delay\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DOWNLOAD_HANDLERS", "header_href": "#download-handlers", "codes": [], "codes_text": [], "index": 46}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DOWNLOAD_HANDLERS_BASE", "header_href": "#download-handlers-base", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'data'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.datauri.DataURIDownloadHandler'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'file'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.file.FileDownloadHandler'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'http'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.http.HTTPDownloadHandler'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'https'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.http.HTTPDownloadHandler'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'s3'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.s3.S3DownloadHandler'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'ftp'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.ftp.FTPDownloadHandler'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">DOWNLOAD_HANDLERS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'ftp'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">DOWNLOAD_HANDLERS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'https'</span><span class=\"p\">:</span> <span class=\"s1\">'scrapy.core.downloader.handlers.http2.H2DownloadHandler'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["{\n    'data': 'scrapy.core.downloader.handlers.datauri.DataURIDownloadHandler',\n    'file': 'scrapy.core.downloader.handlers.file.FileDownloadHandler',\n    'http': 'scrapy.core.downloader.handlers.http.HTTPDownloadHandler',\n    'https': 'scrapy.core.downloader.handlers.http.HTTPDownloadHandler',\n    's3': 'scrapy.core.downloader.handlers.s3.S3DownloadHandler',\n    'ftp': 'scrapy.core.downloader.handlers.ftp.FTPDownloadHandler',\n}\n", "DOWNLOAD_HANDLERS = {\n    'ftp': None,\n}\n", "DOWNLOAD_HANDLERS = {\n    'https': 'scrapy.core.downloader.handlers.http2.H2DownloadHandler',\n}\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DOWNLOAD_TIMEOUT", "header_href": "#download-timeout", "codes": [], "codes_text": [], "index": 48}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DOWNLOAD_MAXSIZE", "header_href": "#download-maxsize", "codes": [], "codes_text": [], "index": 49}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DOWNLOAD_WARNSIZE", "header_href": "#download-warnsize", "codes": [], "codes_text": [], "index": 50}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DOWNLOAD_FAIL_ON_DATALOSS", "header_href": "#download-fail-on-dataloss", "codes": [], "codes_text": [], "index": 51}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DUPEFILTER_CLASS", "header_href": "#dupefilter-class", "codes": [], "codes_text": [], "index": 52}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DUPEFILTER_DEBUG", "header_href": "#dupefilter-debug", "codes": [], "codes_text": [], "index": 53}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "EDITOR", "header_href": "#editor", "codes": [], "codes_text": [], "index": 54}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "EXTENSIONS", "header_href": "#extensions", "codes": [], "codes_text": [], "index": 55}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "EXTENSIONS_BASE", "header_href": "#extensions-base", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.extensions.corestats.CoreStats'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.telnet.TelnetConsole'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.memusage.MemoryUsage'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.memdebug.MemoryDebugger'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.closespider.CloseSpider'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.feedexport.FeedExporter'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.logstats.LogStats'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.spiderstate.SpiderState'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.throttle.AutoThrottle'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["{\n    'scrapy.extensions.corestats.CoreStats': 0,\n    'scrapy.extensions.telnet.TelnetConsole': 0,\n    'scrapy.extensions.memusage.MemoryUsage': 0,\n    'scrapy.extensions.memdebug.MemoryDebugger': 0,\n    'scrapy.extensions.closespider.CloseSpider': 0,\n    'scrapy.extensions.feedexport.FeedExporter': 0,\n    'scrapy.extensions.logstats.LogStats': 0,\n    'scrapy.extensions.spiderstate.SpiderState': 0,\n    'scrapy.extensions.throttle.AutoThrottle': 0,\n}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FEED_TEMPDIR", "header_href": "#feed-tempdir", "codes": [], "codes_text": [], "index": 57}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FEED_STORAGE_GCS_ACL", "header_href": "#feed-storage-gcs-acl", "codes": [], "codes_text": [], "index": 58}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FTP_PASSIVE_MODE", "header_href": "#ftp-passive-mode", "codes": [], "codes_text": [], "index": 59}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FTP_PASSWORD", "header_href": "#ftp-password", "codes": [], "codes_text": [], "index": 60}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FTP_USER", "header_href": "#ftp-user", "codes": [], "codes_text": [], "index": 61}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "GCS_PROJECT_ID", "header_href": "#gcs-project-id", "codes": [], "codes_text": [], "index": 62}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "ITEM_PIPELINES", "header_href": "#item-pipelines", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">ITEM_PIPELINES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'mybot.pipelines.validate.ValidateMyItem'</span><span class=\"p\">:</span> <span class=\"mi\">300</span><span class=\"p\">,</span>\n    <span class=\"s1\">'mybot.pipelines.validate.StoreMyItem'</span><span class=\"p\">:</span> <span class=\"mi\">800</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["ITEM_PIPELINES = {\n    'mybot.pipelines.validate.ValidateMyItem': 300,\n    'mybot.pipelines.validate.StoreMyItem': 800,\n}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "ITEM_PIPELINES_BASE", "header_href": "#item-pipelines-base", "codes": [], "codes_text": [], "index": 64}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "JOBDIR", "header_href": "#jobdir", "codes": [], "codes_text": [], "index": 65}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "LOG_ENABLED", "header_href": "#log-enabled", "codes": [], "codes_text": [], "index": 66}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "LOG_ENCODING", "header_href": "#log-encoding", "codes": [], "codes_text": [], "index": 67}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "LOG_FILE", "header_href": "#log-file", "codes": [], "codes_text": [], "index": 68}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "LOG_FILE_APPEND", "header_href": "#log-file-append", "codes": [], "codes_text": [], "index": 69}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "LOG_FORMAT", "header_href": "#log-format", "codes": [], "codes_text": [], "index": 70}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "LOG_DATEFORMAT", "header_href": "#log-dateformat", "codes": [], "codes_text": [], "index": 71}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "LOG_FORMATTER", "header_href": "#log-formatter", "codes": [], "codes_text": [], "index": 72}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "LOG_LEVEL", "header_href": "#log-level", "codes": [], "codes_text": [], "index": 73}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "LOG_STDOUT", "header_href": "#log-stdout", "codes": [], "codes_text": [], "index": 74}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "LOG_SHORT_NAMES", "header_href": "#log-short-names", "codes": [], "codes_text": [], "index": 75}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "LOGSTATS_INTERVAL", "header_href": "#logstats-interval", "codes": [], "codes_text": [], "index": 76}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MEMDEBUG_ENABLED", "header_href": "#memdebug-enabled", "codes": [], "codes_text": [], "index": 77}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MEMDEBUG_NOTIFY", "header_href": "#memdebug-notify", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">MEMDEBUG_NOTIFY</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'user@example.com'</span><span class=\"p\">]</span>\n</pre></div>"], "codes_text": ["MEMDEBUG_NOTIFY = ['user@example.com']\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MEMUSAGE_ENABLED", "header_href": "#memusage-enabled", "codes": [], "codes_text": [], "index": 79}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MEMUSAGE_LIMIT_MB", "header_href": "#memusage-limit-mb", "codes": [], "codes_text": [], "index": 80}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MEMUSAGE_CHECK_INTERVAL_SECONDS", "header_href": "#memusage-check-interval-seconds", "codes": [], "codes_text": [], "index": 81}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MEMUSAGE_NOTIFY_MAIL", "header_href": "#memusage-notify-mail", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">MEMUSAGE_NOTIFY_MAIL</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'user@example.com'</span><span class=\"p\">]</span>\n</pre></div>"], "codes_text": ["MEMUSAGE_NOTIFY_MAIL = ['user@example.com']\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MEMUSAGE_WARNING_MB", "header_href": "#memusage-warning-mb", "codes": [], "codes_text": [], "index": 83}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "NEWSPIDER_MODULE", "header_href": "#newspider-module", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">NEWSPIDER_MODULE</span> <span class=\"o\">=</span> <span class=\"s1\">'mybot.spiders_dev'</span>\n</pre></div>"], "codes_text": ["NEWSPIDER_MODULE = 'mybot.spiders_dev'\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "RANDOMIZE_DOWNLOAD_DELAY", "header_href": "#randomize-download-delay", "codes": [], "codes_text": [], "index": 85}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "REACTOR_THREADPOOL_MAXSIZE", "header_href": "#reactor-threadpool-maxsize", "codes": [], "codes_text": [], "index": 86}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "REDIRECT_PRIORITY_ADJUST", "header_href": "#redirect-priority-adjust", "codes": [], "codes_text": [], "index": 87}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "ROBOTSTXT_OBEY", "header_href": "#robotstxt-obey", "codes": [], "codes_text": [], "index": 88}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "ROBOTSTXT_PARSER", "header_href": "#robotstxt-parser", "codes": [], "codes_text": [], "index": 89}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "ROBOTSTXT_USER_AGENT", "header_href": "#robotstxt-user-agent", "codes": [], "codes_text": [], "index": 90}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "SCHEDULER", "header_href": "#scheduler", "codes": [], "codes_text": [], "index": 91}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "SCHEDULER_DEBUG", "header_href": "#scheduler-debug", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"mi\">1956</span><span class=\"o\">-</span><span class=\"mi\">01</span><span class=\"o\">-</span><span class=\"mi\">31</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"o\">+</span><span class=\"mi\">0800</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">scheduler</span><span class=\"p\">]</span> <span class=\"n\">ERROR</span><span class=\"p\">:</span> <span class=\"n\">Unable</span> <span class=\"n\">to</span> <span class=\"n\">serialize</span> <span class=\"n\">request</span><span class=\"p\">:</span>\n<span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">&gt;</span> <span class=\"o\">-</span> <span class=\"n\">reason</span><span class=\"p\">:</span> <span class=\"n\">cannot</span> <span class=\"n\">serialize</span> <span class=\"o\">&lt;</span><span class=\"n\">Request</span> <span class=\"n\">at</span> <span class=\"mh\">0x9a7c7ec</span><span class=\"o\">&gt;</span>\n<span class=\"p\">(</span><span class=\"nb\">type</span> <span class=\"n\">Request</span><span class=\"p\">)</span><span class=\"o\">&gt;</span> <span class=\"o\">-</span> <span class=\"n\">no</span> <span class=\"n\">more</span> <span class=\"n\">unserializable</span> <span class=\"n\">requests</span> <span class=\"n\">will</span> <span class=\"n\">be</span> <span class=\"n\">logged</span>\n<span class=\"p\">(</span><span class=\"n\">see</span> <span class=\"s1\">'scheduler/unserializable'</span> <span class=\"n\">stats</span> <span class=\"n\">counter</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["1956-01-31 00:00:00+0800 [scrapy.core.scheduler] ERROR: Unable to serialize request:\n<GET http://example.com> - reason: cannot serialize <Request at 0x9a7c7ec>\n(type Request)> - no more unserializable requests will be logged\n(see 'scheduler/unserializable' stats counter)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "SCHEDULER_DISK_QUEUE", "header_href": "#scheduler-disk-queue", "codes": [], "codes_text": [], "index": 93}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "SCHEDULER_MEMORY_QUEUE", "header_href": "#scheduler-memory-queue", "codes": [], "codes_text": [], "index": 94}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "SCHEDULER_PRIORITY_QUEUE", "header_href": "#scheduler-priority-queue", "codes": [], "codes_text": [], "index": 95}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "SCRAPER_SLOT_MAX_ACTIVE_SIZE", "header_href": "#scraper-slot-max-active-size", "codes": [], "codes_text": [], "index": 96}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "SPIDER_CONTRACTS", "header_href": "#spider-contracts", "codes": [], "codes_text": [], "index": 97}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "SPIDER_CONTRACTS_BASE", "header_href": "#spider-contracts-base", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.contracts.default.UrlContract'</span> <span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.contracts.default.ReturnsContract'</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.contracts.default.ScrapesContract'</span><span class=\"p\">:</span> <span class=\"mi\">3</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">SPIDER_CONTRACTS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.contracts.default.ScrapesContract'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["{\n    'scrapy.contracts.default.UrlContract' : 1,\n    'scrapy.contracts.default.ReturnsContract': 2,\n    'scrapy.contracts.default.ScrapesContract': 3,\n}\n", "SPIDER_CONTRACTS = {\n    'scrapy.contracts.default.ScrapesContract': None,\n}\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "SPIDER_LOADER_CLASS", "header_href": "#spider-loader-class", "codes": [], "codes_text": [], "index": 99}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "SPIDER_LOADER_WARN_ONLY", "header_href": "#spider-loader-warn-only", "codes": [], "codes_text": [], "index": 100}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "SPIDER_MIDDLEWARES", "header_href": "#spider-middlewares", "codes": [], "codes_text": [], "index": 101}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "SPIDER_MIDDLEWARES_BASE", "header_href": "#spider-middlewares-base", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">50</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">500</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.referer.RefererMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">700</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">800</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.depth.DepthMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">900</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["{\n    'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware': 50,\n    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': 500,\n    'scrapy.spidermiddlewares.referer.RefererMiddleware': 700,\n    'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware': 800,\n    'scrapy.spidermiddlewares.depth.DepthMiddleware': 900,\n}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "SPIDER_MODULES", "header_href": "#spider-modules", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">SPIDER_MODULES</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'mybot.spiders_prod'</span><span class=\"p\">,</span> <span class=\"s1\">'mybot.spiders_dev'</span><span class=\"p\">]</span>\n</pre></div>"], "codes_text": ["SPIDER_MODULES = ['mybot.spiders_prod', 'mybot.spiders_dev']\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "STATS_CLASS", "header_href": "#stats-class", "codes": [], "codes_text": [], "index": 104}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "STATS_DUMP", "header_href": "#stats-dump", "codes": [], "codes_text": [], "index": 105}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "STATSMAILER_RCPTS", "header_href": "#statsmailer-rcpts", "codes": [], "codes_text": [], "index": 106}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "TELNETCONSOLE_ENABLED", "header_href": "#telnetconsole-enabled", "codes": [], "codes_text": [], "index": 107}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "TEMPLATES_DIR", "header_href": "#templates-dir", "codes": [], "codes_text": [], "index": 108}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "TWISTED_REACTOR", "header_href": "#twisted-reactor", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">twisted.internet</span> <span class=\"kn\">import</span> <span class=\"n\">reactor</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'quotes'</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">timeout</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">kwargs</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"s1\">'timeout'</span><span class=\"p\">,</span> <span class=\"s1\">'60'</span><span class=\"p\">))</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">QuotesSpider</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">callLater</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">timeout</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">stop</span><span class=\"p\">)</span>\n\n        <span class=\"n\">urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://quotes.toscrape.com/page/1'</span><span class=\"p\">]</span>\n        <span class=\"k\">for</span> <span class=\"n\">url</span> <span class=\"ow\">in</span> <span class=\"n\">urls</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span><span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()}</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">stop</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"o\">.</span><span class=\"n\">close_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"s1\">'timeout'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuotesSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'quotes'</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">timeout</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">kwargs</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"s1\">'timeout'</span><span class=\"p\">,</span> <span class=\"s1\">'60'</span><span class=\"p\">))</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">QuotesSpider</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">start_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"kn\">from</span> <span class=\"nn\">twisted.internet</span> <span class=\"kn\">import</span> <span class=\"n\">reactor</span>\n        <span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">callLater</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">timeout</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">stop</span><span class=\"p\">)</span>\n\n        <span class=\"n\">urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://quotes.toscrape.com/page/1'</span><span class=\"p\">]</span>\n        <span class=\"k\">for</span> <span class=\"n\">url</span> <span class=\"ow\">in</span> <span class=\"n\">urls</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span><span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()}</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">stop</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"o\">.</span><span class=\"n\">close_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"s1\">'timeout'</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import scrapy\nfrom twisted.internet import reactor\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = 'quotes'\n\n    def __init__(self, *args, **kwargs):\n        self.timeout = int(kwargs.pop('timeout', '60'))\n        super(QuotesSpider, self).__init__(*args, **kwargs)\n\n    def start_requests(self):\n        reactor.callLater(self.timeout, self.stop)\n\n        urls = ['https://quotes.toscrape.com/page/1']\n        for url in urls:\n            yield scrapy.Request(url=url, callback=self.parse)\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {'text': quote.css('span.text::text').get()}\n\n    def stop(self):\n        self.crawler.engine.close_spider(self, 'timeout')\n", "import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = 'quotes'\n\n    def __init__(self, *args, **kwargs):\n        self.timeout = int(kwargs.pop('timeout', '60'))\n        super(QuotesSpider, self).__init__(*args, **kwargs)\n\n    def start_requests(self):\n        from twisted.internet import reactor\n        reactor.callLater(self.timeout, self.stop)\n\n        urls = ['https://quotes.toscrape.com/page/1']\n        for url in urls:\n            yield scrapy.Request(url=url, callback=self.parse)\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {'text': quote.css('span.text::text').get()}\n\n    def stop(self):\n        self.crawler.engine.close_spider(self, 'timeout')\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "URLLENGTH_LIMIT", "header_href": "#urllength-limit", "codes": [], "codes_text": [], "index": 110}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "USER_AGENT", "header_href": "#user-agent", "codes": [], "codes_text": [], "index": 111}
{"url": "https://docs.scrapy.org/en/latest/topics/settings.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Settings documented elsewhere:", "header_href": "#settings-documented-elsewhere", "codes": [], "codes_text": [], "index": 112}
{"url": "https://docs.scrapy.org/en/latest/topics/exceptions.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Exceptions", "header_href": "#module-scrapy.exceptions", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse_page</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"s1\">'Bandwidth exceeded'</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">:</span>\n        <span class=\"k\">raise</span> <span class=\"n\">CloseSpider</span><span class=\"p\">(</span><span class=\"s1\">'bandwidth_exceeded'</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["def parse_page(self, response):\n    if 'Bandwidth exceeded' in response.body:\n        raise CloseSpider('bandwidth_exceeded')\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/exceptions.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Built-in Exceptions reference", "header_href": "#built-in-exceptions-reference", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse_page</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"s1\">'Bandwidth exceeded'</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">:</span>\n        <span class=\"k\">raise</span> <span class=\"n\">CloseSpider</span><span class=\"p\">(</span><span class=\"s1\">'bandwidth_exceeded'</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["def parse_page(self, response):\n    if 'Bandwidth exceeded' in response.body:\n        raise CloseSpider('bandwidth_exceeded')\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/exceptions.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "CloseSpider", "header_href": "#closespider", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse_page</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"s1\">'Bandwidth exceeded'</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">:</span>\n        <span class=\"k\">raise</span> <span class=\"n\">CloseSpider</span><span class=\"p\">(</span><span class=\"s1\">'bandwidth_exceeded'</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["def parse_page(self, response):\n    if 'Bandwidth exceeded' in response.body:\n        raise CloseSpider('bandwidth_exceeded')\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/exceptions.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DontCloseSpider", "header_href": "#dontclosespider", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/exceptions.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DropItem", "header_href": "#dropitem", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/exceptions.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "IgnoreRequest", "header_href": "#ignorerequest", "codes": [], "codes_text": [], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/exceptions.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "NotConfigured", "header_href": "#notconfigured", "codes": [], "codes_text": [], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/exceptions.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "NotSupported", "header_href": "#notsupported", "codes": [], "codes_text": [], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/exceptions.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "StopDownload", "header_href": "#stopdownload", "codes": [], "codes_text": [], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/topics/logging.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Logging", "header_href": "#logging", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">warning</span><span class=\"p\">(</span><span class=\"s2\">\"This is a warning\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">WARNING</span><span class=\"p\">,</span> <span class=\"s2\">\"This is a warning\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">()</span>\n<span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">warning</span><span class=\"p\">(</span><span class=\"s2\">\"This is a warning\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"s1\">'mycustomlogger'</span><span class=\"p\">)</span>\n<span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">warning</span><span class=\"p\">(</span><span class=\"s2\">\"This is a warning\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"vm\">__name__</span><span class=\"p\">)</span>\n<span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">warning</span><span class=\"p\">(</span><span class=\"s2\">\"This is a warning\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://scrapy.org'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Parse function called on </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"s1\">'mycustomlogger'</span><span class=\"p\">)</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://scrapy.org'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Parse function called on </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">PoliteLogFormatter</span><span class=\"p\">(</span><span class=\"n\">logformatter</span><span class=\"o\">.</span><span class=\"n\">LogFormatter</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">dropped</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">exception</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"p\">{</span>\n            <span class=\"s1\">'level'</span><span class=\"p\">:</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">INFO</span><span class=\"p\">,</span> <span class=\"c1\"># lowering the level from logging.WARNING</span>\n            <span class=\"s1\">'msg'</span><span class=\"p\">:</span> <span class=\"s2\">\"Dropped: </span><span class=\"si\">%(exception)s</span><span class=\"s2\">\"</span> <span class=\"o\">+</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">linesep</span> <span class=\"o\">+</span> <span class=\"s2\">\"</span><span class=\"si\">%(item)s</span><span class=\"s2\">\"</span><span class=\"p\">,</span>\n            <span class=\"s1\">'args'</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'exception'</span><span class=\"p\">:</span> <span class=\"n\">exception</span><span class=\"p\">,</span>\n                <span class=\"s1\">'item'</span><span class=\"p\">:</span> <span class=\"n\">item</span><span class=\"p\">,</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">22</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">06</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">spidermiddlewares</span><span class=\"o\">.</span><span class=\"n\">httperror</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Ignoring</span>\n<span class=\"n\">response</span> <span class=\"o\">&lt;</span><span class=\"mi\">500</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">-</span><span class=\"mi\">34</span><span class=\"o\">/&gt;</span><span class=\"p\">:</span> <span class=\"n\">HTTP</span> <span class=\"n\">status</span> <span class=\"n\">code</span>\n<span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"n\">handled</span> <span class=\"ow\">or</span> <span class=\"ow\">not</span> <span class=\"n\">allowed</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># ...</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"s1\">'scrapy.spidermiddlewares.httperror'</span><span class=\"p\">)</span>\n        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">setLevel</span><span class=\"p\">(</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">WARNING</span><span class=\"p\">)</span>\n        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">import</span> <span class=\"nn\">re</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">ContentFilter</span><span class=\"p\">(</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">Filter</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">filter</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">record</span><span class=\"p\">):</span>\n        <span class=\"n\">match</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'\\d</span><span class=\"si\">{3}</span><span class=\"s1\"> [Ee]rror, retrying'</span><span class=\"p\">,</span> <span class=\"n\">record</span><span class=\"o\">.</span><span class=\"n\">message</span><span class=\"p\">)</span>\n        <span class=\"k\">if</span> <span class=\"n\">match</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"kc\">False</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># ...</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">handler</span> <span class=\"ow\">in</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">root</span><span class=\"o\">.</span><span class=\"n\">handlers</span><span class=\"p\">:</span>\n            <span class=\"n\">handler</span><span class=\"o\">.</span><span class=\"n\">addFilter</span><span class=\"p\">(</span><span class=\"n\">ContentFilter</span><span class=\"p\">())</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># ...</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"s1\">'my_logger'</span><span class=\"p\">)</span>\n        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">addFilter</span><span class=\"p\">(</span><span class=\"n\">ContentFilter</span><span class=\"p\">())</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">basicConfig</span><span class=\"p\">(</span>\n    <span class=\"n\">filename</span><span class=\"o\">=</span><span class=\"s1\">'log.txt'</span><span class=\"p\">,</span>\n    <span class=\"nb\">format</span><span class=\"o\">=</span><span class=\"s1\">'</span><span class=\"si\">%(levelname)s</span><span class=\"s1\">: </span><span class=\"si\">%(message)s</span><span class=\"s1\">'</span><span class=\"p\">,</span>\n    <span class=\"n\">level</span><span class=\"o\">=</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">INFO</span>\n<span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import logging\nlogging.warning(\"This is a warning\")\n", "import logging\nlogging.log(logging.WARNING, \"This is a warning\")\n", "import logging\nlogger = logging.getLogger()\nlogger.warning(\"This is a warning\")\n", "import logging\nlogger = logging.getLogger('mycustomlogger')\nlogger.warning(\"This is a warning\")\n", "import logging\nlogger = logging.getLogger(__name__)\nlogger.warning(\"This is a warning\")\n", "import scrapy\n\nclass MySpider(scrapy.Spider):\n\n    name = 'myspider'\n    start_urls = ['https://scrapy.org']\n\n    def parse(self, response):\n        self.logger.info('Parse function called on %s', response.url)\n", "import logging\nimport scrapy\n\nlogger = logging.getLogger('mycustomlogger')\n\nclass MySpider(scrapy.Spider):\n\n    name = 'myspider'\n    start_urls = ['https://scrapy.org']\n\n    def parse(self, response):\n        logger.info('Parse function called on %s', response.url)\n", "class PoliteLogFormatter(logformatter.LogFormatter):\n    def dropped(self, item, exception, response, spider):\n        return {\n            'level': logging.INFO, # lowering the level from logging.WARNING\n            'msg': \"Dropped: %(exception)s\" + os.linesep + \"%(item)s\",\n            'args': {\n                'exception': exception,\n                'item': item,\n            }\n        }\n", "2016-12-16 22:00:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring\nresponse <500 https://quotes.toscrape.com/page/1-34/>: HTTP status code\nis not handled or not allowed\n", "import logging\nimport scrapy\n\n\nclass MySpider(scrapy.Spider):\n    # ...\n    def __init__(self, *args, **kwargs):\n        logger = logging.getLogger('scrapy.spidermiddlewares.httperror')\n        logger.setLevel(logging.WARNING)\n        super().__init__(*args, **kwargs)\n", "import logging\nimport re\n\nclass ContentFilter(logging.Filter):\n    def filter(self, record):\n        match = re.search(r'\\d{3} [Ee]rror, retrying', record.message)\n        if match:\n            return False\n", "import logging\nimport scrapy\n\nclass MySpider(scrapy.Spider):\n    # ...\n    def __init__(self, *args, **kwargs):\n        for handler in logging.root.handlers:\n            handler.addFilter(ContentFilter())\n", "import logging\nimport scrapy\n\nclass MySpider(scrapy.Spider):\n    # ...\n    def __init__(self, *args, **kwargs):\n        logger = logging.getLogger('my_logger')\n        logger.addFilter(ContentFilter())\n", "import logging\n\nlogging.basicConfig(\n    filename='log.txt',\n    format='%(levelname)s: %(message)s',\n    level=logging.INFO\n)\n"], "index": 14}
{"url": "https://docs.scrapy.org/en/latest/topics/logging.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Log levels", "header_href": "#log-levels", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/logging.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "How to log messages", "header_href": "#how-to-log-messages", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">warning</span><span class=\"p\">(</span><span class=\"s2\">\"This is a warning\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">WARNING</span><span class=\"p\">,</span> <span class=\"s2\">\"This is a warning\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">()</span>\n<span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">warning</span><span class=\"p\">(</span><span class=\"s2\">\"This is a warning\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"s1\">'mycustomlogger'</span><span class=\"p\">)</span>\n<span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">warning</span><span class=\"p\">(</span><span class=\"s2\">\"This is a warning\"</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"vm\">__name__</span><span class=\"p\">)</span>\n<span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">warning</span><span class=\"p\">(</span><span class=\"s2\">\"This is a warning\"</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import logging\nlogging.warning(\"This is a warning\")\n", "import logging\nlogging.log(logging.WARNING, \"This is a warning\")\n", "import logging\nlogger = logging.getLogger()\nlogger.warning(\"This is a warning\")\n", "import logging\nlogger = logging.getLogger('mycustomlogger')\nlogger.warning(\"This is a warning\")\n", "import logging\nlogger = logging.getLogger(__name__)\nlogger.warning(\"This is a warning\")\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/logging.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Logging from Spiders", "header_href": "#logging-from-spiders", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://scrapy.org'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Parse function called on </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"s1\">'mycustomlogger'</span><span class=\"p\">)</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://scrapy.org'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Parse function called on </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import scrapy\n\nclass MySpider(scrapy.Spider):\n\n    name = 'myspider'\n    start_urls = ['https://scrapy.org']\n\n    def parse(self, response):\n        self.logger.info('Parse function called on %s', response.url)\n", "import logging\nimport scrapy\n\nlogger = logging.getLogger('mycustomlogger')\n\nclass MySpider(scrapy.Spider):\n\n    name = 'myspider'\n    start_urls = ['https://scrapy.org']\n\n    def parse(self, response):\n        logger.info('Parse function called on %s', response.url)\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/logging.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Logging configuration", "header_href": "#logging-configuration", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">PoliteLogFormatter</span><span class=\"p\">(</span><span class=\"n\">logformatter</span><span class=\"o\">.</span><span class=\"n\">LogFormatter</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">dropped</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">exception</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"p\">{</span>\n            <span class=\"s1\">'level'</span><span class=\"p\">:</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">INFO</span><span class=\"p\">,</span> <span class=\"c1\"># lowering the level from logging.WARNING</span>\n            <span class=\"s1\">'msg'</span><span class=\"p\">:</span> <span class=\"s2\">\"Dropped: </span><span class=\"si\">%(exception)s</span><span class=\"s2\">\"</span> <span class=\"o\">+</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">linesep</span> <span class=\"o\">+</span> <span class=\"s2\">\"</span><span class=\"si\">%(item)s</span><span class=\"s2\">\"</span><span class=\"p\">,</span>\n            <span class=\"s1\">'args'</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'exception'</span><span class=\"p\">:</span> <span class=\"n\">exception</span><span class=\"p\">,</span>\n                <span class=\"s1\">'item'</span><span class=\"p\">:</span> <span class=\"n\">item</span><span class=\"p\">,</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">22</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">06</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">spidermiddlewares</span><span class=\"o\">.</span><span class=\"n\">httperror</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Ignoring</span>\n<span class=\"n\">response</span> <span class=\"o\">&lt;</span><span class=\"mi\">500</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">-</span><span class=\"mi\">34</span><span class=\"o\">/&gt;</span><span class=\"p\">:</span> <span class=\"n\">HTTP</span> <span class=\"n\">status</span> <span class=\"n\">code</span>\n<span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"n\">handled</span> <span class=\"ow\">or</span> <span class=\"ow\">not</span> <span class=\"n\">allowed</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># ...</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"s1\">'scrapy.spidermiddlewares.httperror'</span><span class=\"p\">)</span>\n        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">setLevel</span><span class=\"p\">(</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">WARNING</span><span class=\"p\">)</span>\n        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">import</span> <span class=\"nn\">re</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">ContentFilter</span><span class=\"p\">(</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">Filter</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">filter</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">record</span><span class=\"p\">):</span>\n        <span class=\"n\">match</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'\\d</span><span class=\"si\">{3}</span><span class=\"s1\"> [Ee]rror, retrying'</span><span class=\"p\">,</span> <span class=\"n\">record</span><span class=\"o\">.</span><span class=\"n\">message</span><span class=\"p\">)</span>\n        <span class=\"k\">if</span> <span class=\"n\">match</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"kc\">False</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># ...</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">handler</span> <span class=\"ow\">in</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">root</span><span class=\"o\">.</span><span class=\"n\">handlers</span><span class=\"p\">:</span>\n            <span class=\"n\">handler</span><span class=\"o\">.</span><span class=\"n\">addFilter</span><span class=\"p\">(</span><span class=\"n\">ContentFilter</span><span class=\"p\">())</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># ...</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"s1\">'my_logger'</span><span class=\"p\">)</span>\n        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">addFilter</span><span class=\"p\">(</span><span class=\"n\">ContentFilter</span><span class=\"p\">())</span>\n</pre></div>"], "codes_text": ["class PoliteLogFormatter(logformatter.LogFormatter):\n    def dropped(self, item, exception, response, spider):\n        return {\n            'level': logging.INFO, # lowering the level from logging.WARNING\n            'msg': \"Dropped: %(exception)s\" + os.linesep + \"%(item)s\",\n            'args': {\n                'exception': exception,\n                'item': item,\n            }\n        }\n", "2016-12-16 22:00:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring\nresponse <500 https://quotes.toscrape.com/page/1-34/>: HTTP status code\nis not handled or not allowed\n", "import logging\nimport scrapy\n\n\nclass MySpider(scrapy.Spider):\n    # ...\n    def __init__(self, *args, **kwargs):\n        logger = logging.getLogger('scrapy.spidermiddlewares.httperror')\n        logger.setLevel(logging.WARNING)\n        super().__init__(*args, **kwargs)\n", "import logging\nimport re\n\nclass ContentFilter(logging.Filter):\n    def filter(self, record):\n        match = re.search(r'\\d{3} [Ee]rror, retrying', record.message)\n        if match:\n            return False\n", "import logging\nimport scrapy\n\nclass MySpider(scrapy.Spider):\n    # ...\n    def __init__(self, *args, **kwargs):\n        for handler in logging.root.handlers:\n            handler.addFilter(ContentFilter())\n", "import logging\nimport scrapy\n\nclass MySpider(scrapy.Spider):\n    # ...\n    def __init__(self, *args, **kwargs):\n        logger = logging.getLogger('my_logger')\n        logger.addFilter(ContentFilter())\n"], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/logging.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Logging settings", "header_href": "#logging-settings", "codes": [], "codes_text": [], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/logging.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Command-line options", "header_href": "#command-line-options", "codes": [], "codes_text": [], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/logging.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Custom Log Formats", "header_href": "#custom-log-formats", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">PoliteLogFormatter</span><span class=\"p\">(</span><span class=\"n\">logformatter</span><span class=\"o\">.</span><span class=\"n\">LogFormatter</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">dropped</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">exception</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"p\">{</span>\n            <span class=\"s1\">'level'</span><span class=\"p\">:</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">INFO</span><span class=\"p\">,</span> <span class=\"c1\"># lowering the level from logging.WARNING</span>\n            <span class=\"s1\">'msg'</span><span class=\"p\">:</span> <span class=\"s2\">\"Dropped: </span><span class=\"si\">%(exception)s</span><span class=\"s2\">\"</span> <span class=\"o\">+</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">linesep</span> <span class=\"o\">+</span> <span class=\"s2\">\"</span><span class=\"si\">%(item)s</span><span class=\"s2\">\"</span><span class=\"p\">,</span>\n            <span class=\"s1\">'args'</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'exception'</span><span class=\"p\">:</span> <span class=\"n\">exception</span><span class=\"p\">,</span>\n                <span class=\"s1\">'item'</span><span class=\"p\">:</span> <span class=\"n\">item</span><span class=\"p\">,</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["class PoliteLogFormatter(logformatter.LogFormatter):\n    def dropped(self, item, exception, response, spider):\n        return {\n            'level': logging.INFO, # lowering the level from logging.WARNING\n            'msg': \"Dropped: %(exception)s\" + os.linesep + \"%(item)s\",\n            'args': {\n                'exception': exception,\n                'item': item,\n            }\n        }\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/logging.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Advanced customization", "header_href": "#advanced-customization", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">22</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">06</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">spidermiddlewares</span><span class=\"o\">.</span><span class=\"n\">httperror</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Ignoring</span>\n<span class=\"n\">response</span> <span class=\"o\">&lt;</span><span class=\"mi\">500</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">quotes</span><span class=\"o\">.</span><span class=\"n\">toscrape</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">/</span><span class=\"mi\">1</span><span class=\"o\">-</span><span class=\"mi\">34</span><span class=\"o\">/&gt;</span><span class=\"p\">:</span> <span class=\"n\">HTTP</span> <span class=\"n\">status</span> <span class=\"n\">code</span>\n<span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"n\">handled</span> <span class=\"ow\">or</span> <span class=\"ow\">not</span> <span class=\"n\">allowed</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># ...</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"s1\">'scrapy.spidermiddlewares.httperror'</span><span class=\"p\">)</span>\n        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">setLevel</span><span class=\"p\">(</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">WARNING</span><span class=\"p\">)</span>\n        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">import</span> <span class=\"nn\">re</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">ContentFilter</span><span class=\"p\">(</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">Filter</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">filter</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">record</span><span class=\"p\">):</span>\n        <span class=\"n\">match</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'\\d</span><span class=\"si\">{3}</span><span class=\"s1\"> [Ee]rror, retrying'</span><span class=\"p\">,</span> <span class=\"n\">record</span><span class=\"o\">.</span><span class=\"n\">message</span><span class=\"p\">)</span>\n        <span class=\"k\">if</span> <span class=\"n\">match</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"kc\">False</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># ...</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">handler</span> <span class=\"ow\">in</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">root</span><span class=\"o\">.</span><span class=\"n\">handlers</span><span class=\"p\">:</span>\n            <span class=\"n\">handler</span><span class=\"o\">.</span><span class=\"n\">addFilter</span><span class=\"p\">(</span><span class=\"n\">ContentFilter</span><span class=\"p\">())</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># ...</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"s1\">'my_logger'</span><span class=\"p\">)</span>\n        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">addFilter</span><span class=\"p\">(</span><span class=\"n\">ContentFilter</span><span class=\"p\">())</span>\n</pre></div>"], "codes_text": ["2016-12-16 22:00:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring\nresponse <500 https://quotes.toscrape.com/page/1-34/>: HTTP status code\nis not handled or not allowed\n", "import logging\nimport scrapy\n\n\nclass MySpider(scrapy.Spider):\n    # ...\n    def __init__(self, *args, **kwargs):\n        logger = logging.getLogger('scrapy.spidermiddlewares.httperror')\n        logger.setLevel(logging.WARNING)\n        super().__init__(*args, **kwargs)\n", "import logging\nimport re\n\nclass ContentFilter(logging.Filter):\n    def filter(self, record):\n        match = re.search(r'\\d{3} [Ee]rror, retrying', record.message)\n        if match:\n            return False\n", "import logging\nimport scrapy\n\nclass MySpider(scrapy.Spider):\n    # ...\n    def __init__(self, *args, **kwargs):\n        for handler in logging.root.handlers:\n            handler.addFilter(ContentFilter())\n", "import logging\nimport scrapy\n\nclass MySpider(scrapy.Spider):\n    # ...\n    def __init__(self, *args, **kwargs):\n        logger = logging.getLogger('my_logger')\n        logger.addFilter(ContentFilter())\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/logging.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "scrapy.utils.log module", "header_href": "#module-scrapy.utils.log", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">basicConfig</span><span class=\"p\">(</span>\n    <span class=\"n\">filename</span><span class=\"o\">=</span><span class=\"s1\">'log.txt'</span><span class=\"p\">,</span>\n    <span class=\"nb\">format</span><span class=\"o\">=</span><span class=\"s1\">'</span><span class=\"si\">%(levelname)s</span><span class=\"s1\">: </span><span class=\"si\">%(message)s</span><span class=\"s1\">'</span><span class=\"p\">,</span>\n    <span class=\"n\">level</span><span class=\"o\">=</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">INFO</span>\n<span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import logging\n\nlogging.basicConfig(\n    filename='log.txt',\n    format='%(levelname)s: %(message)s',\n    level=logging.INFO\n)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/stats.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Stats Collection", "header_href": "#stats-collection", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">ExtensionThatAccessStats</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">stats</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">stats</span> <span class=\"o\">=</span> <span class=\"n\">stats</span>\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">from_crawler</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">crawler</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"bp\">cls</span><span class=\"p\">(</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">stats</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">stats</span><span class=\"o\">.</span><span class=\"n\">set_value</span><span class=\"p\">(</span><span class=\"s1\">'hostname'</span><span class=\"p\">,</span> <span class=\"n\">socket</span><span class=\"o\">.</span><span class=\"n\">gethostname</span><span class=\"p\">())</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">stats</span><span class=\"o\">.</span><span class=\"n\">inc_value</span><span class=\"p\">(</span><span class=\"s1\">'custom_count'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">stats</span><span class=\"o\">.</span><span class=\"n\">max_value</span><span class=\"p\">(</span><span class=\"s1\">'max_items_scraped'</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">stats</span><span class=\"o\">.</span><span class=\"n\">min_value</span><span class=\"p\">(</span><span class=\"s1\">'min_free_memory_percent'</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">stats</span><span class=\"o\">.</span><span class=\"n\">get_value</span><span class=\"p\">(</span><span class=\"s1\">'custom_count'</span><span class=\"p\">)</span>\n<span class=\"go\">1</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">stats</span><span class=\"o\">.</span><span class=\"n\">get_stats</span><span class=\"p\">()</span>\n<span class=\"go\">{'custom_count': 1, 'start_time': datetime.datetime(2009, 7, 14, 21, 47, 28, 977139)}</span>\n</pre></div>"], "codes_text": ["class ExtensionThatAccessStats:\n\n    def __init__(self, stats):\n        self.stats = stats\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        return cls(crawler.stats)\n", "stats.set_value('hostname', socket.gethostname())\n", "stats.inc_value('custom_count')\n", "stats.max_value('max_items_scraped', value)\n", "stats.min_value('min_free_memory_percent', value)\n", ">>> stats.get_value('custom_count')\n1\n", ">>> stats.get_stats()\n{'custom_count': 1, 'start_time': datetime.datetime(2009, 7, 14, 21, 47, 28, 977139)}\n"], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/stats.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Common Stats Collector uses", "header_href": "#common-stats-collector-uses", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">ExtensionThatAccessStats</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">stats</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">stats</span> <span class=\"o\">=</span> <span class=\"n\">stats</span>\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">from_crawler</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">crawler</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"bp\">cls</span><span class=\"p\">(</span><span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">stats</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">stats</span><span class=\"o\">.</span><span class=\"n\">set_value</span><span class=\"p\">(</span><span class=\"s1\">'hostname'</span><span class=\"p\">,</span> <span class=\"n\">socket</span><span class=\"o\">.</span><span class=\"n\">gethostname</span><span class=\"p\">())</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">stats</span><span class=\"o\">.</span><span class=\"n\">inc_value</span><span class=\"p\">(</span><span class=\"s1\">'custom_count'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">stats</span><span class=\"o\">.</span><span class=\"n\">max_value</span><span class=\"p\">(</span><span class=\"s1\">'max_items_scraped'</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">stats</span><span class=\"o\">.</span><span class=\"n\">min_value</span><span class=\"p\">(</span><span class=\"s1\">'min_free_memory_percent'</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">stats</span><span class=\"o\">.</span><span class=\"n\">get_value</span><span class=\"p\">(</span><span class=\"s1\">'custom_count'</span><span class=\"p\">)</span>\n<span class=\"go\">1</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">stats</span><span class=\"o\">.</span><span class=\"n\">get_stats</span><span class=\"p\">()</span>\n<span class=\"go\">{'custom_count': 1, 'start_time': datetime.datetime(2009, 7, 14, 21, 47, 28, 977139)}</span>\n</pre></div>"], "codes_text": ["class ExtensionThatAccessStats:\n\n    def __init__(self, stats):\n        self.stats = stats\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        return cls(crawler.stats)\n", "stats.set_value('hostname', socket.gethostname())\n", "stats.inc_value('custom_count')\n", "stats.max_value('max_items_scraped', value)\n", "stats.min_value('min_free_memory_percent', value)\n", ">>> stats.get_value('custom_count')\n1\n", ">>> stats.get_stats()\n{'custom_count': 1, 'start_time': datetime.datetime(2009, 7, 14, 21, 47, 28, 977139)}\n"], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/stats.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Available Stats Collectors", "header_href": "#available-stats-collectors", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/stats.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MemoryStatsCollector", "header_href": "#memorystatscollector", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/stats.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DummyStatsCollector", "header_href": "#dummystatscollector", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/email.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Sending e-mail", "header_href": "#module-scrapy.mail", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.mail</span> <span class=\"kn\">import</span> <span class=\"n\">MailSender</span>\n<span class=\"n\">mailer</span> <span class=\"o\">=</span> <span class=\"n\">MailSender</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">mailer</span> <span class=\"o\">=</span> <span class=\"n\">MailSender</span><span class=\"o\">.</span><span class=\"n\">from_settings</span><span class=\"p\">(</span><span class=\"n\">settings</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">mailer</span><span class=\"o\">.</span><span class=\"n\">send</span><span class=\"p\">(</span><span class=\"n\">to</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"someone@example.com\"</span><span class=\"p\">],</span> <span class=\"n\">subject</span><span class=\"o\">=</span><span class=\"s2\">\"Some subject\"</span><span class=\"p\">,</span> <span class=\"n\">body</span><span class=\"o\">=</span><span class=\"s2\">\"Some body\"</span><span class=\"p\">,</span> <span class=\"n\">cc</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"another@example.com\"</span><span class=\"p\">])</span>\n</pre></div>"], "codes_text": ["from scrapy.mail import MailSender\nmailer = MailSender()\n", "mailer = MailSender.from_settings(settings)\n", "mailer.send(to=[\"someone@example.com\"], subject=\"Some subject\", body=\"Some body\", cc=[\"another@example.com\"])\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/email.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Quick example", "header_href": "#quick-example", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.mail</span> <span class=\"kn\">import</span> <span class=\"n\">MailSender</span>\n<span class=\"n\">mailer</span> <span class=\"o\">=</span> <span class=\"n\">MailSender</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">mailer</span> <span class=\"o\">=</span> <span class=\"n\">MailSender</span><span class=\"o\">.</span><span class=\"n\">from_settings</span><span class=\"p\">(</span><span class=\"n\">settings</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">mailer</span><span class=\"o\">.</span><span class=\"n\">send</span><span class=\"p\">(</span><span class=\"n\">to</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"someone@example.com\"</span><span class=\"p\">],</span> <span class=\"n\">subject</span><span class=\"o\">=</span><span class=\"s2\">\"Some subject\"</span><span class=\"p\">,</span> <span class=\"n\">body</span><span class=\"o\">=</span><span class=\"s2\">\"Some body\"</span><span class=\"p\">,</span> <span class=\"n\">cc</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"another@example.com\"</span><span class=\"p\">])</span>\n</pre></div>"], "codes_text": ["from scrapy.mail import MailSender\nmailer = MailSender()\n", "mailer = MailSender.from_settings(settings)\n", "mailer.send(to=[\"someone@example.com\"], subject=\"Some subject\", body=\"Some body\", cc=[\"another@example.com\"])\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/email.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "MailSender class reference", "header_href": "#mailsender-class-reference", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/email.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Mail settings", "header_href": "#mail-settings", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/email.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MAIL_FROM", "header_href": "#mail-from", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/email.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MAIL_HOST", "header_href": "#mail-host", "codes": [], "codes_text": [], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/email.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MAIL_PORT", "header_href": "#mail-port", "codes": [], "codes_text": [], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/email.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MAIL_USER", "header_href": "#mail-user", "codes": [], "codes_text": [], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/email.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MAIL_PASS", "header_href": "#mail-pass", "codes": [], "codes_text": [], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/topics/email.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MAIL_TLS", "header_href": "#mail-tls", "codes": [], "codes_text": [], "index": 10}
{"url": "https://docs.scrapy.org/en/latest/topics/email.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MAIL_SSL", "header_href": "#mail-ssl", "codes": [], "codes_text": [], "index": 11}
{"url": "https://docs.scrapy.org/en/latest/topics/telnetconsole.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Telnet Console", "header_href": "#telnet-console", "codes": ["<div class=\"highlight\"><pre><span></span>telnet localhost 6023\nTrying localhost...\nConnected to localhost.\nEscape character is '^]'.\nUsername:\nPassword:\n&gt;&gt;&gt;\n</pre></div>", "<div class=\"highlight\"><pre><span></span>2018-10-16 14:35:21 [scrapy.extensions.telnet] INFO: Telnet Password: 16f92501e8a59326\n</pre></div>", "<div class=\"highlight\"><pre><span></span>telnet localhost 6023\n&gt;&gt;&gt; est()\nExecution engine status\n\ntime()-engine.start_time                        : 8.62972998619\nlen(engine.downloader.active)                   : 16\nengine.scraper.is_idle()                        : False\nengine.spider.name                              : followall\nengine.spider_is_idle()                         : False\nengine.slot.closing                             : False\nlen(engine.slot.inprogress)                     : 16\nlen(engine.slot.scheduler.dqs or [])            : 0\nlen(engine.slot.scheduler.mqs)                  : 92\nlen(engine.scraper.slot.queue)                  : 0\nlen(engine.scraper.slot.active)                 : 0\nengine.scraper.slot.active_size                 : 0\nengine.scraper.slot.itemproc_size               : 0\nengine.scraper.slot.needs_backout()             : False\n</pre></div>", "<div class=\"highlight\"><pre><span></span>telnet localhost 6023\n&gt;&gt;&gt; engine.pause()\n&gt;&gt;&gt;\n</pre></div>", "<div class=\"highlight\"><pre><span></span>telnet localhost 6023\n&gt;&gt;&gt; engine.unpause()\n&gt;&gt;&gt;\n</pre></div>", "<div class=\"highlight\"><pre><span></span>telnet localhost 6023\n&gt;&gt;&gt; engine.stop()\nConnection closed by foreign host.\n</pre></div>"], "codes_text": ["telnet localhost 6023\nTrying localhost...\nConnected to localhost.\nEscape character is '^]'.\nUsername:\nPassword:\n>>>\n", "2018-10-16 14:35:21 [scrapy.extensions.telnet] INFO: Telnet Password: 16f92501e8a59326\n", "telnet localhost 6023\n>>> est()\nExecution engine status\n\ntime()-engine.start_time                        : 8.62972998619\nlen(engine.downloader.active)                   : 16\nengine.scraper.is_idle()                        : False\nengine.spider.name                              : followall\nengine.spider_is_idle()                         : False\nengine.slot.closing                             : False\nlen(engine.slot.inprogress)                     : 16\nlen(engine.slot.scheduler.dqs or [])            : 0\nlen(engine.slot.scheduler.mqs)                  : 92\nlen(engine.scraper.slot.queue)                  : 0\nlen(engine.scraper.slot.active)                 : 0\nengine.scraper.slot.active_size                 : 0\nengine.scraper.slot.itemproc_size               : 0\nengine.scraper.slot.needs_backout()             : False\n", "telnet localhost 6023\n>>> engine.pause()\n>>>\n", "telnet localhost 6023\n>>> engine.unpause()\n>>>\n", "telnet localhost 6023\n>>> engine.stop()\nConnection closed by foreign host.\n"], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/telnetconsole.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "How to access the telnet console", "header_href": "#how-to-access-the-telnet-console", "codes": ["<div class=\"highlight\"><pre><span></span>telnet localhost 6023\nTrying localhost...\nConnected to localhost.\nEscape character is '^]'.\nUsername:\nPassword:\n&gt;&gt;&gt;\n</pre></div>", "<div class=\"highlight\"><pre><span></span>2018-10-16 14:35:21 [scrapy.extensions.telnet] INFO: Telnet Password: 16f92501e8a59326\n</pre></div>"], "codes_text": ["telnet localhost 6023\nTrying localhost...\nConnected to localhost.\nEscape character is '^]'.\nUsername:\nPassword:\n>>>\n", "2018-10-16 14:35:21 [scrapy.extensions.telnet] INFO: Telnet Password: 16f92501e8a59326\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/telnetconsole.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Available variables in the telnet console", "header_href": "#available-variables-in-the-telnet-console", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/telnetconsole.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Telnet console usage examples", "header_href": "#telnet-console-usage-examples", "codes": ["<div class=\"highlight\"><pre><span></span>telnet localhost 6023\n&gt;&gt;&gt; est()\nExecution engine status\n\ntime()-engine.start_time                        : 8.62972998619\nlen(engine.downloader.active)                   : 16\nengine.scraper.is_idle()                        : False\nengine.spider.name                              : followall\nengine.spider_is_idle()                         : False\nengine.slot.closing                             : False\nlen(engine.slot.inprogress)                     : 16\nlen(engine.slot.scheduler.dqs or [])            : 0\nlen(engine.slot.scheduler.mqs)                  : 92\nlen(engine.scraper.slot.queue)                  : 0\nlen(engine.scraper.slot.active)                 : 0\nengine.scraper.slot.active_size                 : 0\nengine.scraper.slot.itemproc_size               : 0\nengine.scraper.slot.needs_backout()             : False\n</pre></div>", "<div class=\"highlight\"><pre><span></span>telnet localhost 6023\n&gt;&gt;&gt; engine.pause()\n&gt;&gt;&gt;\n</pre></div>", "<div class=\"highlight\"><pre><span></span>telnet localhost 6023\n&gt;&gt;&gt; engine.unpause()\n&gt;&gt;&gt;\n</pre></div>", "<div class=\"highlight\"><pre><span></span>telnet localhost 6023\n&gt;&gt;&gt; engine.stop()\nConnection closed by foreign host.\n</pre></div>"], "codes_text": ["telnet localhost 6023\n>>> est()\nExecution engine status\n\ntime()-engine.start_time                        : 8.62972998619\nlen(engine.downloader.active)                   : 16\nengine.scraper.is_idle()                        : False\nengine.spider.name                              : followall\nengine.spider_is_idle()                         : False\nengine.slot.closing                             : False\nlen(engine.slot.inprogress)                     : 16\nlen(engine.slot.scheduler.dqs or [])            : 0\nlen(engine.slot.scheduler.mqs)                  : 92\nlen(engine.scraper.slot.queue)                  : 0\nlen(engine.scraper.slot.active)                 : 0\nengine.scraper.slot.active_size                 : 0\nengine.scraper.slot.itemproc_size               : 0\nengine.scraper.slot.needs_backout()             : False\n", "telnet localhost 6023\n>>> engine.pause()\n>>>\n", "telnet localhost 6023\n>>> engine.unpause()\n>>>\n", "telnet localhost 6023\n>>> engine.stop()\nConnection closed by foreign host.\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/telnetconsole.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "View engine status", "header_href": "#view-engine-status", "codes": ["<div class=\"highlight\"><pre><span></span>telnet localhost 6023\n&gt;&gt;&gt; est()\nExecution engine status\n\ntime()-engine.start_time                        : 8.62972998619\nlen(engine.downloader.active)                   : 16\nengine.scraper.is_idle()                        : False\nengine.spider.name                              : followall\nengine.spider_is_idle()                         : False\nengine.slot.closing                             : False\nlen(engine.slot.inprogress)                     : 16\nlen(engine.slot.scheduler.dqs or [])            : 0\nlen(engine.slot.scheduler.mqs)                  : 92\nlen(engine.scraper.slot.queue)                  : 0\nlen(engine.scraper.slot.active)                 : 0\nengine.scraper.slot.active_size                 : 0\nengine.scraper.slot.itemproc_size               : 0\nengine.scraper.slot.needs_backout()             : False\n</pre></div>"], "codes_text": ["telnet localhost 6023\n>>> est()\nExecution engine status\n\ntime()-engine.start_time                        : 8.62972998619\nlen(engine.downloader.active)                   : 16\nengine.scraper.is_idle()                        : False\nengine.spider.name                              : followall\nengine.spider_is_idle()                         : False\nengine.slot.closing                             : False\nlen(engine.slot.inprogress)                     : 16\nlen(engine.slot.scheduler.dqs or [])            : 0\nlen(engine.slot.scheduler.mqs)                  : 92\nlen(engine.scraper.slot.queue)                  : 0\nlen(engine.scraper.slot.active)                 : 0\nengine.scraper.slot.active_size                 : 0\nengine.scraper.slot.itemproc_size               : 0\nengine.scraper.slot.needs_backout()             : False\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/telnetconsole.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Pause, resume and stop the Scrapy engine", "header_href": "#pause-resume-and-stop-the-scrapy-engine", "codes": ["<div class=\"highlight\"><pre><span></span>telnet localhost 6023\n&gt;&gt;&gt; engine.pause()\n&gt;&gt;&gt;\n</pre></div>", "<div class=\"highlight\"><pre><span></span>telnet localhost 6023\n&gt;&gt;&gt; engine.unpause()\n&gt;&gt;&gt;\n</pre></div>", "<div class=\"highlight\"><pre><span></span>telnet localhost 6023\n&gt;&gt;&gt; engine.stop()\nConnection closed by foreign host.\n</pre></div>"], "codes_text": ["telnet localhost 6023\n>>> engine.pause()\n>>>\n", "telnet localhost 6023\n>>> engine.unpause()\n>>>\n", "telnet localhost 6023\n>>> engine.stop()\nConnection closed by foreign host.\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/telnetconsole.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Telnet Console signals", "header_href": "#telnet-console-signals", "codes": [], "codes_text": [], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/telnetconsole.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Telnet settings", "header_href": "#telnet-settings", "codes": [], "codes_text": [], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/telnetconsole.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "TELNETCONSOLE_PORT", "header_href": "#telnetconsole-port", "codes": [], "codes_text": [], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/topics/telnetconsole.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "TELNETCONSOLE_HOST", "header_href": "#telnetconsole-host", "codes": [], "codes_text": [], "index": 10}
{"url": "https://docs.scrapy.org/en/latest/topics/telnetconsole.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "TELNETCONSOLE_USERNAME", "header_href": "#telnetconsole-username", "codes": [], "codes_text": [], "index": 11}
{"url": "https://docs.scrapy.org/en/latest/topics/telnetconsole.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "TELNETCONSOLE_PASSWORD", "header_href": "#telnetconsole-password", "codes": [], "codes_text": [], "index": 12}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Frequently Asked Questions", "header_href": "#frequently-asked-questions", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">bs4</span> <span class=\"kn\">import</span> <span class=\"n\">BeautifulSoup</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">ExampleSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"example\"</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"example.com\"</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">(</span>\n        <span class=\"s1\">'http://www.example.com/'</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"c1\"># use lxml to get decent HTML parsing speed</span>\n        <span class=\"n\">soup</span> <span class=\"o\">=</span> <span class=\"n\">BeautifulSoup</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"s1\">'lxml'</span><span class=\"p\">)</span>\n        <span class=\"k\">yield</span> <span class=\"p\">{</span>\n            <span class=\"s2\">\"url\"</span><span class=\"p\">:</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">,</span>\n            <span class=\"s2\">\"title\"</span><span class=\"p\">:</span> <span class=\"n\">soup</span><span class=\"o\">.</span><span class=\"n\">h1</span><span class=\"o\">.</span><span class=\"n\">string</span>\n        <span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">DEPTH_PRIORITY</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>\n<span class=\"n\">SCHEDULER_DISK_QUEUE</span> <span class=\"o\">=</span> <span class=\"s1\">'scrapy.squeues.PickleFifoDiskQueue'</span>\n<span class=\"n\">SCHEDULER_MEMORY_QUEUE</span> <span class=\"o\">=</span> <span class=\"s1\">'scrapy.squeues.FifoMemoryQueue'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">SPIDER_MIDDLEWARES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n    <span class=\"s1\">'myproject.middlewares.CustomOffsiteMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">500</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">runspider</span> <span class=\"n\">my_spider</span><span class=\"o\">.</span><span class=\"n\">py</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n\n    <span class=\"n\">download_delay</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>\n\n    <span class=\"c1\"># [ ... rest of the spider code ... ]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">myspider</span> <span class=\"o\">-</span><span class=\"n\">O</span> <span class=\"n\">items</span><span class=\"o\">.</span><span class=\"n\">json</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">myspider</span> <span class=\"o\">-</span><span class=\"n\">O</span> <span class=\"n\">items</span><span class=\"o\">.</span><span class=\"n\">csv</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">myspider</span> <span class=\"o\">-</span><span class=\"n\">O</span> <span class=\"n\">items</span><span class=\"o\">.</span><span class=\"n\">xml</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">copy</span> <span class=\"kn\">import</span> <span class=\"n\">deepcopy</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">is_item</span><span class=\"p\">,</span> <span class=\"n\">ItemAdapter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MultiplyItemsMiddleware</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_spider_output</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">result</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">item</span> <span class=\"ow\">in</span> <span class=\"n\">result</span><span class=\"p\">:</span>\n            <span class=\"k\">if</span> <span class=\"n\">is_item</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">):</span>\n                <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n                <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'multiply_by'</span><span class=\"p\">]):</span>\n                    <span class=\"k\">yield</span> <span class=\"n\">deepcopy</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["from bs4 import BeautifulSoup\nimport scrapy\n\n\nclass ExampleSpider(scrapy.Spider):\n    name = \"example\"\n    allowed_domains = [\"example.com\"]\n    start_urls = (\n        'http://www.example.com/',\n    )\n\n    def parse(self, response):\n        # use lxml to get decent HTML parsing speed\n        soup = BeautifulSoup(response.text, 'lxml')\n        yield {\n            \"url\": response.url,\n            \"title\": soup.h1.string\n        }\n", "DEPTH_PRIORITY = 1\nSCHEDULER_DISK_QUEUE = 'scrapy.squeues.PickleFifoDiskQueue'\nSCHEDULER_MEMORY_QUEUE = 'scrapy.squeues.FifoMemoryQueue'\n", "SPIDER_MIDDLEWARES = {\n    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': None,\n    'myproject.middlewares.CustomOffsiteMiddleware': 500,\n}\n", "scrapy runspider my_spider.py\n", "class MySpider(CrawlSpider):\n\n    name = 'myspider'\n\n    download_delay = 2\n\n    # [ ... rest of the spider code ... ]\n", "scrapy crawl myspider -O items.json\n", "scrapy crawl myspider -O items.csv\n", "scrapy crawl myspider -O items.xml\n", "from copy import deepcopy\n\nfrom itemadapter import is_item, ItemAdapter\n\nclass MultiplyItemsMiddleware:\n\n    def process_spider_output(self, response, result, spider):\n        for item in result:\n            if is_item(item):\n                adapter = ItemAdapter(item)\n                for _ in range(adapter['multiply_by']):\n                    yield deepcopy(item)\n"], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "How does Scrapy compare to BeautifulSoup or lxml?", "header_href": "#how-does-scrapy-compare-to-beautifulsoup-or-lxml", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Can I use Scrapy with BeautifulSoup?", "header_href": "#can-i-use-scrapy-with-beautifulsoup", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">bs4</span> <span class=\"kn\">import</span> <span class=\"n\">BeautifulSoup</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">ExampleSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"example\"</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"example.com\"</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">(</span>\n        <span class=\"s1\">'http://www.example.com/'</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"c1\"># use lxml to get decent HTML parsing speed</span>\n        <span class=\"n\">soup</span> <span class=\"o\">=</span> <span class=\"n\">BeautifulSoup</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"s1\">'lxml'</span><span class=\"p\">)</span>\n        <span class=\"k\">yield</span> <span class=\"p\">{</span>\n            <span class=\"s2\">\"url\"</span><span class=\"p\">:</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">,</span>\n            <span class=\"s2\">\"title\"</span><span class=\"p\">:</span> <span class=\"n\">soup</span><span class=\"o\">.</span><span class=\"n\">h1</span><span class=\"o\">.</span><span class=\"n\">string</span>\n        <span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["from bs4 import BeautifulSoup\nimport scrapy\n\n\nclass ExampleSpider(scrapy.Spider):\n    name = \"example\"\n    allowed_domains = [\"example.com\"]\n    start_urls = (\n        'http://www.example.com/',\n    )\n\n    def parse(self, response):\n        # use lxml to get decent HTML parsing speed\n        soup = BeautifulSoup(response.text, 'lxml')\n        yield {\n            \"url\": response.url,\n            \"title\": soup.h1.string\n        }\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Did Scrapy “steal” X from Django?", "header_href": "#did-scrapy-steal-x-from-django", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Does Scrapy work with HTTP proxies?", "header_href": "#does-scrapy-work-with-http-proxies", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "How can I scrape an item with attributes in different pages?", "header_href": "#how-can-i-scrape-an-item-with-attributes-in-different-pages", "codes": [], "codes_text": [], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "How can I simulate a user login in my spider?", "header_href": "#how-can-i-simulate-a-user-login-in-my-spider", "codes": [], "codes_text": [], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Does Scrapy crawl in breadth-first or depth-first order?", "header_href": "#does-scrapy-crawl-in-breadth-first-or-depth-first-order", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">DEPTH_PRIORITY</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>\n<span class=\"n\">SCHEDULER_DISK_QUEUE</span> <span class=\"o\">=</span> <span class=\"s1\">'scrapy.squeues.PickleFifoDiskQueue'</span>\n<span class=\"n\">SCHEDULER_MEMORY_QUEUE</span> <span class=\"o\">=</span> <span class=\"s1\">'scrapy.squeues.FifoMemoryQueue'</span>\n</pre></div>"], "codes_text": ["DEPTH_PRIORITY = 1\nSCHEDULER_DISK_QUEUE = 'scrapy.squeues.PickleFifoDiskQueue'\nSCHEDULER_MEMORY_QUEUE = 'scrapy.squeues.FifoMemoryQueue'\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "My Scrapy crawler has memory leaks. What can I do?", "header_href": "#my-scrapy-crawler-has-memory-leaks-what-can-i-do", "codes": [], "codes_text": [], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "How can I make Scrapy consume less memory?", "header_href": "#how-can-i-make-scrapy-consume-less-memory", "codes": [], "codes_text": [], "index": 10}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "How can I prevent memory errors due to many allowed domains?", "header_href": "#how-can-i-prevent-memory-errors-due-to-many-allowed-domains", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">SPIDER_MIDDLEWARES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n    <span class=\"s1\">'myproject.middlewares.CustomOffsiteMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">500</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["SPIDER_MIDDLEWARES = {\n    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': None,\n    'myproject.middlewares.CustomOffsiteMiddleware': 500,\n}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Can I use Basic HTTP Authentication in my spiders?", "header_href": "#can-i-use-basic-http-authentication-in-my-spiders", "codes": [], "codes_text": [], "index": 12}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Why does Scrapy download pages in English instead of my native language?", "header_href": "#why-does-scrapy-download-pages-in-english-instead-of-my-native-language", "codes": [], "codes_text": [], "index": 13}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Where can I find some example Scrapy projects?", "header_href": "#where-can-i-find-some-example-scrapy-projects", "codes": [], "codes_text": [], "index": 14}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Can I run a spider without creating a project?", "header_href": "#can-i-run-a-spider-without-creating-a-project", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">runspider</span> <span class=\"n\">my_spider</span><span class=\"o\">.</span><span class=\"n\">py</span>\n</pre></div>"], "codes_text": ["scrapy runspider my_spider.py\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "I get “Filtered offsite request” messages. How can I fix them?", "header_href": "#i-get-filtered-offsite-request-messages-how-can-i-fix-them", "codes": [], "codes_text": [], "index": 16}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "What is the recommended way to deploy a Scrapy crawler in production?", "header_href": "#what-is-the-recommended-way-to-deploy-a-scrapy-crawler-in-production", "codes": [], "codes_text": [], "index": 17}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Can I use JSON for large exports?", "header_href": "#can-i-use-json-for-large-exports", "codes": [], "codes_text": [], "index": 18}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Can I return (Twisted) deferreds from signal handlers?", "header_href": "#can-i-return-twisted-deferreds-from-signal-handlers", "codes": [], "codes_text": [], "index": 19}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "What does the response status code 999 means?", "header_href": "#what-does-the-response-status-code-999-means", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n\n    <span class=\"n\">download_delay</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>\n\n    <span class=\"c1\"># [ ... rest of the spider code ... ]</span>\n</pre></div>"], "codes_text": ["class MySpider(CrawlSpider):\n\n    name = 'myspider'\n\n    download_delay = 2\n\n    # [ ... rest of the spider code ... ]\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Can I call pdb.set_trace() from my spiders to debug them?", "header_href": "#can-i-call-pdb-set-trace-from-my-spiders-to-debug-them", "codes": [], "codes_text": [], "index": 21}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Simplest way to dump all my scraped items into a JSON/CSV/XML file?", "header_href": "#simplest-way-to-dump-all-my-scraped-items-into-a-json-csv-xml-file", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">myspider</span> <span class=\"o\">-</span><span class=\"n\">O</span> <span class=\"n\">items</span><span class=\"o\">.</span><span class=\"n\">json</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">myspider</span> <span class=\"o\">-</span><span class=\"n\">O</span> <span class=\"n\">items</span><span class=\"o\">.</span><span class=\"n\">csv</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">myspider</span> <span class=\"o\">-</span><span class=\"n\">O</span> <span class=\"n\">items</span><span class=\"o\">.</span><span class=\"n\">xml</span>\n</pre></div>"], "codes_text": ["scrapy crawl myspider -O items.json\n", "scrapy crawl myspider -O items.csv\n", "scrapy crawl myspider -O items.xml\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "What’s this huge cryptic __VIEWSTATE parameter used in some forms?", "header_href": "#what-s-this-huge-cryptic-viewstate-parameter-used-in-some-forms", "codes": [], "codes_text": [], "index": 23}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "What’s the best way to parse big XML/CSV data feeds?", "header_href": "#what-s-the-best-way-to-parse-big-xml-csv-data-feeds", "codes": [], "codes_text": [], "index": 24}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Does Scrapy manage cookies automatically?", "header_href": "#does-scrapy-manage-cookies-automatically", "codes": [], "codes_text": [], "index": 25}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "How can I see the cookies being sent and received from Scrapy?", "header_href": "#how-can-i-see-the-cookies-being-sent-and-received-from-scrapy", "codes": [], "codes_text": [], "index": 26}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "How can I instruct a spider to stop itself?", "header_href": "#how-can-i-instruct-a-spider-to-stop-itself", "codes": [], "codes_text": [], "index": 27}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "How can I prevent my Scrapy bot from getting banned?", "header_href": "#how-can-i-prevent-my-scrapy-bot-from-getting-banned", "codes": [], "codes_text": [], "index": 28}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Should I use spider arguments or settings to configure my spider?", "header_href": "#should-i-use-spider-arguments-or-settings-to-configure-my-spider", "codes": [], "codes_text": [], "index": 29}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "I’m scraping a XML document and my XPath selector doesn’t return any items", "header_href": "#i-m-scraping-a-xml-document-and-my-xpath-selector-doesn-t-return-any-items", "codes": [], "codes_text": [], "index": 30}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "How to split an item into multiple items in an item pipeline?", "header_href": "#how-to-split-an-item-into-multiple-items-in-an-item-pipeline", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">copy</span> <span class=\"kn\">import</span> <span class=\"n\">deepcopy</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">is_item</span><span class=\"p\">,</span> <span class=\"n\">ItemAdapter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MultiplyItemsMiddleware</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_spider_output</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">result</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">item</span> <span class=\"ow\">in</span> <span class=\"n\">result</span><span class=\"p\">:</span>\n            <span class=\"k\">if</span> <span class=\"n\">is_item</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">):</span>\n                <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n                <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'multiply_by'</span><span class=\"p\">]):</span>\n                    <span class=\"k\">yield</span> <span class=\"n\">deepcopy</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["from copy import deepcopy\n\nfrom itemadapter import is_item, ItemAdapter\n\nclass MultiplyItemsMiddleware:\n\n    def process_spider_output(self, response, result, spider):\n        for item in result:\n            if is_item(item):\n                adapter = ItemAdapter(item)\n                for _ in range(adapter['multiply_by']):\n                    yield deepcopy(item)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Does Scrapy support IPv6 addresses?", "header_href": "#does-scrapy-support-ipv6-addresses", "codes": [], "codes_text": [], "index": 32}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "How to deal with <class 'ValueError'>: filedescriptor out of range in select() exceptions?", "header_href": "#how-to-deal-with-class-valueerror-filedescriptor-out-of-range-in-select-exceptions", "codes": [], "codes_text": [], "index": 33}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "How can I cancel the download of a given response?", "header_href": "#how-can-i-cancel-the-download-of-a-given-response", "codes": [], "codes_text": [], "index": 34}
{"url": "https://docs.scrapy.org/en/latest/faq.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Running runspider I get error: No spider found in file: <filename>", "header_href": "#running-runspider-i-get-error-no-spider-found-in-file-filename", "codes": [], "codes_text": [], "index": 35}
{"url": "https://docs.scrapy.org/en/latest/topics/debug.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Debugging Spiders", "header_href": "#debugging-spiders", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">myproject.items</span> <span class=\"kn\">import</span> <span class=\"n\">MyItem</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'myspider'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">(</span>\n        <span class=\"s1\">'http://example.com/page1'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'http://example.com/page2'</span><span class=\"p\">,</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"c1\"># &lt;processing code not shown&gt;</span>\n        <span class=\"c1\"># collect `item_urls`</span>\n        <span class=\"k\">for</span> <span class=\"n\">item_url</span> <span class=\"ow\">in</span> <span class=\"n\">item_urls</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">item_url</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_item</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"c1\"># &lt;processing code not shown&gt;</span>\n        <span class=\"n\">item</span> <span class=\"o\">=</span> <span class=\"n\">MyItem</span><span class=\"p\">()</span>\n        <span class=\"c1\"># populate `item` fields</span>\n        <span class=\"c1\"># and extract item_details_url</span>\n        <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">item_details_url</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_details</span><span class=\"p\">,</span> <span class=\"n\">cb_kwargs</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'item'</span><span class=\"p\">:</span> <span class=\"n\">item</span><span class=\"p\">})</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_details</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n        <span class=\"c1\"># populate more `item` fields</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy parse --spider=myspider -c parse_item -d 2 &lt;item_url&gt;\n[ ... scrapy log lines crawling example.com spider ... ]\n\n&gt;&gt;&gt; STATUS DEPTH LEVEL 2 &lt;&lt;&lt;\n# Scraped Items  ------------------------------------------------------------\n[{'url': &lt;item_url&gt;}]\n\n# Requests  -----------------------------------------------------------------\n[]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy parse --spider=myspider -c parse_item -d 2 -v &lt;item_url&gt;\n[ ... scrapy log lines crawling example.com spider ... ]\n\n&gt;&gt;&gt; DEPTH LEVEL: 1 &lt;&lt;&lt;\n# Scraped Items  ------------------------------------------------------------\n[]\n\n# Requests  -----------------------------------------------------------------\n[&lt;GET item_details_url&gt;]\n\n\n&gt;&gt;&gt; DEPTH LEVEL: 2 &lt;&lt;&lt;\n# Scraped Items  ------------------------------------------------------------\n[{'url': &lt;item_url&gt;}]\n\n# Requests  -----------------------------------------------------------------\n[]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy parse --spider=myspider -d 3 'http://example.com/page1'\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.shell</span> <span class=\"kn\">import</span> <span class=\"n\">inspect_response</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">parse_details</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"n\">item</span><span class=\"p\">:</span>\n        <span class=\"c1\"># populate more `item` fields</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"n\">inspect_response</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.response</span> <span class=\"kn\">import</span> <span class=\"n\">open_in_browser</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">parse_details</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"s2\">\"item name\"</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">:</span>\n        <span class=\"n\">open_in_browser</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse_details</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"n\">item</span><span class=\"p\">:</span>\n        <span class=\"c1\"># populate more `item` fields</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">warning</span><span class=\"p\">(</span><span class=\"s1\">'No item received for </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import scrapy\nfrom myproject.items import MyItem\n\nclass MySpider(scrapy.Spider):\n    name = 'myspider'\n    start_urls = (\n        'http://example.com/page1',\n        'http://example.com/page2',\n        )\n\n    def parse(self, response):\n        # <processing code not shown>\n        # collect `item_urls`\n        for item_url in item_urls:\n            yield scrapy.Request(item_url, self.parse_item)\n\n    def parse_item(self, response):\n        # <processing code not shown>\n        item = MyItem()\n        # populate `item` fields\n        # and extract item_details_url\n        yield scrapy.Request(item_details_url, self.parse_details, cb_kwargs={'item': item})\n\n    def parse_details(self, response, item):\n        # populate more `item` fields\n        return item\n", "$ scrapy parse --spider=myspider -c parse_item -d 2 <item_url>\n[ ... scrapy log lines crawling example.com spider ... ]\n\n>>> STATUS DEPTH LEVEL 2 <<<\n# Scraped Items  ------------------------------------------------------------\n[{'url': <item_url>}]\n\n# Requests  -----------------------------------------------------------------\n[]\n", "$ scrapy parse --spider=myspider -c parse_item -d 2 -v <item_url>\n[ ... scrapy log lines crawling example.com spider ... ]\n\n>>> DEPTH LEVEL: 1 <<<\n# Scraped Items  ------------------------------------------------------------\n[]\n\n# Requests  -----------------------------------------------------------------\n[<GET item_details_url>]\n\n\n>>> DEPTH LEVEL: 2 <<<\n# Scraped Items  ------------------------------------------------------------\n[{'url': <item_url>}]\n\n# Requests  -----------------------------------------------------------------\n[]\n", "$ scrapy parse --spider=myspider -d 3 'http://example.com/page1'\n", "from scrapy.shell import inspect_response\n\ndef parse_details(self, response, item=None):\n    if item:\n        # populate more `item` fields\n        return item\n    else:\n        inspect_response(response, self)\n", "from scrapy.utils.response import open_in_browser\n\ndef parse_details(self, response):\n    if \"item name\" not in response.body:\n        open_in_browser(response)\n", "def parse_details(self, response, item=None):\n    if item:\n        # populate more `item` fields\n        return item\n    else:\n        self.logger.warning('No item received for %s', response.url)\n"], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/debug.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Parse Command", "header_href": "#parse-command", "codes": ["<div class=\"highlight\"><pre><span></span>$ scrapy parse --spider=myspider -c parse_item -d 2 &lt;item_url&gt;\n[ ... scrapy log lines crawling example.com spider ... ]\n\n&gt;&gt;&gt; STATUS DEPTH LEVEL 2 &lt;&lt;&lt;\n# Scraped Items  ------------------------------------------------------------\n[{'url': &lt;item_url&gt;}]\n\n# Requests  -----------------------------------------------------------------\n[]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy parse --spider=myspider -c parse_item -d 2 -v &lt;item_url&gt;\n[ ... scrapy log lines crawling example.com spider ... ]\n\n&gt;&gt;&gt; DEPTH LEVEL: 1 &lt;&lt;&lt;\n# Scraped Items  ------------------------------------------------------------\n[]\n\n# Requests  -----------------------------------------------------------------\n[&lt;GET item_details_url&gt;]\n\n\n&gt;&gt;&gt; DEPTH LEVEL: 2 &lt;&lt;&lt;\n# Scraped Items  ------------------------------------------------------------\n[{'url': &lt;item_url&gt;}]\n\n# Requests  -----------------------------------------------------------------\n[]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy parse --spider=myspider -d 3 'http://example.com/page1'\n</pre></div>"], "codes_text": ["$ scrapy parse --spider=myspider -c parse_item -d 2 <item_url>\n[ ... scrapy log lines crawling example.com spider ... ]\n\n>>> STATUS DEPTH LEVEL 2 <<<\n# Scraped Items  ------------------------------------------------------------\n[{'url': <item_url>}]\n\n# Requests  -----------------------------------------------------------------\n[]\n", "$ scrapy parse --spider=myspider -c parse_item -d 2 -v <item_url>\n[ ... scrapy log lines crawling example.com spider ... ]\n\n>>> DEPTH LEVEL: 1 <<<\n# Scraped Items  ------------------------------------------------------------\n[]\n\n# Requests  -----------------------------------------------------------------\n[<GET item_details_url>]\n\n\n>>> DEPTH LEVEL: 2 <<<\n# Scraped Items  ------------------------------------------------------------\n[{'url': <item_url>}]\n\n# Requests  -----------------------------------------------------------------\n[]\n", "$ scrapy parse --spider=myspider -d 3 'http://example.com/page1'\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/debug.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy Shell", "header_href": "#scrapy-shell", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.shell</span> <span class=\"kn\">import</span> <span class=\"n\">inspect_response</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">parse_details</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"n\">item</span><span class=\"p\">:</span>\n        <span class=\"c1\"># populate more `item` fields</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"n\">inspect_response</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["from scrapy.shell import inspect_response\n\ndef parse_details(self, response, item=None):\n    if item:\n        # populate more `item` fields\n        return item\n    else:\n        inspect_response(response, self)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/debug.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Open in browser", "header_href": "#open-in-browser", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.response</span> <span class=\"kn\">import</span> <span class=\"n\">open_in_browser</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">parse_details</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"s2\">\"item name\"</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">:</span>\n        <span class=\"n\">open_in_browser</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["from scrapy.utils.response import open_in_browser\n\ndef parse_details(self, response):\n    if \"item name\" not in response.body:\n        open_in_browser(response)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/debug.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Logging", "header_href": "#logging", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse_details</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"n\">item</span><span class=\"p\">:</span>\n        <span class=\"c1\"># populate more `item` fields</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">warning</span><span class=\"p\">(</span><span class=\"s1\">'No item received for </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["def parse_details(self, response, item=None):\n    if item:\n        # populate more `item` fields\n        return item\n    else:\n        self.logger.warning('No item received for %s', response.url)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/contracts.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Spiders Contracts", "header_href": "#spiders-contracts", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"sd\">\"\"\" This function parses a sample response. Some contracts are mingled</span>\n<span class=\"sd\">    with this docstring.</span>\n\n<span class=\"sd\">    @url http://www.amazon.com/s?field-keywords=selfish+gene</span>\n<span class=\"sd\">    @returns items 1 16</span>\n<span class=\"sd\">    @returns requests 0 0</span>\n<span class=\"sd\">    @scrapes Title Author Year Price</span>\n<span class=\"sd\">    \"\"\"</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"nd\">@url</span> <span class=\"n\">url</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"nd\">@cb_kwargs</span> <span class=\"p\">{</span><span class=\"s2\">\"arg1\"</span><span class=\"p\">:</span> <span class=\"s2\">\"value1\"</span><span class=\"p\">,</span> <span class=\"s2\">\"arg2\"</span><span class=\"p\">:</span> <span class=\"s2\">\"value2\"</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"nd\">@returns</span> <span class=\"n\">item</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">)</span><span class=\"o\">|</span><span class=\"n\">request</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">)</span> <span class=\"p\">[</span><span class=\"nb\">min</span> <span class=\"p\">[</span><span class=\"nb\">max</span><span class=\"p\">]]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"nd\">@scrapes</span> <span class=\"n\">field_1</span> <span class=\"n\">field_2</span> <span class=\"o\">...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">SPIDER_CONTRACTS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'myproject.contracts.ResponseCheck'</span><span class=\"p\">:</span> <span class=\"mi\">10</span><span class=\"p\">,</span>\n    <span class=\"s1\">'myproject.contracts.ItemValidate'</span><span class=\"p\">:</span> <span class=\"mi\">10</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.contracts</span> <span class=\"kn\">import</span> <span class=\"n\">Contract</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">ContractFail</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">HasHeaderContract</span><span class=\"p\">(</span><span class=\"n\">Contract</span><span class=\"p\">):</span>\n    <span class=\"sd\">\"\"\" Demo contract which checks the presence of a custom header</span>\n<span class=\"sd\">        @has_header X-CustomHeader</span>\n<span class=\"sd\">    \"\"\"</span>\n\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'has_header'</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">pre_process</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">header</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">args</span><span class=\"p\">:</span>\n            <span class=\"k\">if</span> <span class=\"n\">header</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">headers</span><span class=\"p\">:</span>\n                <span class=\"k\">raise</span> <span class=\"n\">ContractFail</span><span class=\"p\">(</span><span class=\"s1\">'X-CustomHeader not present'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">ExampleSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example'</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">environ</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'SCRAPY_CHECK'</span><span class=\"p\">):</span>\n            <span class=\"k\">pass</span>  <span class=\"c1\"># Do some scraper adjustments when a check is running</span>\n</pre></div>"], "codes_text": ["def parse(self, response):\n    \"\"\" This function parses a sample response. Some contracts are mingled\n    with this docstring.\n\n    @url http://www.amazon.com/s?field-keywords=selfish+gene\n    @returns items 1 16\n    @returns requests 0 0\n    @scrapes Title Author Year Price\n    \"\"\"\n", "@url url\n", "@cb_kwargs {\"arg1\": \"value1\", \"arg2\": \"value2\", ...}\n", "@returns item(s)|request(s) [min [max]]\n", "@scrapes field_1 field_2 ...\n", "SPIDER_CONTRACTS = {\n    'myproject.contracts.ResponseCheck': 10,\n    'myproject.contracts.ItemValidate': 10,\n}\n", "from scrapy.contracts import Contract\nfrom scrapy.exceptions import ContractFail\n\nclass HasHeaderContract(Contract):\n    \"\"\" Demo contract which checks the presence of a custom header\n        @has_header X-CustomHeader\n    \"\"\"\n\n    name = 'has_header'\n\n    def pre_process(self, response):\n        for header in self.args:\n            if header not in response.headers:\n                raise ContractFail('X-CustomHeader not present')\n", "import os\nimport scrapy\n\nclass ExampleSpider(scrapy.Spider):\n    name = 'example'\n\n    def __init__(self):\n        if os.environ.get('SCRAPY_CHECK'):\n            pass  # Do some scraper adjustments when a check is running\n"], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/contracts.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Custom Contracts", "header_href": "#custom-contracts", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">SPIDER_CONTRACTS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'myproject.contracts.ResponseCheck'</span><span class=\"p\">:</span> <span class=\"mi\">10</span><span class=\"p\">,</span>\n    <span class=\"s1\">'myproject.contracts.ItemValidate'</span><span class=\"p\">:</span> <span class=\"mi\">10</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.contracts</span> <span class=\"kn\">import</span> <span class=\"n\">Contract</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">ContractFail</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">HasHeaderContract</span><span class=\"p\">(</span><span class=\"n\">Contract</span><span class=\"p\">):</span>\n    <span class=\"sd\">\"\"\" Demo contract which checks the presence of a custom header</span>\n<span class=\"sd\">        @has_header X-CustomHeader</span>\n<span class=\"sd\">    \"\"\"</span>\n\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'has_header'</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">pre_process</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">header</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">args</span><span class=\"p\">:</span>\n            <span class=\"k\">if</span> <span class=\"n\">header</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">headers</span><span class=\"p\">:</span>\n                <span class=\"k\">raise</span> <span class=\"n\">ContractFail</span><span class=\"p\">(</span><span class=\"s1\">'X-CustomHeader not present'</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["SPIDER_CONTRACTS = {\n    'myproject.contracts.ResponseCheck': 10,\n    'myproject.contracts.ItemValidate': 10,\n}\n", "from scrapy.contracts import Contract\nfrom scrapy.exceptions import ContractFail\n\nclass HasHeaderContract(Contract):\n    \"\"\" Demo contract which checks the presence of a custom header\n        @has_header X-CustomHeader\n    \"\"\"\n\n    name = 'has_header'\n\n    def pre_process(self, response):\n        for header in self.args:\n            if header not in response.headers:\n                raise ContractFail('X-CustomHeader not present')\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/contracts.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Detecting check runs", "header_href": "#detecting-check-runs", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">ExampleSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example'</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">environ</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'SCRAPY_CHECK'</span><span class=\"p\">):</span>\n            <span class=\"k\">pass</span>  <span class=\"c1\"># Do some scraper adjustments when a check is running</span>\n</pre></div>"], "codes_text": ["import os\nimport scrapy\n\nclass ExampleSpider(scrapy.Spider):\n    name = 'example'\n\n    def __init__(self):\n        if os.environ.get('SCRAPY_CHECK'):\n            pass  # Do some scraper adjustments when a check is running\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/practices.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Common Practices", "header_href": "#common-practices", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.crawler</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerProcess</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Your spider definition</span>\n    <span class=\"o\">...</span>\n\n<span class=\"n\">process</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerProcess</span><span class=\"p\">(</span><span class=\"n\">settings</span><span class=\"o\">=</span><span class=\"p\">{</span>\n    <span class=\"s2\">\"FEEDS\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n        <span class=\"s2\">\"items.json\"</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s2\">\"format\"</span><span class=\"p\">:</span> <span class=\"s2\">\"json\"</span><span class=\"p\">},</span>\n    <span class=\"p\">},</span>\n<span class=\"p\">})</span>\n\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider</span><span class=\"p\">)</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span> <span class=\"c1\"># the script will block here until the crawling is finished</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.crawler</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerProcess</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.project</span> <span class=\"kn\">import</span> <span class=\"n\">get_project_settings</span>\n\n<span class=\"n\">process</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerProcess</span><span class=\"p\">(</span><span class=\"n\">get_project_settings</span><span class=\"p\">())</span>\n\n<span class=\"c1\"># 'followall' is the name of one of the spiders of the project.</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"s1\">'followall'</span><span class=\"p\">,</span> <span class=\"n\">domain</span><span class=\"o\">=</span><span class=\"s1\">'scrapy.org'</span><span class=\"p\">)</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span> <span class=\"c1\"># the script will block here until the crawling is finished</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">twisted.internet</span> <span class=\"kn\">import</span> <span class=\"n\">reactor</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.crawler</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerRunner</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.log</span> <span class=\"kn\">import</span> <span class=\"n\">configure_logging</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Your spider definition</span>\n    <span class=\"o\">...</span>\n\n<span class=\"n\">configure_logging</span><span class=\"p\">({</span><span class=\"s1\">'LOG_FORMAT'</span><span class=\"p\">:</span> <span class=\"s1\">'</span><span class=\"si\">%(levelname)s</span><span class=\"s1\">: </span><span class=\"si\">%(message)s</span><span class=\"s1\">'</span><span class=\"p\">})</span>\n<span class=\"n\">runner</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerRunner</span><span class=\"p\">()</span>\n\n<span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">runner</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider</span><span class=\"p\">)</span>\n<span class=\"n\">d</span><span class=\"o\">.</span><span class=\"n\">addBoth</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">_</span><span class=\"p\">:</span> <span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">stop</span><span class=\"p\">())</span>\n<span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">()</span> <span class=\"c1\"># the script will block here until the crawling is finished</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.crawler</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerProcess</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.project</span> <span class=\"kn\">import</span> <span class=\"n\">get_project_settings</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider1</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Your first spider definition</span>\n    <span class=\"o\">...</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider2</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Your second spider definition</span>\n    <span class=\"o\">...</span>\n\n<span class=\"n\">settings</span> <span class=\"o\">=</span> <span class=\"n\">get_project_settings</span><span class=\"p\">()</span>\n<span class=\"n\">process</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerProcess</span><span class=\"p\">(</span><span class=\"n\">settings</span><span class=\"p\">)</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider1</span><span class=\"p\">)</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider2</span><span class=\"p\">)</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span> <span class=\"c1\"># the script will block here until all crawling jobs are finished</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">twisted.internet</span> <span class=\"kn\">import</span> <span class=\"n\">reactor</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.crawler</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerRunner</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.log</span> <span class=\"kn\">import</span> <span class=\"n\">configure_logging</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.project</span> <span class=\"kn\">import</span> <span class=\"n\">get_project_settings</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider1</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Your first spider definition</span>\n    <span class=\"o\">...</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider2</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Your second spider definition</span>\n    <span class=\"o\">...</span>\n\n<span class=\"n\">configure_logging</span><span class=\"p\">()</span>\n<span class=\"n\">settings</span> <span class=\"o\">=</span> <span class=\"n\">get_project_settings</span><span class=\"p\">()</span>\n<span class=\"n\">runner</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerRunner</span><span class=\"p\">(</span><span class=\"n\">settings</span><span class=\"p\">)</span>\n<span class=\"n\">runner</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider1</span><span class=\"p\">)</span>\n<span class=\"n\">runner</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider2</span><span class=\"p\">)</span>\n<span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">runner</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">()</span>\n<span class=\"n\">d</span><span class=\"o\">.</span><span class=\"n\">addBoth</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">_</span><span class=\"p\">:</span> <span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">stop</span><span class=\"p\">())</span>\n\n<span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">()</span> <span class=\"c1\"># the script will block here until all crawling jobs are finished</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">twisted.internet</span> <span class=\"kn\">import</span> <span class=\"n\">reactor</span><span class=\"p\">,</span> <span class=\"n\">defer</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.crawler</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerRunner</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.log</span> <span class=\"kn\">import</span> <span class=\"n\">configure_logging</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.project</span> <span class=\"kn\">import</span> <span class=\"n\">get_project_settings</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider1</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Your first spider definition</span>\n    <span class=\"o\">...</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider2</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Your second spider definition</span>\n    <span class=\"o\">...</span>\n\n<span class=\"n\">settings</span> <span class=\"o\">=</span> <span class=\"n\">get_project_settings</span><span class=\"p\">()</span>\n<span class=\"n\">configure_logging</span><span class=\"p\">(</span><span class=\"n\">settings</span><span class=\"p\">)</span>\n<span class=\"n\">runner</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerRunner</span><span class=\"p\">(</span><span class=\"n\">settings</span><span class=\"p\">)</span>\n\n<span class=\"nd\">@defer</span><span class=\"o\">.</span><span class=\"n\">inlineCallbacks</span>\n<span class=\"k\">def</span> <span class=\"nf\">crawl</span><span class=\"p\">():</span>\n    <span class=\"k\">yield</span> <span class=\"n\">runner</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider1</span><span class=\"p\">)</span>\n    <span class=\"k\">yield</span> <span class=\"n\">runner</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider2</span><span class=\"p\">)</span>\n    <span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">stop</span><span class=\"p\">()</span>\n\n<span class=\"n\">crawl</span><span class=\"p\">()</span>\n<span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">()</span> <span class=\"c1\"># the script will block here until the last crawl call is finished</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">somedomain</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">urls</span><span class=\"o\">-</span><span class=\"n\">to</span><span class=\"o\">-</span><span class=\"n\">crawl</span><span class=\"o\">/</span><span class=\"n\">spider1</span><span class=\"o\">/</span><span class=\"n\">part1</span><span class=\"o\">.</span><span class=\"n\">list</span>\n<span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">somedomain</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">urls</span><span class=\"o\">-</span><span class=\"n\">to</span><span class=\"o\">-</span><span class=\"n\">crawl</span><span class=\"o\">/</span><span class=\"n\">spider1</span><span class=\"o\">/</span><span class=\"n\">part2</span><span class=\"o\">.</span><span class=\"n\">list</span>\n<span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">somedomain</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">urls</span><span class=\"o\">-</span><span class=\"n\">to</span><span class=\"o\">-</span><span class=\"n\">crawl</span><span class=\"o\">/</span><span class=\"n\">spider1</span><span class=\"o\">/</span><span class=\"n\">part3</span><span class=\"o\">.</span><span class=\"n\">list</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">curl</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">scrapy1</span><span class=\"o\">.</span><span class=\"n\">mycompany</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"p\">:</span><span class=\"mi\">6800</span><span class=\"o\">/</span><span class=\"n\">schedule</span><span class=\"o\">.</span><span class=\"n\">json</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">project</span><span class=\"o\">=</span><span class=\"n\">myproject</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">spider</span><span class=\"o\">=</span><span class=\"n\">spider1</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">part</span><span class=\"o\">=</span><span class=\"mi\">1</span>\n<span class=\"n\">curl</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">scrapy2</span><span class=\"o\">.</span><span class=\"n\">mycompany</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"p\">:</span><span class=\"mi\">6800</span><span class=\"o\">/</span><span class=\"n\">schedule</span><span class=\"o\">.</span><span class=\"n\">json</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">project</span><span class=\"o\">=</span><span class=\"n\">myproject</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">spider</span><span class=\"o\">=</span><span class=\"n\">spider1</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">part</span><span class=\"o\">=</span><span class=\"mi\">2</span>\n<span class=\"n\">curl</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">scrapy3</span><span class=\"o\">.</span><span class=\"n\">mycompany</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"p\">:</span><span class=\"mi\">6800</span><span class=\"o\">/</span><span class=\"n\">schedule</span><span class=\"o\">.</span><span class=\"n\">json</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">project</span><span class=\"o\">=</span><span class=\"n\">myproject</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">spider</span><span class=\"o\">=</span><span class=\"n\">spider1</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">part</span><span class=\"o\">=</span><span class=\"mi\">3</span>\n</pre></div>"], "codes_text": ["import scrapy\nfrom scrapy.crawler import CrawlerProcess\n\nclass MySpider(scrapy.Spider):\n    # Your spider definition\n    ...\n\nprocess = CrawlerProcess(settings={\n    \"FEEDS\": {\n        \"items.json\": {\"format\": \"json\"},\n    },\n})\n\nprocess.crawl(MySpider)\nprocess.start() # the script will block here until the crawling is finished\n", "from scrapy.crawler import CrawlerProcess\nfrom scrapy.utils.project import get_project_settings\n\nprocess = CrawlerProcess(get_project_settings())\n\n# 'followall' is the name of one of the spiders of the project.\nprocess.crawl('followall', domain='scrapy.org')\nprocess.start() # the script will block here until the crawling is finished\n", "from twisted.internet import reactor\nimport scrapy\nfrom scrapy.crawler import CrawlerRunner\nfrom scrapy.utils.log import configure_logging\n\nclass MySpider(scrapy.Spider):\n    # Your spider definition\n    ...\n\nconfigure_logging({'LOG_FORMAT': '%(levelname)s: %(message)s'})\nrunner = CrawlerRunner()\n\nd = runner.crawl(MySpider)\nd.addBoth(lambda _: reactor.stop())\nreactor.run() # the script will block here until the crawling is finished\n", "import scrapy\nfrom scrapy.crawler import CrawlerProcess\nfrom scrapy.utils.project import get_project_settings\n\nclass MySpider1(scrapy.Spider):\n    # Your first spider definition\n    ...\n\nclass MySpider2(scrapy.Spider):\n    # Your second spider definition\n    ...\n\nsettings = get_project_settings()\nprocess = CrawlerProcess(settings)\nprocess.crawl(MySpider1)\nprocess.crawl(MySpider2)\nprocess.start() # the script will block here until all crawling jobs are finished\n", "import scrapy\nfrom twisted.internet import reactor\nfrom scrapy.crawler import CrawlerRunner\nfrom scrapy.utils.log import configure_logging\nfrom scrapy.utils.project import get_project_settings\n\nclass MySpider1(scrapy.Spider):\n    # Your first spider definition\n    ...\n\nclass MySpider2(scrapy.Spider):\n    # Your second spider definition\n    ...\n\nconfigure_logging()\nsettings = get_project_settings()\nrunner = CrawlerRunner(settings)\nrunner.crawl(MySpider1)\nrunner.crawl(MySpider2)\nd = runner.join()\nd.addBoth(lambda _: reactor.stop())\n\nreactor.run() # the script will block here until all crawling jobs are finished\n", "from twisted.internet import reactor, defer\nfrom scrapy.crawler import CrawlerRunner\nfrom scrapy.utils.log import configure_logging\nfrom scrapy.utils.project import get_project_settings\n\nclass MySpider1(scrapy.Spider):\n    # Your first spider definition\n    ...\n\nclass MySpider2(scrapy.Spider):\n    # Your second spider definition\n    ...\n\nsettings = get_project_settings()\nconfigure_logging(settings)\nrunner = CrawlerRunner(settings)\n\n@defer.inlineCallbacks\ndef crawl():\n    yield runner.crawl(MySpider1)\n    yield runner.crawl(MySpider2)\n    reactor.stop()\n\ncrawl()\nreactor.run() # the script will block here until the last crawl call is finished\n", "http://somedomain.com/urls-to-crawl/spider1/part1.list\nhttp://somedomain.com/urls-to-crawl/spider1/part2.list\nhttp://somedomain.com/urls-to-crawl/spider1/part3.list\n", "curl http://scrapy1.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=1\ncurl http://scrapy2.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=2\ncurl http://scrapy3.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=3\n"], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/practices.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Run Scrapy from a script", "header_href": "#run-scrapy-from-a-script", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.crawler</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerProcess</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Your spider definition</span>\n    <span class=\"o\">...</span>\n\n<span class=\"n\">process</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerProcess</span><span class=\"p\">(</span><span class=\"n\">settings</span><span class=\"o\">=</span><span class=\"p\">{</span>\n    <span class=\"s2\">\"FEEDS\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n        <span class=\"s2\">\"items.json\"</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s2\">\"format\"</span><span class=\"p\">:</span> <span class=\"s2\">\"json\"</span><span class=\"p\">},</span>\n    <span class=\"p\">},</span>\n<span class=\"p\">})</span>\n\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider</span><span class=\"p\">)</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span> <span class=\"c1\"># the script will block here until the crawling is finished</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.crawler</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerProcess</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.project</span> <span class=\"kn\">import</span> <span class=\"n\">get_project_settings</span>\n\n<span class=\"n\">process</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerProcess</span><span class=\"p\">(</span><span class=\"n\">get_project_settings</span><span class=\"p\">())</span>\n\n<span class=\"c1\"># 'followall' is the name of one of the spiders of the project.</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"s1\">'followall'</span><span class=\"p\">,</span> <span class=\"n\">domain</span><span class=\"o\">=</span><span class=\"s1\">'scrapy.org'</span><span class=\"p\">)</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span> <span class=\"c1\"># the script will block here until the crawling is finished</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">twisted.internet</span> <span class=\"kn\">import</span> <span class=\"n\">reactor</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.crawler</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerRunner</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.log</span> <span class=\"kn\">import</span> <span class=\"n\">configure_logging</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Your spider definition</span>\n    <span class=\"o\">...</span>\n\n<span class=\"n\">configure_logging</span><span class=\"p\">({</span><span class=\"s1\">'LOG_FORMAT'</span><span class=\"p\">:</span> <span class=\"s1\">'</span><span class=\"si\">%(levelname)s</span><span class=\"s1\">: </span><span class=\"si\">%(message)s</span><span class=\"s1\">'</span><span class=\"p\">})</span>\n<span class=\"n\">runner</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerRunner</span><span class=\"p\">()</span>\n\n<span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">runner</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider</span><span class=\"p\">)</span>\n<span class=\"n\">d</span><span class=\"o\">.</span><span class=\"n\">addBoth</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">_</span><span class=\"p\">:</span> <span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">stop</span><span class=\"p\">())</span>\n<span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">()</span> <span class=\"c1\"># the script will block here until the crawling is finished</span>\n</pre></div>"], "codes_text": ["import scrapy\nfrom scrapy.crawler import CrawlerProcess\n\nclass MySpider(scrapy.Spider):\n    # Your spider definition\n    ...\n\nprocess = CrawlerProcess(settings={\n    \"FEEDS\": {\n        \"items.json\": {\"format\": \"json\"},\n    },\n})\n\nprocess.crawl(MySpider)\nprocess.start() # the script will block here until the crawling is finished\n", "from scrapy.crawler import CrawlerProcess\nfrom scrapy.utils.project import get_project_settings\n\nprocess = CrawlerProcess(get_project_settings())\n\n# 'followall' is the name of one of the spiders of the project.\nprocess.crawl('followall', domain='scrapy.org')\nprocess.start() # the script will block here until the crawling is finished\n", "from twisted.internet import reactor\nimport scrapy\nfrom scrapy.crawler import CrawlerRunner\nfrom scrapy.utils.log import configure_logging\n\nclass MySpider(scrapy.Spider):\n    # Your spider definition\n    ...\n\nconfigure_logging({'LOG_FORMAT': '%(levelname)s: %(message)s'})\nrunner = CrawlerRunner()\n\nd = runner.crawl(MySpider)\nd.addBoth(lambda _: reactor.stop())\nreactor.run() # the script will block here until the crawling is finished\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/practices.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Running multiple spiders in the same process", "header_href": "#running-multiple-spiders-in-the-same-process", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.crawler</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerProcess</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.project</span> <span class=\"kn\">import</span> <span class=\"n\">get_project_settings</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider1</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Your first spider definition</span>\n    <span class=\"o\">...</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider2</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Your second spider definition</span>\n    <span class=\"o\">...</span>\n\n<span class=\"n\">settings</span> <span class=\"o\">=</span> <span class=\"n\">get_project_settings</span><span class=\"p\">()</span>\n<span class=\"n\">process</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerProcess</span><span class=\"p\">(</span><span class=\"n\">settings</span><span class=\"p\">)</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider1</span><span class=\"p\">)</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider2</span><span class=\"p\">)</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span> <span class=\"c1\"># the script will block here until all crawling jobs are finished</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">twisted.internet</span> <span class=\"kn\">import</span> <span class=\"n\">reactor</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.crawler</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerRunner</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.log</span> <span class=\"kn\">import</span> <span class=\"n\">configure_logging</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.project</span> <span class=\"kn\">import</span> <span class=\"n\">get_project_settings</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider1</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Your first spider definition</span>\n    <span class=\"o\">...</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider2</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Your second spider definition</span>\n    <span class=\"o\">...</span>\n\n<span class=\"n\">configure_logging</span><span class=\"p\">()</span>\n<span class=\"n\">settings</span> <span class=\"o\">=</span> <span class=\"n\">get_project_settings</span><span class=\"p\">()</span>\n<span class=\"n\">runner</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerRunner</span><span class=\"p\">(</span><span class=\"n\">settings</span><span class=\"p\">)</span>\n<span class=\"n\">runner</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider1</span><span class=\"p\">)</span>\n<span class=\"n\">runner</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider2</span><span class=\"p\">)</span>\n<span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">runner</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">()</span>\n<span class=\"n\">d</span><span class=\"o\">.</span><span class=\"n\">addBoth</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">_</span><span class=\"p\">:</span> <span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">stop</span><span class=\"p\">())</span>\n\n<span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">()</span> <span class=\"c1\"># the script will block here until all crawling jobs are finished</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">twisted.internet</span> <span class=\"kn\">import</span> <span class=\"n\">reactor</span><span class=\"p\">,</span> <span class=\"n\">defer</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.crawler</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerRunner</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.log</span> <span class=\"kn\">import</span> <span class=\"n\">configure_logging</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.project</span> <span class=\"kn\">import</span> <span class=\"n\">get_project_settings</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider1</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Your first spider definition</span>\n    <span class=\"o\">...</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider2</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Your second spider definition</span>\n    <span class=\"o\">...</span>\n\n<span class=\"n\">settings</span> <span class=\"o\">=</span> <span class=\"n\">get_project_settings</span><span class=\"p\">()</span>\n<span class=\"n\">configure_logging</span><span class=\"p\">(</span><span class=\"n\">settings</span><span class=\"p\">)</span>\n<span class=\"n\">runner</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerRunner</span><span class=\"p\">(</span><span class=\"n\">settings</span><span class=\"p\">)</span>\n\n<span class=\"nd\">@defer</span><span class=\"o\">.</span><span class=\"n\">inlineCallbacks</span>\n<span class=\"k\">def</span> <span class=\"nf\">crawl</span><span class=\"p\">():</span>\n    <span class=\"k\">yield</span> <span class=\"n\">runner</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider1</span><span class=\"p\">)</span>\n    <span class=\"k\">yield</span> <span class=\"n\">runner</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider2</span><span class=\"p\">)</span>\n    <span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">stop</span><span class=\"p\">()</span>\n\n<span class=\"n\">crawl</span><span class=\"p\">()</span>\n<span class=\"n\">reactor</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">()</span> <span class=\"c1\"># the script will block here until the last crawl call is finished</span>\n</pre></div>"], "codes_text": ["import scrapy\nfrom scrapy.crawler import CrawlerProcess\nfrom scrapy.utils.project import get_project_settings\n\nclass MySpider1(scrapy.Spider):\n    # Your first spider definition\n    ...\n\nclass MySpider2(scrapy.Spider):\n    # Your second spider definition\n    ...\n\nsettings = get_project_settings()\nprocess = CrawlerProcess(settings)\nprocess.crawl(MySpider1)\nprocess.crawl(MySpider2)\nprocess.start() # the script will block here until all crawling jobs are finished\n", "import scrapy\nfrom twisted.internet import reactor\nfrom scrapy.crawler import CrawlerRunner\nfrom scrapy.utils.log import configure_logging\nfrom scrapy.utils.project import get_project_settings\n\nclass MySpider1(scrapy.Spider):\n    # Your first spider definition\n    ...\n\nclass MySpider2(scrapy.Spider):\n    # Your second spider definition\n    ...\n\nconfigure_logging()\nsettings = get_project_settings()\nrunner = CrawlerRunner(settings)\nrunner.crawl(MySpider1)\nrunner.crawl(MySpider2)\nd = runner.join()\nd.addBoth(lambda _: reactor.stop())\n\nreactor.run() # the script will block here until all crawling jobs are finished\n", "from twisted.internet import reactor, defer\nfrom scrapy.crawler import CrawlerRunner\nfrom scrapy.utils.log import configure_logging\nfrom scrapy.utils.project import get_project_settings\n\nclass MySpider1(scrapy.Spider):\n    # Your first spider definition\n    ...\n\nclass MySpider2(scrapy.Spider):\n    # Your second spider definition\n    ...\n\nsettings = get_project_settings()\nconfigure_logging(settings)\nrunner = CrawlerRunner(settings)\n\n@defer.inlineCallbacks\ndef crawl():\n    yield runner.crawl(MySpider1)\n    yield runner.crawl(MySpider2)\n    reactor.stop()\n\ncrawl()\nreactor.run() # the script will block here until the last crawl call is finished\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/practices.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Distributed crawls", "header_href": "#distributed-crawls", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">somedomain</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">urls</span><span class=\"o\">-</span><span class=\"n\">to</span><span class=\"o\">-</span><span class=\"n\">crawl</span><span class=\"o\">/</span><span class=\"n\">spider1</span><span class=\"o\">/</span><span class=\"n\">part1</span><span class=\"o\">.</span><span class=\"n\">list</span>\n<span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">somedomain</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">urls</span><span class=\"o\">-</span><span class=\"n\">to</span><span class=\"o\">-</span><span class=\"n\">crawl</span><span class=\"o\">/</span><span class=\"n\">spider1</span><span class=\"o\">/</span><span class=\"n\">part2</span><span class=\"o\">.</span><span class=\"n\">list</span>\n<span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">somedomain</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">urls</span><span class=\"o\">-</span><span class=\"n\">to</span><span class=\"o\">-</span><span class=\"n\">crawl</span><span class=\"o\">/</span><span class=\"n\">spider1</span><span class=\"o\">/</span><span class=\"n\">part3</span><span class=\"o\">.</span><span class=\"n\">list</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">curl</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">scrapy1</span><span class=\"o\">.</span><span class=\"n\">mycompany</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"p\">:</span><span class=\"mi\">6800</span><span class=\"o\">/</span><span class=\"n\">schedule</span><span class=\"o\">.</span><span class=\"n\">json</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">project</span><span class=\"o\">=</span><span class=\"n\">myproject</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">spider</span><span class=\"o\">=</span><span class=\"n\">spider1</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">part</span><span class=\"o\">=</span><span class=\"mi\">1</span>\n<span class=\"n\">curl</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">scrapy2</span><span class=\"o\">.</span><span class=\"n\">mycompany</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"p\">:</span><span class=\"mi\">6800</span><span class=\"o\">/</span><span class=\"n\">schedule</span><span class=\"o\">.</span><span class=\"n\">json</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">project</span><span class=\"o\">=</span><span class=\"n\">myproject</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">spider</span><span class=\"o\">=</span><span class=\"n\">spider1</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">part</span><span class=\"o\">=</span><span class=\"mi\">2</span>\n<span class=\"n\">curl</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">scrapy3</span><span class=\"o\">.</span><span class=\"n\">mycompany</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"p\">:</span><span class=\"mi\">6800</span><span class=\"o\">/</span><span class=\"n\">schedule</span><span class=\"o\">.</span><span class=\"n\">json</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">project</span><span class=\"o\">=</span><span class=\"n\">myproject</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">spider</span><span class=\"o\">=</span><span class=\"n\">spider1</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">part</span><span class=\"o\">=</span><span class=\"mi\">3</span>\n</pre></div>"], "codes_text": ["http://somedomain.com/urls-to-crawl/spider1/part1.list\nhttp://somedomain.com/urls-to-crawl/spider1/part2.list\nhttp://somedomain.com/urls-to-crawl/spider1/part3.list\n", "curl http://scrapy1.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=1\ncurl http://scrapy2.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=2\ncurl http://scrapy3.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=3\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/practices.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Avoiding getting banned", "header_href": "#avoiding-getting-banned", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/broad-crawls.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Broad Crawls", "header_href": "#broad-crawls", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">SCHEDULER_PRIORITY_QUEUE</span> <span class=\"o\">=</span> <span class=\"s1\">'scrapy.pqueues.DownloaderAwarePriorityQueue'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">CONCURRENT_REQUESTS</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">REACTOR_THREADPOOL_MAXSIZE</span> <span class=\"o\">=</span> <span class=\"mi\">20</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">LOG_LEVEL</span> <span class=\"o\">=</span> <span class=\"s1\">'INFO'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">COOKIES_ENABLED</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">RETRY_ENABLED</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">DOWNLOAD_TIMEOUT</span> <span class=\"o\">=</span> <span class=\"mi\">15</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">REDIRECT_ENABLED</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">AJAXCRAWL_ENABLED</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n</pre></div>"], "codes_text": ["SCHEDULER_PRIORITY_QUEUE = 'scrapy.pqueues.DownloaderAwarePriorityQueue'\n", "CONCURRENT_REQUESTS = 100\n", "REACTOR_THREADPOOL_MAXSIZE = 20\n", "LOG_LEVEL = 'INFO'\n", "COOKIES_ENABLED = False\n", "RETRY_ENABLED = False\n", "DOWNLOAD_TIMEOUT = 15\n", "REDIRECT_ENABLED = False\n", "AJAXCRAWL_ENABLED = True\n"], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/topics/broad-crawls.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Use the right SCHEDULER_PRIORITY_QUEUE", "header_href": "settings.html#std-setting-SCHEDULER_PRIORITY_QUEUE", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">SCHEDULER_PRIORITY_QUEUE</span> <span class=\"o\">=</span> <span class=\"s1\">'scrapy.pqueues.DownloaderAwarePriorityQueue'</span>\n</pre></div>"], "codes_text": ["SCHEDULER_PRIORITY_QUEUE = 'scrapy.pqueues.DownloaderAwarePriorityQueue'\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/broad-crawls.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Increase concurrency", "header_href": "#increase-concurrency", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">CONCURRENT_REQUESTS</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n</pre></div>"], "codes_text": ["CONCURRENT_REQUESTS = 100\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/broad-crawls.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Increase Twisted IO thread pool maximum size", "header_href": "#increase-twisted-io-thread-pool-maximum-size", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">REACTOR_THREADPOOL_MAXSIZE</span> <span class=\"o\">=</span> <span class=\"mi\">20</span>\n</pre></div>"], "codes_text": ["REACTOR_THREADPOOL_MAXSIZE = 20\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/broad-crawls.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Setup your own DNS", "header_href": "#setup-your-own-dns", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/broad-crawls.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Reduce log level", "header_href": "#reduce-log-level", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">LOG_LEVEL</span> <span class=\"o\">=</span> <span class=\"s1\">'INFO'</span>\n</pre></div>"], "codes_text": ["LOG_LEVEL = 'INFO'\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/broad-crawls.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Disable cookies", "header_href": "#disable-cookies", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">COOKIES_ENABLED</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n</pre></div>"], "codes_text": ["COOKIES_ENABLED = False\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/broad-crawls.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Disable retries", "header_href": "#disable-retries", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">RETRY_ENABLED</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n</pre></div>"], "codes_text": ["RETRY_ENABLED = False\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/broad-crawls.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Reduce download timeout", "header_href": "#reduce-download-timeout", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">DOWNLOAD_TIMEOUT</span> <span class=\"o\">=</span> <span class=\"mi\">15</span>\n</pre></div>"], "codes_text": ["DOWNLOAD_TIMEOUT = 15\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/broad-crawls.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Disable redirects", "header_href": "#disable-redirects", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">REDIRECT_ENABLED</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n</pre></div>"], "codes_text": ["REDIRECT_ENABLED = False\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/broad-crawls.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Enable crawling of “Ajax Crawlable Pages”", "header_href": "#enable-crawling-of-ajax-crawlable-pages", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">AJAXCRAWL_ENABLED</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n</pre></div>"], "codes_text": ["AJAXCRAWL_ENABLED = True\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/broad-crawls.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Crawl in BFO order", "header_href": "#crawl-in-bfo-order", "codes": [], "codes_text": [], "index": 12}
{"url": "https://docs.scrapy.org/en/latest/topics/broad-crawls.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Be mindful of memory leaks", "header_href": "#be-mindful-of-memory-leaks", "codes": [], "codes_text": [], "index": 13}
{"url": "https://docs.scrapy.org/en/latest/topics/broad-crawls.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Install a specific Twisted reactor", "header_href": "#install-a-specific-twisted-reactor", "codes": [], "codes_text": [], "index": 14}
{"url": "https://docs.scrapy.org/en/latest/topics/developer-tools.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Using your browser’s Developer Tools for scraping", "header_href": "#using-your-browser-s-developer-tools-for-scraping", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"quote\"</span> <span class=\"na\">itemscope</span><span class=\"o\">=</span><span class=\"s\">\"\"</span> <span class=\"na\">itemtype</span><span class=\"o\">=</span><span class=\"s\">\"http://schema.org/CreativeWork\"</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">span</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"text\"</span> <span class=\"na\">itemprop</span><span class=\"o\">=</span><span class=\"s\">\"text\"</span><span class=\"p\">&gt;</span>(...)<span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>(...)<span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tags\"</span><span class=\"p\">&gt;</span>(...)<span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy shell \"https://quotes.toscrape.com/\"\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'/html/body/div/div[2]/div[1]/div[1]/span[1]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"quote\"</span> <span class=\"na\">itemscope</span><span class=\"o\">=</span><span class=\"s\">\"\"</span> <span class=\"na\">itemtype</span><span class=\"o\">=</span><span class=\"s\">\"http://schema.org/CreativeWork\"</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">span</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"text\"</span> <span class=\"na\">itemprop</span><span class=\"o\">=</span><span class=\"s\">\"text\"</span><span class=\"p\">&gt;</span>\n    “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n  <span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>(...)<span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tags\"</span><span class=\"p\">&gt;</span>(...)<span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//span[has-class(\"text\")]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',</span>\n<span class=\"go\">'“It is our choices, Harry, that show what we truly are, far more than our abilities.”',</span>\n<span class=\"go\">'“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',</span>\n<span class=\"go\">...]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy shell \"quotes.toscrape.com/scroll\"\n(...)\n&gt;&gt;&gt; view(response)\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">import</span> <span class=\"nn\">json</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuoteSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'quote'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'quotes.toscrape.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">page</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://quotes.toscrape.com/api/quotes?page=1'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">)</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s2\">\"quotes\"</span><span class=\"p\">]:</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span><span class=\"s2\">\"quote\"</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"p\">[</span><span class=\"s2\">\"text\"</span><span class=\"p\">]}</span>\n        <span class=\"k\">if</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s2\">\"has_next\"</span><span class=\"p\">]:</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">page</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n            <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s2\">\"https://quotes.toscrape.com/api/quotes?page=</span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">page</span><span class=\"si\">}</span><span class=\"s2\">\"</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">Request</span>\n\n<span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">Request</span><span class=\"o\">.</span><span class=\"n\">from_curl</span><span class=\"p\">(</span>\n    <span class=\"s2\">\"curl 'https://quotes.toscrape.com/api/quotes?page=1' -H 'User-Agent: Mozil\"</span>\n    <span class=\"s2\">\"la/5.0 (X11; Linux x86_64; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Acce\"</span>\n    <span class=\"s2\">\"pt: */*' -H 'Accept-Language: ca,en-US;q=0.7,en;q=0.3' --compressed -H 'X\"</span>\n    <span class=\"s2\">\"-Requested-With: XMLHttpRequest' -H 'Proxy-Authorization: Basic QFRLLTAzM\"</span>\n    <span class=\"s2\">\"zEwZTAxLTk5MWUtNDFiNC1iZWRmLTJjNGI4M2ZiNDBmNDpAVEstMDMzMTBlMDEtOTkxZS00MW\"</span>\n    <span class=\"s2\">\"I0LWJlZGYtMmM0YjgzZmI0MGY0' -H 'Connection: keep-alive' -H 'Referer: http\"</span>\n    <span class=\"s2\">\"://quotes.toscrape.com/scroll' -H 'Cache-Control: max-age=0'\"</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n  <span class=\"text\" itemprop=\"text\">(...)</span>\n  <span>(...)</span>\n  <div class=\"tags\">(...)</div>\n</div>\n", "$ scrapy shell \"https://quotes.toscrape.com/\"\n", ">>> response.xpath('/html/body/div/div[2]/div[1]/div[1]/span[1]/text()').getall()\n['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”']\n", "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n  <span class=\"text\" itemprop=\"text\">\n    “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n  </span>\n  <span>(...)</span>\n  <div class=\"tags\">(...)</div>\n</div>\n", ">>> response.xpath('//span[has-class(\"text\")]/text()').getall()\n['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',\n'“It is our choices, Harry, that show what we truly are, far more than our abilities.”',\n'“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',\n...]\n", "$ scrapy shell \"quotes.toscrape.com/scroll\"\n(...)\n>>> view(response)\n", "import scrapy\nimport json\n\n\nclass QuoteSpider(scrapy.Spider):\n    name = 'quote'\n    allowed_domains = ['quotes.toscrape.com']\n    page = 1\n    start_urls = ['https://quotes.toscrape.com/api/quotes?page=1']\n\n    def parse(self, response):\n        data = json.loads(response.text)\n        for quote in data[\"quotes\"]:\n            yield {\"quote\": quote[\"text\"]}\n        if data[\"has_next\"]:\n            self.page += 1\n            url = f\"https://quotes.toscrape.com/api/quotes?page={self.page}\"\n            yield scrapy.Request(url=url, callback=self.parse)\n", "from scrapy import Request\n\nrequest = Request.from_curl(\n    \"curl 'https://quotes.toscrape.com/api/quotes?page=1' -H 'User-Agent: Mozil\"\n    \"la/5.0 (X11; Linux x86_64; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Acce\"\n    \"pt: */*' -H 'Accept-Language: ca,en-US;q=0.7,en;q=0.3' --compressed -H 'X\"\n    \"-Requested-With: XMLHttpRequest' -H 'Proxy-Authorization: Basic QFRLLTAzM\"\n    \"zEwZTAxLTk5MWUtNDFiNC1iZWRmLTJjNGI4M2ZiNDBmNDpAVEstMDMzMTBlMDEtOTkxZS00MW\"\n    \"I0LWJlZGYtMmM0YjgzZmI0MGY0' -H 'Connection: keep-alive' -H 'Referer: http\"\n    \"://quotes.toscrape.com/scroll' -H 'Cache-Control: max-age=0'\")\n"], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/developer-tools.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Caveats with inspecting the live browser DOM", "header_href": "#caveats-with-inspecting-the-live-browser-dom", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/developer-tools.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Inspecting a website", "header_href": "#inspecting-a-website", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"quote\"</span> <span class=\"na\">itemscope</span><span class=\"o\">=</span><span class=\"s\">\"\"</span> <span class=\"na\">itemtype</span><span class=\"o\">=</span><span class=\"s\">\"http://schema.org/CreativeWork\"</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">span</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"text\"</span> <span class=\"na\">itemprop</span><span class=\"o\">=</span><span class=\"s\">\"text\"</span><span class=\"p\">&gt;</span>(...)<span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>(...)<span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tags\"</span><span class=\"p\">&gt;</span>(...)<span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>$ scrapy shell \"https://quotes.toscrape.com/\"\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'/html/body/div/div[2]/div[1]/div[1]/span[1]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"quote\"</span> <span class=\"na\">itemscope</span><span class=\"o\">=</span><span class=\"s\">\"\"</span> <span class=\"na\">itemtype</span><span class=\"o\">=</span><span class=\"s\">\"http://schema.org/CreativeWork\"</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">span</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"text\"</span> <span class=\"na\">itemprop</span><span class=\"o\">=</span><span class=\"s\">\"text\"</span><span class=\"p\">&gt;</span>\n    “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n  <span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>(...)<span class=\"p\">&lt;/</span><span class=\"nt\">span</span><span class=\"p\">&gt;</span>\n  <span class=\"p\">&lt;</span><span class=\"nt\">div</span> <span class=\"na\">class</span><span class=\"o\">=</span><span class=\"s\">\"tags\"</span><span class=\"p\">&gt;</span>(...)<span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n<span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//span[has-class(\"text\")]/text()'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">()</span>\n<span class=\"go\">['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',</span>\n<span class=\"go\">'“It is our choices, Harry, that show what we truly are, far more than our abilities.”',</span>\n<span class=\"go\">'“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',</span>\n<span class=\"go\">...]</span>\n</pre></div>"], "codes_text": ["<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n  <span class=\"text\" itemprop=\"text\">(...)</span>\n  <span>(...)</span>\n  <div class=\"tags\">(...)</div>\n</div>\n", "$ scrapy shell \"https://quotes.toscrape.com/\"\n", ">>> response.xpath('/html/body/div/div[2]/div[1]/div[1]/span[1]/text()').getall()\n['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”']\n", "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n  <span class=\"text\" itemprop=\"text\">\n    “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n  </span>\n  <span>(...)</span>\n  <div class=\"tags\">(...)</div>\n</div>\n", ">>> response.xpath('//span[has-class(\"text\")]/text()').getall()\n['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',\n'“It is our choices, Harry, that show what we truly are, far more than our abilities.”',\n'“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',\n...]\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/developer-tools.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "The Network-tool", "header_href": "#the-network-tool", "codes": ["<div class=\"highlight\"><pre><span></span>$ scrapy shell \"quotes.toscrape.com/scroll\"\n(...)\n&gt;&gt;&gt; view(response)\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">import</span> <span class=\"nn\">json</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QuoteSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'quote'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'quotes.toscrape.com'</span><span class=\"p\">]</span>\n    <span class=\"n\">page</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://quotes.toscrape.com/api/quotes?page=1'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">)</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s2\">\"quotes\"</span><span class=\"p\">]:</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span><span class=\"s2\">\"quote\"</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"p\">[</span><span class=\"s2\">\"text\"</span><span class=\"p\">]}</span>\n        <span class=\"k\">if</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s2\">\"has_next\"</span><span class=\"p\">]:</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">page</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n            <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s2\">\"https://quotes.toscrape.com/api/quotes?page=</span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">page</span><span class=\"si\">}</span><span class=\"s2\">\"</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">Request</span>\n\n<span class=\"n\">request</span> <span class=\"o\">=</span> <span class=\"n\">Request</span><span class=\"o\">.</span><span class=\"n\">from_curl</span><span class=\"p\">(</span>\n    <span class=\"s2\">\"curl 'https://quotes.toscrape.com/api/quotes?page=1' -H 'User-Agent: Mozil\"</span>\n    <span class=\"s2\">\"la/5.0 (X11; Linux x86_64; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Acce\"</span>\n    <span class=\"s2\">\"pt: */*' -H 'Accept-Language: ca,en-US;q=0.7,en;q=0.3' --compressed -H 'X\"</span>\n    <span class=\"s2\">\"-Requested-With: XMLHttpRequest' -H 'Proxy-Authorization: Basic QFRLLTAzM\"</span>\n    <span class=\"s2\">\"zEwZTAxLTk5MWUtNDFiNC1iZWRmLTJjNGI4M2ZiNDBmNDpAVEstMDMzMTBlMDEtOTkxZS00MW\"</span>\n    <span class=\"s2\">\"I0LWJlZGYtMmM0YjgzZmI0MGY0' -H 'Connection: keep-alive' -H 'Referer: http\"</span>\n    <span class=\"s2\">\"://quotes.toscrape.com/scroll' -H 'Cache-Control: max-age=0'\"</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["$ scrapy shell \"quotes.toscrape.com/scroll\"\n(...)\n>>> view(response)\n", "import scrapy\nimport json\n\n\nclass QuoteSpider(scrapy.Spider):\n    name = 'quote'\n    allowed_domains = ['quotes.toscrape.com']\n    page = 1\n    start_urls = ['https://quotes.toscrape.com/api/quotes?page=1']\n\n    def parse(self, response):\n        data = json.loads(response.text)\n        for quote in data[\"quotes\"]:\n            yield {\"quote\": quote[\"text\"]}\n        if data[\"has_next\"]:\n            self.page += 1\n            url = f\"https://quotes.toscrape.com/api/quotes?page={self.page}\"\n            yield scrapy.Request(url=url, callback=self.parse)\n", "from scrapy import Request\n\nrequest = Request.from_curl(\n    \"curl 'https://quotes.toscrape.com/api/quotes?page=1' -H 'User-Agent: Mozil\"\n    \"la/5.0 (X11; Linux x86_64; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Acce\"\n    \"pt: */*' -H 'Accept-Language: ca,en-US;q=0.7,en;q=0.3' --compressed -H 'X\"\n    \"-Requested-With: XMLHttpRequest' -H 'Proxy-Authorization: Basic QFRLLTAzM\"\n    \"zEwZTAxLTk5MWUtNDFiNC1iZWRmLTJjNGI4M2ZiNDBmNDpAVEstMDMzMTBlMDEtOTkxZS00MW\"\n    \"I0LWJlZGYtMmM0YjgzZmI0MGY0' -H 'Connection: keep-alive' -H 'Referer: http\"\n    \"://quotes.toscrape.com/scroll' -H 'Cache-Control: max-age=0'\")\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/dynamic-content.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Selecting dynamically-loaded content", "header_href": "#selecting-dynamically-loaded-content", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">fetch</span> <span class=\"o\">--</span><span class=\"n\">nolog</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span> <span class=\"o\">&gt;</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">html</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">selector</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s1\">'html'</span><span class=\"p\">])</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">pattern</span> <span class=\"o\">=</span> <span class=\"sa\">r</span><span class=\"s1\">'\\bvar\\s+data\\s*=\\s*(\\{.*?\\})\\s*;\\s*\\n'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">json_data</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'script::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re_first</span><span class=\"p\">(</span><span class=\"n\">pattern</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">json_data</span><span class=\"p\">)</span>\n<span class=\"go\">{'field': 'value'}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">chompjs</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">javascript</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'script::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">chompjs</span><span class=\"o\">.</span><span class=\"n\">parse_js_object</span><span class=\"p\">(</span><span class=\"n\">javascript</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">data</span>\n<span class=\"go\">{'field': 'value', 'secondField': 'second value'}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">js2xml</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">lxml.etree</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">parsel</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">javascript</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'script::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xml</span> <span class=\"o\">=</span> <span class=\"n\">lxml</span><span class=\"o\">.</span><span class=\"n\">etree</span><span class=\"o\">.</span><span class=\"n\">tostring</span><span class=\"p\">(</span><span class=\"n\">js2xml</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"n\">javascript</span><span class=\"p\">),</span> <span class=\"n\">encoding</span><span class=\"o\">=</span><span class=\"s1\">'unicode'</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">selector</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">xml</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'var[name=\"data\"]'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'&lt;var name=\"data\"&gt;&lt;object&gt;&lt;property name=\"field\"&gt;&lt;string&gt;value&lt;/string&gt;&lt;/property&gt;&lt;/object&gt;&lt;/var&gt;'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">playwright.async_api</span> <span class=\"kn\">import</span> <span class=\"n\">async_playwright</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">PlaywrightSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"playwright\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"data:,\"</span><span class=\"p\">]</span>  <span class=\"c1\"># avoid using the default Scrapy downloader</span>\n\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">async</span> <span class=\"k\">with</span> <span class=\"n\">async_playwright</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"n\">pw</span><span class=\"p\">:</span>\n            <span class=\"n\">browser</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">pw</span><span class=\"o\">.</span><span class=\"n\">chromium</span><span class=\"o\">.</span><span class=\"n\">launch</span><span class=\"p\">()</span>\n            <span class=\"n\">page</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">browser</span><span class=\"o\">.</span><span class=\"n\">new_page</span><span class=\"p\">()</span>\n            <span class=\"k\">await</span> <span class=\"n\">page</span><span class=\"o\">.</span><span class=\"n\">goto</span><span class=\"p\">(</span><span class=\"s2\">\"https:/example.org\"</span><span class=\"p\">)</span>\n            <span class=\"n\">title</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">page</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">()</span>\n            <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"s2\">\"title\"</span><span class=\"p\">:</span> <span class=\"n\">title</span><span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["scrapy fetch --nolog https://example.com > response.html\n", "data = json.loads(response.text)\n", "selector = Selector(data['html'])\n", ">>> pattern = r'\\bvar\\s+data\\s*=\\s*(\\{.*?\\})\\s*;\\s*\\n'\n>>> json_data = response.css('script::text').re_first(pattern)\n>>> json.loads(json_data)\n{'field': 'value'}\n", ">>> import chompjs\n>>> javascript = response.css('script::text').get()\n>>> data = chompjs.parse_js_object(javascript)\n>>> data\n{'field': 'value', 'secondField': 'second value'}\n", ">>> import js2xml\n>>> import lxml.etree\n>>> from parsel import Selector\n>>> javascript = response.css('script::text').get()\n>>> xml = lxml.etree.tostring(js2xml.parse(javascript), encoding='unicode')\n>>> selector = Selector(text=xml)\n>>> selector.css('var[name=\"data\"]').get()\n'<var name=\"data\"><object><property name=\"field\"><string>value</string></property></object></var>'\n", "import scrapy\nfrom playwright.async_api import async_playwright\n\nclass PlaywrightSpider(scrapy.Spider):\n    name = \"playwright\"\n    start_urls = [\"data:,\"]  # avoid using the default Scrapy downloader\n\n    async def parse(self, response):\n        async with async_playwright() as pw:\n            browser = await pw.chromium.launch()\n            page = await browser.new_page()\n            await page.goto(\"https:/example.org\")\n            title = await page.title()\n            return {\"title\": title}\n"], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/dynamic-content.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Finding the data source", "header_href": "#finding-the-data-source", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/dynamic-content.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Inspecting the source code of a webpage", "header_href": "#inspecting-the-source-code-of-a-webpage", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">fetch</span> <span class=\"o\">--</span><span class=\"n\">nolog</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span> <span class=\"o\">&gt;</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">html</span>\n</pre></div>"], "codes_text": ["scrapy fetch --nolog https://example.com > response.html\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/dynamic-content.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Reproducing requests", "header_href": "#reproducing-requests", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/dynamic-content.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Handling different response formats", "header_href": "#handling-different-response-formats", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">selector</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s1\">'html'</span><span class=\"p\">])</span>\n</pre></div>"], "codes_text": ["data = json.loads(response.text)\n", "selector = Selector(data['html'])\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/dynamic-content.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Parsing JavaScript code", "header_href": "#parsing-javascript-code", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">pattern</span> <span class=\"o\">=</span> <span class=\"sa\">r</span><span class=\"s1\">'\\bvar\\s+data\\s*=\\s*(\\{.*?\\})\\s*;\\s*\\n'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">json_data</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'script::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">re_first</span><span class=\"p\">(</span><span class=\"n\">pattern</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">json_data</span><span class=\"p\">)</span>\n<span class=\"go\">{'field': 'value'}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">chompjs</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">javascript</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'script::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">chompjs</span><span class=\"o\">.</span><span class=\"n\">parse_js_object</span><span class=\"p\">(</span><span class=\"n\">javascript</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">data</span>\n<span class=\"go\">{'field': 'value', 'secondField': 'second value'}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">js2xml</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">lxml.etree</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">parsel</span> <span class=\"kn\">import</span> <span class=\"n\">Selector</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">javascript</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'script::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">xml</span> <span class=\"o\">=</span> <span class=\"n\">lxml</span><span class=\"o\">.</span><span class=\"n\">etree</span><span class=\"o\">.</span><span class=\"n\">tostring</span><span class=\"p\">(</span><span class=\"n\">js2xml</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"n\">javascript</span><span class=\"p\">),</span> <span class=\"n\">encoding</span><span class=\"o\">=</span><span class=\"s1\">'unicode'</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">selector</span> <span class=\"o\">=</span> <span class=\"n\">Selector</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">=</span><span class=\"n\">xml</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">selector</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'var[name=\"data\"]'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()</span>\n<span class=\"go\">'&lt;var name=\"data\"&gt;&lt;object&gt;&lt;property name=\"field\"&gt;&lt;string&gt;value&lt;/string&gt;&lt;/property&gt;&lt;/object&gt;&lt;/var&gt;'</span>\n</pre></div>"], "codes_text": [">>> pattern = r'\\bvar\\s+data\\s*=\\s*(\\{.*?\\})\\s*;\\s*\\n'\n>>> json_data = response.css('script::text').re_first(pattern)\n>>> json.loads(json_data)\n{'field': 'value'}\n", ">>> import chompjs\n>>> javascript = response.css('script::text').get()\n>>> data = chompjs.parse_js_object(javascript)\n>>> data\n{'field': 'value', 'secondField': 'second value'}\n", ">>> import js2xml\n>>> import lxml.etree\n>>> from parsel import Selector\n>>> javascript = response.css('script::text').get()\n>>> xml = lxml.etree.tostring(js2xml.parse(javascript), encoding='unicode')\n>>> selector = Selector(text=xml)\n>>> selector.css('var[name=\"data\"]').get()\n'<var name=\"data\"><object><property name=\"field\"><string>value</string></property></object></var>'\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/dynamic-content.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Pre-rendering JavaScript", "header_href": "#pre-rendering-javascript", "codes": [], "codes_text": [], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/dynamic-content.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Using a headless browser", "header_href": "#using-a-headless-browser", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">playwright.async_api</span> <span class=\"kn\">import</span> <span class=\"n\">async_playwright</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">PlaywrightSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"playwright\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"data:,\"</span><span class=\"p\">]</span>  <span class=\"c1\"># avoid using the default Scrapy downloader</span>\n\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">async</span> <span class=\"k\">with</span> <span class=\"n\">async_playwright</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"n\">pw</span><span class=\"p\">:</span>\n            <span class=\"n\">browser</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">pw</span><span class=\"o\">.</span><span class=\"n\">chromium</span><span class=\"o\">.</span><span class=\"n\">launch</span><span class=\"p\">()</span>\n            <span class=\"n\">page</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">browser</span><span class=\"o\">.</span><span class=\"n\">new_page</span><span class=\"p\">()</span>\n            <span class=\"k\">await</span> <span class=\"n\">page</span><span class=\"o\">.</span><span class=\"n\">goto</span><span class=\"p\">(</span><span class=\"s2\">\"https:/example.org\"</span><span class=\"p\">)</span>\n            <span class=\"n\">title</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">page</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">()</span>\n            <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"s2\">\"title\"</span><span class=\"p\">:</span> <span class=\"n\">title</span><span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["import scrapy\nfrom playwright.async_api import async_playwright\n\nclass PlaywrightSpider(scrapy.Spider):\n    name = \"playwright\"\n    start_urls = [\"data:,\"]  # avoid using the default Scrapy downloader\n\n    async def parse(self, response):\n        async with async_playwright() as pw:\n            browser = await pw.chromium.launch()\n            page = await browser.new_page()\n            await page.goto(\"https:/example.org\")\n            title = await page.title()\n            return {\"title\": title}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/leaks.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Debugging memory leaks", "header_href": "#debugging-memory-leaks", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">telnet</span> <span class=\"n\">localhost</span> <span class=\"mi\">6023</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">prefs</span><span class=\"p\">()</span>\n<span class=\"n\">Live</span> <span class=\"n\">References</span>\n\n<span class=\"n\">ExampleSpider</span>                       <span class=\"mi\">1</span>   <span class=\"n\">oldest</span><span class=\"p\">:</span> <span class=\"mi\">15</span><span class=\"n\">s</span> <span class=\"n\">ago</span>\n<span class=\"n\">HtmlResponse</span>                       <span class=\"mi\">10</span>   <span class=\"n\">oldest</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"n\">s</span> <span class=\"n\">ago</span>\n<span class=\"n\">Selector</span>                            <span class=\"mi\">2</span>   <span class=\"n\">oldest</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"n\">s</span> <span class=\"n\">ago</span>\n<span class=\"n\">FormRequest</span>                       <span class=\"mi\">878</span>   <span class=\"n\">oldest</span><span class=\"p\">:</span> <span class=\"mi\">7</span><span class=\"n\">s</span> <span class=\"n\">ago</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">return</span> <span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"http://www.somenastyspider.com/product.php?pid=</span><span class=\"si\">{</span><span class=\"n\">product_id</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">,</span>\n               <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">,</span> <span class=\"n\">cb_kwargs</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'referer'</span><span class=\"p\">:</span> <span class=\"n\">response</span><span class=\"p\">})</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">prefs</span><span class=\"p\">()</span>\n<span class=\"go\">Live References</span>\n\n<span class=\"go\">SomenastySpider                     1   oldest: 15s ago</span>\n<span class=\"go\">HtmlResponse                     3890   oldest: 265s ago</span>\n<span class=\"go\">Selector                            2   oldest: 0s ago</span>\n<span class=\"go\">Request                          3878   oldest: 250s ago</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.trackref</span> <span class=\"kn\">import</span> <span class=\"n\">get_oldest</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">r</span> <span class=\"o\">=</span> <span class=\"n\">get_oldest</span><span class=\"p\">(</span><span class=\"s1\">'HtmlResponse'</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">url</span>\n<span class=\"go\">'http://www.somenastyspider.com/product.php?pid=123'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.trackref</span> <span class=\"kn\">import</span> <span class=\"n\">iter_all</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"p\">[</span><span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">url</span> <span class=\"k\">for</span> <span class=\"n\">r</span> <span class=\"ow\">in</span> <span class=\"n\">iter_all</span><span class=\"p\">(</span><span class=\"s1\">'HtmlResponse'</span><span class=\"p\">)]</span>\n<span class=\"go\">['http://www.somenastyspider.com/product.php?pid=123',</span>\n<span class=\"go\"> 'http://www.somenastyspider.com/product.php?pid=584',</span>\n<span class=\"go\">...]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">Spider</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">prefs</span><span class=\"p\">(</span><span class=\"n\">ignore</span><span class=\"o\">=</span><span class=\"n\">Spider</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">Pympler</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">pympler</span> <span class=\"kn\">import</span> <span class=\"n\">muppy</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">all_objects</span> <span class=\"o\">=</span> <span class=\"n\">muppy</span><span class=\"o\">.</span><span class=\"n\">get_objects</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">all_objects</span><span class=\"p\">)</span>\n<span class=\"go\">28667</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">pympler</span> <span class=\"kn\">import</span> <span class=\"n\">summary</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">suml</span> <span class=\"o\">=</span> <span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">summarize</span><span class=\"p\">(</span><span class=\"n\">all_objects</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">print_</span><span class=\"p\">(</span><span class=\"n\">suml</span><span class=\"p\">)</span>\n<span class=\"go\">                               types |   # objects |   total size</span>\n<span class=\"go\">==================================== | =========== | ============</span>\n<span class=\"go\">                         &lt;class 'str |        9822 |      1.10 MB</span>\n<span class=\"go\">                        &lt;class 'dict |        1658 |    856.62 KB</span>\n<span class=\"go\">                        &lt;class 'type |         436 |    443.60 KB</span>\n<span class=\"go\">                        &lt;class 'code |        2974 |    419.56 KB</span>\n<span class=\"go\">          &lt;class '_io.BufferedWriter |           2 |    256.34 KB</span>\n<span class=\"go\">                         &lt;class 'set |         420 |    159.88 KB</span>\n<span class=\"go\">          &lt;class '_io.BufferedReader |           1 |    128.17 KB</span>\n<span class=\"go\">          &lt;class 'wrapper_descriptor |        1130 |     88.28 KB</span>\n<span class=\"go\">                       &lt;class 'tuple |        1304 |     86.57 KB</span>\n<span class=\"go\">                     &lt;class 'weakref |        1013 |     79.14 KB</span>\n<span class=\"go\">  &lt;class 'builtin_function_or_method |         958 |     67.36 KB</span>\n<span class=\"go\">           &lt;class 'method_descriptor |         865 |     60.82 KB</span>\n<span class=\"go\">                 &lt;class 'abc.ABCMeta |          62 |     59.96 KB</span>\n<span class=\"go\">                        &lt;class 'list |         446 |     58.52 KB</span>\n<span class=\"go\">                         &lt;class 'int |        1425 |     43.20 KB</span>\n</pre></div>"], "codes_text": ["telnet localhost 6023\n\n>>> prefs()\nLive References\n\nExampleSpider                       1   oldest: 15s ago\nHtmlResponse                       10   oldest: 1s ago\nSelector                            2   oldest: 0s ago\nFormRequest                       878   oldest: 7s ago\n", "return Request(f\"http://www.somenastyspider.com/product.php?pid={product_id}\",\n               callback=self.parse, cb_kwargs={'referer': response})\n", ">>> prefs()\nLive References\n\nSomenastySpider                     1   oldest: 15s ago\nHtmlResponse                     3890   oldest: 265s ago\nSelector                            2   oldest: 0s ago\nRequest                          3878   oldest: 250s ago\n", ">>> from scrapy.utils.trackref import get_oldest\n>>> r = get_oldest('HtmlResponse')\n>>> r.url\n'http://www.somenastyspider.com/product.php?pid=123'\n", ">>> from scrapy.utils.trackref import iter_all\n>>> [r.url for r in iter_all('HtmlResponse')]\n['http://www.somenastyspider.com/product.php?pid=123',\n 'http://www.somenastyspider.com/product.php?pid=584',\n...]\n", ">>> from scrapy.spiders import Spider\n>>> prefs(ignore=Spider)\n", "pip install Pympler\n", ">>> from pympler import muppy\n>>> all_objects = muppy.get_objects()\n>>> len(all_objects)\n28667\n>>> from pympler import summary\n>>> suml = summary.summarize(all_objects)\n>>> summary.print_(suml)\n                               types |   # objects |   total size\n==================================== | =========== | ============\n                         <class 'str |        9822 |      1.10 MB\n                        <class 'dict |        1658 |    856.62 KB\n                        <class 'type |         436 |    443.60 KB\n                        <class 'code |        2974 |    419.56 KB\n          <class '_io.BufferedWriter |           2 |    256.34 KB\n                         <class 'set |         420 |    159.88 KB\n          <class '_io.BufferedReader |           1 |    128.17 KB\n          <class 'wrapper_descriptor |        1130 |     88.28 KB\n                       <class 'tuple |        1304 |     86.57 KB\n                     <class 'weakref |        1013 |     79.14 KB\n  <class 'builtin_function_or_method |         958 |     67.36 KB\n           <class 'method_descriptor |         865 |     60.82 KB\n                 <class 'abc.ABCMeta |          62 |     59.96 KB\n                        <class 'list |         446 |     58.52 KB\n                         <class 'int |        1425 |     43.20 KB\n"], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/leaks.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Common causes of memory leaks", "header_href": "#common-causes-of-memory-leaks", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/leaks.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Too Many Requests?", "header_href": "#too-many-requests", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/leaks.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Debugging memory leaks with trackref", "header_href": "#debugging-memory-leaks-with-trackref", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">telnet</span> <span class=\"n\">localhost</span> <span class=\"mi\">6023</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">prefs</span><span class=\"p\">()</span>\n<span class=\"n\">Live</span> <span class=\"n\">References</span>\n\n<span class=\"n\">ExampleSpider</span>                       <span class=\"mi\">1</span>   <span class=\"n\">oldest</span><span class=\"p\">:</span> <span class=\"mi\">15</span><span class=\"n\">s</span> <span class=\"n\">ago</span>\n<span class=\"n\">HtmlResponse</span>                       <span class=\"mi\">10</span>   <span class=\"n\">oldest</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"n\">s</span> <span class=\"n\">ago</span>\n<span class=\"n\">Selector</span>                            <span class=\"mi\">2</span>   <span class=\"n\">oldest</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"n\">s</span> <span class=\"n\">ago</span>\n<span class=\"n\">FormRequest</span>                       <span class=\"mi\">878</span>   <span class=\"n\">oldest</span><span class=\"p\">:</span> <span class=\"mi\">7</span><span class=\"n\">s</span> <span class=\"n\">ago</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">return</span> <span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"http://www.somenastyspider.com/product.php?pid=</span><span class=\"si\">{</span><span class=\"n\">product_id</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">,</span>\n               <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">,</span> <span class=\"n\">cb_kwargs</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'referer'</span><span class=\"p\">:</span> <span class=\"n\">response</span><span class=\"p\">})</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">prefs</span><span class=\"p\">()</span>\n<span class=\"go\">Live References</span>\n\n<span class=\"go\">SomenastySpider                     1   oldest: 15s ago</span>\n<span class=\"go\">HtmlResponse                     3890   oldest: 265s ago</span>\n<span class=\"go\">Selector                            2   oldest: 0s ago</span>\n<span class=\"go\">Request                          3878   oldest: 250s ago</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.trackref</span> <span class=\"kn\">import</span> <span class=\"n\">get_oldest</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">r</span> <span class=\"o\">=</span> <span class=\"n\">get_oldest</span><span class=\"p\">(</span><span class=\"s1\">'HtmlResponse'</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">url</span>\n<span class=\"go\">'http://www.somenastyspider.com/product.php?pid=123'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.trackref</span> <span class=\"kn\">import</span> <span class=\"n\">iter_all</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"p\">[</span><span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">url</span> <span class=\"k\">for</span> <span class=\"n\">r</span> <span class=\"ow\">in</span> <span class=\"n\">iter_all</span><span class=\"p\">(</span><span class=\"s1\">'HtmlResponse'</span><span class=\"p\">)]</span>\n<span class=\"go\">['http://www.somenastyspider.com/product.php?pid=123',</span>\n<span class=\"go\"> 'http://www.somenastyspider.com/product.php?pid=584',</span>\n<span class=\"go\">...]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">Spider</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">prefs</span><span class=\"p\">(</span><span class=\"n\">ignore</span><span class=\"o\">=</span><span class=\"n\">Spider</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["telnet localhost 6023\n\n>>> prefs()\nLive References\n\nExampleSpider                       1   oldest: 15s ago\nHtmlResponse                       10   oldest: 1s ago\nSelector                            2   oldest: 0s ago\nFormRequest                       878   oldest: 7s ago\n", "return Request(f\"http://www.somenastyspider.com/product.php?pid={product_id}\",\n               callback=self.parse, cb_kwargs={'referer': response})\n", ">>> prefs()\nLive References\n\nSomenastySpider                     1   oldest: 15s ago\nHtmlResponse                     3890   oldest: 265s ago\nSelector                            2   oldest: 0s ago\nRequest                          3878   oldest: 250s ago\n", ">>> from scrapy.utils.trackref import get_oldest\n>>> r = get_oldest('HtmlResponse')\n>>> r.url\n'http://www.somenastyspider.com/product.php?pid=123'\n", ">>> from scrapy.utils.trackref import iter_all\n>>> [r.url for r in iter_all('HtmlResponse')]\n['http://www.somenastyspider.com/product.php?pid=123',\n 'http://www.somenastyspider.com/product.php?pid=584',\n...]\n", ">>> from scrapy.spiders import Spider\n>>> prefs(ignore=Spider)\n"], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/leaks.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Which objects are tracked?", "header_href": "#which-objects-are-tracked", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/leaks.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "A real example", "header_href": "#a-real-example", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">return</span> <span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"http://www.somenastyspider.com/product.php?pid=</span><span class=\"si\">{</span><span class=\"n\">product_id</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">,</span>\n               <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">,</span> <span class=\"n\">cb_kwargs</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'referer'</span><span class=\"p\">:</span> <span class=\"n\">response</span><span class=\"p\">})</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">prefs</span><span class=\"p\">()</span>\n<span class=\"go\">Live References</span>\n\n<span class=\"go\">SomenastySpider                     1   oldest: 15s ago</span>\n<span class=\"go\">HtmlResponse                     3890   oldest: 265s ago</span>\n<span class=\"go\">Selector                            2   oldest: 0s ago</span>\n<span class=\"go\">Request                          3878   oldest: 250s ago</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.trackref</span> <span class=\"kn\">import</span> <span class=\"n\">get_oldest</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">r</span> <span class=\"o\">=</span> <span class=\"n\">get_oldest</span><span class=\"p\">(</span><span class=\"s1\">'HtmlResponse'</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">url</span>\n<span class=\"go\">'http://www.somenastyspider.com/product.php?pid=123'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.trackref</span> <span class=\"kn\">import</span> <span class=\"n\">iter_all</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"p\">[</span><span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">url</span> <span class=\"k\">for</span> <span class=\"n\">r</span> <span class=\"ow\">in</span> <span class=\"n\">iter_all</span><span class=\"p\">(</span><span class=\"s1\">'HtmlResponse'</span><span class=\"p\">)]</span>\n<span class=\"go\">['http://www.somenastyspider.com/product.php?pid=123',</span>\n<span class=\"go\"> 'http://www.somenastyspider.com/product.php?pid=584',</span>\n<span class=\"go\">...]</span>\n</pre></div>"], "codes_text": ["return Request(f\"http://www.somenastyspider.com/product.php?pid={product_id}\",\n               callback=self.parse, cb_kwargs={'referer': response})\n", ">>> prefs()\nLive References\n\nSomenastySpider                     1   oldest: 15s ago\nHtmlResponse                     3890   oldest: 265s ago\nSelector                            2   oldest: 0s ago\nRequest                          3878   oldest: 250s ago\n", ">>> from scrapy.utils.trackref import get_oldest\n>>> r = get_oldest('HtmlResponse')\n>>> r.url\n'http://www.somenastyspider.com/product.php?pid=123'\n", ">>> from scrapy.utils.trackref import iter_all\n>>> [r.url for r in iter_all('HtmlResponse')]\n['http://www.somenastyspider.com/product.php?pid=123',\n 'http://www.somenastyspider.com/product.php?pid=584',\n...]\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/leaks.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Too many spiders?", "header_href": "#too-many-spiders", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">Spider</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">prefs</span><span class=\"p\">(</span><span class=\"n\">ignore</span><span class=\"o\">=</span><span class=\"n\">Spider</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": [">>> from scrapy.spiders import Spider\n>>> prefs(ignore=Spider)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/leaks.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "scrapy.utils.trackref module", "header_href": "#scrapy-utils-trackref-module", "codes": [], "codes_text": [], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/leaks.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Debugging memory leaks with muppy", "header_href": "#debugging-memory-leaks-with-muppy", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">Pympler</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">pympler</span> <span class=\"kn\">import</span> <span class=\"n\">muppy</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">all_objects</span> <span class=\"o\">=</span> <span class=\"n\">muppy</span><span class=\"o\">.</span><span class=\"n\">get_objects</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">all_objects</span><span class=\"p\">)</span>\n<span class=\"go\">28667</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">pympler</span> <span class=\"kn\">import</span> <span class=\"n\">summary</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">suml</span> <span class=\"o\">=</span> <span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">summarize</span><span class=\"p\">(</span><span class=\"n\">all_objects</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">print_</span><span class=\"p\">(</span><span class=\"n\">suml</span><span class=\"p\">)</span>\n<span class=\"go\">                               types |   # objects |   total size</span>\n<span class=\"go\">==================================== | =========== | ============</span>\n<span class=\"go\">                         &lt;class 'str |        9822 |      1.10 MB</span>\n<span class=\"go\">                        &lt;class 'dict |        1658 |    856.62 KB</span>\n<span class=\"go\">                        &lt;class 'type |         436 |    443.60 KB</span>\n<span class=\"go\">                        &lt;class 'code |        2974 |    419.56 KB</span>\n<span class=\"go\">          &lt;class '_io.BufferedWriter |           2 |    256.34 KB</span>\n<span class=\"go\">                         &lt;class 'set |         420 |    159.88 KB</span>\n<span class=\"go\">          &lt;class '_io.BufferedReader |           1 |    128.17 KB</span>\n<span class=\"go\">          &lt;class 'wrapper_descriptor |        1130 |     88.28 KB</span>\n<span class=\"go\">                       &lt;class 'tuple |        1304 |     86.57 KB</span>\n<span class=\"go\">                     &lt;class 'weakref |        1013 |     79.14 KB</span>\n<span class=\"go\">  &lt;class 'builtin_function_or_method |         958 |     67.36 KB</span>\n<span class=\"go\">           &lt;class 'method_descriptor |         865 |     60.82 KB</span>\n<span class=\"go\">                 &lt;class 'abc.ABCMeta |          62 |     59.96 KB</span>\n<span class=\"go\">                        &lt;class 'list |         446 |     58.52 KB</span>\n<span class=\"go\">                         &lt;class 'int |        1425 |     43.20 KB</span>\n</pre></div>"], "codes_text": ["pip install Pympler\n", ">>> from pympler import muppy\n>>> all_objects = muppy.get_objects()\n>>> len(all_objects)\n28667\n>>> from pympler import summary\n>>> suml = summary.summarize(all_objects)\n>>> summary.print_(suml)\n                               types |   # objects |   total size\n==================================== | =========== | ============\n                         <class 'str |        9822 |      1.10 MB\n                        <class 'dict |        1658 |    856.62 KB\n                        <class 'type |         436 |    443.60 KB\n                        <class 'code |        2974 |    419.56 KB\n          <class '_io.BufferedWriter |           2 |    256.34 KB\n                         <class 'set |         420 |    159.88 KB\n          <class '_io.BufferedReader |           1 |    128.17 KB\n          <class 'wrapper_descriptor |        1130 |     88.28 KB\n                       <class 'tuple |        1304 |     86.57 KB\n                     <class 'weakref |        1013 |     79.14 KB\n  <class 'builtin_function_or_method |         958 |     67.36 KB\n           <class 'method_descriptor |         865 |     60.82 KB\n                 <class 'abc.ABCMeta |          62 |     59.96 KB\n                        <class 'list |         446 |     58.52 KB\n                         <class 'int |        1425 |     43.20 KB\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/leaks.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Leaks without leaks", "header_href": "#leaks-without-leaks", "codes": [], "codes_text": [], "index": 10}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Downloading and processing files and images", "header_href": "#downloading-and-processing-files-and-images", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">ITEM_PIPELINES</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'scrapy.pipelines.images.ImagesPipeline'</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">ITEM_PIPELINES</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'scrapy.pipelines.files.FilesPipeline'</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">FILES_STORE</span> <span class=\"o\">=</span> <span class=\"s1\">'/path/to/valid/dir'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_STORE</span> <span class=\"o\">=</span> <span class=\"s1\">'/path/to/valid/dir'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">image</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">3</span><span class=\"n\">afec3b4765f8f0a07b78f98c07b83f013567a0a</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">3</span><span class=\"n\">afec3b4765f8f0a07b78f98c07b83f013567a0a</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">product</span><span class=\"o\">/</span><span class=\"n\">images</span><span class=\"o\">/</span><span class=\"n\">large</span><span class=\"o\">/</span><span class=\"n\">front</span><span class=\"o\">/</span><span class=\"mi\">0000000004166</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">00</span><span class=\"n\">b08510e4_front</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">hashlib</span>\n<span class=\"kn\">from</span> <span class=\"nn\">os.path</span> <span class=\"kn\">import</span> <span class=\"n\">splitext</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">file_path</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n    <span class=\"n\">image_url_hash</span> <span class=\"o\">=</span> <span class=\"n\">hashlib</span><span class=\"o\">.</span><span class=\"n\">shake_256</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">())</span><span class=\"o\">.</span><span class=\"n\">hexdigest</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n    <span class=\"n\">image_perspective</span> <span class=\"o\">=</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s1\">'/'</span><span class=\"p\">)[</span><span class=\"o\">-</span><span class=\"mi\">2</span><span class=\"p\">]</span>\n    <span class=\"n\">image_filename</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">'</span><span class=\"si\">{</span><span class=\"n\">image_url_hash</span><span class=\"si\">}</span><span class=\"s1\">_</span><span class=\"si\">{</span><span class=\"n\">image_perspective</span><span class=\"si\">}</span><span class=\"s1\">.jpg'</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">image_filename</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">IMAGES_STORE</span><span class=\"o\">&gt;/</span><span class=\"n\">full</span><span class=\"o\">/&lt;</span><span class=\"n\">FILE_NAME</span><span class=\"o\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">ftp</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">username</span><span class=\"p\">:</span><span class=\"n\">password</span><span class=\"nd\">@address</span><span class=\"p\">:</span><span class=\"n\">port</span><span class=\"o\">/</span><span class=\"n\">path</span>\n<span class=\"n\">ftp</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">address</span><span class=\"p\">:</span><span class=\"n\">port</span><span class=\"o\">/</span><span class=\"n\">path</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_STORE</span> <span class=\"o\">=</span> <span class=\"s1\">'s3://bucket/images'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_STORE_S3_ACL</span> <span class=\"o\">=</span> <span class=\"s1\">'public-read'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">AWS_ENDPOINT_URL</span> <span class=\"o\">=</span> <span class=\"s1\">'http://minio.example.com:9000'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">AWS_USE_SSL</span> <span class=\"o\">=</span> <span class=\"kc\">False</span> <span class=\"c1\"># or True (None by default)</span>\n<span class=\"n\">AWS_VERIFY</span> <span class=\"o\">=</span> <span class=\"kc\">False</span> <span class=\"c1\"># or True (None by default)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_STORE</span> <span class=\"o\">=</span> <span class=\"s1\">'gs://bucket/images/'</span>\n<span class=\"n\">GCS_PROJECT_ID</span> <span class=\"o\">=</span> <span class=\"s1\">'project_id'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_STORE_GCS_ACL</span> <span class=\"o\">=</span> <span class=\"s1\">'publicRead'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyItem</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"c1\"># ... other item fields ...</span>\n    <span class=\"n\">image_urls</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">images</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">FILES_URLS_FIELD</span> <span class=\"o\">=</span> <span class=\"s1\">'field_name_for_your_files_urls'</span>\n<span class=\"n\">FILES_RESULT_FIELD</span> <span class=\"o\">=</span> <span class=\"s1\">'field_name_for_your_processed_files'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_URLS_FIELD</span> <span class=\"o\">=</span> <span class=\"s1\">'field_name_for_your_images_urls'</span>\n<span class=\"n\">IMAGES_RESULT_FIELD</span> <span class=\"o\">=</span> <span class=\"s1\">'field_name_for_your_processed_images'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"c1\"># 120 days of delay for files expiration</span>\n<span class=\"n\">FILES_EXPIRES</span> <span class=\"o\">=</span> <span class=\"mi\">120</span>\n\n<span class=\"c1\"># 30 days of delay for images expiration</span>\n<span class=\"n\">IMAGES_EXPIRES</span> <span class=\"o\">=</span> <span class=\"mi\">30</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_THUMBS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'small'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"mi\">50</span><span class=\"p\">,</span> <span class=\"mi\">50</span><span class=\"p\">),</span>\n    <span class=\"s1\">'big'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"mi\">270</span><span class=\"p\">,</span> <span class=\"mi\">270</span><span class=\"p\">),</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">IMAGES_STORE</span><span class=\"o\">&gt;/</span><span class=\"n\">thumbs</span><span class=\"o\">/&lt;</span><span class=\"n\">size_name</span><span class=\"o\">&gt;/&lt;</span><span class=\"n\">image_id</span><span class=\"o\">&gt;.</span><span class=\"n\">jpg</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">IMAGES_STORE</span><span class=\"o\">&gt;/</span><span class=\"n\">full</span><span class=\"o\">/</span><span class=\"mi\">63</span><span class=\"n\">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n<span class=\"o\">&lt;</span><span class=\"n\">IMAGES_STORE</span><span class=\"o\">&gt;/</span><span class=\"n\">thumbs</span><span class=\"o\">/</span><span class=\"n\">small</span><span class=\"o\">/</span><span class=\"mi\">63</span><span class=\"n\">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n<span class=\"o\">&lt;</span><span class=\"n\">IMAGES_STORE</span><span class=\"o\">&gt;/</span><span class=\"n\">thumbs</span><span class=\"o\">/</span><span class=\"n\">big</span><span class=\"o\">/</span><span class=\"mi\">63</span><span class=\"n\">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_MIN_HEIGHT</span> <span class=\"o\">=</span> <span class=\"mi\">110</span>\n<span class=\"n\">IMAGES_MIN_WIDTH</span> <span class=\"o\">=</span> <span class=\"mi\">110</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">MEDIA_ALLOW_REDIRECTS</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">from</span> <span class=\"nn\">urllib.parse</span> <span class=\"kn\">import</span> <span class=\"n\">urlparse</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.pipelines.files</span> <span class=\"kn\">import</span> <span class=\"n\">FilesPipeline</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyFilesPipeline</span><span class=\"p\">(</span><span class=\"n\">FilesPipeline</span><span class=\"p\">):</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">file_path</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"s1\">'files/'</span> <span class=\"o\">+</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">basename</span><span class=\"p\">(</span><span class=\"n\">urlparse</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">get_media_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"p\">):</span>\n    <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n    <span class=\"k\">for</span> <span class=\"n\">file_url</span> <span class=\"ow\">in</span> <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'file_urls'</span><span class=\"p\">]:</span>\n        <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">file_url</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">[(</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n  <span class=\"p\">{</span><span class=\"s1\">'checksum'</span><span class=\"p\">:</span> <span class=\"s1\">'2b00042f7481c7b056c4b410d28f33cf'</span><span class=\"p\">,</span>\n   <span class=\"s1\">'path'</span><span class=\"p\">:</span> <span class=\"s1\">'full/0a79c461a4062ac383dc4fade7bc09f1384a3910.jpg'</span><span class=\"p\">,</span>\n   <span class=\"s1\">'url'</span><span class=\"p\">:</span> <span class=\"s1\">'http://www.example.com/files/product1.pdf'</span><span class=\"p\">,</span>\n   <span class=\"s1\">'status'</span><span class=\"p\">:</span> <span class=\"s1\">'downloaded'</span><span class=\"p\">}),</span>\n <span class=\"p\">(</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n  <span class=\"n\">Failure</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">))]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">DropItem</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">item_completed</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">results</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"p\">):</span>\n    <span class=\"n\">file_paths</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">[</span><span class=\"s1\">'path'</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">ok</span><span class=\"p\">,</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"n\">results</span> <span class=\"k\">if</span> <span class=\"n\">ok</span><span class=\"p\">]</span>\n    <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">file_paths</span><span class=\"p\">:</span>\n        <span class=\"k\">raise</span> <span class=\"n\">DropItem</span><span class=\"p\">(</span><span class=\"s2\">\"Item contains no files\"</span><span class=\"p\">)</span>\n    <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n    <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'file_paths'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">file_paths</span>\n    <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">from</span> <span class=\"nn\">urllib.parse</span> <span class=\"kn\">import</span> <span class=\"n\">urlparse</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.pipelines.images</span> <span class=\"kn\">import</span> <span class=\"n\">ImagesPipeline</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyImagesPipeline</span><span class=\"p\">(</span><span class=\"n\">ImagesPipeline</span><span class=\"p\">):</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">file_path</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"s1\">'files/'</span> <span class=\"o\">+</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">basename</span><span class=\"p\">(</span><span class=\"n\">urlparse</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">DropItem</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.pipelines.images</span> <span class=\"kn\">import</span> <span class=\"n\">ImagesPipeline</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyImagesPipeline</span><span class=\"p\">(</span><span class=\"n\">ImagesPipeline</span><span class=\"p\">):</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">get_media_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">image_url</span> <span class=\"ow\">in</span> <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'image_urls'</span><span class=\"p\">]:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">image_url</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">item_completed</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">results</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"p\">):</span>\n        <span class=\"n\">image_paths</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">[</span><span class=\"s1\">'path'</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">ok</span><span class=\"p\">,</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"n\">results</span> <span class=\"k\">if</span> <span class=\"n\">ok</span><span class=\"p\">]</span>\n        <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">image_paths</span><span class=\"p\">:</span>\n            <span class=\"k\">raise</span> <span class=\"n\">DropItem</span><span class=\"p\">(</span><span class=\"s2\">\"Item contains no images\"</span><span class=\"p\">)</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'image_paths'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">image_paths</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">ITEM_PIPELINES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'myproject.pipelines.MyImagesPipeline'</span><span class=\"p\">:</span> <span class=\"mi\">300</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["ITEM_PIPELINES = {'scrapy.pipelines.images.ImagesPipeline': 1}\n", "ITEM_PIPELINES = {'scrapy.pipelines.files.FilesPipeline': 1}\n", "FILES_STORE = '/path/to/valid/dir'\n", "IMAGES_STORE = '/path/to/valid/dir'\n", "http://www.example.com/image.jpg\n", "3afec3b4765f8f0a07b78f98c07b83f013567a0a\n", "3afec3b4765f8f0a07b78f98c07b83f013567a0a.jpg\n", "http://www.example.com/product/images/large/front/0000000004166\n", "00b08510e4_front.jpg\n", "import hashlib\nfrom os.path import splitext\n\ndef file_path(self, request, response=None, info=None, *, item=None):\n    image_url_hash = hashlib.shake_256(request.url.encode()).hexdigest(5)\n    image_perspective = request.url.split('/')[-2]\n    image_filename = f'{image_url_hash}_{image_perspective}.jpg'\n\n    return image_filename\n", "<IMAGES_STORE>/full/<FILE_NAME>\n", "ftp://username:password@address:port/path\nftp://address:port/path\n", "IMAGES_STORE = 's3://bucket/images'\n", "IMAGES_STORE_S3_ACL = 'public-read'\n", "AWS_ENDPOINT_URL = 'http://minio.example.com:9000'\n", "AWS_USE_SSL = False # or True (None by default)\nAWS_VERIFY = False # or True (None by default)\n", "IMAGES_STORE = 'gs://bucket/images/'\nGCS_PROJECT_ID = 'project_id'\n", "IMAGES_STORE_GCS_ACL = 'publicRead'\n", "import scrapy\n\nclass MyItem(scrapy.Item):\n    # ... other item fields ...\n    image_urls = scrapy.Field()\n    images = scrapy.Field()\n", "FILES_URLS_FIELD = 'field_name_for_your_files_urls'\nFILES_RESULT_FIELD = 'field_name_for_your_processed_files'\n", "IMAGES_URLS_FIELD = 'field_name_for_your_images_urls'\nIMAGES_RESULT_FIELD = 'field_name_for_your_processed_images'\n", "# 120 days of delay for files expiration\nFILES_EXPIRES = 120\n\n# 30 days of delay for images expiration\nIMAGES_EXPIRES = 30\n", "IMAGES_THUMBS = {\n    'small': (50, 50),\n    'big': (270, 270),\n}\n", "<IMAGES_STORE>/thumbs/<size_name>/<image_id>.jpg\n", "<IMAGES_STORE>/full/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg\n<IMAGES_STORE>/thumbs/small/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg\n<IMAGES_STORE>/thumbs/big/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg\n", "IMAGES_MIN_HEIGHT = 110\nIMAGES_MIN_WIDTH = 110\n", "MEDIA_ALLOW_REDIRECTS = True\n", "import os\nfrom urllib.parse import urlparse\n\nfrom scrapy.pipelines.files import FilesPipeline\n\nclass MyFilesPipeline(FilesPipeline):\n\n    def file_path(self, request, response=None, info=None, *, item=None):\n        return 'files/' + os.path.basename(urlparse(request.url).path)\n", "from itemadapter import ItemAdapter\n\ndef get_media_requests(self, item, info):\n    adapter = ItemAdapter(item)\n    for file_url in adapter['file_urls']:\n        yield scrapy.Request(file_url)\n", "[(True,\n  {'checksum': '2b00042f7481c7b056c4b410d28f33cf',\n   'path': 'full/0a79c461a4062ac383dc4fade7bc09f1384a3910.jpg',\n   'url': 'http://www.example.com/files/product1.pdf',\n   'status': 'downloaded'}),\n (False,\n  Failure(...))]\n", "from itemadapter import ItemAdapter\nfrom scrapy.exceptions import DropItem\n\ndef item_completed(self, results, item, info):\n    file_paths = [x['path'] for ok, x in results if ok]\n    if not file_paths:\n        raise DropItem(\"Item contains no files\")\n    adapter = ItemAdapter(item)\n    adapter['file_paths'] = file_paths\n    return item\n", "import os\nfrom urllib.parse import urlparse\n\nfrom scrapy.pipelines.images import ImagesPipeline\n\nclass MyImagesPipeline(ImagesPipeline):\n\n    def file_path(self, request, response=None, info=None, *, item=None):\n        return 'files/' + os.path.basename(urlparse(request.url).path)\n", "import scrapy\nfrom itemadapter import ItemAdapter\nfrom scrapy.exceptions import DropItem\nfrom scrapy.pipelines.images import ImagesPipeline\n\nclass MyImagesPipeline(ImagesPipeline):\n\n    def get_media_requests(self, item, info):\n        for image_url in item['image_urls']:\n            yield scrapy.Request(image_url)\n\n    def item_completed(self, results, item, info):\n        image_paths = [x['path'] for ok, x in results if ok]\n        if not image_paths:\n            raise DropItem(\"Item contains no images\")\n        adapter = ItemAdapter(item)\n        adapter['image_paths'] = image_paths\n        return item\n", "ITEM_PIPELINES = {\n    'myproject.pipelines.MyImagesPipeline': 300\n}\n"], "index": 34}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Using the Files Pipeline", "header_href": "#using-the-files-pipeline", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Using the Images Pipeline", "header_href": "#using-the-images-pipeline", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Enabling your Media Pipeline", "header_href": "#enabling-your-media-pipeline", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">ITEM_PIPELINES</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'scrapy.pipelines.images.ImagesPipeline'</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">ITEM_PIPELINES</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'scrapy.pipelines.files.FilesPipeline'</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">FILES_STORE</span> <span class=\"o\">=</span> <span class=\"s1\">'/path/to/valid/dir'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_STORE</span> <span class=\"o\">=</span> <span class=\"s1\">'/path/to/valid/dir'</span>\n</pre></div>"], "codes_text": ["ITEM_PIPELINES = {'scrapy.pipelines.images.ImagesPipeline': 1}\n", "ITEM_PIPELINES = {'scrapy.pipelines.files.FilesPipeline': 1}\n", "FILES_STORE = '/path/to/valid/dir'\n", "IMAGES_STORE = '/path/to/valid/dir'\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "File Naming", "header_href": "#file-naming", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">image</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">3</span><span class=\"n\">afec3b4765f8f0a07b78f98c07b83f013567a0a</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">3</span><span class=\"n\">afec3b4765f8f0a07b78f98c07b83f013567a0a</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">product</span><span class=\"o\">/</span><span class=\"n\">images</span><span class=\"o\">/</span><span class=\"n\">large</span><span class=\"o\">/</span><span class=\"n\">front</span><span class=\"o\">/</span><span class=\"mi\">0000000004166</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">00</span><span class=\"n\">b08510e4_front</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">hashlib</span>\n<span class=\"kn\">from</span> <span class=\"nn\">os.path</span> <span class=\"kn\">import</span> <span class=\"n\">splitext</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">file_path</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n    <span class=\"n\">image_url_hash</span> <span class=\"o\">=</span> <span class=\"n\">hashlib</span><span class=\"o\">.</span><span class=\"n\">shake_256</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">())</span><span class=\"o\">.</span><span class=\"n\">hexdigest</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n    <span class=\"n\">image_perspective</span> <span class=\"o\">=</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s1\">'/'</span><span class=\"p\">)[</span><span class=\"o\">-</span><span class=\"mi\">2</span><span class=\"p\">]</span>\n    <span class=\"n\">image_filename</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">'</span><span class=\"si\">{</span><span class=\"n\">image_url_hash</span><span class=\"si\">}</span><span class=\"s1\">_</span><span class=\"si\">{</span><span class=\"n\">image_perspective</span><span class=\"si\">}</span><span class=\"s1\">.jpg'</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">image_filename</span>\n</pre></div>"], "codes_text": ["http://www.example.com/image.jpg\n", "3afec3b4765f8f0a07b78f98c07b83f013567a0a\n", "3afec3b4765f8f0a07b78f98c07b83f013567a0a.jpg\n", "http://www.example.com/product/images/large/front/0000000004166\n", "00b08510e4_front.jpg\n", "import hashlib\nfrom os.path import splitext\n\ndef file_path(self, request, response=None, info=None, *, item=None):\n    image_url_hash = hashlib.shake_256(request.url.encode()).hexdigest(5)\n    image_perspective = request.url.split('/')[-2]\n    image_filename = f'{image_url_hash}_{image_perspective}.jpg'\n\n    return image_filename\n"], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Default File Naming", "header_href": "#default-file-naming", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">image</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">3</span><span class=\"n\">afec3b4765f8f0a07b78f98c07b83f013567a0a</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">3</span><span class=\"n\">afec3b4765f8f0a07b78f98c07b83f013567a0a</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n</pre></div>"], "codes_text": ["http://www.example.com/image.jpg\n", "3afec3b4765f8f0a07b78f98c07b83f013567a0a\n", "3afec3b4765f8f0a07b78f98c07b83f013567a0a.jpg\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Custom File Naming", "header_href": "#custom-file-naming", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">product</span><span class=\"o\">/</span><span class=\"n\">images</span><span class=\"o\">/</span><span class=\"n\">large</span><span class=\"o\">/</span><span class=\"n\">front</span><span class=\"o\">/</span><span class=\"mi\">0000000004166</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">00</span><span class=\"n\">b08510e4_front</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">hashlib</span>\n<span class=\"kn\">from</span> <span class=\"nn\">os.path</span> <span class=\"kn\">import</span> <span class=\"n\">splitext</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">file_path</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n    <span class=\"n\">image_url_hash</span> <span class=\"o\">=</span> <span class=\"n\">hashlib</span><span class=\"o\">.</span><span class=\"n\">shake_256</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">())</span><span class=\"o\">.</span><span class=\"n\">hexdigest</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n    <span class=\"n\">image_perspective</span> <span class=\"o\">=</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s1\">'/'</span><span class=\"p\">)[</span><span class=\"o\">-</span><span class=\"mi\">2</span><span class=\"p\">]</span>\n    <span class=\"n\">image_filename</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s1\">'</span><span class=\"si\">{</span><span class=\"n\">image_url_hash</span><span class=\"si\">}</span><span class=\"s1\">_</span><span class=\"si\">{</span><span class=\"n\">image_perspective</span><span class=\"si\">}</span><span class=\"s1\">.jpg'</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">image_filename</span>\n</pre></div>"], "codes_text": ["http://www.example.com/product/images/large/front/0000000004166\n", "00b08510e4_front.jpg\n", "import hashlib\nfrom os.path import splitext\n\ndef file_path(self, request, response=None, info=None, *, item=None):\n    image_url_hash = hashlib.shake_256(request.url.encode()).hexdigest(5)\n    image_perspective = request.url.split('/')[-2]\n    image_filename = f'{image_url_hash}_{image_perspective}.jpg'\n\n    return image_filename\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Supported Storage", "header_href": "#supported-storage", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">IMAGES_STORE</span><span class=\"o\">&gt;/</span><span class=\"n\">full</span><span class=\"o\">/&lt;</span><span class=\"n\">FILE_NAME</span><span class=\"o\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">ftp</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">username</span><span class=\"p\">:</span><span class=\"n\">password</span><span class=\"nd\">@address</span><span class=\"p\">:</span><span class=\"n\">port</span><span class=\"o\">/</span><span class=\"n\">path</span>\n<span class=\"n\">ftp</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">address</span><span class=\"p\">:</span><span class=\"n\">port</span><span class=\"o\">/</span><span class=\"n\">path</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_STORE</span> <span class=\"o\">=</span> <span class=\"s1\">'s3://bucket/images'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_STORE_S3_ACL</span> <span class=\"o\">=</span> <span class=\"s1\">'public-read'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">AWS_ENDPOINT_URL</span> <span class=\"o\">=</span> <span class=\"s1\">'http://minio.example.com:9000'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">AWS_USE_SSL</span> <span class=\"o\">=</span> <span class=\"kc\">False</span> <span class=\"c1\"># or True (None by default)</span>\n<span class=\"n\">AWS_VERIFY</span> <span class=\"o\">=</span> <span class=\"kc\">False</span> <span class=\"c1\"># or True (None by default)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_STORE</span> <span class=\"o\">=</span> <span class=\"s1\">'gs://bucket/images/'</span>\n<span class=\"n\">GCS_PROJECT_ID</span> <span class=\"o\">=</span> <span class=\"s1\">'project_id'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_STORE_GCS_ACL</span> <span class=\"o\">=</span> <span class=\"s1\">'publicRead'</span>\n</pre></div>"], "codes_text": ["<IMAGES_STORE>/full/<FILE_NAME>\n", "ftp://username:password@address:port/path\nftp://address:port/path\n", "IMAGES_STORE = 's3://bucket/images'\n", "IMAGES_STORE_S3_ACL = 'public-read'\n", "AWS_ENDPOINT_URL = 'http://minio.example.com:9000'\n", "AWS_USE_SSL = False # or True (None by default)\nAWS_VERIFY = False # or True (None by default)\n", "IMAGES_STORE = 'gs://bucket/images/'\nGCS_PROJECT_ID = 'project_id'\n", "IMAGES_STORE_GCS_ACL = 'publicRead'\n"], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "File system storage", "header_href": "#file-system-storage", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">IMAGES_STORE</span><span class=\"o\">&gt;/</span><span class=\"n\">full</span><span class=\"o\">/&lt;</span><span class=\"n\">FILE_NAME</span><span class=\"o\">&gt;</span>\n</pre></div>"], "codes_text": ["<IMAGES_STORE>/full/<FILE_NAME>\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "FTP server storage", "header_href": "#ftp-server-storage", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">ftp</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">username</span><span class=\"p\">:</span><span class=\"n\">password</span><span class=\"nd\">@address</span><span class=\"p\">:</span><span class=\"n\">port</span><span class=\"o\">/</span><span class=\"n\">path</span>\n<span class=\"n\">ftp</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">address</span><span class=\"p\">:</span><span class=\"n\">port</span><span class=\"o\">/</span><span class=\"n\">path</span>\n</pre></div>"], "codes_text": ["ftp://username:password@address:port/path\nftp://address:port/path\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Amazon S3 storage", "header_href": "#amazon-s3-storage", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_STORE</span> <span class=\"o\">=</span> <span class=\"s1\">'s3://bucket/images'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_STORE_S3_ACL</span> <span class=\"o\">=</span> <span class=\"s1\">'public-read'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">AWS_ENDPOINT_URL</span> <span class=\"o\">=</span> <span class=\"s1\">'http://minio.example.com:9000'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">AWS_USE_SSL</span> <span class=\"o\">=</span> <span class=\"kc\">False</span> <span class=\"c1\"># or True (None by default)</span>\n<span class=\"n\">AWS_VERIFY</span> <span class=\"o\">=</span> <span class=\"kc\">False</span> <span class=\"c1\"># or True (None by default)</span>\n</pre></div>"], "codes_text": ["IMAGES_STORE = 's3://bucket/images'\n", "IMAGES_STORE_S3_ACL = 'public-read'\n", "AWS_ENDPOINT_URL = 'http://minio.example.com:9000'\n", "AWS_USE_SSL = False # or True (None by default)\nAWS_VERIFY = False # or True (None by default)\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Google Cloud Storage", "header_href": "#google-cloud-storage", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_STORE</span> <span class=\"o\">=</span> <span class=\"s1\">'gs://bucket/images/'</span>\n<span class=\"n\">GCS_PROJECT_ID</span> <span class=\"o\">=</span> <span class=\"s1\">'project_id'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_STORE_GCS_ACL</span> <span class=\"o\">=</span> <span class=\"s1\">'publicRead'</span>\n</pre></div>"], "codes_text": ["IMAGES_STORE = 'gs://bucket/images/'\nGCS_PROJECT_ID = 'project_id'\n", "IMAGES_STORE_GCS_ACL = 'publicRead'\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Usage example", "header_href": "#usage-example", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyItem</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"c1\"># ... other item fields ...</span>\n    <span class=\"n\">image_urls</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">images</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">FILES_URLS_FIELD</span> <span class=\"o\">=</span> <span class=\"s1\">'field_name_for_your_files_urls'</span>\n<span class=\"n\">FILES_RESULT_FIELD</span> <span class=\"o\">=</span> <span class=\"s1\">'field_name_for_your_processed_files'</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_URLS_FIELD</span> <span class=\"o\">=</span> <span class=\"s1\">'field_name_for_your_images_urls'</span>\n<span class=\"n\">IMAGES_RESULT_FIELD</span> <span class=\"o\">=</span> <span class=\"s1\">'field_name_for_your_processed_images'</span>\n</pre></div>"], "codes_text": ["import scrapy\n\nclass MyItem(scrapy.Item):\n    # ... other item fields ...\n    image_urls = scrapy.Field()\n    images = scrapy.Field()\n", "FILES_URLS_FIELD = 'field_name_for_your_files_urls'\nFILES_RESULT_FIELD = 'field_name_for_your_processed_files'\n", "IMAGES_URLS_FIELD = 'field_name_for_your_images_urls'\nIMAGES_RESULT_FIELD = 'field_name_for_your_processed_images'\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Additional features", "header_href": "#additional-features", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"c1\"># 120 days of delay for files expiration</span>\n<span class=\"n\">FILES_EXPIRES</span> <span class=\"o\">=</span> <span class=\"mi\">120</span>\n\n<span class=\"c1\"># 30 days of delay for images expiration</span>\n<span class=\"n\">IMAGES_EXPIRES</span> <span class=\"o\">=</span> <span class=\"mi\">30</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_THUMBS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'small'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"mi\">50</span><span class=\"p\">,</span> <span class=\"mi\">50</span><span class=\"p\">),</span>\n    <span class=\"s1\">'big'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"mi\">270</span><span class=\"p\">,</span> <span class=\"mi\">270</span><span class=\"p\">),</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">IMAGES_STORE</span><span class=\"o\">&gt;/</span><span class=\"n\">thumbs</span><span class=\"o\">/&lt;</span><span class=\"n\">size_name</span><span class=\"o\">&gt;/&lt;</span><span class=\"n\">image_id</span><span class=\"o\">&gt;.</span><span class=\"n\">jpg</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">IMAGES_STORE</span><span class=\"o\">&gt;/</span><span class=\"n\">full</span><span class=\"o\">/</span><span class=\"mi\">63</span><span class=\"n\">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n<span class=\"o\">&lt;</span><span class=\"n\">IMAGES_STORE</span><span class=\"o\">&gt;/</span><span class=\"n\">thumbs</span><span class=\"o\">/</span><span class=\"n\">small</span><span class=\"o\">/</span><span class=\"mi\">63</span><span class=\"n\">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n<span class=\"o\">&lt;</span><span class=\"n\">IMAGES_STORE</span><span class=\"o\">&gt;/</span><span class=\"n\">thumbs</span><span class=\"o\">/</span><span class=\"n\">big</span><span class=\"o\">/</span><span class=\"mi\">63</span><span class=\"n\">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_MIN_HEIGHT</span> <span class=\"o\">=</span> <span class=\"mi\">110</span>\n<span class=\"n\">IMAGES_MIN_WIDTH</span> <span class=\"o\">=</span> <span class=\"mi\">110</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">MEDIA_ALLOW_REDIRECTS</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n</pre></div>"], "codes_text": ["# 120 days of delay for files expiration\nFILES_EXPIRES = 120\n\n# 30 days of delay for images expiration\nIMAGES_EXPIRES = 30\n", "IMAGES_THUMBS = {\n    'small': (50, 50),\n    'big': (270, 270),\n}\n", "<IMAGES_STORE>/thumbs/<size_name>/<image_id>.jpg\n", "<IMAGES_STORE>/full/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg\n<IMAGES_STORE>/thumbs/small/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg\n<IMAGES_STORE>/thumbs/big/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg\n", "IMAGES_MIN_HEIGHT = 110\nIMAGES_MIN_WIDTH = 110\n", "MEDIA_ALLOW_REDIRECTS = True\n"], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "File expiration", "header_href": "#file-expiration", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"c1\"># 120 days of delay for files expiration</span>\n<span class=\"n\">FILES_EXPIRES</span> <span class=\"o\">=</span> <span class=\"mi\">120</span>\n\n<span class=\"c1\"># 30 days of delay for images expiration</span>\n<span class=\"n\">IMAGES_EXPIRES</span> <span class=\"o\">=</span> <span class=\"mi\">30</span>\n</pre></div>"], "codes_text": ["# 120 days of delay for files expiration\nFILES_EXPIRES = 120\n\n# 30 days of delay for images expiration\nIMAGES_EXPIRES = 30\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Thumbnail generation for images", "header_href": "#thumbnail-generation-for-images", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_THUMBS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'small'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"mi\">50</span><span class=\"p\">,</span> <span class=\"mi\">50</span><span class=\"p\">),</span>\n    <span class=\"s1\">'big'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"mi\">270</span><span class=\"p\">,</span> <span class=\"mi\">270</span><span class=\"p\">),</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">IMAGES_STORE</span><span class=\"o\">&gt;/</span><span class=\"n\">thumbs</span><span class=\"o\">/&lt;</span><span class=\"n\">size_name</span><span class=\"o\">&gt;/&lt;</span><span class=\"n\">image_id</span><span class=\"o\">&gt;.</span><span class=\"n\">jpg</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">&lt;</span><span class=\"n\">IMAGES_STORE</span><span class=\"o\">&gt;/</span><span class=\"n\">full</span><span class=\"o\">/</span><span class=\"mi\">63</span><span class=\"n\">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n<span class=\"o\">&lt;</span><span class=\"n\">IMAGES_STORE</span><span class=\"o\">&gt;/</span><span class=\"n\">thumbs</span><span class=\"o\">/</span><span class=\"n\">small</span><span class=\"o\">/</span><span class=\"mi\">63</span><span class=\"n\">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n<span class=\"o\">&lt;</span><span class=\"n\">IMAGES_STORE</span><span class=\"o\">&gt;/</span><span class=\"n\">thumbs</span><span class=\"o\">/</span><span class=\"n\">big</span><span class=\"o\">/</span><span class=\"mi\">63</span><span class=\"n\">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=\"o\">.</span><span class=\"n\">jpg</span>\n</pre></div>"], "codes_text": ["IMAGES_THUMBS = {\n    'small': (50, 50),\n    'big': (270, 270),\n}\n", "<IMAGES_STORE>/thumbs/<size_name>/<image_id>.jpg\n", "<IMAGES_STORE>/full/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg\n<IMAGES_STORE>/thumbs/small/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg\n<IMAGES_STORE>/thumbs/big/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Filtering out small images", "header_href": "#filtering-out-small-images", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">IMAGES_MIN_HEIGHT</span> <span class=\"o\">=</span> <span class=\"mi\">110</span>\n<span class=\"n\">IMAGES_MIN_WIDTH</span> <span class=\"o\">=</span> <span class=\"mi\">110</span>\n</pre></div>"], "codes_text": ["IMAGES_MIN_HEIGHT = 110\nIMAGES_MIN_WIDTH = 110\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Allowing redirections", "header_href": "#allowing-redirections", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">MEDIA_ALLOW_REDIRECTS</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n</pre></div>"], "codes_text": ["MEDIA_ALLOW_REDIRECTS = True\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Extending the Media Pipelines", "header_href": "#module-scrapy.pipelines.files", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">from</span> <span class=\"nn\">urllib.parse</span> <span class=\"kn\">import</span> <span class=\"n\">urlparse</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.pipelines.files</span> <span class=\"kn\">import</span> <span class=\"n\">FilesPipeline</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyFilesPipeline</span><span class=\"p\">(</span><span class=\"n\">FilesPipeline</span><span class=\"p\">):</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">file_path</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"s1\">'files/'</span> <span class=\"o\">+</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">basename</span><span class=\"p\">(</span><span class=\"n\">urlparse</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">get_media_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"p\">):</span>\n    <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n    <span class=\"k\">for</span> <span class=\"n\">file_url</span> <span class=\"ow\">in</span> <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'file_urls'</span><span class=\"p\">]:</span>\n        <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">file_url</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">[(</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n  <span class=\"p\">{</span><span class=\"s1\">'checksum'</span><span class=\"p\">:</span> <span class=\"s1\">'2b00042f7481c7b056c4b410d28f33cf'</span><span class=\"p\">,</span>\n   <span class=\"s1\">'path'</span><span class=\"p\">:</span> <span class=\"s1\">'full/0a79c461a4062ac383dc4fade7bc09f1384a3910.jpg'</span><span class=\"p\">,</span>\n   <span class=\"s1\">'url'</span><span class=\"p\">:</span> <span class=\"s1\">'http://www.example.com/files/product1.pdf'</span><span class=\"p\">,</span>\n   <span class=\"s1\">'status'</span><span class=\"p\">:</span> <span class=\"s1\">'downloaded'</span><span class=\"p\">}),</span>\n <span class=\"p\">(</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n  <span class=\"n\">Failure</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">))]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">DropItem</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">item_completed</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">results</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"p\">):</span>\n    <span class=\"n\">file_paths</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">[</span><span class=\"s1\">'path'</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">ok</span><span class=\"p\">,</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"n\">results</span> <span class=\"k\">if</span> <span class=\"n\">ok</span><span class=\"p\">]</span>\n    <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">file_paths</span><span class=\"p\">:</span>\n        <span class=\"k\">raise</span> <span class=\"n\">DropItem</span><span class=\"p\">(</span><span class=\"s2\">\"Item contains no files\"</span><span class=\"p\">)</span>\n    <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n    <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'file_paths'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">file_paths</span>\n    <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">from</span> <span class=\"nn\">urllib.parse</span> <span class=\"kn\">import</span> <span class=\"n\">urlparse</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.pipelines.images</span> <span class=\"kn\">import</span> <span class=\"n\">ImagesPipeline</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyImagesPipeline</span><span class=\"p\">(</span><span class=\"n\">ImagesPipeline</span><span class=\"p\">):</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">file_path</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">request</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"s1\">'files/'</span> <span class=\"o\">+</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">basename</span><span class=\"p\">(</span><span class=\"n\">urlparse</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import os\nfrom urllib.parse import urlparse\n\nfrom scrapy.pipelines.files import FilesPipeline\n\nclass MyFilesPipeline(FilesPipeline):\n\n    def file_path(self, request, response=None, info=None, *, item=None):\n        return 'files/' + os.path.basename(urlparse(request.url).path)\n", "from itemadapter import ItemAdapter\n\ndef get_media_requests(self, item, info):\n    adapter = ItemAdapter(item)\n    for file_url in adapter['file_urls']:\n        yield scrapy.Request(file_url)\n", "[(True,\n  {'checksum': '2b00042f7481c7b056c4b410d28f33cf',\n   'path': 'full/0a79c461a4062ac383dc4fade7bc09f1384a3910.jpg',\n   'url': 'http://www.example.com/files/product1.pdf',\n   'status': 'downloaded'}),\n (False,\n  Failure(...))]\n", "from itemadapter import ItemAdapter\nfrom scrapy.exceptions import DropItem\n\ndef item_completed(self, results, item, info):\n    file_paths = [x['path'] for ok, x in results if ok]\n    if not file_paths:\n        raise DropItem(\"Item contains no files\")\n    adapter = ItemAdapter(item)\n    adapter['file_paths'] = file_paths\n    return item\n", "import os\nfrom urllib.parse import urlparse\n\nfrom scrapy.pipelines.images import ImagesPipeline\n\nclass MyImagesPipeline(ImagesPipeline):\n\n    def file_path(self, request, response=None, info=None, *, item=None):\n        return 'files/' + os.path.basename(urlparse(request.url).path)\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/media-pipeline.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Custom Images pipeline example", "header_href": "#custom-images-pipeline-example", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">DropItem</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.pipelines.images</span> <span class=\"kn\">import</span> <span class=\"n\">ImagesPipeline</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyImagesPipeline</span><span class=\"p\">(</span><span class=\"n\">ImagesPipeline</span><span class=\"p\">):</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">get_media_requests</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">image_url</span> <span class=\"ow\">in</span> <span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'image_urls'</span><span class=\"p\">]:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">image_url</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">item_completed</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">results</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"p\">):</span>\n        <span class=\"n\">image_paths</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">[</span><span class=\"s1\">'path'</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">ok</span><span class=\"p\">,</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"n\">results</span> <span class=\"k\">if</span> <span class=\"n\">ok</span><span class=\"p\">]</span>\n        <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">image_paths</span><span class=\"p\">:</span>\n            <span class=\"k\">raise</span> <span class=\"n\">DropItem</span><span class=\"p\">(</span><span class=\"s2\">\"Item contains no images\"</span><span class=\"p\">)</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'image_paths'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">image_paths</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">ITEM_PIPELINES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'myproject.pipelines.MyImagesPipeline'</span><span class=\"p\">:</span> <span class=\"mi\">300</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["import scrapy\nfrom itemadapter import ItemAdapter\nfrom scrapy.exceptions import DropItem\nfrom scrapy.pipelines.images import ImagesPipeline\n\nclass MyImagesPipeline(ImagesPipeline):\n\n    def get_media_requests(self, item, info):\n        for image_url in item['image_urls']:\n            yield scrapy.Request(image_url)\n\n    def item_completed(self, results, item, info):\n        image_paths = [x['path'] for ok, x in results if ok]\n        if not image_paths:\n            raise DropItem(\"Item contains no images\")\n        adapter = ItemAdapter(item)\n        adapter['image_paths'] = image_paths\n        return item\n", "ITEM_PIPELINES = {\n    'myproject.pipelines.MyImagesPipeline': 300\n}\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/deploy.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Deploying Spiders", "header_href": "#deploying-spiders", "codes": [], "codes_text": [], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/deploy.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Deploying to a Scrapyd Server", "header_href": "#deploying-to-a-scrapyd-server", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/deploy.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Deploying to Zyte Scrapy Cloud", "header_href": "#deploying-to-zyte-scrapy-cloud", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/autothrottle.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "AutoThrottle extension", "header_href": "#autothrottle-extension", "codes": [], "codes_text": [], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/autothrottle.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Design goals", "header_href": "#design-goals", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/autothrottle.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "How it works", "header_href": "#how-it-works", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/autothrottle.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Throttling algorithm", "header_href": "#throttling-algorithm", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/autothrottle.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Settings", "header_href": "#settings", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/autothrottle.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "AUTOTHROTTLE_ENABLED", "header_href": "#autothrottle-enabled", "codes": [], "codes_text": [], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/autothrottle.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "AUTOTHROTTLE_START_DELAY", "header_href": "#autothrottle-start-delay", "codes": [], "codes_text": [], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/autothrottle.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "AUTOTHROTTLE_MAX_DELAY", "header_href": "#autothrottle-max-delay", "codes": [], "codes_text": [], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/autothrottle.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "AUTOTHROTTLE_TARGET_CONCURRENCY", "header_href": "#autothrottle-target-concurrency", "codes": [], "codes_text": [], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/topics/autothrottle.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "AUTOTHROTTLE_DEBUG", "header_href": "#autothrottle-debug", "codes": [], "codes_text": [], "index": 10}
{"url": "https://docs.scrapy.org/en/latest/topics/benchmarking.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Benchmarking", "header_href": "#benchmarking", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">bench</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">48</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">log</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Scrapy</span> <span class=\"mf\">1.2.2</span> <span class=\"n\">started</span> <span class=\"p\">(</span><span class=\"n\">bot</span><span class=\"p\">:</span> <span class=\"n\">quotesbot</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">48</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">log</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Overridden</span> <span class=\"n\">settings</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'CLOSESPIDER_TIMEOUT'</span><span class=\"p\">:</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"s1\">'ROBOTSTXT_OBEY'</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"s1\">'SPIDER_MODULES'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'quotesbot.spiders'</span><span class=\"p\">],</span> <span class=\"s1\">'LOGSTATS_INTERVAL'</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"s1\">'BOT_NAME'</span><span class=\"p\">:</span> <span class=\"s1\">'quotesbot'</span><span class=\"p\">,</span> <span class=\"s1\">'LOG_LEVEL'</span><span class=\"p\">:</span> <span class=\"s1\">'INFO'</span><span class=\"p\">,</span> <span class=\"s1\">'NEWSPIDER_MODULE'</span><span class=\"p\">:</span> <span class=\"s1\">'quotesbot.spiders'</span><span class=\"p\">}</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">49</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">middleware</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Enabled</span> <span class=\"n\">extensions</span><span class=\"p\">:</span>\n<span class=\"p\">[</span><span class=\"s1\">'scrapy.extensions.closespider.CloseSpider'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.extensions.logstats.LogStats'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.extensions.telnet.TelnetConsole'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.extensions.corestats.CoreStats'</span><span class=\"p\">]</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">49</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">middleware</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Enabled</span> <span class=\"n\">downloader</span> <span class=\"n\">middlewares</span><span class=\"p\">:</span>\n<span class=\"p\">[</span><span class=\"s1\">'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.downloadermiddlewares.retry.RetryMiddleware'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.downloadermiddlewares.cookies.CookiesMiddleware'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.downloadermiddlewares.stats.DownloaderStats'</span><span class=\"p\">]</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">49</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">middleware</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Enabled</span> <span class=\"n\">spider</span> <span class=\"n\">middlewares</span><span class=\"p\">:</span>\n<span class=\"p\">[</span><span class=\"s1\">'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.spidermiddlewares.referer.RefererMiddleware'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware'</span><span class=\"p\">,</span>\n <span class=\"s1\">'scrapy.spidermiddlewares.depth.DepthMiddleware'</span><span class=\"p\">]</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">49</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">middleware</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Enabled</span> <span class=\"n\">item</span> <span class=\"n\">pipelines</span><span class=\"p\">:</span>\n<span class=\"p\">[]</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">49</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Spider</span> <span class=\"n\">opened</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">49</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">logstats</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"mi\">0</span> <span class=\"n\">pages</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">pages</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">),</span> <span class=\"n\">scraped</span> <span class=\"mi\">0</span> <span class=\"n\">items</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">items</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">50</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">logstats</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"mi\">70</span> <span class=\"n\">pages</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">4200</span> <span class=\"n\">pages</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">),</span> <span class=\"n\">scraped</span> <span class=\"mi\">0</span> <span class=\"n\">items</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">items</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">51</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">logstats</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"mi\">134</span> <span class=\"n\">pages</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">3840</span> <span class=\"n\">pages</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">),</span> <span class=\"n\">scraped</span> <span class=\"mi\">0</span> <span class=\"n\">items</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">items</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">52</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">logstats</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"mi\">198</span> <span class=\"n\">pages</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">3840</span> <span class=\"n\">pages</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">),</span> <span class=\"n\">scraped</span> <span class=\"mi\">0</span> <span class=\"n\">items</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">items</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">53</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">logstats</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"mi\">254</span> <span class=\"n\">pages</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">3360</span> <span class=\"n\">pages</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">),</span> <span class=\"n\">scraped</span> <span class=\"mi\">0</span> <span class=\"n\">items</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">items</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">54</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">logstats</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"mi\">302</span> <span class=\"n\">pages</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">2880</span> <span class=\"n\">pages</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">),</span> <span class=\"n\">scraped</span> <span class=\"mi\">0</span> <span class=\"n\">items</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">items</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">55</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">logstats</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"mi\">358</span> <span class=\"n\">pages</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">3360</span> <span class=\"n\">pages</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">),</span> <span class=\"n\">scraped</span> <span class=\"mi\">0</span> <span class=\"n\">items</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">items</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">56</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">logstats</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"mi\">406</span> <span class=\"n\">pages</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">2880</span> <span class=\"n\">pages</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">),</span> <span class=\"n\">scraped</span> <span class=\"mi\">0</span> <span class=\"n\">items</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">items</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">57</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">logstats</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"mi\">438</span> <span class=\"n\">pages</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">1920</span> <span class=\"n\">pages</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">),</span> <span class=\"n\">scraped</span> <span class=\"mi\">0</span> <span class=\"n\">items</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">items</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">58</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">logstats</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"mi\">470</span> <span class=\"n\">pages</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">1920</span> <span class=\"n\">pages</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">),</span> <span class=\"n\">scraped</span> <span class=\"mi\">0</span> <span class=\"n\">items</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">items</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">59</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Closing</span> <span class=\"n\">spider</span> <span class=\"p\">(</span><span class=\"n\">closespider_timeout</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">59</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">extensions</span><span class=\"o\">.</span><span class=\"n\">logstats</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"mi\">518</span> <span class=\"n\">pages</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">2880</span> <span class=\"n\">pages</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">),</span> <span class=\"n\">scraped</span> <span class=\"mi\">0</span> <span class=\"n\">items</span> <span class=\"p\">(</span><span class=\"n\">at</span> <span class=\"mi\">0</span> <span class=\"n\">items</span><span class=\"o\">/</span><span class=\"nb\">min</span><span class=\"p\">)</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">19</span><span class=\"p\">:</span><span class=\"mi\">00</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">statscollectors</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Dumping</span> <span class=\"n\">Scrapy</span> <span class=\"n\">stats</span><span class=\"p\">:</span>\n<span class=\"p\">{</span><span class=\"s1\">'downloader/request_bytes'</span><span class=\"p\">:</span> <span class=\"mi\">229995</span><span class=\"p\">,</span>\n <span class=\"s1\">'downloader/request_count'</span><span class=\"p\">:</span> <span class=\"mi\">534</span><span class=\"p\">,</span>\n <span class=\"s1\">'downloader/request_method_count/GET'</span><span class=\"p\">:</span> <span class=\"mi\">534</span><span class=\"p\">,</span>\n <span class=\"s1\">'downloader/response_bytes'</span><span class=\"p\">:</span> <span class=\"mi\">1565504</span><span class=\"p\">,</span>\n <span class=\"s1\">'downloader/response_count'</span><span class=\"p\">:</span> <span class=\"mi\">534</span><span class=\"p\">,</span>\n <span class=\"s1\">'downloader/response_status_count/200'</span><span class=\"p\">:</span> <span class=\"mi\">534</span><span class=\"p\">,</span>\n <span class=\"s1\">'finish_reason'</span><span class=\"p\">:</span> <span class=\"s1\">'closespider_timeout'</span><span class=\"p\">,</span>\n <span class=\"s1\">'finish_time'</span><span class=\"p\">:</span> <span class=\"n\">datetime</span><span class=\"o\">.</span><span class=\"n\">datetime</span><span class=\"p\">(</span><span class=\"mi\">2016</span><span class=\"p\">,</span> <span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">19</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">647725</span><span class=\"p\">),</span>\n <span class=\"s1\">'log_count/INFO'</span><span class=\"p\">:</span> <span class=\"mi\">17</span><span class=\"p\">,</span>\n <span class=\"s1\">'request_depth_max'</span><span class=\"p\">:</span> <span class=\"mi\">19</span><span class=\"p\">,</span>\n <span class=\"s1\">'response_received_count'</span><span class=\"p\">:</span> <span class=\"mi\">534</span><span class=\"p\">,</span>\n <span class=\"s1\">'scheduler/dequeued'</span><span class=\"p\">:</span> <span class=\"mi\">533</span><span class=\"p\">,</span>\n <span class=\"s1\">'scheduler/dequeued/memory'</span><span class=\"p\">:</span> <span class=\"mi\">533</span><span class=\"p\">,</span>\n <span class=\"s1\">'scheduler/enqueued'</span><span class=\"p\">:</span> <span class=\"mi\">10661</span><span class=\"p\">,</span>\n <span class=\"s1\">'scheduler/enqueued/memory'</span><span class=\"p\">:</span> <span class=\"mi\">10661</span><span class=\"p\">,</span>\n <span class=\"s1\">'start_time'</span><span class=\"p\">:</span> <span class=\"n\">datetime</span><span class=\"o\">.</span><span class=\"n\">datetime</span><span class=\"p\">(</span><span class=\"mi\">2016</span><span class=\"p\">,</span> <span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">18</span><span class=\"p\">,</span> <span class=\"mi\">49</span><span class=\"p\">,</span> <span class=\"mi\">799869</span><span class=\"p\">)}</span>\n<span class=\"mi\">2016</span><span class=\"o\">-</span><span class=\"mi\">12</span><span class=\"o\">-</span><span class=\"mi\">16</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">19</span><span class=\"p\">:</span><span class=\"mi\">00</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Spider</span> <span class=\"n\">closed</span> <span class=\"p\">(</span><span class=\"n\">closespider_timeout</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["scrapy bench\n", "2016-12-16 21:18:48 [scrapy.utils.log] INFO: Scrapy 1.2.2 started (bot: quotesbot)\n2016-12-16 21:18:48 [scrapy.utils.log] INFO: Overridden settings: {'CLOSESPIDER_TIMEOUT': 10, 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['quotesbot.spiders'], 'LOGSTATS_INTERVAL': 1, 'BOT_NAME': 'quotesbot', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'quotesbot.spiders'}\n2016-12-16 21:18:49 [scrapy.middleware] INFO: Enabled extensions:\n['scrapy.extensions.closespider.CloseSpider',\n 'scrapy.extensions.logstats.LogStats',\n 'scrapy.extensions.telnet.TelnetConsole',\n 'scrapy.extensions.corestats.CoreStats']\n2016-12-16 21:18:49 [scrapy.middleware] INFO: Enabled downloader middlewares:\n['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n2016-12-16 21:18:49 [scrapy.middleware] INFO: Enabled spider middlewares:\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n2016-12-16 21:18:49 [scrapy.middleware] INFO: Enabled item pipelines:\n[]\n2016-12-16 21:18:49 [scrapy.core.engine] INFO: Spider opened\n2016-12-16 21:18:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n2016-12-16 21:18:50 [scrapy.extensions.logstats] INFO: Crawled 70 pages (at 4200 pages/min), scraped 0 items (at 0 items/min)\n2016-12-16 21:18:51 [scrapy.extensions.logstats] INFO: Crawled 134 pages (at 3840 pages/min), scraped 0 items (at 0 items/min)\n2016-12-16 21:18:52 [scrapy.extensions.logstats] INFO: Crawled 198 pages (at 3840 pages/min), scraped 0 items (at 0 items/min)\n2016-12-16 21:18:53 [scrapy.extensions.logstats] INFO: Crawled 254 pages (at 3360 pages/min), scraped 0 items (at 0 items/min)\n2016-12-16 21:18:54 [scrapy.extensions.logstats] INFO: Crawled 302 pages (at 2880 pages/min), scraped 0 items (at 0 items/min)\n2016-12-16 21:18:55 [scrapy.extensions.logstats] INFO: Crawled 358 pages (at 3360 pages/min), scraped 0 items (at 0 items/min)\n2016-12-16 21:18:56 [scrapy.extensions.logstats] INFO: Crawled 406 pages (at 2880 pages/min), scraped 0 items (at 0 items/min)\n2016-12-16 21:18:57 [scrapy.extensions.logstats] INFO: Crawled 438 pages (at 1920 pages/min), scraped 0 items (at 0 items/min)\n2016-12-16 21:18:58 [scrapy.extensions.logstats] INFO: Crawled 470 pages (at 1920 pages/min), scraped 0 items (at 0 items/min)\n2016-12-16 21:18:59 [scrapy.core.engine] INFO: Closing spider (closespider_timeout)\n2016-12-16 21:18:59 [scrapy.extensions.logstats] INFO: Crawled 518 pages (at 2880 pages/min), scraped 0 items (at 0 items/min)\n2016-12-16 21:19:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n{'downloader/request_bytes': 229995,\n 'downloader/request_count': 534,\n 'downloader/request_method_count/GET': 534,\n 'downloader/response_bytes': 1565504,\n 'downloader/response_count': 534,\n 'downloader/response_status_count/200': 534,\n 'finish_reason': 'closespider_timeout',\n 'finish_time': datetime.datetime(2016, 12, 16, 16, 19, 0, 647725),\n 'log_count/INFO': 17,\n 'request_depth_max': 19,\n 'response_received_count': 534,\n 'scheduler/dequeued': 533,\n 'scheduler/dequeued/memory': 533,\n 'scheduler/enqueued': 10661,\n 'scheduler/enqueued/memory': 10661,\n 'start_time': datetime.datetime(2016, 12, 16, 16, 18, 49, 799869)}\n2016-12-16 21:19:00 [scrapy.core.engine] INFO: Spider closed (closespider_timeout)\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/jobs.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Jobs: pausing and resuming crawls", "header_href": "#jobs-pausing-and-resuming-crawls", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">somespider</span> <span class=\"o\">-</span><span class=\"n\">s</span> <span class=\"n\">JOBDIR</span><span class=\"o\">=</span><span class=\"n\">crawls</span><span class=\"o\">/</span><span class=\"n\">somespider</span><span class=\"o\">-</span><span class=\"mi\">1</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">somespider</span> <span class=\"o\">-</span><span class=\"n\">s</span> <span class=\"n\">JOBDIR</span><span class=\"o\">=</span><span class=\"n\">crawls</span><span class=\"o\">/</span><span class=\"n\">somespider</span><span class=\"o\">-</span><span class=\"mi\">1</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"c1\"># parse item here</span>\n    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">state</span><span class=\"p\">[</span><span class=\"s1\">'items_count'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">state</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'items_count'</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"mi\">1</span>\n</pre></div>"], "codes_text": ["scrapy crawl somespider -s JOBDIR=crawls/somespider-1\n", "scrapy crawl somespider -s JOBDIR=crawls/somespider-1\n", "def parse_item(self, response):\n    # parse item here\n    self.state['items_count'] = self.state.get('items_count', 0) + 1\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/jobs.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Job directory", "header_href": "#job-directory", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/jobs.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "How to use it", "header_href": "#how-to-use-it", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">somespider</span> <span class=\"o\">-</span><span class=\"n\">s</span> <span class=\"n\">JOBDIR</span><span class=\"o\">=</span><span class=\"n\">crawls</span><span class=\"o\">/</span><span class=\"n\">somespider</span><span class=\"o\">-</span><span class=\"mi\">1</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span> <span class=\"n\">crawl</span> <span class=\"n\">somespider</span> <span class=\"o\">-</span><span class=\"n\">s</span> <span class=\"n\">JOBDIR</span><span class=\"o\">=</span><span class=\"n\">crawls</span><span class=\"o\">/</span><span class=\"n\">somespider</span><span class=\"o\">-</span><span class=\"mi\">1</span>\n</pre></div>"], "codes_text": ["scrapy crawl somespider -s JOBDIR=crawls/somespider-1\n", "scrapy crawl somespider -s JOBDIR=crawls/somespider-1\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/jobs.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Keeping persistent state between batches", "header_href": "#keeping-persistent-state-between-batches", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"c1\"># parse item here</span>\n    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">state</span><span class=\"p\">[</span><span class=\"s1\">'items_count'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">state</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'items_count'</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"mi\">1</span>\n</pre></div>"], "codes_text": ["def parse_item(self, response):\n    # parse item here\n    self.state['items_count'] = self.state.get('items_count', 0) + 1\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/jobs.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Persistence gotchas", "header_href": "#persistence-gotchas", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/jobs.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Cookies expiration", "header_href": "#cookies-expiration", "codes": [], "codes_text": [], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/jobs.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Request serialization", "header_href": "#request-serialization", "codes": [], "codes_text": [], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/coroutines.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Coroutines", "header_href": "#coroutines", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">DbPipeline</span><span class=\"p\">:</span>\n    <span class=\"k\">def</span> <span class=\"nf\">_update_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'field'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">data</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"n\">dfd</span> <span class=\"o\">=</span> <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">get_some_data</span><span class=\"p\">(</span><span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">])</span>\n        <span class=\"n\">dfd</span><span class=\"o\">.</span><span class=\"n\">addCallback</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_update_item</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">dfd</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">DbPipeline</span><span class=\"p\">:</span>\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'field'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">get_some_data</span><span class=\"p\">(</span><span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">])</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpiderDeferred</span><span class=\"p\">(</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># ...</span>\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">additional_response</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">treq</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'https://additional.url'</span><span class=\"p\">)</span>\n        <span class=\"n\">additional_data</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">treq</span><span class=\"o\">.</span><span class=\"n\">content</span><span class=\"p\">(</span><span class=\"n\">additional_response</span><span class=\"p\">)</span>\n        <span class=\"c1\"># ... use response and additional_data to yield items and requests</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpiderAsyncio</span><span class=\"p\">(</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># ...</span>\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">async</span> <span class=\"k\">with</span> <span class=\"n\">aiohttp</span><span class=\"o\">.</span><span class=\"n\">ClientSession</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"n\">session</span><span class=\"p\">:</span>\n            <span class=\"k\">async</span> <span class=\"k\">with</span> <span class=\"n\">session</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'https://additional.url'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">additional_response</span><span class=\"p\">:</span>\n                <span class=\"n\">additional_data</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">additional_response</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">()</span>\n        <span class=\"c1\"># ... use response and additional_data to yield items and requests</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">UniversalSpiderMiddleware</span><span class=\"p\">:</span>\n    <span class=\"k\">def</span> <span class=\"nf\">process_spider_output</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">result</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">r</span> <span class=\"ow\">in</span> <span class=\"n\">result</span><span class=\"p\">:</span>\n            <span class=\"c1\"># ... do something with r</span>\n            <span class=\"k\">yield</span> <span class=\"n\">r</span>\n\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">process_spider_output_async</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">result</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"k\">async</span> <span class=\"k\">for</span> <span class=\"n\">r</span> <span class=\"ow\">in</span> <span class=\"n\">result</span><span class=\"p\">:</span>\n            <span class=\"c1\"># ... do something with r</span>\n            <span class=\"k\">yield</span> <span class=\"n\">r</span>\n</pre></div>"], "codes_text": ["from itemadapter import ItemAdapter\n\nclass DbPipeline:\n    def _update_item(self, data, item):\n        adapter = ItemAdapter(item)\n        adapter['field'] = data\n        return item\n\n    def process_item(self, item, spider):\n        adapter = ItemAdapter(item)\n        dfd = db.get_some_data(adapter['id'])\n        dfd.addCallback(self._update_item, item)\n        return dfd\n", "from itemadapter import ItemAdapter\n\nclass DbPipeline:\n    async def process_item(self, item, spider):\n        adapter = ItemAdapter(item)\n        adapter['field'] = await db.get_some_data(adapter['id'])\n        return item\n", "class MySpiderDeferred(Spider):\n    # ...\n    async def parse(self, response):\n        additional_response = await treq.get('https://additional.url')\n        additional_data = await treq.content(additional_response)\n        # ... use response and additional_data to yield items and requests\n\nclass MySpiderAsyncio(Spider):\n    # ...\n    async def parse(self, response):\n        async with aiohttp.ClientSession() as session:\n            async with session.get('https://additional.url') as additional_response:\n                additional_data = await additional_response.text()\n        # ... use response and additional_data to yield items and requests\n", "class UniversalSpiderMiddleware:\n    def process_spider_output(self, response, result, spider):\n        for r in result:\n            # ... do something with r\n            yield r\n\n    async def process_spider_output_async(self, response, result, spider):\n        async for r in result:\n            # ... do something with r\n            yield r\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/coroutines.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Supported callables", "header_href": "#supported-callables", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/coroutines.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "General usage", "header_href": "#general-usage", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">DbPipeline</span><span class=\"p\">:</span>\n    <span class=\"k\">def</span> <span class=\"nf\">_update_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'field'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">data</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"n\">dfd</span> <span class=\"o\">=</span> <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">get_some_data</span><span class=\"p\">(</span><span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">])</span>\n        <span class=\"n\">dfd</span><span class=\"o\">.</span><span class=\"n\">addCallback</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_update_item</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">dfd</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">DbPipeline</span><span class=\"p\">:</span>\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'field'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">get_some_data</span><span class=\"p\">(</span><span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">])</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpiderDeferred</span><span class=\"p\">(</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># ...</span>\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">additional_response</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">treq</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'https://additional.url'</span><span class=\"p\">)</span>\n        <span class=\"n\">additional_data</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">treq</span><span class=\"o\">.</span><span class=\"n\">content</span><span class=\"p\">(</span><span class=\"n\">additional_response</span><span class=\"p\">)</span>\n        <span class=\"c1\"># ... use response and additional_data to yield items and requests</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpiderAsyncio</span><span class=\"p\">(</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># ...</span>\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">async</span> <span class=\"k\">with</span> <span class=\"n\">aiohttp</span><span class=\"o\">.</span><span class=\"n\">ClientSession</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"n\">session</span><span class=\"p\">:</span>\n            <span class=\"k\">async</span> <span class=\"k\">with</span> <span class=\"n\">session</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'https://additional.url'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">additional_response</span><span class=\"p\">:</span>\n                <span class=\"n\">additional_data</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">additional_response</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">()</span>\n        <span class=\"c1\"># ... use response and additional_data to yield items and requests</span>\n</pre></div>"], "codes_text": ["from itemadapter import ItemAdapter\n\nclass DbPipeline:\n    def _update_item(self, data, item):\n        adapter = ItemAdapter(item)\n        adapter['field'] = data\n        return item\n\n    def process_item(self, item, spider):\n        adapter = ItemAdapter(item)\n        dfd = db.get_some_data(adapter['id'])\n        dfd.addCallback(self._update_item, item)\n        return dfd\n", "from itemadapter import ItemAdapter\n\nclass DbPipeline:\n    async def process_item(self, item, spider):\n        adapter = ItemAdapter(item)\n        adapter['field'] = await db.get_some_data(adapter['id'])\n        return item\n", "class MySpiderDeferred(Spider):\n    # ...\n    async def parse(self, response):\n        additional_response = await treq.get('https://additional.url')\n        additional_data = await treq.content(additional_response)\n        # ... use response and additional_data to yield items and requests\n\nclass MySpiderAsyncio(Spider):\n    # ...\n    async def parse(self, response):\n        async with aiohttp.ClientSession() as session:\n            async with session.get('https://additional.url') as additional_response:\n                additional_data = await additional_response.text()\n        # ... use response and additional_data to yield items and requests\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/coroutines.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Mixing synchronous and asynchronous spider middlewares", "header_href": "#mixing-synchronous-and-asynchronous-spider-middlewares", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/coroutines.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Universal spider middlewares", "header_href": "#universal-spider-middlewares", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">UniversalSpiderMiddleware</span><span class=\"p\">:</span>\n    <span class=\"k\">def</span> <span class=\"nf\">process_spider_output</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">result</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">r</span> <span class=\"ow\">in</span> <span class=\"n\">result</span><span class=\"p\">:</span>\n            <span class=\"c1\"># ... do something with r</span>\n            <span class=\"k\">yield</span> <span class=\"n\">r</span>\n\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">process_spider_output_async</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">,</span> <span class=\"n\">result</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"k\">async</span> <span class=\"k\">for</span> <span class=\"n\">r</span> <span class=\"ow\">in</span> <span class=\"n\">result</span><span class=\"p\">:</span>\n            <span class=\"c1\"># ... do something with r</span>\n            <span class=\"k\">yield</span> <span class=\"n\">r</span>\n</pre></div>"], "codes_text": ["class UniversalSpiderMiddleware:\n    def process_spider_output(self, response, result, spider):\n        for r in result:\n            # ... do something with r\n            yield r\n\n    async def process_spider_output_async(self, response, result, spider):\n        async for r in result:\n            # ... do something with r\n            yield r\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/asyncio.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "asyncio", "header_href": "#asyncio", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">install_reactor</span><span class=\"p\">(</span><span class=\"s1\">'twisted.internet.asyncioreactor.AsyncioSelectorReactor'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">asyncio</span>\n<span class=\"n\">asyncio</span><span class=\"o\">.</span><span class=\"n\">set_event_loop_policy</span><span class=\"p\">(</span><span class=\"n\">asyncio</span><span class=\"o\">.</span><span class=\"n\">WindowsSelectorEventLoopPolicy</span><span class=\"p\">())</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"o\">...</span>\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">treq</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'https://example.com/additional'</span><span class=\"p\">)</span>\n        <span class=\"n\">additional_response</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">deferred_to_future</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"o\">...</span>\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">treq</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'https://example.com/additional'</span><span class=\"p\">)</span>\n        <span class=\"n\">extra_response</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">maybe_deferred_to_future</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.reactor</span> <span class=\"kn\">import</span> <span class=\"n\">is_asyncio_reactor_installed</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyComponent</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">is_asyncio_reactor_installed</span><span class=\"p\">():</span>\n            <span class=\"k\">raise</span> <span class=\"ne\">ValueError</span><span class=\"p\">(</span>\n                <span class=\"sa\">f</span><span class=\"s2\">\"</span><span class=\"si\">{</span><span class=\"n\">MyComponent</span><span class=\"o\">.</span><span class=\"vm\">__qualname__</span><span class=\"si\">}</span><span class=\"s2\"> requires the asyncio Twisted \"</span>\n                <span class=\"sa\">f</span><span class=\"s2\">\"reactor. Make sure you have it configured in the \"</span>\n                <span class=\"sa\">f</span><span class=\"s2\">\"TWISTED_REACTOR setting. See the asyncio documentation \"</span>\n                <span class=\"sa\">f</span><span class=\"s2\">\"of Scrapy for more information.\"</span>\n            <span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["install_reactor('twisted.internet.asyncioreactor.AsyncioSelectorReactor')\n", "import asyncio\nasyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n", "class MySpider(Spider):\n    ...\n    async def parse(self, response):\n        d = treq.get('https://example.com/additional')\n        additional_response = await deferred_to_future(d)\n", "class MySpider(Spider):\n    ...\n    async def parse(self, response):\n        d = treq.get('https://example.com/additional')\n        extra_response = await maybe_deferred_to_future(d)\n", "from scrapy.utils.reactor import is_asyncio_reactor_installed\n\nclass MyComponent:\n\n    def __init__(self):\n        if not is_asyncio_reactor_installed():\n            raise ValueError(\n                f\"{MyComponent.__qualname__} requires the asyncio Twisted \"\n                f\"reactor. Make sure you have it configured in the \"\n                f\"TWISTED_REACTOR setting. See the asyncio documentation \"\n                f\"of Scrapy for more information.\"\n            )\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/asyncio.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Installing the asyncio reactor", "header_href": "#installing-the-asyncio-reactor", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">install_reactor</span><span class=\"p\">(</span><span class=\"s1\">'twisted.internet.asyncioreactor.AsyncioSelectorReactor'</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["install_reactor('twisted.internet.asyncioreactor.AsyncioSelectorReactor')\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/asyncio.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Using custom asyncio loops", "header_href": "#using-custom-asyncio-loops", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/asyncio.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Windows-specific notes", "header_href": "#windows-specific-notes", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">asyncio</span>\n<span class=\"n\">asyncio</span><span class=\"o\">.</span><span class=\"n\">set_event_loop_policy</span><span class=\"p\">(</span><span class=\"n\">asyncio</span><span class=\"o\">.</span><span class=\"n\">WindowsSelectorEventLoopPolicy</span><span class=\"p\">())</span>\n</pre></div>"], "codes_text": ["import asyncio\nasyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/asyncio.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Awaiting on Deferreds", "header_href": "#awaiting-on-deferreds", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"o\">...</span>\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">treq</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'https://example.com/additional'</span><span class=\"p\">)</span>\n        <span class=\"n\">additional_response</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">deferred_to_future</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"o\">...</span>\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">treq</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'https://example.com/additional'</span><span class=\"p\">)</span>\n        <span class=\"n\">extra_response</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">maybe_deferred_to_future</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["class MySpider(Spider):\n    ...\n    async def parse(self, response):\n        d = treq.get('https://example.com/additional')\n        additional_response = await deferred_to_future(d)\n", "class MySpider(Spider):\n    ...\n    async def parse(self, response):\n        d = treq.get('https://example.com/additional')\n        extra_response = await maybe_deferred_to_future(d)\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/asyncio.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Enforcing asyncio as a requirement", "header_href": "#enforcing-asyncio-as-a-requirement", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.utils.reactor</span> <span class=\"kn\">import</span> <span class=\"n\">is_asyncio_reactor_installed</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyComponent</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">is_asyncio_reactor_installed</span><span class=\"p\">():</span>\n            <span class=\"k\">raise</span> <span class=\"ne\">ValueError</span><span class=\"p\">(</span>\n                <span class=\"sa\">f</span><span class=\"s2\">\"</span><span class=\"si\">{</span><span class=\"n\">MyComponent</span><span class=\"o\">.</span><span class=\"vm\">__qualname__</span><span class=\"si\">}</span><span class=\"s2\"> requires the asyncio Twisted \"</span>\n                <span class=\"sa\">f</span><span class=\"s2\">\"reactor. Make sure you have it configured in the \"</span>\n                <span class=\"sa\">f</span><span class=\"s2\">\"TWISTED_REACTOR setting. See the asyncio documentation \"</span>\n                <span class=\"sa\">f</span><span class=\"s2\">\"of Scrapy for more information.\"</span>\n            <span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["from scrapy.utils.reactor import is_asyncio_reactor_installed\n\nclass MyComponent:\n\n    def __init__(self):\n        if not is_asyncio_reactor_installed():\n            raise ValueError(\n                f\"{MyComponent.__qualname__} requires the asyncio Twisted \"\n                f\"reactor. Make sure you have it configured in the \"\n                f\"TWISTED_REACTOR setting. See the asyncio documentation \"\n                f\"of Scrapy for more information.\"\n            )\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/architecture.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Architecture overview", "header_href": "#architecture-overview", "codes": [], "codes_text": [], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/architecture.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Overview", "header_href": "#overview", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/architecture.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Data flow", "header_href": "#data-flow", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/architecture.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Components", "header_href": "#components", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/architecture.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Scrapy Engine", "header_href": "#scrapy-engine", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/architecture.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Scheduler", "header_href": "#scheduler", "codes": [], "codes_text": [], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/architecture.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Downloader", "header_href": "#downloader", "codes": [], "codes_text": [], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/architecture.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Spiders", "header_href": "#spiders", "codes": [], "codes_text": [], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/architecture.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Item Pipeline", "header_href": "#item-pipeline", "codes": [], "codes_text": [], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/topics/architecture.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Downloader middlewares", "header_href": "#downloader-middlewares", "codes": [], "codes_text": [], "index": 10}
{"url": "https://docs.scrapy.org/en/latest/topics/architecture.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Spider middlewares", "header_href": "#spider-middlewares", "codes": [], "codes_text": [], "index": 11}
{"url": "https://docs.scrapy.org/en/latest/topics/architecture.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Event-driven networking", "header_href": "#event-driven-networking", "codes": [], "codes_text": [], "index": 12}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Downloader Middleware", "header_href": "#downloader-middleware", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">DOWNLOADER_MIDDLEWARES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'myproject.middlewares.CustomDownloaderMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">543</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">DOWNLOADER_MIDDLEWARES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'myproject.middlewares.CustomDownloaderMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">543</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">url</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">urls</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">meta</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'cookiejar'</span><span class=\"p\">:</span> <span class=\"n\">i</span><span class=\"p\">},</span>\n        <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_page</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse_page</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"c1\"># do some processing</span>\n    <span class=\"k\">return</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s2\">\"http://www.example.com/otherpage\"</span><span class=\"p\">,</span>\n        <span class=\"n\">meta</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'cookiejar'</span><span class=\"p\">:</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"p\">[</span><span class=\"s1\">'cookiejar'</span><span class=\"p\">]},</span>\n        <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_other_page</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">2011</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">14</span><span class=\"p\">:</span><span class=\"mi\">35</span><span class=\"p\">:</span><span class=\"mi\">10</span><span class=\"o\">-</span><span class=\"mi\">0300</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Spider</span> <span class=\"n\">opened</span>\n<span class=\"mi\">2011</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">14</span><span class=\"p\">:</span><span class=\"mi\">35</span><span class=\"p\">:</span><span class=\"mi\">10</span><span class=\"o\">-</span><span class=\"mi\">0300</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">downloadermiddlewares</span><span class=\"o\">.</span><span class=\"n\">cookies</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Sending</span> <span class=\"n\">cookies</span> <span class=\"n\">to</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">diningcity</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">netherlands</span><span class=\"o\">/</span><span class=\"n\">index</span><span class=\"o\">.</span><span class=\"n\">html</span><span class=\"o\">&gt;</span>\n        <span class=\"n\">Cookie</span><span class=\"p\">:</span> <span class=\"n\">clientlanguage_nl</span><span class=\"o\">=</span><span class=\"n\">en_EN</span>\n<span class=\"mi\">2011</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">14</span><span class=\"p\">:</span><span class=\"mi\">35</span><span class=\"p\">:</span><span class=\"mi\">14</span><span class=\"o\">-</span><span class=\"mi\">0300</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">downloadermiddlewares</span><span class=\"o\">.</span><span class=\"n\">cookies</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Received</span> <span class=\"n\">cookies</span> <span class=\"n\">from</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">diningcity</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">netherlands</span><span class=\"o\">/</span><span class=\"n\">index</span><span class=\"o\">.</span><span class=\"n\">html</span><span class=\"o\">&gt;</span>\n        <span class=\"n\">Set</span><span class=\"o\">-</span><span class=\"n\">Cookie</span><span class=\"p\">:</span> <span class=\"n\">JSESSIONID</span><span class=\"o\">=</span><span class=\"n\">B</span><span class=\"o\">~</span><span class=\"n\">FA4DC0C496C8762AE4F1A620EAB34F38</span><span class=\"p\">;</span> <span class=\"n\">Path</span><span class=\"o\">=/</span>\n        <span class=\"n\">Set</span><span class=\"o\">-</span><span class=\"n\">Cookie</span><span class=\"p\">:</span> <span class=\"n\">ip_isocode</span><span class=\"o\">=</span><span class=\"n\">US</span>\n        <span class=\"n\">Set</span><span class=\"o\">-</span><span class=\"n\">Cookie</span><span class=\"p\">:</span> <span class=\"n\">clientlanguage_nl</span><span class=\"o\">=</span><span class=\"n\">en_EN</span><span class=\"p\">;</span> <span class=\"n\">Expires</span><span class=\"o\">=</span><span class=\"n\">Thu</span><span class=\"p\">,</span> <span class=\"mi\">07</span><span class=\"o\">-</span><span class=\"n\">Apr</span><span class=\"o\">-</span><span class=\"mi\">2011</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">34</span> <span class=\"n\">GMT</span><span class=\"p\">;</span> <span class=\"n\">Path</span><span class=\"o\">=/</span>\n<span class=\"mi\">2011</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">14</span><span class=\"p\">:</span><span class=\"mi\">49</span><span class=\"p\">:</span><span class=\"mi\">50</span><span class=\"o\">-</span><span class=\"mi\">0300</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">diningcity</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">netherlands</span><span class=\"o\">/</span><span class=\"n\">index</span><span class=\"o\">.</span><span class=\"n\">html</span><span class=\"o\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"o\">...</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">SomeIntranetSiteSpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n\n    <span class=\"n\">http_user</span> <span class=\"o\">=</span> <span class=\"s1\">'someuser'</span>\n    <span class=\"n\">http_pass</span> <span class=\"o\">=</span> <span class=\"s1\">'somepass'</span>\n    <span class=\"n\">http_auth_domain</span> <span class=\"o\">=</span> <span class=\"s1\">'intranet.example.com'</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'intranet.example.com'</span>\n\n    <span class=\"c1\"># .. rest of the spider code omitted ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">/</span><span class=\"n\">path</span><span class=\"o\">/</span><span class=\"n\">to</span><span class=\"o\">/</span><span class=\"n\">cache</span><span class=\"o\">/</span><span class=\"nb\">dir</span><span class=\"o\">/</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"mi\">72</span><span class=\"o\">/</span><span class=\"mi\">72811</span><span class=\"n\">f648e718090f041317756c03adb0ada46c7</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">handle_httpstatus_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">301</span><span class=\"p\">,</span> <span class=\"mi\">302</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">:</span>\n        <span class=\"n\">new_request_or_none</span> <span class=\"o\">=</span> <span class=\"n\">get_retry_request</span><span class=\"p\">(</span>\n            <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">request</span><span class=\"p\">,</span>\n            <span class=\"n\">spider</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"p\">,</span>\n            <span class=\"n\">reason</span><span class=\"o\">=</span><span class=\"s1\">'empty'</span><span class=\"p\">,</span>\n        <span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">new_request_or_none</span>\n</pre></div>"], "codes_text": ["DOWNLOADER_MIDDLEWARES = {\n    'myproject.middlewares.CustomDownloaderMiddleware': 543,\n}\n", "DOWNLOADER_MIDDLEWARES = {\n    'myproject.middlewares.CustomDownloaderMiddleware': 543,\n    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,\n}\n", "for i, url in enumerate(urls):\n    yield scrapy.Request(url, meta={'cookiejar': i},\n        callback=self.parse_page)\n", "def parse_page(self, response):\n    # do some processing\n    return scrapy.Request(\"http://www.example.com/otherpage\",\n        meta={'cookiejar': response.meta['cookiejar']},\n        callback=self.parse_other_page)\n", "2011-04-06 14:35:10-0300 [scrapy.core.engine] INFO: Spider opened\n2011-04-06 14:35:10-0300 [scrapy.downloadermiddlewares.cookies] DEBUG: Sending cookies to: <GET http://www.diningcity.com/netherlands/index.html>\n        Cookie: clientlanguage_nl=en_EN\n2011-04-06 14:35:14-0300 [scrapy.downloadermiddlewares.cookies] DEBUG: Received cookies from: <200 http://www.diningcity.com/netherlands/index.html>\n        Set-Cookie: JSESSIONID=B~FA4DC0C496C8762AE4F1A620EAB34F38; Path=/\n        Set-Cookie: ip_isocode=US\n        Set-Cookie: clientlanguage_nl=en_EN; Expires=Thu, 07-Apr-2011 21:21:34 GMT; Path=/\n2011-04-06 14:49:50-0300 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.diningcity.com/netherlands/index.html> (referer: None)\n[...]\n", "from scrapy.spiders import CrawlSpider\n\nclass SomeIntranetSiteSpider(CrawlSpider):\n\n    http_user = 'someuser'\n    http_pass = 'somepass'\n    http_auth_domain = 'intranet.example.com'\n    name = 'intranet.example.com'\n\n    # .. rest of the spider code omitted ...\n", "/path/to/cache/dir/example.com/72/72811f648e718090f041317756c03adb0ada46c7\n", "class MySpider(CrawlSpider):\n    handle_httpstatus_list = [301, 302]\n", "def parse(self, response):\n    if not response.text:\n        new_request_or_none = get_retry_request(\n            response.request,\n            spider=self,\n            reason='empty',\n        )\n        return new_request_or_none\n"], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Activating a downloader middleware", "header_href": "#activating-a-downloader-middleware", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">DOWNLOADER_MIDDLEWARES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'myproject.middlewares.CustomDownloaderMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">543</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">DOWNLOADER_MIDDLEWARES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'myproject.middlewares.CustomDownloaderMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">543</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["DOWNLOADER_MIDDLEWARES = {\n    'myproject.middlewares.CustomDownloaderMiddleware': 543,\n}\n", "DOWNLOADER_MIDDLEWARES = {\n    'myproject.middlewares.CustomDownloaderMiddleware': 543,\n    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,\n}\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Writing your own downloader middleware", "header_href": "#writing-your-own-downloader-middleware", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Built-in downloader middleware reference", "header_href": "#built-in-downloader-middleware-reference", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">url</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">urls</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">meta</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'cookiejar'</span><span class=\"p\">:</span> <span class=\"n\">i</span><span class=\"p\">},</span>\n        <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_page</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse_page</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"c1\"># do some processing</span>\n    <span class=\"k\">return</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s2\">\"http://www.example.com/otherpage\"</span><span class=\"p\">,</span>\n        <span class=\"n\">meta</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'cookiejar'</span><span class=\"p\">:</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"p\">[</span><span class=\"s1\">'cookiejar'</span><span class=\"p\">]},</span>\n        <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_other_page</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">2011</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">14</span><span class=\"p\">:</span><span class=\"mi\">35</span><span class=\"p\">:</span><span class=\"mi\">10</span><span class=\"o\">-</span><span class=\"mi\">0300</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Spider</span> <span class=\"n\">opened</span>\n<span class=\"mi\">2011</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">14</span><span class=\"p\">:</span><span class=\"mi\">35</span><span class=\"p\">:</span><span class=\"mi\">10</span><span class=\"o\">-</span><span class=\"mi\">0300</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">downloadermiddlewares</span><span class=\"o\">.</span><span class=\"n\">cookies</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Sending</span> <span class=\"n\">cookies</span> <span class=\"n\">to</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">diningcity</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">netherlands</span><span class=\"o\">/</span><span class=\"n\">index</span><span class=\"o\">.</span><span class=\"n\">html</span><span class=\"o\">&gt;</span>\n        <span class=\"n\">Cookie</span><span class=\"p\">:</span> <span class=\"n\">clientlanguage_nl</span><span class=\"o\">=</span><span class=\"n\">en_EN</span>\n<span class=\"mi\">2011</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">14</span><span class=\"p\">:</span><span class=\"mi\">35</span><span class=\"p\">:</span><span class=\"mi\">14</span><span class=\"o\">-</span><span class=\"mi\">0300</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">downloadermiddlewares</span><span class=\"o\">.</span><span class=\"n\">cookies</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Received</span> <span class=\"n\">cookies</span> <span class=\"n\">from</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">diningcity</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">netherlands</span><span class=\"o\">/</span><span class=\"n\">index</span><span class=\"o\">.</span><span class=\"n\">html</span><span class=\"o\">&gt;</span>\n        <span class=\"n\">Set</span><span class=\"o\">-</span><span class=\"n\">Cookie</span><span class=\"p\">:</span> <span class=\"n\">JSESSIONID</span><span class=\"o\">=</span><span class=\"n\">B</span><span class=\"o\">~</span><span class=\"n\">FA4DC0C496C8762AE4F1A620EAB34F38</span><span class=\"p\">;</span> <span class=\"n\">Path</span><span class=\"o\">=/</span>\n        <span class=\"n\">Set</span><span class=\"o\">-</span><span class=\"n\">Cookie</span><span class=\"p\">:</span> <span class=\"n\">ip_isocode</span><span class=\"o\">=</span><span class=\"n\">US</span>\n        <span class=\"n\">Set</span><span class=\"o\">-</span><span class=\"n\">Cookie</span><span class=\"p\">:</span> <span class=\"n\">clientlanguage_nl</span><span class=\"o\">=</span><span class=\"n\">en_EN</span><span class=\"p\">;</span> <span class=\"n\">Expires</span><span class=\"o\">=</span><span class=\"n\">Thu</span><span class=\"p\">,</span> <span class=\"mi\">07</span><span class=\"o\">-</span><span class=\"n\">Apr</span><span class=\"o\">-</span><span class=\"mi\">2011</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">34</span> <span class=\"n\">GMT</span><span class=\"p\">;</span> <span class=\"n\">Path</span><span class=\"o\">=/</span>\n<span class=\"mi\">2011</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">14</span><span class=\"p\">:</span><span class=\"mi\">49</span><span class=\"p\">:</span><span class=\"mi\">50</span><span class=\"o\">-</span><span class=\"mi\">0300</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">diningcity</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">netherlands</span><span class=\"o\">/</span><span class=\"n\">index</span><span class=\"o\">.</span><span class=\"n\">html</span><span class=\"o\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"o\">...</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">SomeIntranetSiteSpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n\n    <span class=\"n\">http_user</span> <span class=\"o\">=</span> <span class=\"s1\">'someuser'</span>\n    <span class=\"n\">http_pass</span> <span class=\"o\">=</span> <span class=\"s1\">'somepass'</span>\n    <span class=\"n\">http_auth_domain</span> <span class=\"o\">=</span> <span class=\"s1\">'intranet.example.com'</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'intranet.example.com'</span>\n\n    <span class=\"c1\"># .. rest of the spider code omitted ...</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"o\">/</span><span class=\"n\">path</span><span class=\"o\">/</span><span class=\"n\">to</span><span class=\"o\">/</span><span class=\"n\">cache</span><span class=\"o\">/</span><span class=\"nb\">dir</span><span class=\"o\">/</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"mi\">72</span><span class=\"o\">/</span><span class=\"mi\">72811</span><span class=\"n\">f648e718090f041317756c03adb0ada46c7</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">handle_httpstatus_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">301</span><span class=\"p\">,</span> <span class=\"mi\">302</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">:</span>\n        <span class=\"n\">new_request_or_none</span> <span class=\"o\">=</span> <span class=\"n\">get_retry_request</span><span class=\"p\">(</span>\n            <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">request</span><span class=\"p\">,</span>\n            <span class=\"n\">spider</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"p\">,</span>\n            <span class=\"n\">reason</span><span class=\"o\">=</span><span class=\"s1\">'empty'</span><span class=\"p\">,</span>\n        <span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">new_request_or_none</span>\n</pre></div>"], "codes_text": ["for i, url in enumerate(urls):\n    yield scrapy.Request(url, meta={'cookiejar': i},\n        callback=self.parse_page)\n", "def parse_page(self, response):\n    # do some processing\n    return scrapy.Request(\"http://www.example.com/otherpage\",\n        meta={'cookiejar': response.meta['cookiejar']},\n        callback=self.parse_other_page)\n", "2011-04-06 14:35:10-0300 [scrapy.core.engine] INFO: Spider opened\n2011-04-06 14:35:10-0300 [scrapy.downloadermiddlewares.cookies] DEBUG: Sending cookies to: <GET http://www.diningcity.com/netherlands/index.html>\n        Cookie: clientlanguage_nl=en_EN\n2011-04-06 14:35:14-0300 [scrapy.downloadermiddlewares.cookies] DEBUG: Received cookies from: <200 http://www.diningcity.com/netherlands/index.html>\n        Set-Cookie: JSESSIONID=B~FA4DC0C496C8762AE4F1A620EAB34F38; Path=/\n        Set-Cookie: ip_isocode=US\n        Set-Cookie: clientlanguage_nl=en_EN; Expires=Thu, 07-Apr-2011 21:21:34 GMT; Path=/\n2011-04-06 14:49:50-0300 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.diningcity.com/netherlands/index.html> (referer: None)\n[...]\n", "from scrapy.spiders import CrawlSpider\n\nclass SomeIntranetSiteSpider(CrawlSpider):\n\n    http_user = 'someuser'\n    http_pass = 'somepass'\n    http_auth_domain = 'intranet.example.com'\n    name = 'intranet.example.com'\n\n    # .. rest of the spider code omitted ...\n", "/path/to/cache/dir/example.com/72/72811f648e718090f041317756c03adb0ada46c7\n", "class MySpider(CrawlSpider):\n    handle_httpstatus_list = [301, 302]\n", "def parse(self, response):\n    if not response.text:\n        new_request_or_none = get_retry_request(\n            response.request,\n            spider=self,\n            reason='empty',\n        )\n        return new_request_or_none\n"], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "CookiesMiddleware", "header_href": "#module-scrapy.downloadermiddlewares.cookies", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">url</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">urls</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">meta</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'cookiejar'</span><span class=\"p\">:</span> <span class=\"n\">i</span><span class=\"p\">},</span>\n        <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_page</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse_page</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"c1\"># do some processing</span>\n    <span class=\"k\">return</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s2\">\"http://www.example.com/otherpage\"</span><span class=\"p\">,</span>\n        <span class=\"n\">meta</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'cookiejar'</span><span class=\"p\">:</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"p\">[</span><span class=\"s1\">'cookiejar'</span><span class=\"p\">]},</span>\n        <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_other_page</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">2011</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">14</span><span class=\"p\">:</span><span class=\"mi\">35</span><span class=\"p\">:</span><span class=\"mi\">10</span><span class=\"o\">-</span><span class=\"mi\">0300</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Spider</span> <span class=\"n\">opened</span>\n<span class=\"mi\">2011</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">14</span><span class=\"p\">:</span><span class=\"mi\">35</span><span class=\"p\">:</span><span class=\"mi\">10</span><span class=\"o\">-</span><span class=\"mi\">0300</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">downloadermiddlewares</span><span class=\"o\">.</span><span class=\"n\">cookies</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Sending</span> <span class=\"n\">cookies</span> <span class=\"n\">to</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">diningcity</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">netherlands</span><span class=\"o\">/</span><span class=\"n\">index</span><span class=\"o\">.</span><span class=\"n\">html</span><span class=\"o\">&gt;</span>\n        <span class=\"n\">Cookie</span><span class=\"p\">:</span> <span class=\"n\">clientlanguage_nl</span><span class=\"o\">=</span><span class=\"n\">en_EN</span>\n<span class=\"mi\">2011</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">14</span><span class=\"p\">:</span><span class=\"mi\">35</span><span class=\"p\">:</span><span class=\"mi\">14</span><span class=\"o\">-</span><span class=\"mi\">0300</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">downloadermiddlewares</span><span class=\"o\">.</span><span class=\"n\">cookies</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Received</span> <span class=\"n\">cookies</span> <span class=\"n\">from</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">diningcity</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">netherlands</span><span class=\"o\">/</span><span class=\"n\">index</span><span class=\"o\">.</span><span class=\"n\">html</span><span class=\"o\">&gt;</span>\n        <span class=\"n\">Set</span><span class=\"o\">-</span><span class=\"n\">Cookie</span><span class=\"p\">:</span> <span class=\"n\">JSESSIONID</span><span class=\"o\">=</span><span class=\"n\">B</span><span class=\"o\">~</span><span class=\"n\">FA4DC0C496C8762AE4F1A620EAB34F38</span><span class=\"p\">;</span> <span class=\"n\">Path</span><span class=\"o\">=/</span>\n        <span class=\"n\">Set</span><span class=\"o\">-</span><span class=\"n\">Cookie</span><span class=\"p\">:</span> <span class=\"n\">ip_isocode</span><span class=\"o\">=</span><span class=\"n\">US</span>\n        <span class=\"n\">Set</span><span class=\"o\">-</span><span class=\"n\">Cookie</span><span class=\"p\">:</span> <span class=\"n\">clientlanguage_nl</span><span class=\"o\">=</span><span class=\"n\">en_EN</span><span class=\"p\">;</span> <span class=\"n\">Expires</span><span class=\"o\">=</span><span class=\"n\">Thu</span><span class=\"p\">,</span> <span class=\"mi\">07</span><span class=\"o\">-</span><span class=\"n\">Apr</span><span class=\"o\">-</span><span class=\"mi\">2011</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">34</span> <span class=\"n\">GMT</span><span class=\"p\">;</span> <span class=\"n\">Path</span><span class=\"o\">=/</span>\n<span class=\"mi\">2011</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">14</span><span class=\"p\">:</span><span class=\"mi\">49</span><span class=\"p\">:</span><span class=\"mi\">50</span><span class=\"o\">-</span><span class=\"mi\">0300</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">diningcity</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">netherlands</span><span class=\"o\">/</span><span class=\"n\">index</span><span class=\"o\">.</span><span class=\"n\">html</span><span class=\"o\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"o\">...</span><span class=\"p\">]</span>\n</pre></div>"], "codes_text": ["for i, url in enumerate(urls):\n    yield scrapy.Request(url, meta={'cookiejar': i},\n        callback=self.parse_page)\n", "def parse_page(self, response):\n    # do some processing\n    return scrapy.Request(\"http://www.example.com/otherpage\",\n        meta={'cookiejar': response.meta['cookiejar']},\n        callback=self.parse_other_page)\n", "2011-04-06 14:35:10-0300 [scrapy.core.engine] INFO: Spider opened\n2011-04-06 14:35:10-0300 [scrapy.downloadermiddlewares.cookies] DEBUG: Sending cookies to: <GET http://www.diningcity.com/netherlands/index.html>\n        Cookie: clientlanguage_nl=en_EN\n2011-04-06 14:35:14-0300 [scrapy.downloadermiddlewares.cookies] DEBUG: Received cookies from: <200 http://www.diningcity.com/netherlands/index.html>\n        Set-Cookie: JSESSIONID=B~FA4DC0C496C8762AE4F1A620EAB34F38; Path=/\n        Set-Cookie: ip_isocode=US\n        Set-Cookie: clientlanguage_nl=en_EN; Expires=Thu, 07-Apr-2011 21:21:34 GMT; Path=/\n2011-04-06 14:49:50-0300 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.diningcity.com/netherlands/index.html> (referer: None)\n[...]\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Multiple cookie sessions per spider", "header_href": "#multiple-cookie-sessions-per-spider", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">url</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">urls</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">meta</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'cookiejar'</span><span class=\"p\">:</span> <span class=\"n\">i</span><span class=\"p\">},</span>\n        <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_page</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse_page</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"c1\"># do some processing</span>\n    <span class=\"k\">return</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s2\">\"http://www.example.com/otherpage\"</span><span class=\"p\">,</span>\n        <span class=\"n\">meta</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'cookiejar'</span><span class=\"p\">:</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"p\">[</span><span class=\"s1\">'cookiejar'</span><span class=\"p\">]},</span>\n        <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse_other_page</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["for i, url in enumerate(urls):\n    yield scrapy.Request(url, meta={'cookiejar': i},\n        callback=self.parse_page)\n", "def parse_page(self, response):\n    # do some processing\n    return scrapy.Request(\"http://www.example.com/otherpage\",\n        meta={'cookiejar': response.meta['cookiejar']},\n        callback=self.parse_other_page)\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "COOKIES_ENABLED", "header_href": "#cookies-enabled", "codes": [], "codes_text": [], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "COOKIES_DEBUG", "header_href": "#cookies-debug", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"mi\">2011</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">14</span><span class=\"p\">:</span><span class=\"mi\">35</span><span class=\"p\">:</span><span class=\"mi\">10</span><span class=\"o\">-</span><span class=\"mi\">0300</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">INFO</span><span class=\"p\">:</span> <span class=\"n\">Spider</span> <span class=\"n\">opened</span>\n<span class=\"mi\">2011</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">14</span><span class=\"p\">:</span><span class=\"mi\">35</span><span class=\"p\">:</span><span class=\"mi\">10</span><span class=\"o\">-</span><span class=\"mi\">0300</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">downloadermiddlewares</span><span class=\"o\">.</span><span class=\"n\">cookies</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Sending</span> <span class=\"n\">cookies</span> <span class=\"n\">to</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">diningcity</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">netherlands</span><span class=\"o\">/</span><span class=\"n\">index</span><span class=\"o\">.</span><span class=\"n\">html</span><span class=\"o\">&gt;</span>\n        <span class=\"n\">Cookie</span><span class=\"p\">:</span> <span class=\"n\">clientlanguage_nl</span><span class=\"o\">=</span><span class=\"n\">en_EN</span>\n<span class=\"mi\">2011</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">14</span><span class=\"p\">:</span><span class=\"mi\">35</span><span class=\"p\">:</span><span class=\"mi\">14</span><span class=\"o\">-</span><span class=\"mi\">0300</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">downloadermiddlewares</span><span class=\"o\">.</span><span class=\"n\">cookies</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Received</span> <span class=\"n\">cookies</span> <span class=\"n\">from</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"mi\">200</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">diningcity</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">netherlands</span><span class=\"o\">/</span><span class=\"n\">index</span><span class=\"o\">.</span><span class=\"n\">html</span><span class=\"o\">&gt;</span>\n        <span class=\"n\">Set</span><span class=\"o\">-</span><span class=\"n\">Cookie</span><span class=\"p\">:</span> <span class=\"n\">JSESSIONID</span><span class=\"o\">=</span><span class=\"n\">B</span><span class=\"o\">~</span><span class=\"n\">FA4DC0C496C8762AE4F1A620EAB34F38</span><span class=\"p\">;</span> <span class=\"n\">Path</span><span class=\"o\">=/</span>\n        <span class=\"n\">Set</span><span class=\"o\">-</span><span class=\"n\">Cookie</span><span class=\"p\">:</span> <span class=\"n\">ip_isocode</span><span class=\"o\">=</span><span class=\"n\">US</span>\n        <span class=\"n\">Set</span><span class=\"o\">-</span><span class=\"n\">Cookie</span><span class=\"p\">:</span> <span class=\"n\">clientlanguage_nl</span><span class=\"o\">=</span><span class=\"n\">en_EN</span><span class=\"p\">;</span> <span class=\"n\">Expires</span><span class=\"o\">=</span><span class=\"n\">Thu</span><span class=\"p\">,</span> <span class=\"mi\">07</span><span class=\"o\">-</span><span class=\"n\">Apr</span><span class=\"o\">-</span><span class=\"mi\">2011</span> <span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">21</span><span class=\"p\">:</span><span class=\"mi\">34</span> <span class=\"n\">GMT</span><span class=\"p\">;</span> <span class=\"n\">Path</span><span class=\"o\">=/</span>\n<span class=\"mi\">2011</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">14</span><span class=\"p\">:</span><span class=\"mi\">49</span><span class=\"p\">:</span><span class=\"mi\">50</span><span class=\"o\">-</span><span class=\"mi\">0300</span> <span class=\"p\">[</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"p\">]</span> <span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Crawled</span> <span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">diningcity</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">netherlands</span><span class=\"o\">/</span><span class=\"n\">index</span><span class=\"o\">.</span><span class=\"n\">html</span><span class=\"o\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">referer</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"o\">...</span><span class=\"p\">]</span>\n</pre></div>"], "codes_text": ["2011-04-06 14:35:10-0300 [scrapy.core.engine] INFO: Spider opened\n2011-04-06 14:35:10-0300 [scrapy.downloadermiddlewares.cookies] DEBUG: Sending cookies to: <GET http://www.diningcity.com/netherlands/index.html>\n        Cookie: clientlanguage_nl=en_EN\n2011-04-06 14:35:14-0300 [scrapy.downloadermiddlewares.cookies] DEBUG: Received cookies from: <200 http://www.diningcity.com/netherlands/index.html>\n        Set-Cookie: JSESSIONID=B~FA4DC0C496C8762AE4F1A620EAB34F38; Path=/\n        Set-Cookie: ip_isocode=US\n        Set-Cookie: clientlanguage_nl=en_EN; Expires=Thu, 07-Apr-2011 21:21:34 GMT; Path=/\n2011-04-06 14:49:50-0300 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.diningcity.com/netherlands/index.html> (referer: None)\n[...]\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DefaultHeadersMiddleware", "header_href": "#module-scrapy.downloadermiddlewares.defaultheaders", "codes": [], "codes_text": [], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DownloadTimeoutMiddleware", "header_href": "#module-scrapy.downloadermiddlewares.downloadtimeout", "codes": [], "codes_text": [], "index": 10}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "HttpAuthMiddleware", "header_href": "#module-scrapy.downloadermiddlewares.httpauth", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">SomeIntranetSiteSpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n\n    <span class=\"n\">http_user</span> <span class=\"o\">=</span> <span class=\"s1\">'someuser'</span>\n    <span class=\"n\">http_pass</span> <span class=\"o\">=</span> <span class=\"s1\">'somepass'</span>\n    <span class=\"n\">http_auth_domain</span> <span class=\"o\">=</span> <span class=\"s1\">'intranet.example.com'</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'intranet.example.com'</span>\n\n    <span class=\"c1\"># .. rest of the spider code omitted ...</span>\n</pre></div>"], "codes_text": ["from scrapy.spiders import CrawlSpider\n\nclass SomeIntranetSiteSpider(CrawlSpider):\n\n    http_user = 'someuser'\n    http_pass = 'somepass'\n    http_auth_domain = 'intranet.example.com'\n    name = 'intranet.example.com'\n\n    # .. rest of the spider code omitted ...\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "HttpCacheMiddleware", "header_href": "#module-scrapy.downloadermiddlewares.httpcache", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"o\">/</span><span class=\"n\">path</span><span class=\"o\">/</span><span class=\"n\">to</span><span class=\"o\">/</span><span class=\"n\">cache</span><span class=\"o\">/</span><span class=\"nb\">dir</span><span class=\"o\">/</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"mi\">72</span><span class=\"o\">/</span><span class=\"mi\">72811</span><span class=\"n\">f648e718090f041317756c03adb0ada46c7</span>\n</pre></div>"], "codes_text": ["/path/to/cache/dir/example.com/72/72811f648e718090f041317756c03adb0ada46c7\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Dummy policy (default)", "header_href": "#dummy-policy-default", "codes": [], "codes_text": [], "index": 13}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "RFC2616 policy", "header_href": "#rfc2616-policy", "codes": [], "codes_text": [], "index": 14}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Filesystem storage backend (default)", "header_href": "#filesystem-storage-backend-default", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"o\">/</span><span class=\"n\">path</span><span class=\"o\">/</span><span class=\"n\">to</span><span class=\"o\">/</span><span class=\"n\">cache</span><span class=\"o\">/</span><span class=\"nb\">dir</span><span class=\"o\">/</span><span class=\"n\">example</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"mi\">72</span><span class=\"o\">/</span><span class=\"mi\">72811</span><span class=\"n\">f648e718090f041317756c03adb0ada46c7</span>\n</pre></div>"], "codes_text": ["/path/to/cache/dir/example.com/72/72811f648e718090f041317756c03adb0ada46c7\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "DBM storage backend", "header_href": "#dbm-storage-backend", "codes": [], "codes_text": [], "index": 16}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Writing your own storage backend", "header_href": "#writing-your-own-storage-backend", "codes": [], "codes_text": [], "index": 17}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "HTTPCache middleware settings", "header_href": "#httpcache-middleware-settings", "codes": [], "codes_text": [], "index": 18}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "HTTPCACHE_ENABLED", "header_href": "#httpcache-enabled", "codes": [], "codes_text": [], "index": 19}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "HTTPCACHE_EXPIRATION_SECS", "header_href": "#httpcache-expiration-secs", "codes": [], "codes_text": [], "index": 20}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "HTTPCACHE_DIR", "header_href": "#httpcache-dir", "codes": [], "codes_text": [], "index": 21}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "HTTPCACHE_IGNORE_HTTP_CODES", "header_href": "#httpcache-ignore-http-codes", "codes": [], "codes_text": [], "index": 22}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "HTTPCACHE_IGNORE_MISSING", "header_href": "#httpcache-ignore-missing", "codes": [], "codes_text": [], "index": 23}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "HTTPCACHE_IGNORE_SCHEMES", "header_href": "#httpcache-ignore-schemes", "codes": [], "codes_text": [], "index": 24}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "HTTPCACHE_STORAGE", "header_href": "#httpcache-storage", "codes": [], "codes_text": [], "index": 25}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "HTTPCACHE_DBM_MODULE", "header_href": "#httpcache-dbm-module", "codes": [], "codes_text": [], "index": 26}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "HTTPCACHE_POLICY", "header_href": "#httpcache-policy", "codes": [], "codes_text": [], "index": 27}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "HTTPCACHE_GZIP", "header_href": "#httpcache-gzip", "codes": [], "codes_text": [], "index": 28}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "HTTPCACHE_ALWAYS_STORE", "header_href": "#httpcache-always-store", "codes": [], "codes_text": [], "index": 29}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "HTTPCACHE_IGNORE_RESPONSE_CACHE_CONTROLS", "header_href": "#httpcache-ignore-response-cache-controls", "codes": [], "codes_text": [], "index": 30}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "HttpCompressionMiddleware", "header_href": "#module-scrapy.downloadermiddlewares.httpcompression", "codes": [], "codes_text": [], "index": 31}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "HttpCompressionMiddleware Settings", "header_href": "#httpcompressionmiddleware-settings", "codes": [], "codes_text": [], "index": 32}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "COMPRESSION_ENABLED", "header_href": "#compression-enabled", "codes": [], "codes_text": [], "index": 33}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "HttpProxyMiddleware", "header_href": "#module-scrapy.downloadermiddlewares.httpproxy", "codes": [], "codes_text": [], "index": 34}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "RedirectMiddleware", "header_href": "#module-scrapy.downloadermiddlewares.redirect", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">handle_httpstatus_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">301</span><span class=\"p\">,</span> <span class=\"mi\">302</span><span class=\"p\">]</span>\n</pre></div>"], "codes_text": ["class MySpider(CrawlSpider):\n    handle_httpstatus_list = [301, 302]\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "RedirectMiddleware settings", "header_href": "#redirectmiddleware-settings", "codes": [], "codes_text": [], "index": 36}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "REDIRECT_ENABLED", "header_href": "#redirect-enabled", "codes": [], "codes_text": [], "index": 37}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "REDIRECT_MAX_TIMES", "header_href": "#redirect-max-times", "codes": [], "codes_text": [], "index": 38}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MetaRefreshMiddleware", "header_href": "#metarefreshmiddleware", "codes": [], "codes_text": [], "index": 39}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "MetaRefreshMiddleware settings", "header_href": "#metarefreshmiddleware-settings", "codes": [], "codes_text": [], "index": 40}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "METAREFRESH_ENABLED", "header_href": "#metarefresh-enabled", "codes": [], "codes_text": [], "index": 41}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "METAREFRESH_IGNORE_TAGS", "header_href": "#metarefresh-ignore-tags", "codes": [], "codes_text": [], "index": 42}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "METAREFRESH_MAXDELAY", "header_href": "#metarefresh-maxdelay", "codes": [], "codes_text": [], "index": 43}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "RetryMiddleware", "header_href": "#module-scrapy.downloadermiddlewares.retry", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">:</span>\n        <span class=\"n\">new_request_or_none</span> <span class=\"o\">=</span> <span class=\"n\">get_retry_request</span><span class=\"p\">(</span>\n            <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">request</span><span class=\"p\">,</span>\n            <span class=\"n\">spider</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"p\">,</span>\n            <span class=\"n\">reason</span><span class=\"o\">=</span><span class=\"s1\">'empty'</span><span class=\"p\">,</span>\n        <span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">new_request_or_none</span>\n</pre></div>"], "codes_text": ["def parse(self, response):\n    if not response.text:\n        new_request_or_none = get_retry_request(\n            response.request,\n            spider=self,\n            reason='empty',\n        )\n        return new_request_or_none\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "RetryMiddleware Settings", "header_href": "#retrymiddleware-settings", "codes": [], "codes_text": [], "index": 45}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "RETRY_ENABLED", "header_href": "#retry-enabled", "codes": [], "codes_text": [], "index": 46}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "RETRY_TIMES", "header_href": "#retry-times", "codes": [], "codes_text": [], "index": 47}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "RETRY_HTTP_CODES", "header_href": "#retry-http-codes", "codes": [], "codes_text": [], "index": 48}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "RETRY_PRIORITY_ADJUST", "header_href": "#retry-priority-adjust", "codes": [], "codes_text": [], "index": 49}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "RobotsTxtMiddleware", "header_href": "#module-scrapy.downloadermiddlewares.robotstxt", "codes": [], "codes_text": [], "index": 50}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Protego parser", "header_href": "#protego-parser", "codes": [], "codes_text": [], "index": 51}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "RobotFileParser", "header_href": "#robotfileparser", "codes": [], "codes_text": [], "index": 52}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Reppy parser", "header_href": "#reppy-parser", "codes": [], "codes_text": [], "index": 53}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Robotexclusionrulesparser", "header_href": "#robotexclusionrulesparser", "codes": [], "codes_text": [], "index": 54}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Implementing support for a new parser", "header_href": "#implementing-support-for-a-new-parser", "codes": [], "codes_text": [], "index": 55}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DownloaderStats", "header_href": "#module-scrapy.downloadermiddlewares.stats", "codes": [], "codes_text": [], "index": 56}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "UserAgentMiddleware", "header_href": "#module-scrapy.downloadermiddlewares.useragent", "codes": [], "codes_text": [], "index": 57}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "AjaxCrawlMiddleware", "header_href": "#module-scrapy.downloadermiddlewares.ajaxcrawl", "codes": [], "codes_text": [], "index": 58}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "AjaxCrawlMiddleware Settings", "header_href": "#ajaxcrawlmiddleware-settings", "codes": [], "codes_text": [], "index": 59}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "AJAXCRAWL_ENABLED", "header_href": "#ajaxcrawl-enabled", "codes": [], "codes_text": [], "index": 60}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "HttpProxyMiddleware settings", "header_href": "#httpproxymiddleware-settings", "codes": [], "codes_text": [], "index": 61}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "HTTPPROXY_ENABLED", "header_href": "#httpproxy-enabled", "codes": [], "codes_text": [], "index": 62}
{"url": "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "HTTPPROXY_AUTH_ENCODING", "header_href": "#httpproxy-auth-encoding", "codes": [], "codes_text": [], "index": 63}
{"url": "https://docs.scrapy.org/en/latest/topics/spider-middleware.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Spider Middleware", "header_href": "#spider-middleware", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">SPIDER_MIDDLEWARES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'myproject.middlewares.CustomSpiderMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">543</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">SPIDER_MIDDLEWARES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'myproject.middlewares.CustomSpiderMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">543</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">handle_httpstatus_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">404</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Filtered</span> <span class=\"n\">offsite</span> <span class=\"n\">request</span> <span class=\"n\">to</span> <span class=\"s1\">'www.othersite.com'</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">othersite</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">some</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">.</span><span class=\"n\">html</span><span class=\"o\">&gt;</span>\n</pre></div>"], "codes_text": ["SPIDER_MIDDLEWARES = {\n    'myproject.middlewares.CustomSpiderMiddleware': 543,\n}\n", "SPIDER_MIDDLEWARES = {\n    'myproject.middlewares.CustomSpiderMiddleware': 543,\n    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': None,\n}\n", "class MySpider(CrawlSpider):\n    handle_httpstatus_list = [404]\n", "DEBUG: Filtered offsite request to 'www.othersite.com': <GET http://www.othersite.com/some/page.html>\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/spider-middleware.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Activating a spider middleware", "header_href": "#activating-a-spider-middleware", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">SPIDER_MIDDLEWARES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'myproject.middlewares.CustomSpiderMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">543</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">SPIDER_MIDDLEWARES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'myproject.middlewares.CustomSpiderMiddleware'</span><span class=\"p\">:</span> <span class=\"mi\">543</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["SPIDER_MIDDLEWARES = {\n    'myproject.middlewares.CustomSpiderMiddleware': 543,\n}\n", "SPIDER_MIDDLEWARES = {\n    'myproject.middlewares.CustomSpiderMiddleware': 543,\n    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': None,\n}\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/spider-middleware.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Writing your own spider middleware", "header_href": "#writing-your-own-spider-middleware", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/spider-middleware.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Built-in spider middleware reference", "header_href": "#built-in-spider-middleware-reference", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">handle_httpstatus_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">404</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Filtered</span> <span class=\"n\">offsite</span> <span class=\"n\">request</span> <span class=\"n\">to</span> <span class=\"s1\">'www.othersite.com'</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">othersite</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">some</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">.</span><span class=\"n\">html</span><span class=\"o\">&gt;</span>\n</pre></div>"], "codes_text": ["class MySpider(CrawlSpider):\n    handle_httpstatus_list = [404]\n", "DEBUG: Filtered offsite request to 'www.othersite.com': <GET http://www.othersite.com/some/page.html>\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/spider-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "DepthMiddleware", "header_href": "#module-scrapy.spidermiddlewares.depth", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/spider-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "HttpErrorMiddleware", "header_href": "#module-scrapy.spidermiddlewares.httperror", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">handle_httpstatus_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">404</span><span class=\"p\">]</span>\n</pre></div>"], "codes_text": ["class MySpider(CrawlSpider):\n    handle_httpstatus_list = [404]\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/spider-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "HttpErrorMiddleware settings", "header_href": "#httperrormiddleware-settings", "codes": [], "codes_text": [], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/spider-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "HTTPERROR_ALLOWED_CODES", "header_href": "#httperror-allowed-codes", "codes": [], "codes_text": [], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/spider-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "HTTPERROR_ALLOW_ALL", "header_href": "#httperror-allow-all", "codes": [], "codes_text": [], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/topics/spider-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "OffsiteMiddleware", "header_href": "#module-scrapy.spidermiddlewares.offsite", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">DEBUG</span><span class=\"p\">:</span> <span class=\"n\">Filtered</span> <span class=\"n\">offsite</span> <span class=\"n\">request</span> <span class=\"n\">to</span> <span class=\"s1\">'www.othersite.com'</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">GET</span> <span class=\"n\">http</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">othersite</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">some</span><span class=\"o\">/</span><span class=\"n\">page</span><span class=\"o\">.</span><span class=\"n\">html</span><span class=\"o\">&gt;</span>\n</pre></div>"], "codes_text": ["DEBUG: Filtered offsite request to 'www.othersite.com': <GET http://www.othersite.com/some/page.html>\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/spider-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "RefererMiddleware", "header_href": "#module-scrapy.spidermiddlewares.referer", "codes": [], "codes_text": [], "index": 11}
{"url": "https://docs.scrapy.org/en/latest/topics/spider-middleware.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "RefererMiddleware settings", "header_href": "#referermiddleware-settings", "codes": [], "codes_text": [], "index": 12}
{"url": "https://docs.scrapy.org/en/latest/topics/spider-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "REFERER_ENABLED", "header_href": "#referer-enabled", "codes": [], "codes_text": [], "index": 13}
{"url": "https://docs.scrapy.org/en/latest/topics/spider-middleware.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "REFERRER_POLICY", "header_href": "#referrer-policy", "codes": [], "codes_text": [], "index": 14}
{"url": "https://docs.scrapy.org/en/latest/topics/spider-middleware.html", "head": "", "markdown_depth": "######", "header_depth": 6, "header_text": "Acceptable values for REFERRER_POLICY", "header_href": "#acceptable-values-for-referrer-policy", "codes": [], "codes_text": [], "index": 15}
{"url": "https://docs.scrapy.org/en/latest/topics/spider-middleware.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "UrlLengthMiddleware", "header_href": "#module-scrapy.spidermiddlewares.urllength", "codes": [], "codes_text": [], "index": 16}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Extensions", "header_href": "#extensions", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">EXTENSIONS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.extensions.corestats.CoreStats'</span><span class=\"p\">:</span> <span class=\"mi\">500</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.telnet.TelnetConsole'</span><span class=\"p\">:</span> <span class=\"mi\">500</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">EXTENSIONS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.extensions.corestats.CoreStats'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">signals</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">NotConfigured</span>\n\n<span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"vm\">__name__</span><span class=\"p\">)</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">SpiderOpenCloseLogging</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item_count</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">item_count</span> <span class=\"o\">=</span> <span class=\"n\">item_count</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">items_scraped</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">from_crawler</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">crawler</span><span class=\"p\">):</span>\n        <span class=\"c1\"># first check if the extension should be enabled and raise</span>\n        <span class=\"c1\"># NotConfigured otherwise</span>\n        <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">getbool</span><span class=\"p\">(</span><span class=\"s1\">'MYEXT_ENABLED'</span><span class=\"p\">):</span>\n            <span class=\"k\">raise</span> <span class=\"n\">NotConfigured</span>\n\n        <span class=\"c1\"># get the number of items from settings</span>\n        <span class=\"n\">item_count</span> <span class=\"o\">=</span> <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">getint</span><span class=\"p\">(</span><span class=\"s1\">'MYEXT_ITEMCOUNT'</span><span class=\"p\">,</span> <span class=\"mi\">1000</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># instantiate the extension object</span>\n        <span class=\"n\">ext</span> <span class=\"o\">=</span> <span class=\"bp\">cls</span><span class=\"p\">(</span><span class=\"n\">item_count</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># connect the extension object to signals</span>\n        <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">ext</span><span class=\"o\">.</span><span class=\"n\">spider_opened</span><span class=\"p\">,</span> <span class=\"n\">signal</span><span class=\"o\">=</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">spider_opened</span><span class=\"p\">)</span>\n        <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">ext</span><span class=\"o\">.</span><span class=\"n\">spider_closed</span><span class=\"p\">,</span> <span class=\"n\">signal</span><span class=\"o\">=</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">spider_closed</span><span class=\"p\">)</span>\n        <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">ext</span><span class=\"o\">.</span><span class=\"n\">item_scraped</span><span class=\"p\">,</span> <span class=\"n\">signal</span><span class=\"o\">=</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">item_scraped</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># return the extension object</span>\n        <span class=\"k\">return</span> <span class=\"n\">ext</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">spider_opened</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s2\">\"opened spider </span><span class=\"si\">%s</span><span class=\"s2\">\"</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">spider_closed</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s2\">\"closed spider </span><span class=\"si\">%s</span><span class=\"s2\">\"</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">item_scraped</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">items_scraped</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n        <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">items_scraped</span> <span class=\"o\">%</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">item_count</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n            <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s2\">\"scraped </span><span class=\"si\">%d</span><span class=\"s2\"> items\"</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">items_scraped</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">kill</span> <span class=\"o\">-</span><span class=\"n\">QUIT</span> <span class=\"o\">&lt;</span><span class=\"n\">pid</span><span class=\"o\">&gt;</span>\n</pre></div>"], "codes_text": ["EXTENSIONS = {\n    'scrapy.extensions.corestats.CoreStats': 500,\n    'scrapy.extensions.telnet.TelnetConsole': 500,\n}\n", "EXTENSIONS = {\n    'scrapy.extensions.corestats.CoreStats': None,\n}\n", "import logging\nfrom scrapy import signals\nfrom scrapy.exceptions import NotConfigured\n\nlogger = logging.getLogger(__name__)\n\nclass SpiderOpenCloseLogging:\n\n    def __init__(self, item_count):\n        self.item_count = item_count\n        self.items_scraped = 0\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # first check if the extension should be enabled and raise\n        # NotConfigured otherwise\n        if not crawler.settings.getbool('MYEXT_ENABLED'):\n            raise NotConfigured\n\n        # get the number of items from settings\n        item_count = crawler.settings.getint('MYEXT_ITEMCOUNT', 1000)\n\n        # instantiate the extension object\n        ext = cls(item_count)\n\n        # connect the extension object to signals\n        crawler.signals.connect(ext.spider_opened, signal=signals.spider_opened)\n        crawler.signals.connect(ext.spider_closed, signal=signals.spider_closed)\n        crawler.signals.connect(ext.item_scraped, signal=signals.item_scraped)\n\n        # return the extension object\n        return ext\n\n    def spider_opened(self, spider):\n        logger.info(\"opened spider %s\", spider.name)\n\n    def spider_closed(self, spider):\n        logger.info(\"closed spider %s\", spider.name)\n\n    def item_scraped(self, item, spider):\n        self.items_scraped += 1\n        if self.items_scraped % self.item_count == 0:\n            logger.info(\"scraped %d items\", self.items_scraped)\n", "kill -QUIT <pid>\n"], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Extension settings", "header_href": "#extension-settings", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Loading & activating extensions", "header_href": "#loading-activating-extensions", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">EXTENSIONS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.extensions.corestats.CoreStats'</span><span class=\"p\">:</span> <span class=\"mi\">500</span><span class=\"p\">,</span>\n    <span class=\"s1\">'scrapy.extensions.telnet.TelnetConsole'</span><span class=\"p\">:</span> <span class=\"mi\">500</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["EXTENSIONS = {\n    'scrapy.extensions.corestats.CoreStats': 500,\n    'scrapy.extensions.telnet.TelnetConsole': 500,\n}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Available, enabled and disabled extensions", "header_href": "#available-enabled-and-disabled-extensions", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Disabling an extension", "header_href": "#disabling-an-extension", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">EXTENSIONS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy.extensions.corestats.CoreStats'</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["EXTENSIONS = {\n    'scrapy.extensions.corestats.CoreStats': None,\n}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Writing your own extension", "header_href": "#writing-your-own-extension", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">signals</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">NotConfigured</span>\n\n<span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"vm\">__name__</span><span class=\"p\">)</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">SpiderOpenCloseLogging</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item_count</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">item_count</span> <span class=\"o\">=</span> <span class=\"n\">item_count</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">items_scraped</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">from_crawler</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">crawler</span><span class=\"p\">):</span>\n        <span class=\"c1\"># first check if the extension should be enabled and raise</span>\n        <span class=\"c1\"># NotConfigured otherwise</span>\n        <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">getbool</span><span class=\"p\">(</span><span class=\"s1\">'MYEXT_ENABLED'</span><span class=\"p\">):</span>\n            <span class=\"k\">raise</span> <span class=\"n\">NotConfigured</span>\n\n        <span class=\"c1\"># get the number of items from settings</span>\n        <span class=\"n\">item_count</span> <span class=\"o\">=</span> <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">getint</span><span class=\"p\">(</span><span class=\"s1\">'MYEXT_ITEMCOUNT'</span><span class=\"p\">,</span> <span class=\"mi\">1000</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># instantiate the extension object</span>\n        <span class=\"n\">ext</span> <span class=\"o\">=</span> <span class=\"bp\">cls</span><span class=\"p\">(</span><span class=\"n\">item_count</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># connect the extension object to signals</span>\n        <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">ext</span><span class=\"o\">.</span><span class=\"n\">spider_opened</span><span class=\"p\">,</span> <span class=\"n\">signal</span><span class=\"o\">=</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">spider_opened</span><span class=\"p\">)</span>\n        <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">ext</span><span class=\"o\">.</span><span class=\"n\">spider_closed</span><span class=\"p\">,</span> <span class=\"n\">signal</span><span class=\"o\">=</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">spider_closed</span><span class=\"p\">)</span>\n        <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">ext</span><span class=\"o\">.</span><span class=\"n\">item_scraped</span><span class=\"p\">,</span> <span class=\"n\">signal</span><span class=\"o\">=</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">item_scraped</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># return the extension object</span>\n        <span class=\"k\">return</span> <span class=\"n\">ext</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">spider_opened</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s2\">\"opened spider </span><span class=\"si\">%s</span><span class=\"s2\">\"</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">spider_closed</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s2\">\"closed spider </span><span class=\"si\">%s</span><span class=\"s2\">\"</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">item_scraped</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">items_scraped</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n        <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">items_scraped</span> <span class=\"o\">%</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">item_count</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n            <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s2\">\"scraped </span><span class=\"si\">%d</span><span class=\"s2\"> items\"</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">items_scraped</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import logging\nfrom scrapy import signals\nfrom scrapy.exceptions import NotConfigured\n\nlogger = logging.getLogger(__name__)\n\nclass SpiderOpenCloseLogging:\n\n    def __init__(self, item_count):\n        self.item_count = item_count\n        self.items_scraped = 0\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # first check if the extension should be enabled and raise\n        # NotConfigured otherwise\n        if not crawler.settings.getbool('MYEXT_ENABLED'):\n            raise NotConfigured\n\n        # get the number of items from settings\n        item_count = crawler.settings.getint('MYEXT_ITEMCOUNT', 1000)\n\n        # instantiate the extension object\n        ext = cls(item_count)\n\n        # connect the extension object to signals\n        crawler.signals.connect(ext.spider_opened, signal=signals.spider_opened)\n        crawler.signals.connect(ext.spider_closed, signal=signals.spider_closed)\n        crawler.signals.connect(ext.item_scraped, signal=signals.item_scraped)\n\n        # return the extension object\n        return ext\n\n    def spider_opened(self, spider):\n        logger.info(\"opened spider %s\", spider.name)\n\n    def spider_closed(self, spider):\n        logger.info(\"closed spider %s\", spider.name)\n\n    def item_scraped(self, item, spider):\n        self.items_scraped += 1\n        if self.items_scraped % self.item_count == 0:\n            logger.info(\"scraped %d items\", self.items_scraped)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Sample extension", "header_href": "#sample-extension", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">signals</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">NotConfigured</span>\n\n<span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"vm\">__name__</span><span class=\"p\">)</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">SpiderOpenCloseLogging</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item_count</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">item_count</span> <span class=\"o\">=</span> <span class=\"n\">item_count</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">items_scraped</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">from_crawler</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">crawler</span><span class=\"p\">):</span>\n        <span class=\"c1\"># first check if the extension should be enabled and raise</span>\n        <span class=\"c1\"># NotConfigured otherwise</span>\n        <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">getbool</span><span class=\"p\">(</span><span class=\"s1\">'MYEXT_ENABLED'</span><span class=\"p\">):</span>\n            <span class=\"k\">raise</span> <span class=\"n\">NotConfigured</span>\n\n        <span class=\"c1\"># get the number of items from settings</span>\n        <span class=\"n\">item_count</span> <span class=\"o\">=</span> <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">settings</span><span class=\"o\">.</span><span class=\"n\">getint</span><span class=\"p\">(</span><span class=\"s1\">'MYEXT_ITEMCOUNT'</span><span class=\"p\">,</span> <span class=\"mi\">1000</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># instantiate the extension object</span>\n        <span class=\"n\">ext</span> <span class=\"o\">=</span> <span class=\"bp\">cls</span><span class=\"p\">(</span><span class=\"n\">item_count</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># connect the extension object to signals</span>\n        <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">ext</span><span class=\"o\">.</span><span class=\"n\">spider_opened</span><span class=\"p\">,</span> <span class=\"n\">signal</span><span class=\"o\">=</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">spider_opened</span><span class=\"p\">)</span>\n        <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">ext</span><span class=\"o\">.</span><span class=\"n\">spider_closed</span><span class=\"p\">,</span> <span class=\"n\">signal</span><span class=\"o\">=</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">spider_closed</span><span class=\"p\">)</span>\n        <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">ext</span><span class=\"o\">.</span><span class=\"n\">item_scraped</span><span class=\"p\">,</span> <span class=\"n\">signal</span><span class=\"o\">=</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">item_scraped</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># return the extension object</span>\n        <span class=\"k\">return</span> <span class=\"n\">ext</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">spider_opened</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s2\">\"opened spider </span><span class=\"si\">%s</span><span class=\"s2\">\"</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">spider_closed</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s2\">\"closed spider </span><span class=\"si\">%s</span><span class=\"s2\">\"</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">item_scraped</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">items_scraped</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n        <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">items_scraped</span> <span class=\"o\">%</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">item_count</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n            <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s2\">\"scraped </span><span class=\"si\">%d</span><span class=\"s2\"> items\"</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">items_scraped</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import logging\nfrom scrapy import signals\nfrom scrapy.exceptions import NotConfigured\n\nlogger = logging.getLogger(__name__)\n\nclass SpiderOpenCloseLogging:\n\n    def __init__(self, item_count):\n        self.item_count = item_count\n        self.items_scraped = 0\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # first check if the extension should be enabled and raise\n        # NotConfigured otherwise\n        if not crawler.settings.getbool('MYEXT_ENABLED'):\n            raise NotConfigured\n\n        # get the number of items from settings\n        item_count = crawler.settings.getint('MYEXT_ITEMCOUNT', 1000)\n\n        # instantiate the extension object\n        ext = cls(item_count)\n\n        # connect the extension object to signals\n        crawler.signals.connect(ext.spider_opened, signal=signals.spider_opened)\n        crawler.signals.connect(ext.spider_closed, signal=signals.spider_closed)\n        crawler.signals.connect(ext.item_scraped, signal=signals.item_scraped)\n\n        # return the extension object\n        return ext\n\n    def spider_opened(self, spider):\n        logger.info(\"opened spider %s\", spider.name)\n\n    def spider_closed(self, spider):\n        logger.info(\"closed spider %s\", spider.name)\n\n    def item_scraped(self, item, spider):\n        self.items_scraped += 1\n        if self.items_scraped % self.item_count == 0:\n            logger.info(\"scraped %d items\", self.items_scraped)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Built-in extensions reference", "header_href": "#built-in-extensions-reference", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">kill</span> <span class=\"o\">-</span><span class=\"n\">QUIT</span> <span class=\"o\">&lt;</span><span class=\"n\">pid</span><span class=\"o\">&gt;</span>\n</pre></div>"], "codes_text": ["kill -QUIT <pid>\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "General purpose extensions", "header_href": "#general-purpose-extensions", "codes": [], "codes_text": [], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Log Stats extension", "header_href": "#module-scrapy.extensions.logstats", "codes": [], "codes_text": [], "index": 10}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Core Stats extension", "header_href": "#module-scrapy.extensions.corestats", "codes": [], "codes_text": [], "index": 11}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Telnet console extension", "header_href": "#module-scrapy.extensions.telnet", "codes": [], "codes_text": [], "index": 12}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Memory usage extension", "header_href": "#module-scrapy.extensions.memusage", "codes": [], "codes_text": [], "index": 13}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Memory debugger extension", "header_href": "#module-scrapy.extensions.memdebug", "codes": [], "codes_text": [], "index": 14}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Close spider extension", "header_href": "#module-scrapy.extensions.closespider", "codes": [], "codes_text": [], "index": 15}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "CLOSESPIDER_TIMEOUT", "header_href": "#closespider-timeout", "codes": [], "codes_text": [], "index": 16}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "CLOSESPIDER_ITEMCOUNT", "header_href": "#closespider-itemcount", "codes": [], "codes_text": [], "index": 17}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "CLOSESPIDER_PAGECOUNT", "header_href": "#closespider-pagecount", "codes": [], "codes_text": [], "index": 18}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "#####", "header_depth": 5, "header_text": "CLOSESPIDER_ERRORCOUNT", "header_href": "#closespider-errorcount", "codes": [], "codes_text": [], "index": 19}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "StatsMailer extension", "header_href": "#module-scrapy.extensions.statsmailer", "codes": [], "codes_text": [], "index": 20}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Debugging extensions", "header_href": "#debugging-extensions", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">kill</span> <span class=\"o\">-</span><span class=\"n\">QUIT</span> <span class=\"o\">&lt;</span><span class=\"n\">pid</span><span class=\"o\">&gt;</span>\n</pre></div>"], "codes_text": ["kill -QUIT <pid>\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Stack trace dump extension", "header_href": "#stack-trace-dump-extension", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">kill</span> <span class=\"o\">-</span><span class=\"n\">QUIT</span> <span class=\"o\">&lt;</span><span class=\"n\">pid</span><span class=\"o\">&gt;</span>\n</pre></div>"], "codes_text": ["kill -QUIT <pid>\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/extensions.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Debugger extension", "header_href": "#debugger-extension", "codes": [], "codes_text": [], "index": 23}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Signals", "header_href": "#signals", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">signals</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">Spider</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">DmozSpider</span><span class=\"p\">(</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"dmoz\"</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"dmoz.org\"</span><span class=\"p\">]</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"s2\">\"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/\"</span><span class=\"p\">,</span>\n        <span class=\"s2\">\"http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/\"</span><span class=\"p\">,</span>\n    <span class=\"p\">]</span>\n\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">from_crawler</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">crawler</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"n\">spider</span> <span class=\"o\">=</span> <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">DmozSpider</span><span class=\"p\">,</span> <span class=\"bp\">cls</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">from_crawler</span><span class=\"p\">(</span><span class=\"n\">crawler</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n        <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">spider_closed</span><span class=\"p\">,</span> <span class=\"n\">signal</span><span class=\"o\">=</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">spider_closed</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">spider</span>\n\n\n    <span class=\"k\">def</span> <span class=\"nf\">spider_closed</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Spider closed: </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">)</span>\n\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">SignalSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'signals'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span><span class=\"p\">]</span>\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">from_crawler</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">crawler</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"n\">spider</span> <span class=\"o\">=</span> <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">SignalSpider</span><span class=\"p\">,</span> <span class=\"bp\">cls</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">from_crawler</span><span class=\"p\">(</span><span class=\"n\">crawler</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n        <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">item_scraped</span><span class=\"p\">,</span> <span class=\"n\">signal</span><span class=\"o\">=</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">item_scraped</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">spider</span>\n\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">item_scraped</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n        <span class=\"c1\"># Send the scraped item to the server</span>\n        <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">treq</span><span class=\"o\">.</span><span class=\"n\">post</span><span class=\"p\">(</span>\n            <span class=\"s1\">'http://example.com/post'</span><span class=\"p\">,</span>\n            <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">dumps</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">(</span><span class=\"s1\">'ascii'</span><span class=\"p\">),</span>\n            <span class=\"n\">headers</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"sa\">b</span><span class=\"s1\">'Content-Type'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"sa\">b</span><span class=\"s1\">'application/json'</span><span class=\"p\">]}</span>\n        <span class=\"p\">)</span>\n\n        <span class=\"k\">return</span> <span class=\"n\">response</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'small.author::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'tags'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.tags a.tag::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">(),</span>\n            <span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["from scrapy import signals\nfrom scrapy import Spider\n\n\nclass DmozSpider(Spider):\n    name = \"dmoz\"\n    allowed_domains = [\"dmoz.org\"]\n    start_urls = [\n        \"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/\",\n        \"http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/\",\n    ]\n\n\n    @classmethod\n    def from_crawler(cls, crawler, *args, **kwargs):\n        spider = super(DmozSpider, cls).from_crawler(crawler, *args, **kwargs)\n        crawler.signals.connect(spider.spider_closed, signal=signals.spider_closed)\n        return spider\n\n\n    def spider_closed(self, spider):\n        spider.logger.info('Spider closed: %s', spider.name)\n\n\n    def parse(self, response):\n        pass\n", "class SignalSpider(scrapy.Spider):\n    name = 'signals'\n    start_urls = ['https://quotes.toscrape.com/page/1/']\n\n    @classmethod\n    def from_crawler(cls, crawler, *args, **kwargs):\n        spider = super(SignalSpider, cls).from_crawler(crawler, *args, **kwargs)\n        crawler.signals.connect(spider.item_scraped, signal=signals.item_scraped)\n        return spider\n\n    async def item_scraped(self, item):\n        # Send the scraped item to the server\n        response = await treq.post(\n            'http://example.com/post',\n            json.dumps(item).encode('ascii'),\n            headers={b'Content-Type': [b'application/json']}\n        )\n\n        return response\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {\n                'text': quote.css('span.text::text').get(),\n                'author': quote.css('small.author::text').get(),\n                'tags': quote.css('div.tags a.tag::text').getall(),\n            }\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Deferred signal handlers", "header_href": "#deferred-signal-handlers", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">SignalSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'signals'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://quotes.toscrape.com/page/1/'</span><span class=\"p\">]</span>\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">from_crawler</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">crawler</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"n\">spider</span> <span class=\"o\">=</span> <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">SignalSpider</span><span class=\"p\">,</span> <span class=\"bp\">cls</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">from_crawler</span><span class=\"p\">(</span><span class=\"n\">crawler</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n        <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span><span class=\"n\">spider</span><span class=\"o\">.</span><span class=\"n\">item_scraped</span><span class=\"p\">,</span> <span class=\"n\">signal</span><span class=\"o\">=</span><span class=\"n\">signals</span><span class=\"o\">.</span><span class=\"n\">item_scraped</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">spider</span>\n\n    <span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">item_scraped</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n        <span class=\"c1\"># Send the scraped item to the server</span>\n        <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">treq</span><span class=\"o\">.</span><span class=\"n\">post</span><span class=\"p\">(</span>\n            <span class=\"s1\">'http://example.com/post'</span><span class=\"p\">,</span>\n            <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">dumps</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">(</span><span class=\"s1\">'ascii'</span><span class=\"p\">),</span>\n            <span class=\"n\">headers</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"sa\">b</span><span class=\"s1\">'Content-Type'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"sa\">b</span><span class=\"s1\">'application/json'</span><span class=\"p\">]}</span>\n        <span class=\"p\">)</span>\n\n        <span class=\"k\">return</span> <span class=\"n\">response</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">quote</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.quote'</span><span class=\"p\">):</span>\n            <span class=\"k\">yield</span> <span class=\"p\">{</span>\n                <span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'span.text::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'author'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'small.author::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n                <span class=\"s1\">'tags'</span><span class=\"p\">:</span> <span class=\"n\">quote</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'div.tags a.tag::text'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getall</span><span class=\"p\">(),</span>\n            <span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["class SignalSpider(scrapy.Spider):\n    name = 'signals'\n    start_urls = ['https://quotes.toscrape.com/page/1/']\n\n    @classmethod\n    def from_crawler(cls, crawler, *args, **kwargs):\n        spider = super(SignalSpider, cls).from_crawler(crawler, *args, **kwargs)\n        crawler.signals.connect(spider.item_scraped, signal=signals.item_scraped)\n        return spider\n\n    async def item_scraped(self, item):\n        # Send the scraped item to the server\n        response = await treq.post(\n            'http://example.com/post',\n            json.dumps(item).encode('ascii'),\n            headers={b'Content-Type': [b'application/json']}\n        )\n\n        return response\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {\n                'text': quote.css('span.text::text').get(),\n                'author': quote.css('small.author::text').get(),\n                'tags': quote.css('div.tags a.tag::text').getall(),\n            }\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Built-in signals reference", "header_href": "#module-scrapy.signals", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Engine signals", "header_href": "#engine-signals", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "engine_started", "header_href": "#engine-started", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "engine_stopped", "header_href": "#engine-stopped", "codes": [], "codes_text": [], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Item signals", "header_href": "#item-signals", "codes": [], "codes_text": [], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "item_scraped", "header_href": "#item-scraped", "codes": [], "codes_text": [], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "item_dropped", "header_href": "#item-dropped", "codes": [], "codes_text": [], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "item_error", "header_href": "#item-error", "codes": [], "codes_text": [], "index": 10}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Spider signals", "header_href": "#spider-signals", "codes": [], "codes_text": [], "index": 11}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "spider_closed", "header_href": "#spider-closed", "codes": [], "codes_text": [], "index": 12}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "spider_opened", "header_href": "#spider-opened", "codes": [], "codes_text": [], "index": 13}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "spider_idle", "header_href": "#spider-idle", "codes": [], "codes_text": [], "index": 14}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "spider_error", "header_href": "#spider-error", "codes": [], "codes_text": [], "index": 15}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Request signals", "header_href": "#request-signals", "codes": [], "codes_text": [], "index": 16}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "request_scheduled", "header_href": "#request-scheduled", "codes": [], "codes_text": [], "index": 17}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "request_dropped", "header_href": "#request-dropped", "codes": [], "codes_text": [], "index": 18}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "request_reached_downloader", "header_href": "#request-reached-downloader", "codes": [], "codes_text": [], "index": 19}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "request_left_downloader", "header_href": "#request-left-downloader", "codes": [], "codes_text": [], "index": 20}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "bytes_received", "header_href": "#bytes-received", "codes": [], "codes_text": [], "index": 21}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "headers_received", "header_href": "#headers-received", "codes": [], "codes_text": [], "index": 22}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Response signals", "header_href": "#response-signals", "codes": [], "codes_text": [], "index": 23}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "response_received", "header_href": "#response-received", "codes": [], "codes_text": [], "index": 24}
{"url": "https://docs.scrapy.org/en/latest/topics/signals.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "response_downloaded", "header_href": "#response-downloaded", "codes": [], "codes_text": [], "index": 25}
{"url": "https://docs.scrapy.org/en/latest/topics/scheduler.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Scheduler", "header_href": "#module-scrapy.core.scheduler", "codes": [], "codes_text": [], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/scheduler.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Overriding the default scheduler", "header_href": "#overriding-the-default-scheduler", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/scheduler.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Minimal scheduler interface", "header_href": "#minimal-scheduler-interface", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/scheduler.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Default Scrapy scheduler", "header_href": "#default-scrapy-scheduler", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/exporters.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Item Exporters", "header_href": "#module-scrapy.exporters", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exporters</span> <span class=\"kn\">import</span> <span class=\"n\">XmlItemExporter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">PerYearXmlExportPipeline</span><span class=\"p\">:</span>\n    <span class=\"sd\">\"\"\"Distribute items across multiple XML files according to their 'year' field\"\"\"</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">open_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">year_to_exporter</span> <span class=\"o\">=</span> <span class=\"p\">{}</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">close_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">exporter</span><span class=\"p\">,</span> <span class=\"n\">xml_file</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">year_to_exporter</span><span class=\"o\">.</span><span class=\"n\">values</span><span class=\"p\">():</span>\n            <span class=\"n\">exporter</span><span class=\"o\">.</span><span class=\"n\">finish_exporting</span><span class=\"p\">()</span>\n            <span class=\"n\">xml_file</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">_exporter_for_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"n\">year</span> <span class=\"o\">=</span> <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'year'</span><span class=\"p\">]</span>\n        <span class=\"k\">if</span> <span class=\"n\">year</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">year_to_exporter</span><span class=\"p\">:</span>\n            <span class=\"n\">xml_file</span> <span class=\"o\">=</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'</span><span class=\"si\">{</span><span class=\"n\">year</span><span class=\"si\">}</span><span class=\"s1\">.xml'</span><span class=\"p\">,</span> <span class=\"s1\">'wb'</span><span class=\"p\">)</span>\n            <span class=\"n\">exporter</span> <span class=\"o\">=</span> <span class=\"n\">XmlItemExporter</span><span class=\"p\">(</span><span class=\"n\">xml_file</span><span class=\"p\">)</span>\n            <span class=\"n\">exporter</span><span class=\"o\">.</span><span class=\"n\">start_exporting</span><span class=\"p\">()</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">year_to_exporter</span><span class=\"p\">[</span><span class=\"n\">year</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">exporter</span><span class=\"p\">,</span> <span class=\"n\">xml_file</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">year_to_exporter</span><span class=\"p\">[</span><span class=\"n\">year</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">exporter</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_exporter_for_item</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"n\">exporter</span><span class=\"o\">.</span><span class=\"n\">export_item</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">serialize_price</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"sa\">f</span><span class=\"s1\">'$ </span><span class=\"si\">{</span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span><span class=\"si\">}</span><span class=\"s1\">'</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">Product</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">price</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">(</span><span class=\"n\">serializer</span><span class=\"o\">=</span><span class=\"n\">serialize_price</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.exporters</span> <span class=\"kn\">import</span> <span class=\"n\">XmlItemExporter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">ProductXmlExporter</span><span class=\"p\">(</span><span class=\"n\">XmlItemExporter</span><span class=\"p\">):</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">serialize_field</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">field</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">name</span> <span class=\"o\">==</span> <span class=\"s1\">'price'</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"sa\">f</span><span class=\"s1\">'$ </span><span class=\"si\">{</span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span><span class=\"si\">}</span><span class=\"s1\">'</span>\n        <span class=\"k\">return</span> <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">serialize_field</span><span class=\"p\">(</span><span class=\"n\">field</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">Item</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'Color TV'</span><span class=\"p\">,</span> <span class=\"n\">price</span><span class=\"o\">=</span><span class=\"s1\">'1200'</span><span class=\"p\">)</span>\n<span class=\"n\">Item</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'DVD player'</span><span class=\"p\">,</span> <span class=\"n\">price</span><span class=\"o\">=</span><span class=\"s1\">'200'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">[</span><span class=\"s1\">'field1'</span><span class=\"p\">,</span> <span class=\"s1\">'field2'</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span><span class=\"s1\">'field1'</span><span class=\"p\">:</span> <span class=\"s1\">'Field 1'</span><span class=\"p\">,</span> <span class=\"s1\">'field2'</span><span class=\"p\">:</span> <span class=\"s1\">'Field 2'</span><span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;items&gt;\n  &lt;item&gt;\n    &lt;name&gt;Color TV&lt;/name&gt;\n    &lt;price&gt;1200&lt;/price&gt;\n &lt;/item&gt;\n  &lt;item&gt;\n    &lt;name&gt;DVD player&lt;/name&gt;\n    &lt;price&gt;200&lt;/price&gt;\n &lt;/item&gt;\n&lt;/items&gt;\n</pre></div>", "<div class=\"highlight\"><pre><span></span>Item(name=['John', 'Doe'], age='23')\n</pre></div>", "<div class=\"highlight\"><pre><span></span>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;items&gt;\n  &lt;item&gt;\n    &lt;name&gt;\n      &lt;value&gt;John&lt;/value&gt;\n      &lt;value&gt;Doe&lt;/value&gt;\n    &lt;/name&gt;\n    &lt;age&gt;23&lt;/age&gt;\n  &lt;/item&gt;\n&lt;/items&gt;\n</pre></div>", "<div class=\"highlight\"><pre><span></span>product,price\nColor TV,1200\nDVD player,200\n</pre></div>", "<div class=\"highlight\"><pre><span></span>{'name': 'Color TV', 'price': '1200'}\n{'name': 'DVD player', 'price': '200'}\n</pre></div>", "<div class=\"highlight\"><pre><span></span>[{\"name\": \"Color TV\", \"price\": \"1200\"},\n{\"name\": \"DVD player\", \"price\": \"200\"}]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>{\"name\": \"Color TV\", \"price\": \"1200\"}\n{\"name\": \"DVD player\", \"price\": \"200\"}\n</pre></div>"], "codes_text": ["from itemadapter import ItemAdapter\nfrom scrapy.exporters import XmlItemExporter\n\nclass PerYearXmlExportPipeline:\n    \"\"\"Distribute items across multiple XML files according to their 'year' field\"\"\"\n\n    def open_spider(self, spider):\n        self.year_to_exporter = {}\n\n    def close_spider(self, spider):\n        for exporter, xml_file in self.year_to_exporter.values():\n            exporter.finish_exporting()\n            xml_file.close()\n\n    def _exporter_for_item(self, item):\n        adapter = ItemAdapter(item)\n        year = adapter['year']\n        if year not in self.year_to_exporter:\n            xml_file = open(f'{year}.xml', 'wb')\n            exporter = XmlItemExporter(xml_file)\n            exporter.start_exporting()\n            self.year_to_exporter[year] = (exporter, xml_file)\n        return self.year_to_exporter[year][0]\n\n    def process_item(self, item, spider):\n        exporter = self._exporter_for_item(item)\n        exporter.export_item(item)\n        return item\n", "import scrapy\n\ndef serialize_price(value):\n    return f'$ {str(value)}'\n\nclass Product(scrapy.Item):\n    name = scrapy.Field()\n    price = scrapy.Field(serializer=serialize_price)\n", "from scrapy.exporters import XmlItemExporter\n\nclass ProductXmlExporter(XmlItemExporter):\n\n    def serialize_field(self, field, name, value):\n        if name == 'price':\n            return f'$ {str(value)}'\n        return super().serialize_field(field, name, value)\n", "Item(name='Color TV', price='1200')\nItem(name='DVD player', price='200')\n", "['field1', 'field2']\n", "{'field1': 'Field 1', 'field2': 'Field 2'}\n", "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<items>\n  <item>\n    <name>Color TV</name>\n    <price>1200</price>\n </item>\n  <item>\n    <name>DVD player</name>\n    <price>200</price>\n </item>\n</items>\n", "Item(name=['John', 'Doe'], age='23')\n", "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<items>\n  <item>\n    <name>\n      <value>John</value>\n      <value>Doe</value>\n    </name>\n    <age>23</age>\n  </item>\n</items>\n", "product,price\nColor TV,1200\nDVD player,200\n", "{'name': 'Color TV', 'price': '1200'}\n{'name': 'DVD player', 'price': '200'}\n", "[{\"name\": \"Color TV\", \"price\": \"1200\"},\n{\"name\": \"DVD player\", \"price\": \"200\"}]\n", "{\"name\": \"Color TV\", \"price\": \"1200\"}\n{\"name\": \"DVD player\", \"price\": \"200\"}\n"], "index": 13}
{"url": "https://docs.scrapy.org/en/latest/topics/exporters.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Using Item Exporters", "header_href": "#using-item-exporters", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">itemadapter</span> <span class=\"kn\">import</span> <span class=\"n\">ItemAdapter</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.exporters</span> <span class=\"kn\">import</span> <span class=\"n\">XmlItemExporter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">PerYearXmlExportPipeline</span><span class=\"p\">:</span>\n    <span class=\"sd\">\"\"\"Distribute items across multiple XML files according to their 'year' field\"\"\"</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">open_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">year_to_exporter</span> <span class=\"o\">=</span> <span class=\"p\">{}</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">close_spider</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">exporter</span><span class=\"p\">,</span> <span class=\"n\">xml_file</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">year_to_exporter</span><span class=\"o\">.</span><span class=\"n\">values</span><span class=\"p\">():</span>\n            <span class=\"n\">exporter</span><span class=\"o\">.</span><span class=\"n\">finish_exporting</span><span class=\"p\">()</span>\n            <span class=\"n\">xml_file</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">_exporter_for_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n        <span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">ItemAdapter</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"n\">year</span> <span class=\"o\">=</span> <span class=\"n\">adapter</span><span class=\"p\">[</span><span class=\"s1\">'year'</span><span class=\"p\">]</span>\n        <span class=\"k\">if</span> <span class=\"n\">year</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">year_to_exporter</span><span class=\"p\">:</span>\n            <span class=\"n\">xml_file</span> <span class=\"o\">=</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">'</span><span class=\"si\">{</span><span class=\"n\">year</span><span class=\"si\">}</span><span class=\"s1\">.xml'</span><span class=\"p\">,</span> <span class=\"s1\">'wb'</span><span class=\"p\">)</span>\n            <span class=\"n\">exporter</span> <span class=\"o\">=</span> <span class=\"n\">XmlItemExporter</span><span class=\"p\">(</span><span class=\"n\">xml_file</span><span class=\"p\">)</span>\n            <span class=\"n\">exporter</span><span class=\"o\">.</span><span class=\"n\">start_exporting</span><span class=\"p\">()</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">year_to_exporter</span><span class=\"p\">[</span><span class=\"n\">year</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">exporter</span><span class=\"p\">,</span> <span class=\"n\">xml_file</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">year_to_exporter</span><span class=\"p\">[</span><span class=\"n\">year</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">,</span> <span class=\"n\">spider</span><span class=\"p\">):</span>\n        <span class=\"n\">exporter</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_exporter_for_item</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"n\">exporter</span><span class=\"o\">.</span><span class=\"n\">export_item</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">item</span>\n</pre></div>"], "codes_text": ["from itemadapter import ItemAdapter\nfrom scrapy.exporters import XmlItemExporter\n\nclass PerYearXmlExportPipeline:\n    \"\"\"Distribute items across multiple XML files according to their 'year' field\"\"\"\n\n    def open_spider(self, spider):\n        self.year_to_exporter = {}\n\n    def close_spider(self, spider):\n        for exporter, xml_file in self.year_to_exporter.values():\n            exporter.finish_exporting()\n            xml_file.close()\n\n    def _exporter_for_item(self, item):\n        adapter = ItemAdapter(item)\n        year = adapter['year']\n        if year not in self.year_to_exporter:\n            xml_file = open(f'{year}.xml', 'wb')\n            exporter = XmlItemExporter(xml_file)\n            exporter.start_exporting()\n            self.year_to_exporter[year] = (exporter, xml_file)\n        return self.year_to_exporter[year][0]\n\n    def process_item(self, item, spider):\n        exporter = self._exporter_for_item(item)\n        exporter.export_item(item)\n        return item\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/exporters.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Serialization of item fields", "header_href": "#serialization-of-item-fields", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">serialize_price</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"sa\">f</span><span class=\"s1\">'$ </span><span class=\"si\">{</span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span><span class=\"si\">}</span><span class=\"s1\">'</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">Product</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">price</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">(</span><span class=\"n\">serializer</span><span class=\"o\">=</span><span class=\"n\">serialize_price</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.exporters</span> <span class=\"kn\">import</span> <span class=\"n\">XmlItemExporter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">ProductXmlExporter</span><span class=\"p\">(</span><span class=\"n\">XmlItemExporter</span><span class=\"p\">):</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">serialize_field</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">field</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">name</span> <span class=\"o\">==</span> <span class=\"s1\">'price'</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"sa\">f</span><span class=\"s1\">'$ </span><span class=\"si\">{</span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span><span class=\"si\">}</span><span class=\"s1\">'</span>\n        <span class=\"k\">return</span> <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">serialize_field</span><span class=\"p\">(</span><span class=\"n\">field</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import scrapy\n\ndef serialize_price(value):\n    return f'$ {str(value)}'\n\nclass Product(scrapy.Item):\n    name = scrapy.Field()\n    price = scrapy.Field(serializer=serialize_price)\n", "from scrapy.exporters import XmlItemExporter\n\nclass ProductXmlExporter(XmlItemExporter):\n\n    def serialize_field(self, field, name, value):\n        if name == 'price':\n            return f'$ {str(value)}'\n        return super().serialize_field(field, name, value)\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/exporters.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "1. Declaring a serializer in the field", "header_href": "#declaring-a-serializer-in-the-field", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">serialize_price</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"sa\">f</span><span class=\"s1\">'$ </span><span class=\"si\">{</span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span><span class=\"si\">}</span><span class=\"s1\">'</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">Product</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">price</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">(</span><span class=\"n\">serializer</span><span class=\"o\">=</span><span class=\"n\">serialize_price</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["import scrapy\n\ndef serialize_price(value):\n    return f'$ {str(value)}'\n\nclass Product(scrapy.Item):\n    name = scrapy.Field()\n    price = scrapy.Field(serializer=serialize_price)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/exporters.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "2. Overriding the serialize_field() method", "header_href": "#overriding-the-serialize-field-method", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.exporters</span> <span class=\"kn\">import</span> <span class=\"n\">XmlItemExporter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">ProductXmlExporter</span><span class=\"p\">(</span><span class=\"n\">XmlItemExporter</span><span class=\"p\">):</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">serialize_field</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">field</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">name</span> <span class=\"o\">==</span> <span class=\"s1\">'price'</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"sa\">f</span><span class=\"s1\">'$ </span><span class=\"si\">{</span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span><span class=\"si\">}</span><span class=\"s1\">'</span>\n        <span class=\"k\">return</span> <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">serialize_field</span><span class=\"p\">(</span><span class=\"n\">field</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["from scrapy.exporters import XmlItemExporter\n\nclass ProductXmlExporter(XmlItemExporter):\n\n    def serialize_field(self, field, name, value):\n        if name == 'price':\n            return f'$ {str(value)}'\n        return super().serialize_field(field, name, value)\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/exporters.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Built-in Item Exporters reference", "header_href": "#built-in-item-exporters-reference", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">Item</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'Color TV'</span><span class=\"p\">,</span> <span class=\"n\">price</span><span class=\"o\">=</span><span class=\"s1\">'1200'</span><span class=\"p\">)</span>\n<span class=\"n\">Item</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'DVD player'</span><span class=\"p\">,</span> <span class=\"n\">price</span><span class=\"o\">=</span><span class=\"s1\">'200'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">[</span><span class=\"s1\">'field1'</span><span class=\"p\">,</span> <span class=\"s1\">'field2'</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span><span class=\"s1\">'field1'</span><span class=\"p\">:</span> <span class=\"s1\">'Field 1'</span><span class=\"p\">,</span> <span class=\"s1\">'field2'</span><span class=\"p\">:</span> <span class=\"s1\">'Field 2'</span><span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;items&gt;\n  &lt;item&gt;\n    &lt;name&gt;Color TV&lt;/name&gt;\n    &lt;price&gt;1200&lt;/price&gt;\n &lt;/item&gt;\n  &lt;item&gt;\n    &lt;name&gt;DVD player&lt;/name&gt;\n    &lt;price&gt;200&lt;/price&gt;\n &lt;/item&gt;\n&lt;/items&gt;\n</pre></div>", "<div class=\"highlight\"><pre><span></span>Item(name=['John', 'Doe'], age='23')\n</pre></div>", "<div class=\"highlight\"><pre><span></span>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;items&gt;\n  &lt;item&gt;\n    &lt;name&gt;\n      &lt;value&gt;John&lt;/value&gt;\n      &lt;value&gt;Doe&lt;/value&gt;\n    &lt;/name&gt;\n    &lt;age&gt;23&lt;/age&gt;\n  &lt;/item&gt;\n&lt;/items&gt;\n</pre></div>", "<div class=\"highlight\"><pre><span></span>product,price\nColor TV,1200\nDVD player,200\n</pre></div>", "<div class=\"highlight\"><pre><span></span>{'name': 'Color TV', 'price': '1200'}\n{'name': 'DVD player', 'price': '200'}\n</pre></div>", "<div class=\"highlight\"><pre><span></span>[{\"name\": \"Color TV\", \"price\": \"1200\"},\n{\"name\": \"DVD player\", \"price\": \"200\"}]\n</pre></div>", "<div class=\"highlight\"><pre><span></span>{\"name\": \"Color TV\", \"price\": \"1200\"}\n{\"name\": \"DVD player\", \"price\": \"200\"}\n</pre></div>"], "codes_text": ["Item(name='Color TV', price='1200')\nItem(name='DVD player', price='200')\n", "['field1', 'field2']\n", "{'field1': 'Field 1', 'field2': 'Field 2'}\n", "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<items>\n  <item>\n    <name>Color TV</name>\n    <price>1200</price>\n </item>\n  <item>\n    <name>DVD player</name>\n    <price>200</price>\n </item>\n</items>\n", "Item(name=['John', 'Doe'], age='23')\n", "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<items>\n  <item>\n    <name>\n      <value>John</value>\n      <value>Doe</value>\n    </name>\n    <age>23</age>\n  </item>\n</items>\n", "product,price\nColor TV,1200\nDVD player,200\n", "{'name': 'Color TV', 'price': '1200'}\n{'name': 'DVD player', 'price': '200'}\n", "[{\"name\": \"Color TV\", \"price\": \"1200\"},\n{\"name\": \"DVD player\", \"price\": \"200\"}]\n", "{\"name\": \"Color TV\", \"price\": \"1200\"}\n{\"name\": \"DVD player\", \"price\": \"200\"}\n"], "index": 10}
{"url": "https://docs.scrapy.org/en/latest/topics/exporters.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "BaseItemExporter", "header_href": "#baseitemexporter", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"p\">[</span><span class=\"s1\">'field1'</span><span class=\"p\">,</span> <span class=\"s1\">'field2'</span><span class=\"p\">]</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"p\">{</span><span class=\"s1\">'field1'</span><span class=\"p\">:</span> <span class=\"s1\">'Field 1'</span><span class=\"p\">,</span> <span class=\"s1\">'field2'</span><span class=\"p\">:</span> <span class=\"s1\">'Field 2'</span><span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["['field1', 'field2']\n", "{'field1': 'Field 1', 'field2': 'Field 2'}\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/exporters.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "PythonItemExporter", "header_href": "#pythonitemexporter", "codes": [], "codes_text": [], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/topics/exporters.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "XmlItemExporter", "header_href": "#xmlitemexporter", "codes": ["<div class=\"highlight\"><pre><span></span>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;items&gt;\n  &lt;item&gt;\n    &lt;name&gt;Color TV&lt;/name&gt;\n    &lt;price&gt;1200&lt;/price&gt;\n &lt;/item&gt;\n  &lt;item&gt;\n    &lt;name&gt;DVD player&lt;/name&gt;\n    &lt;price&gt;200&lt;/price&gt;\n &lt;/item&gt;\n&lt;/items&gt;\n</pre></div>", "<div class=\"highlight\"><pre><span></span>Item(name=['John', 'Doe'], age='23')\n</pre></div>", "<div class=\"highlight\"><pre><span></span>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;items&gt;\n  &lt;item&gt;\n    &lt;name&gt;\n      &lt;value&gt;John&lt;/value&gt;\n      &lt;value&gt;Doe&lt;/value&gt;\n    &lt;/name&gt;\n    &lt;age&gt;23&lt;/age&gt;\n  &lt;/item&gt;\n&lt;/items&gt;\n</pre></div>"], "codes_text": ["<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<items>\n  <item>\n    <name>Color TV</name>\n    <price>1200</price>\n </item>\n  <item>\n    <name>DVD player</name>\n    <price>200</price>\n </item>\n</items>\n", "Item(name=['John', 'Doe'], age='23')\n", "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<items>\n  <item>\n    <name>\n      <value>John</value>\n      <value>Doe</value>\n    </name>\n    <age>23</age>\n  </item>\n</items>\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/topics/exporters.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "CsvItemExporter", "header_href": "#csvitemexporter", "codes": ["<div class=\"highlight\"><pre><span></span>product,price\nColor TV,1200\nDVD player,200\n</pre></div>"], "codes_text": ["product,price\nColor TV,1200\nDVD player,200\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/exporters.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "PickleItemExporter", "header_href": "#pickleitemexporter", "codes": [], "codes_text": [], "index": 11}
{"url": "https://docs.scrapy.org/en/latest/topics/exporters.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "PprintItemExporter", "header_href": "#pprintitemexporter", "codes": ["<div class=\"highlight\"><pre><span></span>{'name': 'Color TV', 'price': '1200'}\n{'name': 'DVD player', 'price': '200'}\n</pre></div>"], "codes_text": ["{'name': 'Color TV', 'price': '1200'}\n{'name': 'DVD player', 'price': '200'}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/exporters.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "JsonItemExporter", "header_href": "#jsonitemexporter", "codes": ["<div class=\"highlight\"><pre><span></span>[{\"name\": \"Color TV\", \"price\": \"1200\"},\n{\"name\": \"DVD player\", \"price\": \"200\"}]\n</pre></div>"], "codes_text": ["[{\"name\": \"Color TV\", \"price\": \"1200\"},\n{\"name\": \"DVD player\", \"price\": \"200\"}]\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/exporters.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "JsonLinesItemExporter", "header_href": "#jsonlinesitemexporter", "codes": ["<div class=\"highlight\"><pre><span></span>{\"name\": \"Color TV\", \"price\": \"1200\"}\n{\"name\": \"DVD player\", \"price\": \"200\"}\n</pre></div>"], "codes_text": ["{\"name\": \"Color TV\", \"price\": \"1200\"}\n{\"name\": \"DVD player\", \"price\": \"200\"}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/exporters.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "MarshalItemExporter", "header_href": "#marshalitemexporter", "codes": [], "codes_text": [], "index": 15}
{"url": "https://docs.scrapy.org/en/latest/topics/components.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Components", "header_href": "#components", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">pkg_resources</span> <span class=\"kn\">import</span> <span class=\"n\">parse_version</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyComponent</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">parse_version</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">__version__</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span> <span class=\"n\">parse_version</span><span class=\"p\">(</span><span class=\"s1\">'2.7'</span><span class=\"p\">):</span>\n            <span class=\"k\">raise</span> <span class=\"ne\">RuntimeError</span><span class=\"p\">(</span>\n                <span class=\"sa\">f</span><span class=\"s2\">\"</span><span class=\"si\">{</span><span class=\"n\">MyComponent</span><span class=\"o\">.</span><span class=\"vm\">__qualname__</span><span class=\"si\">}</span><span class=\"s2\"> requires Scrapy 2.7 or \"</span>\n                <span class=\"sa\">f</span><span class=\"s2\">\"later, which allow defining the process_spider_output \"</span>\n                <span class=\"sa\">f</span><span class=\"s2\">\"method of spider middlewares as an asynchronous \"</span>\n                <span class=\"sa\">f</span><span class=\"s2\">\"generator.\"</span>\n            <span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["from pkg_resources import parse_version\n\nimport scrapy\n\nclass MyComponent:\n\n    def __init__(self):\n        if parse_version(scrapy.__version__) < parse_version('2.7'):\n            raise RuntimeError(\n                f\"{MyComponent.__qualname__} requires Scrapy 2.7 or \"\n                f\"later, which allow defining the process_spider_output \"\n                f\"method of spider middlewares as an asynchronous \"\n                f\"generator.\"\n            )\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/components.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Enforcing component requirements", "header_href": "#enforcing-component-requirements", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">pkg_resources</span> <span class=\"kn\">import</span> <span class=\"n\">parse_version</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyComponent</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">parse_version</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">__version__</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span> <span class=\"n\">parse_version</span><span class=\"p\">(</span><span class=\"s1\">'2.7'</span><span class=\"p\">):</span>\n            <span class=\"k\">raise</span> <span class=\"ne\">RuntimeError</span><span class=\"p\">(</span>\n                <span class=\"sa\">f</span><span class=\"s2\">\"</span><span class=\"si\">{</span><span class=\"n\">MyComponent</span><span class=\"o\">.</span><span class=\"vm\">__qualname__</span><span class=\"si\">}</span><span class=\"s2\"> requires Scrapy 2.7 or \"</span>\n                <span class=\"sa\">f</span><span class=\"s2\">\"later, which allow defining the process_spider_output \"</span>\n                <span class=\"sa\">f</span><span class=\"s2\">\"method of spider middlewares as an asynchronous \"</span>\n                <span class=\"sa\">f</span><span class=\"s2\">\"generator.\"</span>\n            <span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["from pkg_resources import parse_version\n\nimport scrapy\n\nclass MyComponent:\n\n    def __init__(self):\n        if parse_version(scrapy.__version__) < parse_version('2.7'):\n            raise RuntimeError(\n                f\"{MyComponent.__qualname__} requires Scrapy 2.7 or \"\n                f\"later, which allow defining the process_spider_output \"\n                f\"method of spider middlewares as an asynchronous \"\n                f\"generator.\"\n            )\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/api.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Core API", "header_href": "#core-api", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">SETTINGS_PRIORITIES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'default'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'command'</span><span class=\"p\">:</span> <span class=\"mi\">10</span><span class=\"p\">,</span>\n    <span class=\"s1\">'project'</span><span class=\"p\">:</span> <span class=\"mi\">20</span><span class=\"p\">,</span>\n    <span class=\"s1\">'spider'</span><span class=\"p\">:</span> <span class=\"mi\">30</span><span class=\"p\">,</span>\n    <span class=\"s1\">'cmdline'</span><span class=\"p\">:</span> <span class=\"mi\">40</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["SETTINGS_PRIORITIES = {\n    'default': 0,\n    'command': 10,\n    'project': 20,\n    'spider': 30,\n    'cmdline': 40,\n}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/api.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Crawler API", "header_href": "#crawler-api", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/topics/api.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Settings API", "header_href": "#module-scrapy.settings", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">SETTINGS_PRIORITIES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'default'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s1\">'command'</span><span class=\"p\">:</span> <span class=\"mi\">10</span><span class=\"p\">,</span>\n    <span class=\"s1\">'project'</span><span class=\"p\">:</span> <span class=\"mi\">20</span><span class=\"p\">,</span>\n    <span class=\"s1\">'spider'</span><span class=\"p\">:</span> <span class=\"mi\">30</span><span class=\"p\">,</span>\n    <span class=\"s1\">'cmdline'</span><span class=\"p\">:</span> <span class=\"mi\">40</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["SETTINGS_PRIORITIES = {\n    'default': 0,\n    'command': 10,\n    'project': 20,\n    'spider': 30,\n    'cmdline': 40,\n}\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/topics/api.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "SpiderLoader API", "header_href": "#module-scrapy.spiderloader", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/topics/api.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Signals API", "header_href": "#module-scrapy.signalmanager", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/topics/api.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Stats Collector API", "header_href": "#stats-collector-api", "codes": [], "codes_text": [], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Release notes", "header_href": "#release-notes", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">feedexport</span><span class=\"o\">/</span><span class=\"n\">success_count</span><span class=\"o\">/&lt;</span><span class=\"n\">storage</span> <span class=\"nb\">type</span><span class=\"o\">&gt;</span>\n<span class=\"n\">feedexport</span><span class=\"o\">/</span><span class=\"n\">failed_count</span><span class=\"o\">/&lt;</span><span class=\"n\">storage</span> <span class=\"nb\">type</span><span class=\"o\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">urllength</span><span class=\"o\">/</span><span class=\"n\">request_ignored_count</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">httpcompression</span><span class=\"o\">/</span><span class=\"n\">response_bytes</span>\n<span class=\"n\">httpcompression</span><span class=\"o\">/</span><span class=\"n\">response_count</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">item</span> <span class=\"o\">=</span> <span class=\"n\">MyItem</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'field'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'value1'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"o\">=</span><span class=\"n\">item</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'field'</span><span class=\"p\">]</span>\n<span class=\"go\">['value1']</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">href</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.page a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">extract</span><span class=\"p\">():</span>\n    <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">urljoin</span><span class=\"p\">(</span><span class=\"n\">href</span><span class=\"p\">)</span>\n    <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">,</span> <span class=\"n\">encoding</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">encoding</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.page a'</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MyItem</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">MyItem</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"s1\">'url'</span><span class=\"p\">:</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">custom_settings</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n        <span class=\"s2\">\"DOWNLOAD_DELAY\"</span><span class=\"p\">:</span> <span class=\"mf\">5.0</span><span class=\"p\">,</span>\n        <span class=\"s2\">\"RETRY_ENABLED\"</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n    <span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">log</span>\n<span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">msg</span><span class=\"p\">(</span><span class=\"s1\">'MESSAGE'</span><span class=\"p\">,</span> <span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">INFO</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'MESSAGE'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Response received'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.crawler</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerProcess</span>\n\n<span class=\"n\">process</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerProcess</span><span class=\"p\">({</span>\n    <span class=\"s1\">'USER_AGENT'</span><span class=\"p\">:</span> <span class=\"s1\">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'</span>\n<span class=\"p\">})</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider</span><span class=\"p\">)</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">69</span> <span class=\"n\">Daniel</span> <span class=\"n\">Graña</span> <span class=\"o\">&lt;</span><span class=\"n\">dangra</span><span class=\"o\">@...&gt;</span>\n<span class=\"mi\">37</span> <span class=\"n\">Pablo</span> <span class=\"n\">Hoffman</span> <span class=\"o\">&lt;</span><span class=\"n\">pablo</span><span class=\"o\">@...&gt;</span>\n<span class=\"mi\">13</span> <span class=\"n\">Mikhail</span> <span class=\"n\">Korobov</span> <span class=\"o\">&lt;</span><span class=\"n\">kmike84</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">9</span> <span class=\"n\">Alex</span> <span class=\"n\">Cepoi</span> <span class=\"o\">&lt;</span><span class=\"n\">alex</span><span class=\"o\">.</span><span class=\"n\">cepoi</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">9</span> <span class=\"n\">alexanderlukanin13</span> <span class=\"o\">&lt;</span><span class=\"n\">alexander</span><span class=\"o\">.</span><span class=\"n\">lukanin</span><span class=\"mf\">.13</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">8</span> <span class=\"n\">Rolando</span> <span class=\"n\">Espinoza</span> <span class=\"n\">La</span> <span class=\"n\">fuente</span> <span class=\"o\">&lt;</span><span class=\"n\">darkrho</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">8</span> <span class=\"n\">Lukasz</span> <span class=\"n\">Biedrycki</span> <span class=\"o\">&lt;</span><span class=\"n\">lukasz</span><span class=\"o\">.</span><span class=\"n\">biedrycki</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">6</span> <span class=\"n\">Nicolas</span> <span class=\"n\">Ramirez</span> <span class=\"o\">&lt;</span><span class=\"n\">nramirez</span><span class=\"o\">.</span><span class=\"n\">uy</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">3</span> <span class=\"n\">Paul</span> <span class=\"n\">Tremberth</span> <span class=\"o\">&lt;</span><span class=\"n\">paul</span><span class=\"o\">.</span><span class=\"n\">tremberth</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">2</span> <span class=\"n\">Martin</span> <span class=\"n\">Olveyra</span> <span class=\"o\">&lt;</span><span class=\"n\">molveyra</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">2</span> <span class=\"n\">Stefan</span> <span class=\"o\">&lt;</span><span class=\"n\">misc</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">2</span> <span class=\"n\">Rolando</span> <span class=\"n\">Espinoza</span> <span class=\"o\">&lt;</span><span class=\"n\">darkrho</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">2</span> <span class=\"n\">Loren</span> <span class=\"n\">Davie</span> <span class=\"o\">&lt;</span><span class=\"n\">loren</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">2</span> <span class=\"n\">irgmedeiros</span> <span class=\"o\">&lt;</span><span class=\"n\">irgmedeiros</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Stefan</span> <span class=\"n\">Koch</span> <span class=\"o\">&lt;</span><span class=\"n\">taikano</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Stefan</span> <span class=\"o\">&lt;</span><span class=\"n\">cct</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">scraperdragon</span> <span class=\"o\">&lt;</span><span class=\"n\">dragon</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Kumara</span> <span class=\"n\">Tharmalingam</span> <span class=\"o\">&lt;</span><span class=\"n\">ktharmal</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Francesco</span> <span class=\"n\">Piccinno</span> <span class=\"o\">&lt;</span><span class=\"n\">stack</span><span class=\"o\">.</span><span class=\"n\">box</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Marcos</span> <span class=\"n\">Campal</span> <span class=\"o\">&lt;</span><span class=\"n\">duendex</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Dragon</span> <span class=\"n\">Dave</span> <span class=\"o\">&lt;</span><span class=\"n\">dragon</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Capi</span> <span class=\"n\">Etheriel</span> <span class=\"o\">&lt;</span><span class=\"n\">barraponto</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">cacovsky</span> <span class=\"o\">&lt;</span><span class=\"n\">amarquesferraz</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Berend</span> <span class=\"n\">Iwema</span> <span class=\"o\">&lt;</span><span class=\"n\">berend</span><span class=\"o\">@...&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"mi\">130</span> <span class=\"n\">Pablo</span> <span class=\"n\">Hoffman</span> <span class=\"o\">&lt;</span><span class=\"n\">pablo</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">97</span> <span class=\"n\">Daniel</span> <span class=\"n\">Graña</span> <span class=\"o\">&lt;</span><span class=\"n\">dangra</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">20</span> <span class=\"n\">Nicolás</span> <span class=\"n\">Ramírez</span> <span class=\"o\">&lt;</span><span class=\"n\">nramirez</span><span class=\"o\">.</span><span class=\"n\">uy</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">13</span> <span class=\"n\">Mikhail</span> <span class=\"n\">Korobov</span> <span class=\"o\">&lt;</span><span class=\"n\">kmike84</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">12</span> <span class=\"n\">Pedro</span> <span class=\"n\">Faustino</span> <span class=\"o\">&lt;</span><span class=\"n\">pedrobandim</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">11</span> <span class=\"n\">Steven</span> <span class=\"n\">Almeroth</span> <span class=\"o\">&lt;</span><span class=\"n\">sroth77</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">5</span> <span class=\"n\">Rolando</span> <span class=\"n\">Espinoza</span> <span class=\"n\">La</span> <span class=\"n\">fuente</span> <span class=\"o\">&lt;</span><span class=\"n\">darkrho</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">4</span> <span class=\"n\">Michal</span> <span class=\"n\">Danilak</span> <span class=\"o\">&lt;</span><span class=\"n\">mimino</span><span class=\"o\">.</span><span class=\"n\">coder</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">4</span> <span class=\"n\">Alex</span> <span class=\"n\">Cepoi</span> <span class=\"o\">&lt;</span><span class=\"n\">alex</span><span class=\"o\">.</span><span class=\"n\">cepoi</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">4</span> <span class=\"n\">Alexandr</span> <span class=\"n\">N</span> <span class=\"n\">Zamaraev</span> <span class=\"p\">(</span><span class=\"n\">aka</span> <span class=\"n\">tonal</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">tonal</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">3</span> <span class=\"n\">paul</span> <span class=\"o\">&lt;</span><span class=\"n\">paul</span><span class=\"o\">.</span><span class=\"n\">tremberth</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">3</span> <span class=\"n\">Martin</span> <span class=\"n\">Olveyra</span> <span class=\"o\">&lt;</span><span class=\"n\">molveyra</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">3</span> <span class=\"n\">Jordi</span> <span class=\"n\">Llonch</span> <span class=\"o\">&lt;</span><span class=\"n\">llonchj</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">3</span> <span class=\"n\">arijitchakraborty</span> <span class=\"o\">&lt;</span><span class=\"n\">myself</span><span class=\"o\">.</span><span class=\"n\">arijit</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">2</span> <span class=\"n\">Shane</span> <span class=\"n\">Evans</span> <span class=\"o\">&lt;</span><span class=\"n\">shane</span><span class=\"o\">.</span><span class=\"n\">evans</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">2</span> <span class=\"n\">joehillen</span> <span class=\"o\">&lt;</span><span class=\"n\">joehillen</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">2</span> <span class=\"n\">Hart</span> <span class=\"o\">&lt;</span><span class=\"n\">HartSimha</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">2</span> <span class=\"n\">Dan</span> <span class=\"o\">&lt;</span><span class=\"n\">ellisd23</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Zuhao</span> <span class=\"n\">Wan</span> <span class=\"o\">&lt;</span><span class=\"n\">wanzuhao</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">whodatninja</span> <span class=\"o\">&lt;</span><span class=\"n\">blake</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">vkrest</span> <span class=\"o\">&lt;</span><span class=\"n\">v</span><span class=\"o\">.</span><span class=\"n\">krestiannykov</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">tpeng</span> <span class=\"o\">&lt;</span><span class=\"n\">pengtaoo</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Tom</span> <span class=\"n\">Mortimer</span><span class=\"o\">-</span><span class=\"n\">Jones</span> <span class=\"o\">&lt;</span><span class=\"n\">tom</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Rocio</span> <span class=\"n\">Aramberri</span> <span class=\"o\">&lt;</span><span class=\"n\">roschegel</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Pedro</span> <span class=\"o\">&lt;</span><span class=\"n\">pedro</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">notsobad</span> <span class=\"o\">&lt;</span><span class=\"n\">wangxiaohugg</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Natan</span> <span class=\"n\">L</span> <span class=\"o\">&lt;</span><span class=\"n\">kuyanatan</span><span class=\"o\">.</span><span class=\"n\">nlao</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Mark</span> <span class=\"n\">Grey</span> <span class=\"o\">&lt;</span><span class=\"n\">mark</span><span class=\"o\">.</span><span class=\"n\">grey</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Luan</span> <span class=\"o\">&lt;</span><span class=\"n\">luanpab</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Libor</span> <span class=\"n\">Nenadál</span> <span class=\"o\">&lt;</span><span class=\"n\">libor</span><span class=\"o\">.</span><span class=\"n\">nenadal</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Juan</span> <span class=\"n\">M</span> <span class=\"n\">Uys</span> <span class=\"o\">&lt;</span><span class=\"n\">opyate</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Jonas</span> <span class=\"n\">Brunsgaard</span> <span class=\"o\">&lt;</span><span class=\"n\">jonas</span><span class=\"o\">.</span><span class=\"n\">brunsgaard</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Ilya</span> <span class=\"n\">Baryshev</span> <span class=\"o\">&lt;</span><span class=\"n\">baryshev</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Hasnain</span> <span class=\"n\">Lakhani</span> <span class=\"o\">&lt;</span><span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">hasnain</span><span class=\"o\">.</span><span class=\"n\">lakhani</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Emanuel</span> <span class=\"n\">Schorsch</span> <span class=\"o\">&lt;</span><span class=\"n\">emschorsch</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Chris</span> <span class=\"n\">Tilden</span> <span class=\"o\">&lt;</span><span class=\"n\">chris</span><span class=\"o\">.</span><span class=\"n\">tilden</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Capi</span> <span class=\"n\">Etheriel</span> <span class=\"o\">&lt;</span><span class=\"n\">barraponto</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">cacovsky</span> <span class=\"o\">&lt;</span><span class=\"n\">amarquesferraz</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Berend</span> <span class=\"n\">Iwema</span> <span class=\"o\">&lt;</span><span class=\"n\">berend</span><span class=\"o\">@...&gt;</span>\n</pre></div>"], "codes_text": ["feedexport/success_count/<storage type>\nfeedexport/failed_count/<storage type>\n", "urllength/request_ignored_count\n", "httpcompression/response_bytes\nhttpcompression/response_count\n", ">>> item = MyItem()\n>>> item['field'] = 'value1'\n>>> loader = ItemLoader(item=item)\n>>> item['field']\n['value1']\n", "for href in response.css('li.page a::attr(href)').extract():\n    url = response.urljoin(href)\n    yield scrapy.Request(url, self.parse, encoding=response.encoding)\n", "for a in response.css('li.page a'):\n    yield response.follow(a, self.parse)\n", "class MyItem(scrapy.Item):\n    url = scrapy.Field()\n\nclass MySpider(scrapy.Spider):\n    def parse(self, response):\n        return MyItem(url=response.url)\n", "class MySpider(scrapy.Spider):\n    def parse(self, response):\n        return {'url': response.url}\n", "class MySpider(scrapy.Spider):\n    custom_settings = {\n        \"DOWNLOAD_DELAY\": 5.0,\n        \"RETRY_ENABLED\": False,\n    }\n", "from scrapy import log\nlog.msg('MESSAGE', log.INFO)\n", "import logging\nlogging.info('MESSAGE')\n", "class MySpider(scrapy.Spider):\n    def parse(self, response):\n        self.logger.info('Response received')\n", "from scrapy.crawler import CrawlerProcess\n\nprocess = CrawlerProcess({\n    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n})\nprocess.crawl(MySpider)\nprocess.start()\n", "69 Daniel Graña <dangra@...>\n37 Pablo Hoffman <pablo@...>\n13 Mikhail Korobov <kmike84@...>\n 9 Alex Cepoi <alex.cepoi@...>\n 9 alexanderlukanin13 <alexander.lukanin.13@...>\n 8 Rolando Espinoza La fuente <darkrho@...>\n 8 Lukasz Biedrycki <lukasz.biedrycki@...>\n 6 Nicolas Ramirez <nramirez.uy@...>\n 3 Paul Tremberth <paul.tremberth@...>\n 2 Martin Olveyra <molveyra@...>\n 2 Stefan <misc@...>\n 2 Rolando Espinoza <darkrho@...>\n 2 Loren Davie <loren@...>\n 2 irgmedeiros <irgmedeiros@...>\n 1 Stefan Koch <taikano@...>\n 1 Stefan <cct@...>\n 1 scraperdragon <dragon@...>\n 1 Kumara Tharmalingam <ktharmal@...>\n 1 Francesco Piccinno <stack.box@...>\n 1 Marcos Campal <duendex@...>\n 1 Dragon Dave <dragon@...>\n 1 Capi Etheriel <barraponto@...>\n 1 cacovsky <amarquesferraz@...>\n 1 Berend Iwema <berend@...>\n", "130 Pablo Hoffman <pablo@...>\n 97 Daniel Graña <dangra@...>\n 20 Nicolás Ramírez <nramirez.uy@...>\n 13 Mikhail Korobov <kmike84@...>\n 12 Pedro Faustino <pedrobandim@...>\n 11 Steven Almeroth <sroth77@...>\n  5 Rolando Espinoza La fuente <darkrho@...>\n  4 Michal Danilak <mimino.coder@...>\n  4 Alex Cepoi <alex.cepoi@...>\n  4 Alexandr N Zamaraev (aka tonal) <tonal@...>\n  3 paul <paul.tremberth@...>\n  3 Martin Olveyra <molveyra@...>\n  3 Jordi Llonch <llonchj@...>\n  3 arijitchakraborty <myself.arijit@...>\n  2 Shane Evans <shane.evans@...>\n  2 joehillen <joehillen@...>\n  2 Hart <HartSimha@...>\n  2 Dan <ellisd23@...>\n  1 Zuhao Wan <wanzuhao@...>\n  1 whodatninja <blake@...>\n  1 vkrest <v.krestiannykov@...>\n  1 tpeng <pengtaoo@...>\n  1 Tom Mortimer-Jones <tom@...>\n  1 Rocio Aramberri <roschegel@...>\n  1 Pedro <pedro@...>\n  1 notsobad <wangxiaohugg@...>\n  1 Natan L <kuyanatan.nlao@...>\n  1 Mark Grey <mark.grey@...>\n  1 Luan <luanpab@...>\n  1 Libor Nenadál <libor.nenadal@...>\n  1 Juan M Uys <opyate@...>\n  1 Jonas Brunsgaard <jonas.brunsgaard@...>\n  1 Ilya Baryshev <baryshev@...>\n  1 Hasnain Lakhani <m.hasnain.lakhani@...>\n  1 Emanuel Schorsch <emschorsch@...>\n  1 Chris Tilden <chris.tilden@...>\n  1 Capi Etheriel <barraponto@...>\n  1 cacovsky <amarquesferraz@...>\n  1 Berend Iwema <berend@...>\n"], "index": 15}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 2.7.1 (2022-11-02)", "header_href": "#scrapy-2-7-1-2022-11-02", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features", "header_href": "#new-features", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#bug-fixes", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#documentation", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Quality assurance", "header_href": "#quality-assurance", "codes": [], "codes_text": [], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 2.7.0 (2022-10-17)", "header_href": "#scrapy-2-7-0-2022-10-17", "codes": [], "codes_text": [], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Modified requirements", "header_href": "#modified-requirements", "codes": [], "codes_text": [], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecations", "header_href": "#deprecations", "codes": [], "codes_text": [], "index": 9}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features", "header_href": "#id1", "codes": [], "codes_text": [], "index": 10}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id2", "codes": [], "codes_text": [], "index": 11}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id3", "codes": [], "codes_text": [], "index": 12}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Quality assurance", "header_href": "#id4", "codes": [], "codes_text": [], "index": 13}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 2.6.3 (2022-09-27)", "header_href": "#scrapy-2-6-3-2022-09-27", "codes": [], "codes_text": [], "index": 14}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 2.6.2 (2022-07-25)", "header_href": "#scrapy-2-6-2-2022-07-25", "codes": [], "codes_text": [], "index": 15}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 2.6.1 (2022-03-01)", "header_href": "#scrapy-2-6-1-2022-03-01", "codes": [], "codes_text": [], "index": 16}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 2.6.0 (2022-03-01)", "header_href": "#scrapy-2-6-0-2022-03-01", "codes": [], "codes_text": [], "index": 17}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Security bug fixes", "header_href": "#security-bug-fixes", "codes": [], "codes_text": [], "index": 18}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Modified requirements", "header_href": "#id5", "codes": [], "codes_text": [], "index": 19}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Backward-incompatible changes", "header_href": "#backward-incompatible-changes", "codes": [], "codes_text": [], "index": 20}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecation removals", "header_href": "#deprecation-removals", "codes": [], "codes_text": [], "index": 21}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecations", "header_href": "#id6", "codes": [], "codes_text": [], "index": 22}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features", "header_href": "#id7", "codes": [], "codes_text": [], "index": 23}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id8", "codes": [], "codes_text": [], "index": 24}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id9", "codes": [], "codes_text": [], "index": 25}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Quality Assurance", "header_href": "#id10", "codes": [], "codes_text": [], "index": 26}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 2.5.1 (2021-10-05)", "header_href": "#scrapy-2-5-1-2021-10-05", "codes": [], "codes_text": [], "index": 27}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 2.5.0 (2021-04-06)", "header_href": "#scrapy-2-5-0-2021-04-06", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">feedexport</span><span class=\"o\">/</span><span class=\"n\">success_count</span><span class=\"o\">/&lt;</span><span class=\"n\">storage</span> <span class=\"nb\">type</span><span class=\"o\">&gt;</span>\n<span class=\"n\">feedexport</span><span class=\"o\">/</span><span class=\"n\">failed_count</span><span class=\"o\">/&lt;</span><span class=\"n\">storage</span> <span class=\"nb\">type</span><span class=\"o\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">urllength</span><span class=\"o\">/</span><span class=\"n\">request_ignored_count</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">httpcompression</span><span class=\"o\">/</span><span class=\"n\">response_bytes</span>\n<span class=\"n\">httpcompression</span><span class=\"o\">/</span><span class=\"n\">response_count</span>\n</pre></div>"], "codes_text": ["feedexport/success_count/<storage type>\nfeedexport/failed_count/<storage type>\n", "urllength/request_ignored_count\n", "httpcompression/response_bytes\nhttpcompression/response_count\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecation removals", "header_href": "#id11", "codes": [], "codes_text": [], "index": 29}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecations", "header_href": "#id12", "codes": [], "codes_text": [], "index": 30}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features", "header_href": "#id13", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">feedexport</span><span class=\"o\">/</span><span class=\"n\">success_count</span><span class=\"o\">/&lt;</span><span class=\"n\">storage</span> <span class=\"nb\">type</span><span class=\"o\">&gt;</span>\n<span class=\"n\">feedexport</span><span class=\"o\">/</span><span class=\"n\">failed_count</span><span class=\"o\">/&lt;</span><span class=\"n\">storage</span> <span class=\"nb\">type</span><span class=\"o\">&gt;</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">urllength</span><span class=\"o\">/</span><span class=\"n\">request_ignored_count</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">httpcompression</span><span class=\"o\">/</span><span class=\"n\">response_bytes</span>\n<span class=\"n\">httpcompression</span><span class=\"o\">/</span><span class=\"n\">response_count</span>\n</pre></div>"], "codes_text": ["feedexport/success_count/<storage type>\nfeedexport/failed_count/<storage type>\n", "urllength/request_ignored_count\n", "httpcompression/response_bytes\nhttpcompression/response_count\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id14", "codes": [], "codes_text": [], "index": 32}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id15", "codes": [], "codes_text": [], "index": 33}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Quality Assurance", "header_href": "#id16", "codes": [], "codes_text": [], "index": 34}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 2.4.1 (2020-11-17)", "header_href": "#scrapy-2-4-1-2020-11-17", "codes": [], "codes_text": [], "index": 35}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 2.4.0 (2020-10-11)", "header_href": "#scrapy-2-4-0-2020-10-11", "codes": [], "codes_text": [], "index": 36}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Modified requirements", "header_href": "#id17", "codes": [], "codes_text": [], "index": 37}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Backward-incompatible changes", "header_href": "#id18", "codes": [], "codes_text": [], "index": 38}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecation removals", "header_href": "#id19", "codes": [], "codes_text": [], "index": 39}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecations", "header_href": "#id21", "codes": [], "codes_text": [], "index": 40}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features", "header_href": "#id22", "codes": [], "codes_text": [], "index": 41}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id23", "codes": [], "codes_text": [], "index": 42}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id24", "codes": [], "codes_text": [], "index": 43}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Quality assurance", "header_href": "#id25", "codes": [], "codes_text": [], "index": 44}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 2.3.0 (2020-08-04)", "header_href": "#scrapy-2-3-0-2020-08-04", "codes": [], "codes_text": [], "index": 45}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecation removals", "header_href": "#id26", "codes": [], "codes_text": [], "index": 46}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecations", "header_href": "#id27", "codes": [], "codes_text": [], "index": 47}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features", "header_href": "#id28", "codes": [], "codes_text": [], "index": 48}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id29", "codes": [], "codes_text": [], "index": 49}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id30", "codes": [], "codes_text": [], "index": 50}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Quality assurance", "header_href": "#id31", "codes": [], "codes_text": [], "index": 51}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 2.2.1 (2020-07-17)", "header_href": "#scrapy-2-2-1-2020-07-17", "codes": [], "codes_text": [], "index": 52}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 2.2.0 (2020-06-24)", "header_href": "#scrapy-2-2-0-2020-06-24", "codes": [], "codes_text": [], "index": 53}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Backward-incompatible changes", "header_href": "#id32", "codes": [], "codes_text": [], "index": 54}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecations", "header_href": "#id33", "codes": [], "codes_text": [], "index": 55}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features", "header_href": "#id34", "codes": [], "codes_text": [], "index": 56}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id35", "codes": [], "codes_text": [], "index": 57}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id36", "codes": [], "codes_text": [], "index": 58}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Quality assurance", "header_href": "#id37", "codes": [], "codes_text": [], "index": 59}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 2.1.0 (2020-04-24)", "header_href": "#scrapy-2-1-0-2020-04-24", "codes": [], "codes_text": [], "index": 60}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Backward-incompatible changes", "header_href": "#id38", "codes": [], "codes_text": [], "index": 61}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecation removals", "header_href": "#id39", "codes": [], "codes_text": [], "index": 62}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecations", "header_href": "#id40", "codes": [], "codes_text": [], "index": 63}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features", "header_href": "#id41", "codes": [], "codes_text": [], "index": 64}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id42", "codes": [], "codes_text": [], "index": 65}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id43", "codes": [], "codes_text": [], "index": 66}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Quality assurance", "header_href": "#id44", "codes": [], "codes_text": [], "index": 67}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 2.0.1 (2020-03-18)", "header_href": "#scrapy-2-0-1-2020-03-18", "codes": [], "codes_text": [], "index": 68}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 2.0.0 (2020-03-03)", "header_href": "#scrapy-2-0-0-2020-03-03", "codes": [], "codes_text": [], "index": 69}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Backward-incompatible changes", "header_href": "#id45", "codes": [], "codes_text": [], "index": 70}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecation removals", "header_href": "#id46", "codes": [], "codes_text": [], "index": 71}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecations", "header_href": "#id47", "codes": [], "codes_text": [], "index": 72}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features", "header_href": "#id48", "codes": [], "codes_text": [], "index": 73}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id49", "codes": [], "codes_text": [], "index": 74}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id50", "codes": [], "codes_text": [], "index": 75}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Quality assurance", "header_href": "#id51", "codes": [], "codes_text": [], "index": 76}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Changes to scheduler queue classes", "header_href": "#changes-to-scheduler-queue-classes", "codes": [], "codes_text": [], "index": 77}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.8.3 (2022-07-25)", "header_href": "#scrapy-1-8-3-2022-07-25", "codes": [], "codes_text": [], "index": 78}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.8.2 (2022-03-01)", "header_href": "#scrapy-1-8-2-2022-03-01", "codes": [], "codes_text": [], "index": 79}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.8.1 (2021-10-05)", "header_href": "#scrapy-1-8-1-2021-10-05", "codes": [], "codes_text": [], "index": 80}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.8.0 (2019-10-28)", "header_href": "#scrapy-1-8-0-2019-10-28", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">item</span> <span class=\"o\">=</span> <span class=\"n\">MyItem</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'field'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'value1'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"o\">=</span><span class=\"n\">item</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'field'</span><span class=\"p\">]</span>\n<span class=\"go\">['value1']</span>\n</pre></div>"], "codes_text": [">>> item = MyItem()\n>>> item['field'] = 'value1'\n>>> loader = ItemLoader(item=item)\n>>> item['field']\n['value1']\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Backward-incompatible changes", "header_href": "#id56", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">item</span> <span class=\"o\">=</span> <span class=\"n\">MyItem</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'field'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'value1'</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">ItemLoader</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"o\">=</span><span class=\"n\">item</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">item</span><span class=\"p\">[</span><span class=\"s1\">'field'</span><span class=\"p\">]</span>\n<span class=\"go\">['value1']</span>\n</pre></div>"], "codes_text": [">>> item = MyItem()\n>>> item['field'] = 'value1'\n>>> loader = ItemLoader(item=item)\n>>> item['field']\n['value1']\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features", "header_href": "#id57", "codes": [], "codes_text": [], "index": 83}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id58", "codes": [], "codes_text": [], "index": 84}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id59", "codes": [], "codes_text": [], "index": 85}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecation removals", "header_href": "#id60", "codes": [], "codes_text": [], "index": 86}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecations", "header_href": "#id62", "codes": [], "codes_text": [], "index": 87}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Other changes", "header_href": "#other-changes", "codes": [], "codes_text": [], "index": 88}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.7.4 (2019-10-21)", "header_href": "#scrapy-1-7-4-2019-10-21", "codes": [], "codes_text": [], "index": 89}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.7.3 (2019-08-01)", "header_href": "#scrapy-1-7-3-2019-08-01", "codes": [], "codes_text": [], "index": 90}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.7.2 (2019-07-23)", "header_href": "#scrapy-1-7-2-2019-07-23", "codes": [], "codes_text": [], "index": 91}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.7.1 (2019-07-18)", "header_href": "#scrapy-1-7-1-2019-07-18", "codes": [], "codes_text": [], "index": 92}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.7.0 (2019-07-18)", "header_href": "#scrapy-1-7-0-2019-07-18", "codes": [], "codes_text": [], "index": 93}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Backward-incompatible changes", "header_href": "#id64", "codes": [], "codes_text": [], "index": 94}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features", "header_href": "#id65", "codes": [], "codes_text": [], "index": 95}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id66", "codes": [], "codes_text": [], "index": 96}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id67", "codes": [], "codes_text": [], "index": 97}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecation removals", "header_href": "#id68", "codes": [], "codes_text": [], "index": 98}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecations", "header_href": "#id70", "codes": [], "codes_text": [], "index": 99}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Other changes", "header_href": "#id72", "codes": [], "codes_text": [], "index": 100}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.6.0 (2019-01-30)", "header_href": "#scrapy-1-6-0-2019-01-30", "codes": [], "codes_text": [], "index": 101}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Selector API changes", "header_href": "#selector-api-changes", "codes": [], "codes_text": [], "index": 102}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Telnet console", "header_href": "#telnet-console", "codes": [], "codes_text": [], "index": 103}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New extensibility features", "header_href": "#new-extensibility-features", "codes": [], "codes_text": [], "index": 104}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New FilePipeline and MediaPipeline features", "header_href": "#new-filepipeline-and-mediapipeline-features", "codes": [], "codes_text": [], "index": 105}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "scrapy.contracts improvements", "header_href": "#scrapy-contracts-improvements", "codes": [], "codes_text": [], "index": 106}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Usability improvements", "header_href": "#usability-improvements", "codes": [], "codes_text": [], "index": 107}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id73", "codes": [], "codes_text": [], "index": 108}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation improvements", "header_href": "#documentation-improvements", "codes": [], "codes_text": [], "index": 109}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecation removals", "header_href": "#id74", "codes": [], "codes_text": [], "index": 110}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Other improvements, cleanups", "header_href": "#other-improvements-cleanups", "codes": [], "codes_text": [], "index": 111}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.5.2 (2019-01-22)", "header_href": "#scrapy-1-5-2-2019-01-22", "codes": [], "codes_text": [], "index": 112}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.5.1 (2018-07-12)", "header_href": "#scrapy-1-5-1-2018-07-12", "codes": [], "codes_text": [], "index": 113}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.5.0 (2017-12-29)", "header_href": "#scrapy-1-5-0-2017-12-29", "codes": [], "codes_text": [], "index": 114}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Backward Incompatible Changes", "header_href": "#id75", "codes": [], "codes_text": [], "index": 115}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features", "header_href": "#id76", "codes": [], "codes_text": [], "index": 116}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id77", "codes": [], "codes_text": [], "index": 117}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Docs", "header_href": "#docs", "codes": [], "codes_text": [], "index": 118}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.4.0 (2017-05-18)", "header_href": "#scrapy-1-4-0-2017-05-18", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">href</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.page a::attr(href)'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">extract</span><span class=\"p\">():</span>\n    <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">urljoin</span><span class=\"p\">(</span><span class=\"n\">href</span><span class=\"p\">)</span>\n    <span class=\"k\">yield</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">,</span> <span class=\"n\">encoding</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">encoding</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s1\">'li.page a'</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["for href in response.css('li.page a::attr(href)').extract():\n    url = response.urljoin(href)\n    yield scrapy.Request(url, self.parse, encoding=response.encoding)\n", "for a in response.css('li.page a'):\n    yield response.follow(a, self.parse)\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecations and Backward Incompatible Changes", "header_href": "#deprecations-and-backward-incompatible-changes", "codes": [], "codes_text": [], "index": 120}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New Features", "header_href": "#id78", "codes": [], "codes_text": [], "index": 121}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id79", "codes": [], "codes_text": [], "index": 122}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Cleanups & Refactoring", "header_href": "#cleanups-refactoring", "codes": [], "codes_text": [], "index": 123}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id80", "codes": [], "codes_text": [], "index": 124}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.3.3 (2017-03-10)", "header_href": "#scrapy-1-3-3-2017-03-10", "codes": [], "codes_text": [], "index": 125}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id81", "codes": [], "codes_text": [], "index": 126}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.3.2 (2017-02-13)", "header_href": "#scrapy-1-3-2-2017-02-13", "codes": [], "codes_text": [], "index": 127}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id82", "codes": [], "codes_text": [], "index": 128}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.3.1 (2017-02-08)", "header_href": "#scrapy-1-3-1-2017-02-08", "codes": [], "codes_text": [], "index": 129}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features", "header_href": "#id83", "codes": [], "codes_text": [], "index": 130}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id84", "codes": [], "codes_text": [], "index": 131}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id85", "codes": [], "codes_text": [], "index": 132}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Cleanups", "header_href": "#cleanups", "codes": [], "codes_text": [], "index": 133}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.3.0 (2016-12-21)", "header_href": "#scrapy-1-3-0-2016-12-21", "codes": [], "codes_text": [], "index": 134}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New Features", "header_href": "#id86", "codes": [], "codes_text": [], "index": 135}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Dependencies & Cleanups", "header_href": "#dependencies-cleanups", "codes": [], "codes_text": [], "index": 136}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.2.3 (2017-03-03)", "header_href": "#scrapy-1-2-3-2017-03-03", "codes": [], "codes_text": [], "index": 137}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.2.2 (2016-12-06)", "header_href": "#scrapy-1-2-2-2016-12-06", "codes": [], "codes_text": [], "index": 138}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id87", "codes": [], "codes_text": [], "index": 139}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id88", "codes": [], "codes_text": [], "index": 140}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Other changes", "header_href": "#id89", "codes": [], "codes_text": [], "index": 141}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.2.1 (2016-10-21)", "header_href": "#scrapy-1-2-1-2016-10-21", "codes": [], "codes_text": [], "index": 142}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id90", "codes": [], "codes_text": [], "index": 143}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id91", "codes": [], "codes_text": [], "index": 144}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Other changes", "header_href": "#id92", "codes": [], "codes_text": [], "index": 145}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.2.0 (2016-10-03)", "header_href": "#scrapy-1-2-0-2016-10-03", "codes": [], "codes_text": [], "index": 146}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New Features", "header_href": "#id93", "codes": [], "codes_text": [], "index": 147}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id94", "codes": [], "codes_text": [], "index": 148}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Refactoring", "header_href": "#refactoring", "codes": [], "codes_text": [], "index": 149}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Tests & Requirements", "header_href": "#tests-requirements", "codes": [], "codes_text": [], "index": 150}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id95", "codes": [], "codes_text": [], "index": 151}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.1.4 (2017-03-03)", "header_href": "#scrapy-1-1-4-2017-03-03", "codes": [], "codes_text": [], "index": 152}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.1.3 (2016-09-22)", "header_href": "#scrapy-1-1-3-2016-09-22", "codes": [], "codes_text": [], "index": 153}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id96", "codes": [], "codes_text": [], "index": 154}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id97", "codes": [], "codes_text": [], "index": 155}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.1.2 (2016-08-18)", "header_href": "#scrapy-1-1-2-2016-08-18", "codes": [], "codes_text": [], "index": 156}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id98", "codes": [], "codes_text": [], "index": 157}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.1.1 (2016-07-13)", "header_href": "#scrapy-1-1-1-2016-07-13", "codes": [], "codes_text": [], "index": 158}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bug fixes", "header_href": "#id99", "codes": [], "codes_text": [], "index": 159}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features", "header_href": "#id100", "codes": [], "codes_text": [], "index": 160}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Documentation", "header_href": "#id101", "codes": [], "codes_text": [], "index": 161}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Tests", "header_href": "#tests", "codes": [], "codes_text": [], "index": 162}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.1.0 (2016-05-11)", "header_href": "#scrapy-1-1-0-2016-05-11", "codes": [], "codes_text": [], "index": 163}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Beta Python 3 Support", "header_href": "#beta-python-3-support", "codes": [], "codes_text": [], "index": 164}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Additional New Features and Enhancements", "header_href": "#additional-new-features-and-enhancements", "codes": [], "codes_text": [], "index": 165}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecations and Removals", "header_href": "#deprecations-and-removals", "codes": [], "codes_text": [], "index": 166}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Relocations", "header_href": "#relocations", "codes": [], "codes_text": [], "index": 167}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bugfixes", "header_href": "#bugfixes", "codes": [], "codes_text": [], "index": 168}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.0.7 (2017-03-03)", "header_href": "#scrapy-1-0-7-2017-03-03", "codes": [], "codes_text": [], "index": 169}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.0.6 (2016-05-04)", "header_href": "#scrapy-1-0-6-2016-05-04", "codes": [], "codes_text": [], "index": 170}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.0.5 (2016-02-04)", "header_href": "#scrapy-1-0-5-2016-02-04", "codes": [], "codes_text": [], "index": 171}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.0.4 (2015-12-30)", "header_href": "#scrapy-1-0-4-2015-12-30", "codes": [], "codes_text": [], "index": 172}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.0.3 (2015-08-11)", "header_href": "#scrapy-1-0-3-2015-08-11", "codes": [], "codes_text": [], "index": 173}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.0.2 (2015-08-06)", "header_href": "#scrapy-1-0-2-2015-08-06", "codes": [], "codes_text": [], "index": 174}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.0.1 (2015-07-01)", "header_href": "#scrapy-1-0-1-2015-07-01", "codes": [], "codes_text": [], "index": 175}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 1.0.0 (2015-06-19)", "header_href": "#scrapy-1-0-0-2015-06-19", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MyItem</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">MyItem</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"s1\">'url'</span><span class=\"p\">:</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">custom_settings</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n        <span class=\"s2\">\"DOWNLOAD_DELAY\"</span><span class=\"p\">:</span> <span class=\"mf\">5.0</span><span class=\"p\">,</span>\n        <span class=\"s2\">\"RETRY_ENABLED\"</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n    <span class=\"p\">}</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">log</span>\n<span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">msg</span><span class=\"p\">(</span><span class=\"s1\">'MESSAGE'</span><span class=\"p\">,</span> <span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">INFO</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'MESSAGE'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Response received'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.crawler</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerProcess</span>\n\n<span class=\"n\">process</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerProcess</span><span class=\"p\">({</span>\n    <span class=\"s1\">'USER_AGENT'</span><span class=\"p\">:</span> <span class=\"s1\">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'</span>\n<span class=\"p\">})</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider</span><span class=\"p\">)</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n</pre></div>"], "codes_text": ["class MyItem(scrapy.Item):\n    url = scrapy.Field()\n\nclass MySpider(scrapy.Spider):\n    def parse(self, response):\n        return MyItem(url=response.url)\n", "class MySpider(scrapy.Spider):\n    def parse(self, response):\n        return {'url': response.url}\n", "class MySpider(scrapy.Spider):\n    custom_settings = {\n        \"DOWNLOAD_DELAY\": 5.0,\n        \"RETRY_ENABLED\": False,\n    }\n", "from scrapy import log\nlog.msg('MESSAGE', log.INFO)\n", "import logging\nlogging.info('MESSAGE')\n", "class MySpider(scrapy.Spider):\n    def parse(self, response):\n        self.logger.info('Response received')\n", "from scrapy.crawler import CrawlerProcess\n\nprocess = CrawlerProcess({\n    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n})\nprocess.crawl(MySpider)\nprocess.start()\n"], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Support for returning dictionaries in spiders", "header_href": "#support-for-returning-dictionaries-in-spiders", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MyItem</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Field</span><span class=\"p\">()</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">MyItem</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"s1\">'url'</span><span class=\"p\">:</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["class MyItem(scrapy.Item):\n    url = scrapy.Field()\n\nclass MySpider(scrapy.Spider):\n    def parse(self, response):\n        return MyItem(url=response.url)\n", "class MySpider(scrapy.Spider):\n    def parse(self, response):\n        return {'url': response.url}\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Per-spider settings (GSoC 2014)", "header_href": "#per-spider-settings-gsoc-2014", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">custom_settings</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n        <span class=\"s2\">\"DOWNLOAD_DELAY\"</span><span class=\"p\">:</span> <span class=\"mf\">5.0</span><span class=\"p\">,</span>\n        <span class=\"s2\">\"RETRY_ENABLED\"</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n    <span class=\"p\">}</span>\n</pre></div>"], "codes_text": ["class MySpider(scrapy.Spider):\n    custom_settings = {\n        \"DOWNLOAD_DELAY\": 5.0,\n        \"RETRY_ENABLED\": False,\n    }\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Python Logging", "header_href": "#python-logging", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy</span> <span class=\"kn\">import</span> <span class=\"n\">log</span>\n<span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">msg</span><span class=\"p\">(</span><span class=\"s1\">'MESSAGE'</span><span class=\"p\">,</span> <span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">INFO</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'MESSAGE'</span><span class=\"p\">)</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Response received'</span><span class=\"p\">)</span>\n</pre></div>"], "codes_text": ["from scrapy import log\nlog.msg('MESSAGE', log.INFO)\n", "import logging\nlogging.info('MESSAGE')\n", "class MySpider(scrapy.Spider):\n    def parse(self, response):\n        self.logger.info('Response received')\n"], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Crawler API refactoring (GSoC 2014)", "header_href": "#crawler-api-refactoring-gsoc-2014", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">scrapy.crawler</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerProcess</span>\n\n<span class=\"n\">process</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerProcess</span><span class=\"p\">({</span>\n    <span class=\"s1\">'USER_AGENT'</span><span class=\"p\">:</span> <span class=\"s1\">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'</span>\n<span class=\"p\">})</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">(</span><span class=\"n\">MySpider</span><span class=\"p\">)</span>\n<span class=\"n\">process</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n</pre></div>"], "codes_text": ["from scrapy.crawler import CrawlerProcess\n\nprocess = CrawlerProcess({\n    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n})\nprocess.crawl(MySpider)\nprocess.start()\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Module Relocations", "header_href": "#module-relocations", "codes": [], "codes_text": [], "index": 181}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "####", "header_depth": 4, "header_text": "Full list of relocations", "header_href": "#full-list-of-relocations", "codes": [], "codes_text": [], "index": 182}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Changelog", "header_href": "#changelog", "codes": [], "codes_text": [], "index": 183}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.24.6 (2015-04-20)", "header_href": "#scrapy-0-24-6-2015-04-20", "codes": [], "codes_text": [], "index": 184}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.24.5 (2015-02-25)", "header_href": "#scrapy-0-24-5-2015-02-25", "codes": [], "codes_text": [], "index": 185}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.24.4 (2014-08-09)", "header_href": "#scrapy-0-24-4-2014-08-09", "codes": [], "codes_text": [], "index": 186}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.24.3 (2014-08-09)", "header_href": "#scrapy-0-24-3-2014-08-09", "codes": [], "codes_text": [], "index": 187}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.24.2 (2014-07-08)", "header_href": "#scrapy-0-24-2-2014-07-08", "codes": [], "codes_text": [], "index": 188}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.24.1 (2014-06-27)", "header_href": "#scrapy-0-24-1-2014-06-27", "codes": [], "codes_text": [], "index": 189}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.24.0 (2014-06-26)", "header_href": "#scrapy-0-24-0-2014-06-26", "codes": [], "codes_text": [], "index": 190}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Enhancements", "header_href": "#enhancements", "codes": [], "codes_text": [], "index": 191}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bugfixes", "header_href": "#id103", "codes": [], "codes_text": [], "index": 192}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.22.2 (released 2014-02-14)", "header_href": "#scrapy-0-22-2-released-2014-02-14", "codes": [], "codes_text": [], "index": 193}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.22.1 (released 2014-02-08)", "header_href": "#scrapy-0-22-1-released-2014-02-08", "codes": [], "codes_text": [], "index": 194}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.22.0 (released 2014-01-17)", "header_href": "#scrapy-0-22-0-released-2014-01-17", "codes": [], "codes_text": [], "index": 195}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Enhancements", "header_href": "#id104", "codes": [], "codes_text": [], "index": 196}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Fixes", "header_href": "#fixes", "codes": [], "codes_text": [], "index": 197}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.20.2 (released 2013-12-09)", "header_href": "#scrapy-0-20-2-released-2013-12-09", "codes": [], "codes_text": [], "index": 198}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.20.1 (released 2013-11-28)", "header_href": "#scrapy-0-20-1-released-2013-11-28", "codes": [], "codes_text": [], "index": 199}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.20.0 (released 2013-11-08)", "header_href": "#scrapy-0-20-0-released-2013-11-08", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"mi\">69</span> <span class=\"n\">Daniel</span> <span class=\"n\">Graña</span> <span class=\"o\">&lt;</span><span class=\"n\">dangra</span><span class=\"o\">@...&gt;</span>\n<span class=\"mi\">37</span> <span class=\"n\">Pablo</span> <span class=\"n\">Hoffman</span> <span class=\"o\">&lt;</span><span class=\"n\">pablo</span><span class=\"o\">@...&gt;</span>\n<span class=\"mi\">13</span> <span class=\"n\">Mikhail</span> <span class=\"n\">Korobov</span> <span class=\"o\">&lt;</span><span class=\"n\">kmike84</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">9</span> <span class=\"n\">Alex</span> <span class=\"n\">Cepoi</span> <span class=\"o\">&lt;</span><span class=\"n\">alex</span><span class=\"o\">.</span><span class=\"n\">cepoi</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">9</span> <span class=\"n\">alexanderlukanin13</span> <span class=\"o\">&lt;</span><span class=\"n\">alexander</span><span class=\"o\">.</span><span class=\"n\">lukanin</span><span class=\"mf\">.13</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">8</span> <span class=\"n\">Rolando</span> <span class=\"n\">Espinoza</span> <span class=\"n\">La</span> <span class=\"n\">fuente</span> <span class=\"o\">&lt;</span><span class=\"n\">darkrho</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">8</span> <span class=\"n\">Lukasz</span> <span class=\"n\">Biedrycki</span> <span class=\"o\">&lt;</span><span class=\"n\">lukasz</span><span class=\"o\">.</span><span class=\"n\">biedrycki</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">6</span> <span class=\"n\">Nicolas</span> <span class=\"n\">Ramirez</span> <span class=\"o\">&lt;</span><span class=\"n\">nramirez</span><span class=\"o\">.</span><span class=\"n\">uy</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">3</span> <span class=\"n\">Paul</span> <span class=\"n\">Tremberth</span> <span class=\"o\">&lt;</span><span class=\"n\">paul</span><span class=\"o\">.</span><span class=\"n\">tremberth</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">2</span> <span class=\"n\">Martin</span> <span class=\"n\">Olveyra</span> <span class=\"o\">&lt;</span><span class=\"n\">molveyra</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">2</span> <span class=\"n\">Stefan</span> <span class=\"o\">&lt;</span><span class=\"n\">misc</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">2</span> <span class=\"n\">Rolando</span> <span class=\"n\">Espinoza</span> <span class=\"o\">&lt;</span><span class=\"n\">darkrho</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">2</span> <span class=\"n\">Loren</span> <span class=\"n\">Davie</span> <span class=\"o\">&lt;</span><span class=\"n\">loren</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">2</span> <span class=\"n\">irgmedeiros</span> <span class=\"o\">&lt;</span><span class=\"n\">irgmedeiros</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Stefan</span> <span class=\"n\">Koch</span> <span class=\"o\">&lt;</span><span class=\"n\">taikano</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Stefan</span> <span class=\"o\">&lt;</span><span class=\"n\">cct</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">scraperdragon</span> <span class=\"o\">&lt;</span><span class=\"n\">dragon</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Kumara</span> <span class=\"n\">Tharmalingam</span> <span class=\"o\">&lt;</span><span class=\"n\">ktharmal</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Francesco</span> <span class=\"n\">Piccinno</span> <span class=\"o\">&lt;</span><span class=\"n\">stack</span><span class=\"o\">.</span><span class=\"n\">box</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Marcos</span> <span class=\"n\">Campal</span> <span class=\"o\">&lt;</span><span class=\"n\">duendex</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Dragon</span> <span class=\"n\">Dave</span> <span class=\"o\">&lt;</span><span class=\"n\">dragon</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Capi</span> <span class=\"n\">Etheriel</span> <span class=\"o\">&lt;</span><span class=\"n\">barraponto</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">cacovsky</span> <span class=\"o\">&lt;</span><span class=\"n\">amarquesferraz</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Berend</span> <span class=\"n\">Iwema</span> <span class=\"o\">&lt;</span><span class=\"n\">berend</span><span class=\"o\">@...&gt;</span>\n</pre></div>"], "codes_text": ["69 Daniel Graña <dangra@...>\n37 Pablo Hoffman <pablo@...>\n13 Mikhail Korobov <kmike84@...>\n 9 Alex Cepoi <alex.cepoi@...>\n 9 alexanderlukanin13 <alexander.lukanin.13@...>\n 8 Rolando Espinoza La fuente <darkrho@...>\n 8 Lukasz Biedrycki <lukasz.biedrycki@...>\n 6 Nicolas Ramirez <nramirez.uy@...>\n 3 Paul Tremberth <paul.tremberth@...>\n 2 Martin Olveyra <molveyra@...>\n 2 Stefan <misc@...>\n 2 Rolando Espinoza <darkrho@...>\n 2 Loren Davie <loren@...>\n 2 irgmedeiros <irgmedeiros@...>\n 1 Stefan Koch <taikano@...>\n 1 Stefan <cct@...>\n 1 scraperdragon <dragon@...>\n 1 Kumara Tharmalingam <ktharmal@...>\n 1 Francesco Piccinno <stack.box@...>\n 1 Marcos Campal <duendex@...>\n 1 Dragon Dave <dragon@...>\n 1 Capi Etheriel <barraponto@...>\n 1 cacovsky <amarquesferraz@...>\n 1 Berend Iwema <berend@...>\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Enhancements", "header_href": "#id105", "codes": [], "codes_text": [], "index": 201}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Bugfixes", "header_href": "#id106", "codes": [], "codes_text": [], "index": 202}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Other", "header_href": "#other", "codes": [], "codes_text": [], "index": 203}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Thanks", "header_href": "#thanks", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"mi\">69</span> <span class=\"n\">Daniel</span> <span class=\"n\">Graña</span> <span class=\"o\">&lt;</span><span class=\"n\">dangra</span><span class=\"o\">@...&gt;</span>\n<span class=\"mi\">37</span> <span class=\"n\">Pablo</span> <span class=\"n\">Hoffman</span> <span class=\"o\">&lt;</span><span class=\"n\">pablo</span><span class=\"o\">@...&gt;</span>\n<span class=\"mi\">13</span> <span class=\"n\">Mikhail</span> <span class=\"n\">Korobov</span> <span class=\"o\">&lt;</span><span class=\"n\">kmike84</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">9</span> <span class=\"n\">Alex</span> <span class=\"n\">Cepoi</span> <span class=\"o\">&lt;</span><span class=\"n\">alex</span><span class=\"o\">.</span><span class=\"n\">cepoi</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">9</span> <span class=\"n\">alexanderlukanin13</span> <span class=\"o\">&lt;</span><span class=\"n\">alexander</span><span class=\"o\">.</span><span class=\"n\">lukanin</span><span class=\"mf\">.13</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">8</span> <span class=\"n\">Rolando</span> <span class=\"n\">Espinoza</span> <span class=\"n\">La</span> <span class=\"n\">fuente</span> <span class=\"o\">&lt;</span><span class=\"n\">darkrho</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">8</span> <span class=\"n\">Lukasz</span> <span class=\"n\">Biedrycki</span> <span class=\"o\">&lt;</span><span class=\"n\">lukasz</span><span class=\"o\">.</span><span class=\"n\">biedrycki</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">6</span> <span class=\"n\">Nicolas</span> <span class=\"n\">Ramirez</span> <span class=\"o\">&lt;</span><span class=\"n\">nramirez</span><span class=\"o\">.</span><span class=\"n\">uy</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">3</span> <span class=\"n\">Paul</span> <span class=\"n\">Tremberth</span> <span class=\"o\">&lt;</span><span class=\"n\">paul</span><span class=\"o\">.</span><span class=\"n\">tremberth</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">2</span> <span class=\"n\">Martin</span> <span class=\"n\">Olveyra</span> <span class=\"o\">&lt;</span><span class=\"n\">molveyra</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">2</span> <span class=\"n\">Stefan</span> <span class=\"o\">&lt;</span><span class=\"n\">misc</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">2</span> <span class=\"n\">Rolando</span> <span class=\"n\">Espinoza</span> <span class=\"o\">&lt;</span><span class=\"n\">darkrho</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">2</span> <span class=\"n\">Loren</span> <span class=\"n\">Davie</span> <span class=\"o\">&lt;</span><span class=\"n\">loren</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">2</span> <span class=\"n\">irgmedeiros</span> <span class=\"o\">&lt;</span><span class=\"n\">irgmedeiros</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Stefan</span> <span class=\"n\">Koch</span> <span class=\"o\">&lt;</span><span class=\"n\">taikano</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Stefan</span> <span class=\"o\">&lt;</span><span class=\"n\">cct</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">scraperdragon</span> <span class=\"o\">&lt;</span><span class=\"n\">dragon</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Kumara</span> <span class=\"n\">Tharmalingam</span> <span class=\"o\">&lt;</span><span class=\"n\">ktharmal</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Francesco</span> <span class=\"n\">Piccinno</span> <span class=\"o\">&lt;</span><span class=\"n\">stack</span><span class=\"o\">.</span><span class=\"n\">box</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Marcos</span> <span class=\"n\">Campal</span> <span class=\"o\">&lt;</span><span class=\"n\">duendex</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Dragon</span> <span class=\"n\">Dave</span> <span class=\"o\">&lt;</span><span class=\"n\">dragon</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Capi</span> <span class=\"n\">Etheriel</span> <span class=\"o\">&lt;</span><span class=\"n\">barraponto</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">cacovsky</span> <span class=\"o\">&lt;</span><span class=\"n\">amarquesferraz</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">1</span> <span class=\"n\">Berend</span> <span class=\"n\">Iwema</span> <span class=\"o\">&lt;</span><span class=\"n\">berend</span><span class=\"o\">@...&gt;</span>\n</pre></div>"], "codes_text": ["69 Daniel Graña <dangra@...>\n37 Pablo Hoffman <pablo@...>\n13 Mikhail Korobov <kmike84@...>\n 9 Alex Cepoi <alex.cepoi@...>\n 9 alexanderlukanin13 <alexander.lukanin.13@...>\n 8 Rolando Espinoza La fuente <darkrho@...>\n 8 Lukasz Biedrycki <lukasz.biedrycki@...>\n 6 Nicolas Ramirez <nramirez.uy@...>\n 3 Paul Tremberth <paul.tremberth@...>\n 2 Martin Olveyra <molveyra@...>\n 2 Stefan <misc@...>\n 2 Rolando Espinoza <darkrho@...>\n 2 Loren Davie <loren@...>\n 2 irgmedeiros <irgmedeiros@...>\n 1 Stefan Koch <taikano@...>\n 1 Stefan <cct@...>\n 1 scraperdragon <dragon@...>\n 1 Kumara Tharmalingam <ktharmal@...>\n 1 Francesco Piccinno <stack.box@...>\n 1 Marcos Campal <duendex@...>\n 1 Dragon Dave <dragon@...>\n 1 Capi Etheriel <barraponto@...>\n 1 cacovsky <amarquesferraz@...>\n 1 Berend Iwema <berend@...>\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.18.4 (released 2013-10-10)", "header_href": "#scrapy-0-18-4-released-2013-10-10", "codes": [], "codes_text": [], "index": 205}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.18.3 (released 2013-10-03)", "header_href": "#scrapy-0-18-3-released-2013-10-03", "codes": [], "codes_text": [], "index": 206}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.18.2 (released 2013-09-03)", "header_href": "#scrapy-0-18-2-released-2013-09-03", "codes": [], "codes_text": [], "index": 207}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.18.1 (released 2013-08-27)", "header_href": "#scrapy-0-18-1-released-2013-08-27", "codes": [], "codes_text": [], "index": 208}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.18.0 (released 2013-08-09)", "header_href": "#scrapy-0-18-0-released-2013-08-09", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"mi\">130</span> <span class=\"n\">Pablo</span> <span class=\"n\">Hoffman</span> <span class=\"o\">&lt;</span><span class=\"n\">pablo</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">97</span> <span class=\"n\">Daniel</span> <span class=\"n\">Graña</span> <span class=\"o\">&lt;</span><span class=\"n\">dangra</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">20</span> <span class=\"n\">Nicolás</span> <span class=\"n\">Ramírez</span> <span class=\"o\">&lt;</span><span class=\"n\">nramirez</span><span class=\"o\">.</span><span class=\"n\">uy</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">13</span> <span class=\"n\">Mikhail</span> <span class=\"n\">Korobov</span> <span class=\"o\">&lt;</span><span class=\"n\">kmike84</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">12</span> <span class=\"n\">Pedro</span> <span class=\"n\">Faustino</span> <span class=\"o\">&lt;</span><span class=\"n\">pedrobandim</span><span class=\"o\">@...&gt;</span>\n <span class=\"mi\">11</span> <span class=\"n\">Steven</span> <span class=\"n\">Almeroth</span> <span class=\"o\">&lt;</span><span class=\"n\">sroth77</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">5</span> <span class=\"n\">Rolando</span> <span class=\"n\">Espinoza</span> <span class=\"n\">La</span> <span class=\"n\">fuente</span> <span class=\"o\">&lt;</span><span class=\"n\">darkrho</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">4</span> <span class=\"n\">Michal</span> <span class=\"n\">Danilak</span> <span class=\"o\">&lt;</span><span class=\"n\">mimino</span><span class=\"o\">.</span><span class=\"n\">coder</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">4</span> <span class=\"n\">Alex</span> <span class=\"n\">Cepoi</span> <span class=\"o\">&lt;</span><span class=\"n\">alex</span><span class=\"o\">.</span><span class=\"n\">cepoi</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">4</span> <span class=\"n\">Alexandr</span> <span class=\"n\">N</span> <span class=\"n\">Zamaraev</span> <span class=\"p\">(</span><span class=\"n\">aka</span> <span class=\"n\">tonal</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span><span class=\"n\">tonal</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">3</span> <span class=\"n\">paul</span> <span class=\"o\">&lt;</span><span class=\"n\">paul</span><span class=\"o\">.</span><span class=\"n\">tremberth</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">3</span> <span class=\"n\">Martin</span> <span class=\"n\">Olveyra</span> <span class=\"o\">&lt;</span><span class=\"n\">molveyra</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">3</span> <span class=\"n\">Jordi</span> <span class=\"n\">Llonch</span> <span class=\"o\">&lt;</span><span class=\"n\">llonchj</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">3</span> <span class=\"n\">arijitchakraborty</span> <span class=\"o\">&lt;</span><span class=\"n\">myself</span><span class=\"o\">.</span><span class=\"n\">arijit</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">2</span> <span class=\"n\">Shane</span> <span class=\"n\">Evans</span> <span class=\"o\">&lt;</span><span class=\"n\">shane</span><span class=\"o\">.</span><span class=\"n\">evans</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">2</span> <span class=\"n\">joehillen</span> <span class=\"o\">&lt;</span><span class=\"n\">joehillen</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">2</span> <span class=\"n\">Hart</span> <span class=\"o\">&lt;</span><span class=\"n\">HartSimha</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">2</span> <span class=\"n\">Dan</span> <span class=\"o\">&lt;</span><span class=\"n\">ellisd23</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Zuhao</span> <span class=\"n\">Wan</span> <span class=\"o\">&lt;</span><span class=\"n\">wanzuhao</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">whodatninja</span> <span class=\"o\">&lt;</span><span class=\"n\">blake</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">vkrest</span> <span class=\"o\">&lt;</span><span class=\"n\">v</span><span class=\"o\">.</span><span class=\"n\">krestiannykov</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">tpeng</span> <span class=\"o\">&lt;</span><span class=\"n\">pengtaoo</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Tom</span> <span class=\"n\">Mortimer</span><span class=\"o\">-</span><span class=\"n\">Jones</span> <span class=\"o\">&lt;</span><span class=\"n\">tom</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Rocio</span> <span class=\"n\">Aramberri</span> <span class=\"o\">&lt;</span><span class=\"n\">roschegel</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Pedro</span> <span class=\"o\">&lt;</span><span class=\"n\">pedro</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">notsobad</span> <span class=\"o\">&lt;</span><span class=\"n\">wangxiaohugg</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Natan</span> <span class=\"n\">L</span> <span class=\"o\">&lt;</span><span class=\"n\">kuyanatan</span><span class=\"o\">.</span><span class=\"n\">nlao</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Mark</span> <span class=\"n\">Grey</span> <span class=\"o\">&lt;</span><span class=\"n\">mark</span><span class=\"o\">.</span><span class=\"n\">grey</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Luan</span> <span class=\"o\">&lt;</span><span class=\"n\">luanpab</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Libor</span> <span class=\"n\">Nenadál</span> <span class=\"o\">&lt;</span><span class=\"n\">libor</span><span class=\"o\">.</span><span class=\"n\">nenadal</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Juan</span> <span class=\"n\">M</span> <span class=\"n\">Uys</span> <span class=\"o\">&lt;</span><span class=\"n\">opyate</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Jonas</span> <span class=\"n\">Brunsgaard</span> <span class=\"o\">&lt;</span><span class=\"n\">jonas</span><span class=\"o\">.</span><span class=\"n\">brunsgaard</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Ilya</span> <span class=\"n\">Baryshev</span> <span class=\"o\">&lt;</span><span class=\"n\">baryshev</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Hasnain</span> <span class=\"n\">Lakhani</span> <span class=\"o\">&lt;</span><span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">hasnain</span><span class=\"o\">.</span><span class=\"n\">lakhani</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Emanuel</span> <span class=\"n\">Schorsch</span> <span class=\"o\">&lt;</span><span class=\"n\">emschorsch</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Chris</span> <span class=\"n\">Tilden</span> <span class=\"o\">&lt;</span><span class=\"n\">chris</span><span class=\"o\">.</span><span class=\"n\">tilden</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Capi</span> <span class=\"n\">Etheriel</span> <span class=\"o\">&lt;</span><span class=\"n\">barraponto</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">cacovsky</span> <span class=\"o\">&lt;</span><span class=\"n\">amarquesferraz</span><span class=\"o\">@...&gt;</span>\n  <span class=\"mi\">1</span> <span class=\"n\">Berend</span> <span class=\"n\">Iwema</span> <span class=\"o\">&lt;</span><span class=\"n\">berend</span><span class=\"o\">@...&gt;</span>\n</pre></div>"], "codes_text": ["130 Pablo Hoffman <pablo@...>\n 97 Daniel Graña <dangra@...>\n 20 Nicolás Ramírez <nramirez.uy@...>\n 13 Mikhail Korobov <kmike84@...>\n 12 Pedro Faustino <pedrobandim@...>\n 11 Steven Almeroth <sroth77@...>\n  5 Rolando Espinoza La fuente <darkrho@...>\n  4 Michal Danilak <mimino.coder@...>\n  4 Alex Cepoi <alex.cepoi@...>\n  4 Alexandr N Zamaraev (aka tonal) <tonal@...>\n  3 paul <paul.tremberth@...>\n  3 Martin Olveyra <molveyra@...>\n  3 Jordi Llonch <llonchj@...>\n  3 arijitchakraborty <myself.arijit@...>\n  2 Shane Evans <shane.evans@...>\n  2 joehillen <joehillen@...>\n  2 Hart <HartSimha@...>\n  2 Dan <ellisd23@...>\n  1 Zuhao Wan <wanzuhao@...>\n  1 whodatninja <blake@...>\n  1 vkrest <v.krestiannykov@...>\n  1 tpeng <pengtaoo@...>\n  1 Tom Mortimer-Jones <tom@...>\n  1 Rocio Aramberri <roschegel@...>\n  1 Pedro <pedro@...>\n  1 notsobad <wangxiaohugg@...>\n  1 Natan L <kuyanatan.nlao@...>\n  1 Mark Grey <mark.grey@...>\n  1 Luan <luanpab@...>\n  1 Libor Nenadál <libor.nenadal@...>\n  1 Juan M Uys <opyate@...>\n  1 Jonas Brunsgaard <jonas.brunsgaard@...>\n  1 Ilya Baryshev <baryshev@...>\n  1 Hasnain Lakhani <m.hasnain.lakhani@...>\n  1 Emanuel Schorsch <emschorsch@...>\n  1 Chris Tilden <chris.tilden@...>\n  1 Capi Etheriel <barraponto@...>\n  1 cacovsky <amarquesferraz@...>\n  1 Berend Iwema <berend@...>\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.16.5 (released 2013-05-30)", "header_href": "#scrapy-0-16-5-released-2013-05-30", "codes": [], "codes_text": [], "index": 210}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.16.4 (released 2013-01-23)", "header_href": "#scrapy-0-16-4-released-2013-01-23", "codes": [], "codes_text": [], "index": 211}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.16.3 (released 2012-12-07)", "header_href": "#scrapy-0-16-3-released-2012-12-07", "codes": [], "codes_text": [], "index": 212}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.16.2 (released 2012-11-09)", "header_href": "#scrapy-0-16-2-released-2012-11-09", "codes": [], "codes_text": [], "index": 213}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.16.1 (released 2012-10-26)", "header_href": "#scrapy-0-16-1-released-2012-10-26", "codes": [], "codes_text": [], "index": 214}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.16.0 (released 2012-10-18)", "header_href": "#scrapy-0-16-0-released-2012-10-18", "codes": [], "codes_text": [], "index": 215}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.14.4", "header_href": "#scrapy-0-14-4", "codes": [], "codes_text": [], "index": 216}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.14.3", "header_href": "#scrapy-0-14-3", "codes": [], "codes_text": [], "index": 217}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.14.2", "header_href": "#scrapy-0-14-2", "codes": [], "codes_text": [], "index": 218}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.14.1", "header_href": "#scrapy-0-14-1", "codes": [], "codes_text": [], "index": 219}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.14", "header_href": "#scrapy-0-14", "codes": [], "codes_text": [], "index": 220}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features and settings", "header_href": "#new-features-and-settings", "codes": [], "codes_text": [], "index": 221}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Code rearranged and removed", "header_href": "#code-rearranged-and-removed", "codes": [], "codes_text": [], "index": 222}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.12", "header_href": "#scrapy-0-12", "codes": [], "codes_text": [], "index": 223}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features and improvements", "header_href": "#new-features-and-improvements", "codes": [], "codes_text": [], "index": 224}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Scrapyd changes", "header_href": "#scrapyd-changes", "codes": [], "codes_text": [], "index": 225}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Changes to settings", "header_href": "#changes-to-settings", "codes": [], "codes_text": [], "index": 226}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Deprecated/obsoleted functionality", "header_href": "#deprecated-obsoleted-functionality", "codes": [], "codes_text": [], "index": 227}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.10", "header_href": "#scrapy-0-10", "codes": [], "codes_text": [], "index": 228}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features and improvements", "header_href": "#id107", "codes": [], "codes_text": [], "index": 229}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Command-line tool changes", "header_href": "#command-line-tool-changes", "codes": [], "codes_text": [], "index": 230}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "API changes", "header_href": "#api-changes", "codes": [], "codes_text": [], "index": 231}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Changes to settings", "header_href": "#id108", "codes": [], "codes_text": [], "index": 232}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.9", "header_href": "#scrapy-0-9", "codes": [], "codes_text": [], "index": 233}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features and improvements", "header_href": "#id109", "codes": [], "codes_text": [], "index": 234}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "API changes", "header_href": "#id110", "codes": [], "codes_text": [], "index": 235}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Changes to default settings", "header_href": "#changes-to-default-settings", "codes": [], "codes_text": [], "index": 236}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.8", "header_href": "#scrapy-0-8", "codes": [], "codes_text": [], "index": 237}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "New features", "header_href": "#id111", "codes": [], "codes_text": [], "index": 238}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Backward-incompatible changes", "header_href": "#id112", "codes": [], "codes_text": [], "index": 239}
{"url": "https://docs.scrapy.org/en/latest/news.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Scrapy 0.7", "header_href": "#scrapy-0-7", "codes": [], "codes_text": [], "index": 240}
{"url": "https://docs.scrapy.org/en/latest/contributing.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Contributing to Scrapy", "header_href": "#contributing-to-scrapy", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span> <span class=\"o\">-</span><span class=\"n\">e</span> <span class=\"n\">docs</span><span class=\"o\">-</span><span class=\"n\">coverage</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span> <span class=\"o\">-</span><span class=\"n\">e</span> <span class=\"n\">py37</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span> <span class=\"o\">-</span><span class=\"n\">e</span> <span class=\"n\">py37</span><span class=\"p\">,</span><span class=\"n\">py38</span> <span class=\"o\">-</span><span class=\"n\">p</span> <span class=\"n\">auto</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span> <span class=\"o\">--</span> <span class=\"n\">scrapy</span> <span class=\"n\">tests</span> <span class=\"o\">-</span><span class=\"n\">x</span>  <span class=\"c1\"># stop after first failure</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span> <span class=\"o\">-</span><span class=\"n\">e</span> <span class=\"n\">py37</span> <span class=\"o\">--</span> <span class=\"n\">scrapy</span> <span class=\"n\">tests</span> <span class=\"o\">-</span><span class=\"n\">n</span> <span class=\"n\">auto</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">loader</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tests</span><span class=\"o\">/</span><span class=\"n\">test_loader</span><span class=\"o\">.</span><span class=\"n\">py</span>\n</pre></div>"], "codes_text": ["tox -e docs-coverage\n", "tox\n", "tox -e py37\n", "tox -e py37,py38 -p auto\n", "tox -- scrapy tests -x  # stop after first failure\n", "tox -e py37 -- scrapy tests -n auto\n", "scrapy.loader\n", "tests/test_loader.py\n"], "index": 8}
{"url": "https://docs.scrapy.org/en/latest/contributing.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Reporting bugs", "header_href": "#reporting-bugs", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/contributing.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Writing patches", "header_href": "#writing-patches", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span> <span class=\"o\">-</span><span class=\"n\">e</span> <span class=\"n\">docs</span><span class=\"o\">-</span><span class=\"n\">coverage</span>\n</pre></div>"], "codes_text": ["tox -e docs-coverage\n"], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/contributing.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Submitting patches", "header_href": "#submitting-patches", "codes": [], "codes_text": [], "index": 4}
{"url": "https://docs.scrapy.org/en/latest/contributing.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Coding style", "header_href": "#coding-style", "codes": [], "codes_text": [], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/contributing.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Documentation policies", "header_href": "#documentation-policies", "codes": [], "codes_text": [], "index": 6}
{"url": "https://docs.scrapy.org/en/latest/contributing.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Tests", "header_href": "#tests", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span> <span class=\"o\">-</span><span class=\"n\">e</span> <span class=\"n\">py37</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span> <span class=\"o\">-</span><span class=\"n\">e</span> <span class=\"n\">py37</span><span class=\"p\">,</span><span class=\"n\">py38</span> <span class=\"o\">-</span><span class=\"n\">p</span> <span class=\"n\">auto</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span> <span class=\"o\">--</span> <span class=\"n\">scrapy</span> <span class=\"n\">tests</span> <span class=\"o\">-</span><span class=\"n\">x</span>  <span class=\"c1\"># stop after first failure</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span> <span class=\"o\">-</span><span class=\"n\">e</span> <span class=\"n\">py37</span> <span class=\"o\">--</span> <span class=\"n\">scrapy</span> <span class=\"n\">tests</span> <span class=\"o\">-</span><span class=\"n\">n</span> <span class=\"n\">auto</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">loader</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tests</span><span class=\"o\">/</span><span class=\"n\">test_loader</span><span class=\"o\">.</span><span class=\"n\">py</span>\n</pre></div>"], "codes_text": ["tox\n", "tox -e py37\n", "tox -e py37,py38 -p auto\n", "tox -- scrapy tests -x  # stop after first failure\n", "tox -e py37 -- scrapy tests -n auto\n", "scrapy.loader\n", "tests/test_loader.py\n"], "index": 7}
{"url": "https://docs.scrapy.org/en/latest/contributing.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Running tests", "header_href": "#running-tests", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span> <span class=\"o\">-</span><span class=\"n\">e</span> <span class=\"n\">py37</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span> <span class=\"o\">-</span><span class=\"n\">e</span> <span class=\"n\">py37</span><span class=\"p\">,</span><span class=\"n\">py38</span> <span class=\"o\">-</span><span class=\"n\">p</span> <span class=\"n\">auto</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span> <span class=\"o\">--</span> <span class=\"n\">scrapy</span> <span class=\"n\">tests</span> <span class=\"o\">-</span><span class=\"n\">x</span>  <span class=\"c1\"># stop after first failure</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tox</span> <span class=\"o\">-</span><span class=\"n\">e</span> <span class=\"n\">py37</span> <span class=\"o\">--</span> <span class=\"n\">scrapy</span> <span class=\"n\">tests</span> <span class=\"o\">-</span><span class=\"n\">n</span> <span class=\"n\">auto</span>\n</pre></div>"], "codes_text": ["tox\n", "tox -e py37\n", "tox -e py37,py38 -p auto\n", "tox -- scrapy tests -x  # stop after first failure\n", "tox -e py37 -- scrapy tests -n auto\n"], "index": 5}
{"url": "https://docs.scrapy.org/en/latest/contributing.html", "head": "", "markdown_depth": "###", "header_depth": 3, "header_text": "Writing tests", "header_href": "#writing-tests", "codes": ["<div class=\"highlight\"><pre><span></span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">loader</span>\n</pre></div>", "<div class=\"highlight\"><pre><span></span><span class=\"n\">tests</span><span class=\"o\">/</span><span class=\"n\">test_loader</span><span class=\"o\">.</span><span class=\"n\">py</span>\n</pre></div>"], "codes_text": ["scrapy.loader\n", "tests/test_loader.py\n"], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/versioning.html", "head": "", "markdown_depth": "#", "header_depth": 1, "header_text": "Versioning and API stability", "header_href": "#versioning-and-api-stability", "codes": [], "codes_text": [], "index": 1}
{"url": "https://docs.scrapy.org/en/latest/versioning.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Versioning", "header_href": "#id1", "codes": [], "codes_text": [], "index": 2}
{"url": "https://docs.scrapy.org/en/latest/versioning.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "API stability", "header_href": "#api-stability", "codes": [], "codes_text": [], "index": 3}
{"url": "https://docs.scrapy.org/en/latest/versioning.html", "head": "", "markdown_depth": "##", "header_depth": 2, "header_text": "Deprecation policy", "header_href": "#deprecation-policy", "codes": [], "codes_text": [], "index": 4}
