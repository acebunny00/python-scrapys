url,head,markdown_depth,header_depth,header_text,header_href,codes,codes_text,index
https://docs.scrapy.org/en/latest/index.html,"<head>
  <meta charset=""utf-8""><meta name=""generator"" content=""Docutils 0.17.1: http://docutils.sourceforge.net/"">

  <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
  <title>Scrapy 2.7 documentation — Scrapy 2.7.1 documentation</title>
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/pygments.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/theme.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster.custom.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster.bundle.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-shadow.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-punk.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-noir.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-light.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-borderless.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/micromodal.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/sphinx_rtd_theme.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/custom.css"" type=""text/css"">
    <link rel=""canonical"" href=""https://docs.scrapy.org/en/latest/index.html"">
  <!--[if lt IE 9]>
    <script src=""https://docs.scrapy.org/en/latest/_static/js/html5shiv.min.js""></script>
  <![endif]-->
  
        <script data-url_root=""./"" id=""documentation_options"" src=""https://docs.scrapy.org/en/latest/_static/documentation_options.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/jquery.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/underscore.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/_sphinx_javascript_frameworks_compat.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/doctools.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/hoverxref.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/tooltipster.bundle.min.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/micromodal.min.js""></script>
        <script async=""async"" src=""https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js""></script>
        <script async=""async"" src=""https://docs.scrapy.org/_/static/javascript/readthedocs-doc-embed.js""></script>
    <script src=""https://docs.scrapy.org/en/latest/_static/js/theme.js""></script>
    <link rel=""index"" title=""Index"" href=""genindex.html"">
    <link rel=""search"" title=""Search"" href=""search.html"">
    <link rel=""next"" title=""Scrapy at a glance"" href=""intro/overview.html""> 

<!-- RTD Extra Head -->

<link rel=""stylesheet"" href=""https://docs.scrapy.org/_/static/css/readthedocs-doc-embed.css"" type=""text/css"">

<script type=""application/json"" id=""READTHEDOCS_DATA"">{""ad_free"": false, ""api_host"": ""https://readthedocs.org"", ""build_date"": ""2022-11-02T11:04:52Z"", ""builder"": ""sphinx"", ""canonical_url"": null, ""commit"": ""6ded3cf4"", ""docroot"": ""/docs/"", ""features"": {""docsearch_disabled"": false}, ""global_analytics_code"": ""UA-17997319-1"", ""language"": ""en"", ""page"": ""index"", ""programming_language"": ""py"", ""project"": ""scrapy"", ""proxied_api_host"": ""/_"", ""source_suffix"": "".rst"", ""subprojects"": {}, ""theme"": ""sphinx_rtd_theme"", ""user_analytics_code"": ""UA-10231918-2"", ""version"": ""latest""}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type=""text/javascript"">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type=""text/javascript"" src=""https://docs.scrapy.org/_/static/javascript/readthedocs-analytics.js"" async=""async""></script>

<!-- end RTD <extrahead> -->
</head>
",#,1,Scrapy 2.7 documentation,#scrapy-version-documentation,,,1
https://docs.scrapy.org/en/latest/index.html,"<head>
  <meta charset=""utf-8""><meta name=""generator"" content=""Docutils 0.17.1: http://docutils.sourceforge.net/"">

  <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
  <title>Scrapy 2.7 documentation — Scrapy 2.7.1 documentation</title>
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/pygments.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/theme.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster.custom.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster.bundle.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-shadow.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-punk.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-noir.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-light.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-borderless.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/micromodal.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/sphinx_rtd_theme.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/custom.css"" type=""text/css"">
    <link rel=""canonical"" href=""https://docs.scrapy.org/en/latest/index.html"">
  <!--[if lt IE 9]>
    <script src=""https://docs.scrapy.org/en/latest/_static/js/html5shiv.min.js""></script>
  <![endif]-->
  
        <script data-url_root=""./"" id=""documentation_options"" src=""https://docs.scrapy.org/en/latest/_static/documentation_options.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/jquery.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/underscore.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/_sphinx_javascript_frameworks_compat.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/doctools.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/hoverxref.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/tooltipster.bundle.min.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/micromodal.min.js""></script>
        <script async=""async"" src=""https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js""></script>
        <script async=""async"" src=""https://docs.scrapy.org/_/static/javascript/readthedocs-doc-embed.js""></script>
    <script src=""https://docs.scrapy.org/en/latest/_static/js/theme.js""></script>
    <link rel=""index"" title=""Index"" href=""genindex.html"">
    <link rel=""search"" title=""Search"" href=""search.html"">
    <link rel=""next"" title=""Scrapy at a glance"" href=""intro/overview.html""> 

<!-- RTD Extra Head -->

<link rel=""stylesheet"" href=""https://docs.scrapy.org/_/static/css/readthedocs-doc-embed.css"" type=""text/css"">

<script type=""application/json"" id=""READTHEDOCS_DATA"">{""ad_free"": false, ""api_host"": ""https://readthedocs.org"", ""build_date"": ""2022-11-02T11:04:52Z"", ""builder"": ""sphinx"", ""canonical_url"": null, ""commit"": ""6ded3cf4"", ""docroot"": ""/docs/"", ""features"": {""docsearch_disabled"": false}, ""global_analytics_code"": ""UA-17997319-1"", ""language"": ""en"", ""page"": ""index"", ""programming_language"": ""py"", ""project"": ""scrapy"", ""proxied_api_host"": ""/_"", ""source_suffix"": "".rst"", ""subprojects"": {}, ""theme"": ""sphinx_rtd_theme"", ""user_analytics_code"": ""UA-10231918-2"", ""version"": ""latest""}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type=""text/javascript"">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type=""text/javascript"" src=""https://docs.scrapy.org/_/static/javascript/readthedocs-analytics.js"" async=""async""></script>

<!-- end RTD <extrahead> -->
</head>
",##,2,Getting help,#getting-help,,,2
https://docs.scrapy.org/en/latest/index.html,"<head>
  <meta charset=""utf-8""><meta name=""generator"" content=""Docutils 0.17.1: http://docutils.sourceforge.net/"">

  <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
  <title>Scrapy 2.7 documentation — Scrapy 2.7.1 documentation</title>
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/pygments.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/theme.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster.custom.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster.bundle.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-shadow.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-punk.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-noir.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-light.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-borderless.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/micromodal.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/sphinx_rtd_theme.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/custom.css"" type=""text/css"">
    <link rel=""canonical"" href=""https://docs.scrapy.org/en/latest/index.html"">
  <!--[if lt IE 9]>
    <script src=""https://docs.scrapy.org/en/latest/_static/js/html5shiv.min.js""></script>
  <![endif]-->
  
        <script data-url_root=""./"" id=""documentation_options"" src=""https://docs.scrapy.org/en/latest/_static/documentation_options.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/jquery.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/underscore.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/_sphinx_javascript_frameworks_compat.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/doctools.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/hoverxref.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/tooltipster.bundle.min.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/micromodal.min.js""></script>
        <script async=""async"" src=""https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js""></script>
        <script async=""async"" src=""https://docs.scrapy.org/_/static/javascript/readthedocs-doc-embed.js""></script>
    <script src=""https://docs.scrapy.org/en/latest/_static/js/theme.js""></script>
    <link rel=""index"" title=""Index"" href=""genindex.html"">
    <link rel=""search"" title=""Search"" href=""search.html"">
    <link rel=""next"" title=""Scrapy at a glance"" href=""intro/overview.html""> 

<!-- RTD Extra Head -->

<link rel=""stylesheet"" href=""https://docs.scrapy.org/_/static/css/readthedocs-doc-embed.css"" type=""text/css"">

<script type=""application/json"" id=""READTHEDOCS_DATA"">{""ad_free"": false, ""api_host"": ""https://readthedocs.org"", ""build_date"": ""2022-11-02T11:04:52Z"", ""builder"": ""sphinx"", ""canonical_url"": null, ""commit"": ""6ded3cf4"", ""docroot"": ""/docs/"", ""features"": {""docsearch_disabled"": false}, ""global_analytics_code"": ""UA-17997319-1"", ""language"": ""en"", ""page"": ""index"", ""programming_language"": ""py"", ""project"": ""scrapy"", ""proxied_api_host"": ""/_"", ""source_suffix"": "".rst"", ""subprojects"": {}, ""theme"": ""sphinx_rtd_theme"", ""user_analytics_code"": ""UA-10231918-2"", ""version"": ""latest""}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type=""text/javascript"">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type=""text/javascript"" src=""https://docs.scrapy.org/_/static/javascript/readthedocs-analytics.js"" async=""async""></script>

<!-- end RTD <extrahead> -->
</head>
",##,2,First steps,#first-steps,,,3
https://docs.scrapy.org/en/latest/index.html,"<head>
  <meta charset=""utf-8""><meta name=""generator"" content=""Docutils 0.17.1: http://docutils.sourceforge.net/"">

  <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
  <title>Scrapy 2.7 documentation — Scrapy 2.7.1 documentation</title>
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/pygments.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/theme.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster.custom.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster.bundle.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-shadow.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-punk.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-noir.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-light.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-borderless.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/micromodal.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/sphinx_rtd_theme.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/custom.css"" type=""text/css"">
    <link rel=""canonical"" href=""https://docs.scrapy.org/en/latest/index.html"">
  <!--[if lt IE 9]>
    <script src=""https://docs.scrapy.org/en/latest/_static/js/html5shiv.min.js""></script>
  <![endif]-->
  
        <script data-url_root=""./"" id=""documentation_options"" src=""https://docs.scrapy.org/en/latest/_static/documentation_options.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/jquery.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/underscore.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/_sphinx_javascript_frameworks_compat.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/doctools.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/hoverxref.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/tooltipster.bundle.min.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/micromodal.min.js""></script>
        <script async=""async"" src=""https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js""></script>
        <script async=""async"" src=""https://docs.scrapy.org/_/static/javascript/readthedocs-doc-embed.js""></script>
    <script src=""https://docs.scrapy.org/en/latest/_static/js/theme.js""></script>
    <link rel=""index"" title=""Index"" href=""genindex.html"">
    <link rel=""search"" title=""Search"" href=""search.html"">
    <link rel=""next"" title=""Scrapy at a glance"" href=""intro/overview.html""> 

<!-- RTD Extra Head -->

<link rel=""stylesheet"" href=""https://docs.scrapy.org/_/static/css/readthedocs-doc-embed.css"" type=""text/css"">

<script type=""application/json"" id=""READTHEDOCS_DATA"">{""ad_free"": false, ""api_host"": ""https://readthedocs.org"", ""build_date"": ""2022-11-02T11:04:52Z"", ""builder"": ""sphinx"", ""canonical_url"": null, ""commit"": ""6ded3cf4"", ""docroot"": ""/docs/"", ""features"": {""docsearch_disabled"": false}, ""global_analytics_code"": ""UA-17997319-1"", ""language"": ""en"", ""page"": ""index"", ""programming_language"": ""py"", ""project"": ""scrapy"", ""proxied_api_host"": ""/_"", ""source_suffix"": "".rst"", ""subprojects"": {}, ""theme"": ""sphinx_rtd_theme"", ""user_analytics_code"": ""UA-10231918-2"", ""version"": ""latest""}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type=""text/javascript"">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type=""text/javascript"" src=""https://docs.scrapy.org/_/static/javascript/readthedocs-analytics.js"" async=""async""></script>

<!-- end RTD <extrahead> -->
</head>
",##,2,Basic concepts,#basic-concepts,,,4
https://docs.scrapy.org/en/latest/index.html,"<head>
  <meta charset=""utf-8""><meta name=""generator"" content=""Docutils 0.17.1: http://docutils.sourceforge.net/"">

  <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
  <title>Scrapy 2.7 documentation — Scrapy 2.7.1 documentation</title>
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/pygments.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/theme.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster.custom.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster.bundle.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-shadow.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-punk.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-noir.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-light.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-borderless.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/micromodal.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/sphinx_rtd_theme.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/custom.css"" type=""text/css"">
    <link rel=""canonical"" href=""https://docs.scrapy.org/en/latest/index.html"">
  <!--[if lt IE 9]>
    <script src=""https://docs.scrapy.org/en/latest/_static/js/html5shiv.min.js""></script>
  <![endif]-->
  
        <script data-url_root=""./"" id=""documentation_options"" src=""https://docs.scrapy.org/en/latest/_static/documentation_options.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/jquery.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/underscore.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/_sphinx_javascript_frameworks_compat.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/doctools.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/hoverxref.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/tooltipster.bundle.min.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/micromodal.min.js""></script>
        <script async=""async"" src=""https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js""></script>
        <script async=""async"" src=""https://docs.scrapy.org/_/static/javascript/readthedocs-doc-embed.js""></script>
    <script src=""https://docs.scrapy.org/en/latest/_static/js/theme.js""></script>
    <link rel=""index"" title=""Index"" href=""genindex.html"">
    <link rel=""search"" title=""Search"" href=""search.html"">
    <link rel=""next"" title=""Scrapy at a glance"" href=""intro/overview.html""> 

<!-- RTD Extra Head -->

<link rel=""stylesheet"" href=""https://docs.scrapy.org/_/static/css/readthedocs-doc-embed.css"" type=""text/css"">

<script type=""application/json"" id=""READTHEDOCS_DATA"">{""ad_free"": false, ""api_host"": ""https://readthedocs.org"", ""build_date"": ""2022-11-02T11:04:52Z"", ""builder"": ""sphinx"", ""canonical_url"": null, ""commit"": ""6ded3cf4"", ""docroot"": ""/docs/"", ""features"": {""docsearch_disabled"": false}, ""global_analytics_code"": ""UA-17997319-1"", ""language"": ""en"", ""page"": ""index"", ""programming_language"": ""py"", ""project"": ""scrapy"", ""proxied_api_host"": ""/_"", ""source_suffix"": "".rst"", ""subprojects"": {}, ""theme"": ""sphinx_rtd_theme"", ""user_analytics_code"": ""UA-10231918-2"", ""version"": ""latest""}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type=""text/javascript"">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type=""text/javascript"" src=""https://docs.scrapy.org/_/static/javascript/readthedocs-analytics.js"" async=""async""></script>

<!-- end RTD <extrahead> -->
</head>
",##,2,Built-in services,#built-in-services,,,5
https://docs.scrapy.org/en/latest/index.html,"<head>
  <meta charset=""utf-8""><meta name=""generator"" content=""Docutils 0.17.1: http://docutils.sourceforge.net/"">

  <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
  <title>Scrapy 2.7 documentation — Scrapy 2.7.1 documentation</title>
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/pygments.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/theme.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster.custom.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster.bundle.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-shadow.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-punk.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-noir.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-light.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-borderless.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/micromodal.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/sphinx_rtd_theme.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/custom.css"" type=""text/css"">
    <link rel=""canonical"" href=""https://docs.scrapy.org/en/latest/index.html"">
  <!--[if lt IE 9]>
    <script src=""https://docs.scrapy.org/en/latest/_static/js/html5shiv.min.js""></script>
  <![endif]-->
  
        <script data-url_root=""./"" id=""documentation_options"" src=""https://docs.scrapy.org/en/latest/_static/documentation_options.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/jquery.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/underscore.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/_sphinx_javascript_frameworks_compat.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/doctools.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/hoverxref.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/tooltipster.bundle.min.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/micromodal.min.js""></script>
        <script async=""async"" src=""https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js""></script>
        <script async=""async"" src=""https://docs.scrapy.org/_/static/javascript/readthedocs-doc-embed.js""></script>
    <script src=""https://docs.scrapy.org/en/latest/_static/js/theme.js""></script>
    <link rel=""index"" title=""Index"" href=""genindex.html"">
    <link rel=""search"" title=""Search"" href=""search.html"">
    <link rel=""next"" title=""Scrapy at a glance"" href=""intro/overview.html""> 

<!-- RTD Extra Head -->

<link rel=""stylesheet"" href=""https://docs.scrapy.org/_/static/css/readthedocs-doc-embed.css"" type=""text/css"">

<script type=""application/json"" id=""READTHEDOCS_DATA"">{""ad_free"": false, ""api_host"": ""https://readthedocs.org"", ""build_date"": ""2022-11-02T11:04:52Z"", ""builder"": ""sphinx"", ""canonical_url"": null, ""commit"": ""6ded3cf4"", ""docroot"": ""/docs/"", ""features"": {""docsearch_disabled"": false}, ""global_analytics_code"": ""UA-17997319-1"", ""language"": ""en"", ""page"": ""index"", ""programming_language"": ""py"", ""project"": ""scrapy"", ""proxied_api_host"": ""/_"", ""source_suffix"": "".rst"", ""subprojects"": {}, ""theme"": ""sphinx_rtd_theme"", ""user_analytics_code"": ""UA-10231918-2"", ""version"": ""latest""}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type=""text/javascript"">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type=""text/javascript"" src=""https://docs.scrapy.org/_/static/javascript/readthedocs-analytics.js"" async=""async""></script>

<!-- end RTD <extrahead> -->
</head>
",##,2,Solving specific problems,#solving-specific-problems,,,6
https://docs.scrapy.org/en/latest/index.html,"<head>
  <meta charset=""utf-8""><meta name=""generator"" content=""Docutils 0.17.1: http://docutils.sourceforge.net/"">

  <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
  <title>Scrapy 2.7 documentation — Scrapy 2.7.1 documentation</title>
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/pygments.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/theme.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster.custom.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster.bundle.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-shadow.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-punk.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-noir.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-light.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-borderless.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/micromodal.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/sphinx_rtd_theme.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/custom.css"" type=""text/css"">
    <link rel=""canonical"" href=""https://docs.scrapy.org/en/latest/index.html"">
  <!--[if lt IE 9]>
    <script src=""https://docs.scrapy.org/en/latest/_static/js/html5shiv.min.js""></script>
  <![endif]-->
  
        <script data-url_root=""./"" id=""documentation_options"" src=""https://docs.scrapy.org/en/latest/_static/documentation_options.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/jquery.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/underscore.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/_sphinx_javascript_frameworks_compat.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/doctools.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/hoverxref.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/tooltipster.bundle.min.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/micromodal.min.js""></script>
        <script async=""async"" src=""https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js""></script>
        <script async=""async"" src=""https://docs.scrapy.org/_/static/javascript/readthedocs-doc-embed.js""></script>
    <script src=""https://docs.scrapy.org/en/latest/_static/js/theme.js""></script>
    <link rel=""index"" title=""Index"" href=""genindex.html"">
    <link rel=""search"" title=""Search"" href=""search.html"">
    <link rel=""next"" title=""Scrapy at a glance"" href=""intro/overview.html""> 

<!-- RTD Extra Head -->

<link rel=""stylesheet"" href=""https://docs.scrapy.org/_/static/css/readthedocs-doc-embed.css"" type=""text/css"">

<script type=""application/json"" id=""READTHEDOCS_DATA"">{""ad_free"": false, ""api_host"": ""https://readthedocs.org"", ""build_date"": ""2022-11-02T11:04:52Z"", ""builder"": ""sphinx"", ""canonical_url"": null, ""commit"": ""6ded3cf4"", ""docroot"": ""/docs/"", ""features"": {""docsearch_disabled"": false}, ""global_analytics_code"": ""UA-17997319-1"", ""language"": ""en"", ""page"": ""index"", ""programming_language"": ""py"", ""project"": ""scrapy"", ""proxied_api_host"": ""/_"", ""source_suffix"": "".rst"", ""subprojects"": {}, ""theme"": ""sphinx_rtd_theme"", ""user_analytics_code"": ""UA-10231918-2"", ""version"": ""latest""}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type=""text/javascript"">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type=""text/javascript"" src=""https://docs.scrapy.org/_/static/javascript/readthedocs-analytics.js"" async=""async""></script>

<!-- end RTD <extrahead> -->
</head>
",##,2,Extending Scrapy,#extending-scrapy,,,7
https://docs.scrapy.org/en/latest/index.html,"<head>
  <meta charset=""utf-8""><meta name=""generator"" content=""Docutils 0.17.1: http://docutils.sourceforge.net/"">

  <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
  <title>Scrapy 2.7 documentation — Scrapy 2.7.1 documentation</title>
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/pygments.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/theme.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster.custom.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster.bundle.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-shadow.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-punk.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-noir.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-light.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/tooltipster-sideTip-borderless.min.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/micromodal.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/css/sphinx_rtd_theme.css"" type=""text/css"">
      <link rel=""stylesheet"" href=""https://docs.scrapy.org/en/latest/_static/custom.css"" type=""text/css"">
    <link rel=""canonical"" href=""https://docs.scrapy.org/en/latest/index.html"">
  <!--[if lt IE 9]>
    <script src=""https://docs.scrapy.org/en/latest/_static/js/html5shiv.min.js""></script>
  <![endif]-->
  
        <script data-url_root=""./"" id=""documentation_options"" src=""https://docs.scrapy.org/en/latest/_static/documentation_options.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/jquery.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/underscore.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/_sphinx_javascript_frameworks_compat.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/doctools.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/hoverxref.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/tooltipster.bundle.min.js""></script>
        <script src=""https://docs.scrapy.org/en/latest/_static/js/micromodal.min.js""></script>
        <script async=""async"" src=""https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js""></script>
        <script async=""async"" src=""https://docs.scrapy.org/_/static/javascript/readthedocs-doc-embed.js""></script>
    <script src=""https://docs.scrapy.org/en/latest/_static/js/theme.js""></script>
    <link rel=""index"" title=""Index"" href=""genindex.html"">
    <link rel=""search"" title=""Search"" href=""search.html"">
    <link rel=""next"" title=""Scrapy at a glance"" href=""intro/overview.html""> 

<!-- RTD Extra Head -->

<link rel=""stylesheet"" href=""https://docs.scrapy.org/_/static/css/readthedocs-doc-embed.css"" type=""text/css"">

<script type=""application/json"" id=""READTHEDOCS_DATA"">{""ad_free"": false, ""api_host"": ""https://readthedocs.org"", ""build_date"": ""2022-11-02T11:04:52Z"", ""builder"": ""sphinx"", ""canonical_url"": null, ""commit"": ""6ded3cf4"", ""docroot"": ""/docs/"", ""features"": {""docsearch_disabled"": false}, ""global_analytics_code"": ""UA-17997319-1"", ""language"": ""en"", ""page"": ""index"", ""programming_language"": ""py"", ""project"": ""scrapy"", ""proxied_api_host"": ""/_"", ""source_suffix"": "".rst"", ""subprojects"": {}, ""theme"": ""sphinx_rtd_theme"", ""user_analytics_code"": ""UA-10231918-2"", ""version"": ""latest""}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type=""text/javascript"">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type=""text/javascript"" src=""https://docs.scrapy.org/_/static/javascript/readthedocs-analytics.js"" async=""async""></script>

<!-- end RTD <extrahead> -->
</head>
",##,2,All the rest,#all-the-rest,,,8
https://docs.scrapy.org/en/latest/intro/overview.html,,#,1,Scrapy at a glance,#scrapy-at-a-glance,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'quotes'</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'https://quotes.toscrape.com/tag/humor/'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span>
                <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'span/small/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
            <span class=""p"">}</span>

        <span class=""n"">next_page</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a::attr(""href"")'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">if</span> <span class=""n"">next_page</span> <span class=""ow"">is</span> <span class=""ow"">not</span> <span class=""kc"">None</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">next_page</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">runspider</span> <span class=""n"">quotes_spider</span><span class=""o"">.</span><span class=""n"">py</span> <span class=""o"">-</span><span class=""n"">o</span> <span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">jsonl</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span><span class=""s2"">""author""</span><span class=""p"">:</span> <span class=""s2"">""Jane Austen""</span><span class=""p"">,</span> <span class=""s2"">""text""</span><span class=""p"">:</span> <span class=""s2"">""</span><span class=""se"">\u201c</span><span class=""s2"">The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.</span><span class=""se"">\u201d</span><span class=""s2"">""</span><span class=""p"">}</span>
<span class=""p"">{</span><span class=""s2"">""author""</span><span class=""p"">:</span> <span class=""s2"">""Steve Martin""</span><span class=""p"">,</span> <span class=""s2"">""text""</span><span class=""p"">:</span> <span class=""s2"">""</span><span class=""se"">\u201c</span><span class=""s2"">A day without sunshine is like, you know, night.</span><span class=""se"">\u201d</span><span class=""s2"">""</span><span class=""p"">}</span>
<span class=""p"">{</span><span class=""s2"">""author""</span><span class=""p"">:</span> <span class=""s2"">""Garrison Keillor""</span><span class=""p"">,</span> <span class=""s2"">""text""</span><span class=""p"">:</span> <span class=""s2"">""</span><span class=""se"">\u201c</span><span class=""s2"">Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.</span><span class=""se"">\u201d</span><span class=""s2"">""</span><span class=""p"">}</span>
<span class=""o"">...</span>
</pre></div>","import scrapy


class QuotesSpider(scrapy.Spider):
    name = 'quotes'
    start_urls = [
        'https://quotes.toscrape.com/tag/humor/',
    ]

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'author': quote.xpath('span/small/text()').get(),
                'text': quote.css('span.text::text').get(),
            }

        next_page = response.css('li.next a::attr(""href"")').get()
        if next_page is not None:
            yield response.follow(next_page, self.parse)
,scrapy runspider quotes_spider.py -o quotes.jsonl
,{""author"": ""Jane Austen"", ""text"": ""\u201cThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.\u201d""}
{""author"": ""Steve Martin"", ""text"": ""\u201cA day without sunshine is like, you know, night.\u201d""}
{""author"": ""Garrison Keillor"", ""text"": ""\u201cAnyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.\u201d""}
...
",3
https://docs.scrapy.org/en/latest/intro/overview.html,,##,2,Walk-through of an example spider,#walk-through-of-an-example-spider,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'quotes'</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'https://quotes.toscrape.com/tag/humor/'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span>
                <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'span/small/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
            <span class=""p"">}</span>

        <span class=""n"">next_page</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a::attr(""href"")'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">if</span> <span class=""n"">next_page</span> <span class=""ow"">is</span> <span class=""ow"">not</span> <span class=""kc"">None</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">next_page</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">runspider</span> <span class=""n"">quotes_spider</span><span class=""o"">.</span><span class=""n"">py</span> <span class=""o"">-</span><span class=""n"">o</span> <span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">jsonl</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span><span class=""s2"">""author""</span><span class=""p"">:</span> <span class=""s2"">""Jane Austen""</span><span class=""p"">,</span> <span class=""s2"">""text""</span><span class=""p"">:</span> <span class=""s2"">""</span><span class=""se"">\u201c</span><span class=""s2"">The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.</span><span class=""se"">\u201d</span><span class=""s2"">""</span><span class=""p"">}</span>
<span class=""p"">{</span><span class=""s2"">""author""</span><span class=""p"">:</span> <span class=""s2"">""Steve Martin""</span><span class=""p"">,</span> <span class=""s2"">""text""</span><span class=""p"">:</span> <span class=""s2"">""</span><span class=""se"">\u201c</span><span class=""s2"">A day without sunshine is like, you know, night.</span><span class=""se"">\u201d</span><span class=""s2"">""</span><span class=""p"">}</span>
<span class=""p"">{</span><span class=""s2"">""author""</span><span class=""p"">:</span> <span class=""s2"">""Garrison Keillor""</span><span class=""p"">,</span> <span class=""s2"">""text""</span><span class=""p"">:</span> <span class=""s2"">""</span><span class=""se"">\u201c</span><span class=""s2"">Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.</span><span class=""se"">\u201d</span><span class=""s2"">""</span><span class=""p"">}</span>
<span class=""o"">...</span>
</pre></div>","import scrapy


class QuotesSpider(scrapy.Spider):
    name = 'quotes'
    start_urls = [
        'https://quotes.toscrape.com/tag/humor/',
    ]

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'author': quote.xpath('span/small/text()').get(),
                'text': quote.css('span.text::text').get(),
            }

        next_page = response.css('li.next a::attr(""href"")').get()
        if next_page is not None:
            yield response.follow(next_page, self.parse)
,scrapy runspider quotes_spider.py -o quotes.jsonl
,{""author"": ""Jane Austen"", ""text"": ""\u201cThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.\u201d""}
{""author"": ""Steve Martin"", ""text"": ""\u201cA day without sunshine is like, you know, night.\u201d""}
{""author"": ""Garrison Keillor"", ""text"": ""\u201cAnyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.\u201d""}
...
",3
https://docs.scrapy.org/en/latest/intro/overview.html,,###,3,What just happened?,#what-just-happened,,,3
https://docs.scrapy.org/en/latest/intro/overview.html,,##,2,What else?,#what-else,,,4
https://docs.scrapy.org/en/latest/intro/overview.html,,##,2,What’s next?,#what-s-next,,,5
https://docs.scrapy.org/en/latest/intro/install.html,,#,1,Installation guide,#installation-guide,"<div class=""highlight""><pre><span></span><span class=""n"">conda</span> <span class=""n"">install</span> <span class=""o"">-</span><span class=""n"">c</span> <span class=""n"">conda</span><span class=""o"">-</span><span class=""n"">forge</span> <span class=""n"">scrapy</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">pip</span> <span class=""n"">install</span> <span class=""n"">Scrapy</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">conda</span> <span class=""n"">install</span> <span class=""o"">-</span><span class=""n"">c</span> <span class=""n"">conda</span><span class=""o"">-</span><span class=""n"">forge</span> <span class=""n"">scrapy</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sudo</span> <span class=""n"">apt</span><span class=""o"">-</span><span class=""n"">get</span> <span class=""n"">install</span> <span class=""n"">python3</span> <span class=""n"">python3</span><span class=""o"">-</span><span class=""n"">dev</span> <span class=""n"">python3</span><span class=""o"">-</span><span class=""n"">pip</span> <span class=""n"">libxml2</span><span class=""o"">-</span><span class=""n"">dev</span> <span class=""n"">libxslt1</span><span class=""o"">-</span><span class=""n"">dev</span> <span class=""n"">zlib1g</span><span class=""o"">-</span><span class=""n"">dev</span> <span class=""n"">libffi</span><span class=""o"">-</span><span class=""n"">dev</span> <span class=""n"">libssl</span><span class=""o"">-</span><span class=""n"">dev</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">pip</span> <span class=""n"">install</span> <span class=""n"">scrapy</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">xcode</span><span class=""o"">-</span><span class=""n"">select</span> <span class=""o"">--</span><span class=""n"">install</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">echo</span> <span class=""s2"">""export PATH=/usr/local/bin:/usr/local/sbin:$PATH""</span> <span class=""o"">&gt;&gt;</span> <span class=""o"">~/.</span><span class=""n"">bashrc</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">source</span> <span class=""o"">~/.</span><span class=""n"">bashrc</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">brew</span> <span class=""n"">install</span> <span class=""n"">python</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">brew</span> <span class=""n"">update</span><span class=""p"">;</span> <span class=""n"">brew</span> <span class=""n"">upgrade</span> <span class=""n"">python</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">pip</span> <span class=""n"">install</span> <span class=""n"">Scrapy</span>
</pre></div>,<div class=""highlight""><pre><span></span>[…]
  File ""[…]/site-packages/twisted/protocols/tls.py"", line 63, in &lt;module&gt;
    from twisted.internet._sslverify import _setAcceptableProtocols
  File ""[…]/site-packages/twisted/internet/_sslverify.py"", line 38, in &lt;module&gt;
    TLSVersion.TLSv1_1: SSL.OP_NO_TLSv1_1,
AttributeError: 'module' object has no attribute 'OP_NO_TLSv1_1'
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">pip</span> <span class=""n"">install</span> <span class=""n"">twisted</span><span class=""p"">[</span><span class=""n"">tls</span><span class=""p"">]</span>
</pre></div>","conda install -c conda-forge scrapy
,pip install Scrapy
,conda install -c conda-forge scrapy
,sudo apt-get install python3 python3-dev python3-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev
,pip install scrapy
,xcode-select --install
,echo ""export PATH=/usr/local/bin:/usr/local/sbin:$PATH"" >> ~/.bashrc
,source ~/.bashrc
,brew install python
,brew update; brew upgrade python
,pip install Scrapy
,[…]
  File ""[…]/site-packages/twisted/protocols/tls.py"", line 63, in <module>
    from twisted.internet._sslverify import _setAcceptableProtocols
  File ""[…]/site-packages/twisted/internet/_sslverify.py"", line 38, in <module>
    TLSVersion.TLSv1_1: SSL.OP_NO_TLSv1_1,
AttributeError: 'module' object has no attribute 'OP_NO_TLSv1_1'
,pip install twisted[tls]
",13
https://docs.scrapy.org/en/latest/intro/install.html,,##,2,Supported Python versions,#supported-python-versions,,,2
https://docs.scrapy.org/en/latest/intro/install.html,,##,2,Installing Scrapy,#installing-scrapy,"<div class=""highlight""><pre><span></span><span class=""n"">conda</span> <span class=""n"">install</span> <span class=""o"">-</span><span class=""n"">c</span> <span class=""n"">conda</span><span class=""o"">-</span><span class=""n"">forge</span> <span class=""n"">scrapy</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">pip</span> <span class=""n"">install</span> <span class=""n"">Scrapy</span>
</pre></div>","conda install -c conda-forge scrapy
,pip install Scrapy
",2
https://docs.scrapy.org/en/latest/intro/install.html,,###,3,Things that are good to know,#things-that-are-good-to-know,,,4
https://docs.scrapy.org/en/latest/intro/install.html,,###,3,Using a virtual environment (recommended),#using-a-virtual-environment-recommended,,,5
https://docs.scrapy.org/en/latest/intro/install.html,,##,2,Platform specific installation notes,#platform-specific-installation-notes,"<div class=""highlight""><pre><span></span><span class=""n"">conda</span> <span class=""n"">install</span> <span class=""o"">-</span><span class=""n"">c</span> <span class=""n"">conda</span><span class=""o"">-</span><span class=""n"">forge</span> <span class=""n"">scrapy</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sudo</span> <span class=""n"">apt</span><span class=""o"">-</span><span class=""n"">get</span> <span class=""n"">install</span> <span class=""n"">python3</span> <span class=""n"">python3</span><span class=""o"">-</span><span class=""n"">dev</span> <span class=""n"">python3</span><span class=""o"">-</span><span class=""n"">pip</span> <span class=""n"">libxml2</span><span class=""o"">-</span><span class=""n"">dev</span> <span class=""n"">libxslt1</span><span class=""o"">-</span><span class=""n"">dev</span> <span class=""n"">zlib1g</span><span class=""o"">-</span><span class=""n"">dev</span> <span class=""n"">libffi</span><span class=""o"">-</span><span class=""n"">dev</span> <span class=""n"">libssl</span><span class=""o"">-</span><span class=""n"">dev</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">pip</span> <span class=""n"">install</span> <span class=""n"">scrapy</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">xcode</span><span class=""o"">-</span><span class=""n"">select</span> <span class=""o"">--</span><span class=""n"">install</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">echo</span> <span class=""s2"">""export PATH=/usr/local/bin:/usr/local/sbin:$PATH""</span> <span class=""o"">&gt;&gt;</span> <span class=""o"">~/.</span><span class=""n"">bashrc</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">source</span> <span class=""o"">~/.</span><span class=""n"">bashrc</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">brew</span> <span class=""n"">install</span> <span class=""n"">python</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">brew</span> <span class=""n"">update</span><span class=""p"">;</span> <span class=""n"">brew</span> <span class=""n"">upgrade</span> <span class=""n"">python</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">pip</span> <span class=""n"">install</span> <span class=""n"">Scrapy</span>
</pre></div>","conda install -c conda-forge scrapy
,sudo apt-get install python3 python3-dev python3-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev
,pip install scrapy
,xcode-select --install
,echo ""export PATH=/usr/local/bin:/usr/local/sbin:$PATH"" >> ~/.bashrc
,source ~/.bashrc
,brew install python
,brew update; brew upgrade python
,pip install Scrapy
",9
https://docs.scrapy.org/en/latest/intro/install.html,,###,3,Windows,#windows,"<div class=""highlight""><pre><span></span><span class=""n"">conda</span> <span class=""n"">install</span> <span class=""o"">-</span><span class=""n"">c</span> <span class=""n"">conda</span><span class=""o"">-</span><span class=""n"">forge</span> <span class=""n"">scrapy</span>
</pre></div>","conda install -c conda-forge scrapy
",1
https://docs.scrapy.org/en/latest/intro/install.html,,###,3,Ubuntu 14.04 or above,#ubuntu-14-04-or-above,"<div class=""highlight""><pre><span></span><span class=""n"">sudo</span> <span class=""n"">apt</span><span class=""o"">-</span><span class=""n"">get</span> <span class=""n"">install</span> <span class=""n"">python3</span> <span class=""n"">python3</span><span class=""o"">-</span><span class=""n"">dev</span> <span class=""n"">python3</span><span class=""o"">-</span><span class=""n"">pip</span> <span class=""n"">libxml2</span><span class=""o"">-</span><span class=""n"">dev</span> <span class=""n"">libxslt1</span><span class=""o"">-</span><span class=""n"">dev</span> <span class=""n"">zlib1g</span><span class=""o"">-</span><span class=""n"">dev</span> <span class=""n"">libffi</span><span class=""o"">-</span><span class=""n"">dev</span> <span class=""n"">libssl</span><span class=""o"">-</span><span class=""n"">dev</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">pip</span> <span class=""n"">install</span> <span class=""n"">scrapy</span>
</pre></div>","sudo apt-get install python3 python3-dev python3-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev
,pip install scrapy
",2
https://docs.scrapy.org/en/latest/intro/install.html,,###,3,macOS,#macos,"<div class=""highlight""><pre><span></span><span class=""n"">xcode</span><span class=""o"">-</span><span class=""n"">select</span> <span class=""o"">--</span><span class=""n"">install</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">echo</span> <span class=""s2"">""export PATH=/usr/local/bin:/usr/local/sbin:$PATH""</span> <span class=""o"">&gt;&gt;</span> <span class=""o"">~/.</span><span class=""n"">bashrc</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">source</span> <span class=""o"">~/.</span><span class=""n"">bashrc</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">brew</span> <span class=""n"">install</span> <span class=""n"">python</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">brew</span> <span class=""n"">update</span><span class=""p"">;</span> <span class=""n"">brew</span> <span class=""n"">upgrade</span> <span class=""n"">python</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">pip</span> <span class=""n"">install</span> <span class=""n"">Scrapy</span>
</pre></div>","xcode-select --install
,echo ""export PATH=/usr/local/bin:/usr/local/sbin:$PATH"" >> ~/.bashrc
,source ~/.bashrc
,brew install python
,brew update; brew upgrade python
,pip install Scrapy
",6
https://docs.scrapy.org/en/latest/intro/install.html,,###,3,PyPy,#pypy,,,10
https://docs.scrapy.org/en/latest/intro/install.html,,##,2,Troubleshooting,#troubleshooting,"<div class=""highlight""><pre><span></span>[…]
  File ""[…]/site-packages/twisted/protocols/tls.py"", line 63, in &lt;module&gt;
    from twisted.internet._sslverify import _setAcceptableProtocols
  File ""[…]/site-packages/twisted/internet/_sslverify.py"", line 38, in &lt;module&gt;
    TLSVersion.TLSv1_1: SSL.OP_NO_TLSv1_1,
AttributeError: 'module' object has no attribute 'OP_NO_TLSv1_1'
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">pip</span> <span class=""n"">install</span> <span class=""n"">twisted</span><span class=""p"">[</span><span class=""n"">tls</span><span class=""p"">]</span>
</pre></div>","[…]
  File ""[…]/site-packages/twisted/protocols/tls.py"", line 63, in <module>
    from twisted.internet._sslverify import _setAcceptableProtocols
  File ""[…]/site-packages/twisted/internet/_sslverify.py"", line 38, in <module>
    TLSVersion.TLSv1_1: SSL.OP_NO_TLSv1_1,
AttributeError: 'module' object has no attribute 'OP_NO_TLSv1_1'
,pip install twisted[tls]
",2
https://docs.scrapy.org/en/latest/intro/install.html,,###,3,AttributeError: ‘module’ object has no attribute ‘OP_NO_TLSv1_1’,#attributeerror-module-object-has-no-attribute-op-no-tlsv1-1,"<div class=""highlight""><pre><span></span>[…]
  File ""[…]/site-packages/twisted/protocols/tls.py"", line 63, in &lt;module&gt;
    from twisted.internet._sslverify import _setAcceptableProtocols
  File ""[…]/site-packages/twisted/internet/_sslverify.py"", line 38, in &lt;module&gt;
    TLSVersion.TLSv1_1: SSL.OP_NO_TLSv1_1,
AttributeError: 'module' object has no attribute 'OP_NO_TLSv1_1'
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">pip</span> <span class=""n"">install</span> <span class=""n"">twisted</span><span class=""p"">[</span><span class=""n"">tls</span><span class=""p"">]</span>
</pre></div>","[…]
  File ""[…]/site-packages/twisted/protocols/tls.py"", line 63, in <module>
    from twisted.internet._sslverify import _setAcceptableProtocols
  File ""[…]/site-packages/twisted/internet/_sslverify.py"", line 38, in <module>
    TLSVersion.TLSv1_1: SSL.OP_NO_TLSv1_1,
AttributeError: 'module' object has no attribute 'OP_NO_TLSv1_1'
,pip install twisted[tls]
",2
https://docs.scrapy.org/en/latest/intro/tutorial.html,,#,1,Scrapy Tutorial,#scrapy-tutorial,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">startproject</span> <span class=""n"">tutorial</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tutorial</span><span class=""o"">/</span>
    <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">cfg</span>            <span class=""c1""># deploy configuration file</span>

    <span class=""n"">tutorial</span><span class=""o"">/</span>             <span class=""c1""># project's Python module, you'll import your code from here</span>
        <span class=""fm"">__init__</span><span class=""o"">.</span><span class=""n"">py</span>

        <span class=""n"">items</span><span class=""o"">.</span><span class=""n"">py</span>          <span class=""c1""># project items definition file</span>

        <span class=""n"">middlewares</span><span class=""o"">.</span><span class=""n"">py</span>    <span class=""c1""># project middlewares file</span>

        <span class=""n"">pipelines</span><span class=""o"">.</span><span class=""n"">py</span>      <span class=""c1""># project pipelines file</span>

        <span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">py</span>       <span class=""c1""># project settings file</span>

        <span class=""n"">spiders</span><span class=""o"">/</span>          <span class=""c1""># a directory where you'll later put your spiders</span>
            <span class=""fm"">__init__</span><span class=""o"">.</span><span class=""n"">py</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""quotes""</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""n"">urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
            <span class=""s1"">'https://quotes.toscrape.com/page/1/'</span><span class=""p"">,</span>
            <span class=""s1"">'https://quotes.toscrape.com/page/2/'</span><span class=""p"">,</span>
        <span class=""p"">]</span>
        <span class=""k"">for</span> <span class=""n"">url</span> <span class=""ow"">in</span> <span class=""n"">urls</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">page</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""o"">.</span><span class=""n"">split</span><span class=""p"">(</span><span class=""s2"">""/""</span><span class=""p"">)[</span><span class=""o"">-</span><span class=""mi"">2</span><span class=""p"">]</span>
        <span class=""n"">filename</span> <span class=""o"">=</span> <span class=""sa"">f</span><span class=""s1"">'quotes-</span><span class=""si"">{</span><span class=""n"">page</span><span class=""si"">}</span><span class=""s1"">.html'</span>
        <span class=""k"">with</span> <span class=""nb"">open</span><span class=""p"">(</span><span class=""n"">filename</span><span class=""p"">,</span> <span class=""s1"">'wb'</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">f</span><span class=""p"">:</span>
            <span class=""n"">f</span><span class=""o"">.</span><span class=""n"">write</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">body</span><span class=""p"">)</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">log</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s1"">'Saved file </span><span class=""si"">{</span><span class=""n"">filename</span><span class=""si"">}</span><span class=""s1"">'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">quotes</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">...</span> <span class=""p"">(</span><span class=""n"">omitted</span> <span class=""k"">for</span> <span class=""n"">brevity</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Spider</span> <span class=""n"">opened</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">logstats</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""mi"">0</span> <span class=""n"">pages</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">pages</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">),</span> <span class=""n"">scraped</span> <span class=""mi"">0</span> <span class=""n"">items</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">items</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">telnet</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Telnet</span> <span class=""n"">console</span> <span class=""n"">listening</span> <span class=""n"">on</span> <span class=""mf"">127.0.0.1</span><span class=""p"">:</span><span class=""mi"">6023</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">404</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">robots</span><span class=""o"">.</span><span class=""n"">txt</span><span class=""o"">&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">2</span><span class=""o"">/&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">quotes</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Saved</span> <span class=""n"">file</span> <span class=""n"">quotes</span><span class=""o"">-</span><span class=""mf"">1.</span><span class=""n"">html</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">quotes</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Saved</span> <span class=""n"">file</span> <span class=""n"">quotes</span><span class=""o"">-</span><span class=""mf"">2.</span><span class=""n"">html</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Closing</span> <span class=""n"">spider</span> <span class=""p"">(</span><span class=""n"">finished</span><span class=""p"">)</span>
<span class=""o"">...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""quotes""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/1/'</span><span class=""p"">,</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/2/'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">page</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""o"">.</span><span class=""n"">split</span><span class=""p"">(</span><span class=""s2"">""/""</span><span class=""p"">)[</span><span class=""o"">-</span><span class=""mi"">2</span><span class=""p"">]</span>
        <span class=""n"">filename</span> <span class=""o"">=</span> <span class=""sa"">f</span><span class=""s1"">'quotes-</span><span class=""si"">{</span><span class=""n"">page</span><span class=""si"">}</span><span class=""s1"">.html'</span>
        <span class=""k"">with</span> <span class=""nb"">open</span><span class=""p"">(</span><span class=""n"">filename</span><span class=""p"">,</span> <span class=""s1"">'wb'</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">f</span><span class=""p"">:</span>
            <span class=""n"">f</span><span class=""o"">.</span><span class=""n"">write</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">body</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""s1"">'https://quotes.toscrape.com/page/1/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""s2"">""https://quotes.toscrape.com/page/1/""</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">[</span> <span class=""o"">...</span> <span class=""n"">Scrapy</span> <span class=""n"">log</span> <span class=""n"">here</span> <span class=""o"">...</span> <span class=""p"">]</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">09</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">12</span><span class=""p"">:</span><span class=""mi"">09</span><span class=""p"">:</span><span class=""mi"">27</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span> <span class=""n"">Available</span> <span class=""n"">Scrapy</span> <span class=""n"">objects</span><span class=""p"">:</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">scrapy</span>     <span class=""n"">scrapy</span> <span class=""n"">module</span> <span class=""p"">(</span><span class=""n"">contains</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">,</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Selector</span><span class=""p"">,</span> <span class=""n"">etc</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">crawler</span>    <span class=""o"">&lt;</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">Crawler</span> <span class=""nb"">object</span> <span class=""n"">at</span> <span class=""mh"">0x7fa91d888c90</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">item</span>       <span class=""p"">{}</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">request</span>    <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">response</span>   <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">settings</span>   <span class=""o"">&lt;</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">Settings</span> <span class=""nb"">object</span> <span class=""n"">at</span> <span class=""mh"">0x7fa91d888c10</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">spider</span>     <span class=""o"">&lt;</span><span class=""n"">DefaultSpider</span> <span class=""s1"">'default'</span> <span class=""n"">at</span> <span class=""mh"">0x7fa91c8af990</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span> <span class=""n"">Useful</span> <span class=""n"">shortcuts</span><span class=""p"">:</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">shelp</span><span class=""p"">()</span>           <span class=""n"">Shell</span> <span class=""n"">help</span> <span class=""p"">(</span><span class=""nb"">print</span> <span class=""n"">this</span> <span class=""n"">help</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">fetch</span><span class=""p"">(</span><span class=""n"">req_or_url</span><span class=""p"">)</span> <span class=""n"">Fetch</span> <span class=""n"">request</span> <span class=""p"">(</span><span class=""ow"">or</span> <span class=""n"">URL</span><span class=""p"">)</span> <span class=""ow"">and</span> <span class=""n"">update</span> <span class=""n"">local</span> <span class=""n"">objects</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">view</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">)</span>    <span class=""n"">View</span> <span class=""n"">response</span> <span class=""ow"">in</span> <span class=""n"">a</span> <span class=""n"">browser</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title'</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='descendant-or-self::title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['Quotes to Scrape']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['&lt;title&gt;Quotes to Scrape&lt;/title&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Quotes to Scrape'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Quotes to Scrape'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'noelement'</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gt"">Traceback (most recent call last):</span>
<span class=""c"">...</span>
<span class=""gr"">IndexError</span>: <span class=""n"">list index out of range</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""noelement""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'Quotes.*'</span><span class=""p"">)</span>
<span class=""go"">['Quotes to Scrape']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'Q\w+'</span><span class=""p"">)</span>
<span class=""go"">['Quotes']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'(\w+) to (\w+)'</span><span class=""p"">)</span>
<span class=""go"">['Quotes', 'Scrape']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title'</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='//title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Quotes to Scrape'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""quote""</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">span</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""text""</span><span class=""p"">&gt;</span>“The world as we have created it is a process of our
    thinking. It cannot be changed without changing our thinking.”<span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
        by <span class=""p"">&lt;</span><span class=""nt"">small</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""author""</span><span class=""p"">&gt;</span>Albert Einstein<span class=""p"">&lt;/</span><span class=""nt"">small</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/author/Albert-Einstein""</span><span class=""p"">&gt;</span>(about)<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tags""</span><span class=""p"">&gt;</span>
        Tags:
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tag""</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/tag/change/page/1/""</span><span class=""p"">&gt;</span>change<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tag""</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/tag/deep-thoughts/page/1/""</span><span class=""p"">&gt;</span>deep-thoughts<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tag""</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/tag/thinking/page/1/""</span><span class=""p"">&gt;</span>thinking<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tag""</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/tag/world/page/1/""</span><span class=""p"">&gt;</span>world<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""s1"">'https://quotes.toscrape.com'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.quote""</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath=""descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"" data='&lt;div class=""quote"" itemscope itemtype...'&gt;,</span>
<span class=""go""> &lt;Selector xpath=""descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"" data='&lt;div class=""quote"" itemscope itemtype...'&gt;,</span>
<span class=""go""> ...]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">quote</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.quote""</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">text</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""span.text::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">text</span>
<span class=""go"">'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">author</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""small.author::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">author</span>
<span class=""go"">'Albert Einstein'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">tags</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.tags a.tag::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">tags</span>
<span class=""go"">['change', 'deep-thoughts', 'thinking', 'world']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.quote""</span><span class=""p"">):</span>
<span class=""gp"">... </span>    <span class=""n"">text</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""span.text::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""n"">author</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""small.author::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""n"">tags</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.tags a.tag::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">text</span><span class=""p"">,</span> <span class=""n"">author</span><span class=""o"">=</span><span class=""n"">author</span><span class=""p"">,</span> <span class=""n"">tags</span><span class=""o"">=</span><span class=""n"">tags</span><span class=""p"">))</span>
<span class=""go"">{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}</span>
<span class=""go"">{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}</span>
<span class=""gp"">...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""quotes""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/1/'</span><span class=""p"">,</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/2/'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span>
                <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'small.author::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'tags'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.tags a.tag::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">(),</span>
            <span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">09</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">57</span><span class=""p"">:</span><span class=""mi"">19</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">scraper</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Scraped</span> <span class=""kn"">from</span> <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span>
<span class=""p"">{</span><span class=""s1"">'tags'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""s1"">'life'</span><span class=""p"">,</span> <span class=""s1"">'love'</span><span class=""p"">],</span> <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""s1"">'André Gide'</span><span class=""p"">,</span> <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""s1"">'“It is better to be hated for what you are than to be loved for what you are not.”'</span><span class=""p"">}</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">09</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">57</span><span class=""p"">:</span><span class=""mi"">19</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">scraper</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Scraped</span> <span class=""kn"">from</span> <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span>
<span class=""p"">{</span><span class=""s1"">'tags'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""s1"">'edison'</span><span class=""p"">,</span> <span class=""s1"">'failure'</span><span class=""p"">,</span> <span class=""s1"">'inspirational'</span><span class=""p"">,</span> <span class=""s1"">'paraphrased'</span><span class=""p"">],</span> <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""s1"">'Thomas A. Edison'</span><span class=""p"">,</span> <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""s2"">""“I have not failed. I've just found 10,000 ways that won't work.”""</span><span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">quotes</span> <span class=""o"">-</span><span class=""n"">O</span> <span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">json</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">quotes</span> <span class=""o"">-</span><span class=""n"">o</span> <span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">jsonl</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">&lt;</span><span class=""nt"">ul</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""pager""</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">li</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""next""</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/page/2/""</span><span class=""p"">&gt;</span>Next <span class=""p"">&lt;</span><span class=""nt"">span</span> <span class=""na"">aria-hidden</span><span class=""o"">=</span><span class=""s"">""true""</span><span class=""p"">&gt;</span><span class=""ni"">&amp;rarr;</span><span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;/</span><span class=""nt"">li</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;/</span><span class=""nt"">ul</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'&lt;a href=""/page/2/""&gt;Next &lt;span aria-hidden=""true""&gt;→&lt;/span&gt;&lt;/a&gt;'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'/page/2/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'href'</span><span class=""p"">]</span>
<span class=""go"">'/page/2/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""quotes""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/1/'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span>
                <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'small.author::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'tags'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.tags a.tag::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">(),</span>
            <span class=""p"">}</span>

        <span class=""n"">next_page</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">if</span> <span class=""n"">next_page</span> <span class=""ow"">is</span> <span class=""ow"">not</span> <span class=""kc"">None</span><span class=""p"">:</span>
            <span class=""n"">next_page</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">urljoin</span><span class=""p"">(</span><span class=""n"">next_page</span><span class=""p"">)</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">next_page</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""quotes""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/1/'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span>
                <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span small::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'tags'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.tags a.tag::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">(),</span>
            <span class=""p"">}</span>

        <span class=""n"">next_page</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">if</span> <span class=""n"">next_page</span> <span class=""ow"">is</span> <span class=""ow"">not</span> <span class=""kc"">None</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">next_page</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">href</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'ul.pager a::attr(href)'</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">href</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">a</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'ul.pager a'</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">a</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">anchors</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'ul.pager a'</span><span class=""p"">)</span>
<span class=""k"">yield from</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow_all</span><span class=""p"">(</span><span class=""n"">anchors</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">yield from</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow_all</span><span class=""p"">(</span><span class=""n"">css</span><span class=""o"">=</span><span class=""s1"">'ul.pager a'</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">AuthorSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'author'</span>

    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://quotes.toscrape.com/'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">author_page_links</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'.author + a'</span><span class=""p"">)</span>
        <span class=""k"">yield from</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow_all</span><span class=""p"">(</span><span class=""n"">author_page_links</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_author</span><span class=""p"">)</span>

        <span class=""n"">pagination_links</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a'</span><span class=""p"">)</span>
        <span class=""k"">yield from</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow_all</span><span class=""p"">(</span><span class=""n"">pagination_links</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse_author</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">def</span> <span class=""nf"">extract_with_css</span><span class=""p"">(</span><span class=""n"">query</span><span class=""p"">):</span>
            <span class=""k"">return</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""n"">query</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""n"">default</span><span class=""o"">=</span><span class=""s1"">''</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">strip</span><span class=""p"">()</span>

        <span class=""k"">yield</span> <span class=""p"">{</span>
            <span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""n"">extract_with_css</span><span class=""p"">(</span><span class=""s1"">'h3.author-title::text'</span><span class=""p"">),</span>
            <span class=""s1"">'birthdate'</span><span class=""p"">:</span> <span class=""n"">extract_with_css</span><span class=""p"">(</span><span class=""s1"">'.author-born-date::text'</span><span class=""p"">),</span>
            <span class=""s1"">'bio'</span><span class=""p"">:</span> <span class=""n"">extract_with_css</span><span class=""p"">(</span><span class=""s1"">'.author-description::text'</span><span class=""p"">),</span>
        <span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">quotes</span> <span class=""o"">-</span><span class=""n"">O</span> <span class=""n"">quotes</span><span class=""o"">-</span><span class=""n"">humor</span><span class=""o"">.</span><span class=""n"">json</span> <span class=""o"">-</span><span class=""n"">a</span> <span class=""n"">tag</span><span class=""o"">=</span><span class=""n"">humor</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""quotes""</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""n"">url</span> <span class=""o"">=</span> <span class=""s1"">'https://quotes.toscrape.com/'</span>
        <span class=""n"">tag</span> <span class=""o"">=</span> <span class=""nb"">getattr</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""s1"">'tag'</span><span class=""p"">,</span> <span class=""kc"">None</span><span class=""p"">)</span>
        <span class=""k"">if</span> <span class=""n"">tag</span> <span class=""ow"">is</span> <span class=""ow"">not</span> <span class=""kc"">None</span><span class=""p"">:</span>
            <span class=""n"">url</span> <span class=""o"">=</span> <span class=""n"">url</span> <span class=""o"">+</span> <span class=""s1"">'tag/'</span> <span class=""o"">+</span> <span class=""n"">tag</span>
        <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span>
                <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'small.author::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
            <span class=""p"">}</span>

        <span class=""n"">next_page</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">if</span> <span class=""n"">next_page</span> <span class=""ow"">is</span> <span class=""ow"">not</span> <span class=""kc"">None</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">next_page</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>","scrapy startproject tutorial
,tutorial/
    scrapy.cfg            # deploy configuration file

    tutorial/             # project's Python module, you'll import your code from here
        __init__.py

        items.py          # project items definition file

        middlewares.py    # project middlewares file

        pipelines.py      # project pipelines file

        settings.py       # project settings file

        spiders/          # a directory where you'll later put your spiders
            __init__.py
,import scrapy


class QuotesSpider(scrapy.Spider):
    name = ""quotes""

    def start_requests(self):
        urls = [
            'https://quotes.toscrape.com/page/1/',
            'https://quotes.toscrape.com/page/2/',
        ]
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)

    def parse(self, response):
        page = response.url.split(""/"")[-2]
        filename = f'quotes-{page}.html'
        with open(filename, 'wb') as f:
            f.write(response.body)
        self.log(f'Saved file {filename}')
,scrapy crawl quotes
,... (omitted for brevity)
2016-12-16 21:24:05 [scrapy.core.engine] INFO: Spider opened
2016-12-16 21:24:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-16 21:24:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://quotes.toscrape.com/robots.txt> (referer: None)
2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/1/> (referer: None)
2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/2/> (referer: None)
2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-1.html
2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-2.html
2016-12-16 21:24:05 [scrapy.core.engine] INFO: Closing spider (finished)
...
,import scrapy


class QuotesSpider(scrapy.Spider):
    name = ""quotes""
    start_urls = [
        'https://quotes.toscrape.com/page/1/',
        'https://quotes.toscrape.com/page/2/',
    ]

    def parse(self, response):
        page = response.url.split(""/"")[-2]
        filename = f'quotes-{page}.html'
        with open(filename, 'wb') as f:
            f.write(response.body)
,scrapy shell 'https://quotes.toscrape.com/page/1/'
,scrapy shell ""https://quotes.toscrape.com/page/1/""
,[ ... Scrapy log here ... ]
2016-09-19 12:09:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/1/> (referer: None)
[s] Available Scrapy objects:
[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)
[s]   crawler    <scrapy.crawler.Crawler object at 0x7fa91d888c90>
[s]   item       {}
[s]   request    <GET https://quotes.toscrape.com/page/1/>
[s]   response   <200 https://quotes.toscrape.com/page/1/>
[s]   settings   <scrapy.settings.Settings object at 0x7fa91d888c10>
[s]   spider     <DefaultSpider 'default' at 0x7fa91c8af990>
[s] Useful shortcuts:
[s]   shelp()           Shell help (print this help)
[s]   fetch(req_or_url) Fetch request (or URL) and update local objects
[s]   view(response)    View response in a browser
,>>> response.css('title')
[<Selector xpath='descendant-or-self::title' data='<title>Quotes to Scrape</title>'>]
,>>> response.css('title::text').getall()
['Quotes to Scrape']
,>>> response.css('title').getall()
['<title>Quotes to Scrape</title>']
,>>> response.css('title::text').get()
'Quotes to Scrape'
,>>> response.css('title::text')[0].get()
'Quotes to Scrape'
,>>> response.css('noelement')[0].get()
Traceback (most recent call last):
...
IndexError: list index out of range
,>>> response.css(""noelement"").get()
,>>> response.css('title::text').re(r'Quotes.*')
['Quotes to Scrape']
>>> response.css('title::text').re(r'Q\w+')
['Quotes']
>>> response.css('title::text').re(r'(\w+) to (\w+)')
['Quotes', 'Scrape']
,>>> response.xpath('//title')
[<Selector xpath='//title' data='<title>Quotes to Scrape</title>'>]
>>> response.xpath('//title/text()').get()
'Quotes to Scrape'
,<div class=""quote"">
    <span class=""text"">“The world as we have created it is a process of our
    thinking. It cannot be changed without changing our thinking.”</span>
    <span>
        by <small class=""author"">Albert Einstein</small>
        <a href=""/author/Albert-Einstein"">(about)</a>
    </span>
    <div class=""tags"">
        Tags:
        <a class=""tag"" href=""/tag/change/page/1/"">change</a>
        <a class=""tag"" href=""/tag/deep-thoughts/page/1/"">deep-thoughts</a>
        <a class=""tag"" href=""/tag/thinking/page/1/"">thinking</a>
        <a class=""tag"" href=""/tag/world/page/1/"">world</a>
    </div>
</div>
,scrapy shell 'https://quotes.toscrape.com'
,>>> response.css(""div.quote"")
[<Selector xpath=""descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"" data='<div class=""quote"" itemscope itemtype...'>,
 <Selector xpath=""descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"" data='<div class=""quote"" itemscope itemtype...'>,
 ...]
,>>> quote = response.css(""div.quote"")[0]
,>>> text = quote.css(""span.text::text"").get()
>>> text
'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'
>>> author = quote.css(""small.author::text"").get()
>>> author
'Albert Einstein'
,>>> tags = quote.css(""div.tags a.tag::text"").getall()
>>> tags
['change', 'deep-thoughts', 'thinking', 'world']
,>>> for quote in response.css(""div.quote""):
...     text = quote.css(""span.text::text"").get()
...     author = quote.css(""small.author::text"").get()
...     tags = quote.css(""div.tags a.tag::text"").getall()
...     print(dict(text=text, author=author, tags=tags))
{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}
{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}
...
,import scrapy


class QuotesSpider(scrapy.Spider):
    name = ""quotes""
    start_urls = [
        'https://quotes.toscrape.com/page/1/',
        'https://quotes.toscrape.com/page/2/',
    ]

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('small.author::text').get(),
                'tags': quote.css('div.tags a.tag::text').getall(),
            }
,2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>
{'tags': ['life', 'love'], 'author': 'André Gide', 'text': '“It is better to be hated for what you are than to be loved for what you are not.”'}
2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>
{'tags': ['edison', 'failure', 'inspirational', 'paraphrased'], 'author': 'Thomas A. Edison', 'text': ""“I have not failed. I've just found 10,000 ways that won't work.”""}
,scrapy crawl quotes -O quotes.json
,scrapy crawl quotes -o quotes.jsonl
,<ul class=""pager"">
    <li class=""next"">
        <a href=""/page/2/"">Next <span aria-hidden=""true"">→</span></a>
    </li>
</ul>
,>>> response.css('li.next a').get()
'<a href=""/page/2/"">Next <span aria-hidden=""true"">→</span></a>'
,>>> response.css('li.next a::attr(href)').get()
'/page/2/'
,>>> response.css('li.next a').attrib['href']
'/page/2/'
,import scrapy


class QuotesSpider(scrapy.Spider):
    name = ""quotes""
    start_urls = [
        'https://quotes.toscrape.com/page/1/',
    ]

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('small.author::text').get(),
                'tags': quote.css('div.tags a.tag::text').getall(),
            }

        next_page = response.css('li.next a::attr(href)').get()
        if next_page is not None:
            next_page = response.urljoin(next_page)
            yield scrapy.Request(next_page, callback=self.parse)
,import scrapy


class QuotesSpider(scrapy.Spider):
    name = ""quotes""
    start_urls = [
        'https://quotes.toscrape.com/page/1/',
    ]

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('span small::text').get(),
                'tags': quote.css('div.tags a.tag::text').getall(),
            }

        next_page = response.css('li.next a::attr(href)').get()
        if next_page is not None:
            yield response.follow(next_page, callback=self.parse)
,for href in response.css('ul.pager a::attr(href)'):
    yield response.follow(href, callback=self.parse)
,for a in response.css('ul.pager a'):
    yield response.follow(a, callback=self.parse)
,anchors = response.css('ul.pager a')
yield from response.follow_all(anchors, callback=self.parse)
,yield from response.follow_all(css='ul.pager a', callback=self.parse)
,import scrapy


class AuthorSpider(scrapy.Spider):
    name = 'author'

    start_urls = ['https://quotes.toscrape.com/']

    def parse(self, response):
        author_page_links = response.css('.author + a')
        yield from response.follow_all(author_page_links, self.parse_author)

        pagination_links = response.css('li.next a')
        yield from response.follow_all(pagination_links, self.parse)

    def parse_author(self, response):
        def extract_with_css(query):
            return response.css(query).get(default='').strip()

        yield {
            'name': extract_with_css('h3.author-title::text'),
            'birthdate': extract_with_css('.author-born-date::text'),
            'bio': extract_with_css('.author-description::text'),
        }
,scrapy crawl quotes -O quotes-humor.json -a tag=humor
,import scrapy


class QuotesSpider(scrapy.Spider):
    name = ""quotes""

    def start_requests(self):
        url = 'https://quotes.toscrape.com/'
        tag = getattr(self, 'tag', None)
        if tag is not None:
            url = url + 'tag/' + tag
        yield scrapy.Request(url, self.parse)

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('small.author::text').get(),
            }

        next_page = response.css('li.next a::attr(href)').get()
        if next_page is not None:
            yield response.follow(next_page, self.parse)
",42
https://docs.scrapy.org/en/latest/intro/tutorial.html,,##,2,Creating a project,#creating-a-project,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">startproject</span> <span class=""n"">tutorial</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tutorial</span><span class=""o"">/</span>
    <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">cfg</span>            <span class=""c1""># deploy configuration file</span>

    <span class=""n"">tutorial</span><span class=""o"">/</span>             <span class=""c1""># project's Python module, you'll import your code from here</span>
        <span class=""fm"">__init__</span><span class=""o"">.</span><span class=""n"">py</span>

        <span class=""n"">items</span><span class=""o"">.</span><span class=""n"">py</span>          <span class=""c1""># project items definition file</span>

        <span class=""n"">middlewares</span><span class=""o"">.</span><span class=""n"">py</span>    <span class=""c1""># project middlewares file</span>

        <span class=""n"">pipelines</span><span class=""o"">.</span><span class=""n"">py</span>      <span class=""c1""># project pipelines file</span>

        <span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">py</span>       <span class=""c1""># project settings file</span>

        <span class=""n"">spiders</span><span class=""o"">/</span>          <span class=""c1""># a directory where you'll later put your spiders</span>
            <span class=""fm"">__init__</span><span class=""o"">.</span><span class=""n"">py</span>
</pre></div>","scrapy startproject tutorial
,tutorial/
    scrapy.cfg            # deploy configuration file

    tutorial/             # project's Python module, you'll import your code from here
        __init__.py

        items.py          # project items definition file

        middlewares.py    # project middlewares file

        pipelines.py      # project pipelines file

        settings.py       # project settings file

        spiders/          # a directory where you'll later put your spiders
            __init__.py
",2
https://docs.scrapy.org/en/latest/intro/tutorial.html,,##,2,Our first Spider,#our-first-spider,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""quotes""</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""n"">urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
            <span class=""s1"">'https://quotes.toscrape.com/page/1/'</span><span class=""p"">,</span>
            <span class=""s1"">'https://quotes.toscrape.com/page/2/'</span><span class=""p"">,</span>
        <span class=""p"">]</span>
        <span class=""k"">for</span> <span class=""n"">url</span> <span class=""ow"">in</span> <span class=""n"">urls</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">page</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""o"">.</span><span class=""n"">split</span><span class=""p"">(</span><span class=""s2"">""/""</span><span class=""p"">)[</span><span class=""o"">-</span><span class=""mi"">2</span><span class=""p"">]</span>
        <span class=""n"">filename</span> <span class=""o"">=</span> <span class=""sa"">f</span><span class=""s1"">'quotes-</span><span class=""si"">{</span><span class=""n"">page</span><span class=""si"">}</span><span class=""s1"">.html'</span>
        <span class=""k"">with</span> <span class=""nb"">open</span><span class=""p"">(</span><span class=""n"">filename</span><span class=""p"">,</span> <span class=""s1"">'wb'</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">f</span><span class=""p"">:</span>
            <span class=""n"">f</span><span class=""o"">.</span><span class=""n"">write</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">body</span><span class=""p"">)</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">log</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s1"">'Saved file </span><span class=""si"">{</span><span class=""n"">filename</span><span class=""si"">}</span><span class=""s1"">'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">quotes</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">...</span> <span class=""p"">(</span><span class=""n"">omitted</span> <span class=""k"">for</span> <span class=""n"">brevity</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Spider</span> <span class=""n"">opened</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">logstats</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""mi"">0</span> <span class=""n"">pages</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">pages</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">),</span> <span class=""n"">scraped</span> <span class=""mi"">0</span> <span class=""n"">items</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">items</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">telnet</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Telnet</span> <span class=""n"">console</span> <span class=""n"">listening</span> <span class=""n"">on</span> <span class=""mf"">127.0.0.1</span><span class=""p"">:</span><span class=""mi"">6023</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">404</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">robots</span><span class=""o"">.</span><span class=""n"">txt</span><span class=""o"">&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">2</span><span class=""o"">/&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">quotes</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Saved</span> <span class=""n"">file</span> <span class=""n"">quotes</span><span class=""o"">-</span><span class=""mf"">1.</span><span class=""n"">html</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">quotes</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Saved</span> <span class=""n"">file</span> <span class=""n"">quotes</span><span class=""o"">-</span><span class=""mf"">2.</span><span class=""n"">html</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Closing</span> <span class=""n"">spider</span> <span class=""p"">(</span><span class=""n"">finished</span><span class=""p"">)</span>
<span class=""o"">...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""quotes""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/1/'</span><span class=""p"">,</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/2/'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">page</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""o"">.</span><span class=""n"">split</span><span class=""p"">(</span><span class=""s2"">""/""</span><span class=""p"">)[</span><span class=""o"">-</span><span class=""mi"">2</span><span class=""p"">]</span>
        <span class=""n"">filename</span> <span class=""o"">=</span> <span class=""sa"">f</span><span class=""s1"">'quotes-</span><span class=""si"">{</span><span class=""n"">page</span><span class=""si"">}</span><span class=""s1"">.html'</span>
        <span class=""k"">with</span> <span class=""nb"">open</span><span class=""p"">(</span><span class=""n"">filename</span><span class=""p"">,</span> <span class=""s1"">'wb'</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">f</span><span class=""p"">:</span>
            <span class=""n"">f</span><span class=""o"">.</span><span class=""n"">write</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">body</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""s1"">'https://quotes.toscrape.com/page/1/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""s2"">""https://quotes.toscrape.com/page/1/""</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">[</span> <span class=""o"">...</span> <span class=""n"">Scrapy</span> <span class=""n"">log</span> <span class=""n"">here</span> <span class=""o"">...</span> <span class=""p"">]</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">09</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">12</span><span class=""p"">:</span><span class=""mi"">09</span><span class=""p"">:</span><span class=""mi"">27</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span> <span class=""n"">Available</span> <span class=""n"">Scrapy</span> <span class=""n"">objects</span><span class=""p"">:</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">scrapy</span>     <span class=""n"">scrapy</span> <span class=""n"">module</span> <span class=""p"">(</span><span class=""n"">contains</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">,</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Selector</span><span class=""p"">,</span> <span class=""n"">etc</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">crawler</span>    <span class=""o"">&lt;</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">Crawler</span> <span class=""nb"">object</span> <span class=""n"">at</span> <span class=""mh"">0x7fa91d888c90</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">item</span>       <span class=""p"">{}</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">request</span>    <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">response</span>   <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">settings</span>   <span class=""o"">&lt;</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">Settings</span> <span class=""nb"">object</span> <span class=""n"">at</span> <span class=""mh"">0x7fa91d888c10</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">spider</span>     <span class=""o"">&lt;</span><span class=""n"">DefaultSpider</span> <span class=""s1"">'default'</span> <span class=""n"">at</span> <span class=""mh"">0x7fa91c8af990</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span> <span class=""n"">Useful</span> <span class=""n"">shortcuts</span><span class=""p"">:</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">shelp</span><span class=""p"">()</span>           <span class=""n"">Shell</span> <span class=""n"">help</span> <span class=""p"">(</span><span class=""nb"">print</span> <span class=""n"">this</span> <span class=""n"">help</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">fetch</span><span class=""p"">(</span><span class=""n"">req_or_url</span><span class=""p"">)</span> <span class=""n"">Fetch</span> <span class=""n"">request</span> <span class=""p"">(</span><span class=""ow"">or</span> <span class=""n"">URL</span><span class=""p"">)</span> <span class=""ow"">and</span> <span class=""n"">update</span> <span class=""n"">local</span> <span class=""n"">objects</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">view</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">)</span>    <span class=""n"">View</span> <span class=""n"">response</span> <span class=""ow"">in</span> <span class=""n"">a</span> <span class=""n"">browser</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title'</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='descendant-or-self::title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['Quotes to Scrape']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['&lt;title&gt;Quotes to Scrape&lt;/title&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Quotes to Scrape'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Quotes to Scrape'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'noelement'</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gt"">Traceback (most recent call last):</span>
<span class=""c"">...</span>
<span class=""gr"">IndexError</span>: <span class=""n"">list index out of range</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""noelement""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'Quotes.*'</span><span class=""p"">)</span>
<span class=""go"">['Quotes to Scrape']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'Q\w+'</span><span class=""p"">)</span>
<span class=""go"">['Quotes']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'(\w+) to (\w+)'</span><span class=""p"">)</span>
<span class=""go"">['Quotes', 'Scrape']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title'</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='//title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Quotes to Scrape'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""quote""</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">span</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""text""</span><span class=""p"">&gt;</span>“The world as we have created it is a process of our
    thinking. It cannot be changed without changing our thinking.”<span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
        by <span class=""p"">&lt;</span><span class=""nt"">small</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""author""</span><span class=""p"">&gt;</span>Albert Einstein<span class=""p"">&lt;/</span><span class=""nt"">small</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/author/Albert-Einstein""</span><span class=""p"">&gt;</span>(about)<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tags""</span><span class=""p"">&gt;</span>
        Tags:
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tag""</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/tag/change/page/1/""</span><span class=""p"">&gt;</span>change<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tag""</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/tag/deep-thoughts/page/1/""</span><span class=""p"">&gt;</span>deep-thoughts<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tag""</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/tag/thinking/page/1/""</span><span class=""p"">&gt;</span>thinking<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tag""</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/tag/world/page/1/""</span><span class=""p"">&gt;</span>world<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""s1"">'https://quotes.toscrape.com'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.quote""</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath=""descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"" data='&lt;div class=""quote"" itemscope itemtype...'&gt;,</span>
<span class=""go""> &lt;Selector xpath=""descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"" data='&lt;div class=""quote"" itemscope itemtype...'&gt;,</span>
<span class=""go""> ...]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">quote</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.quote""</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">text</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""span.text::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">text</span>
<span class=""go"">'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">author</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""small.author::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">author</span>
<span class=""go"">'Albert Einstein'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">tags</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.tags a.tag::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">tags</span>
<span class=""go"">['change', 'deep-thoughts', 'thinking', 'world']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.quote""</span><span class=""p"">):</span>
<span class=""gp"">... </span>    <span class=""n"">text</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""span.text::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""n"">author</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""small.author::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""n"">tags</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.tags a.tag::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">text</span><span class=""p"">,</span> <span class=""n"">author</span><span class=""o"">=</span><span class=""n"">author</span><span class=""p"">,</span> <span class=""n"">tags</span><span class=""o"">=</span><span class=""n"">tags</span><span class=""p"">))</span>
<span class=""go"">{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}</span>
<span class=""go"">{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}</span>
<span class=""gp"">...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""quotes""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/1/'</span><span class=""p"">,</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/2/'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span>
                <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'small.author::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'tags'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.tags a.tag::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">(),</span>
            <span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">09</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">57</span><span class=""p"">:</span><span class=""mi"">19</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">scraper</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Scraped</span> <span class=""kn"">from</span> <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span>
<span class=""p"">{</span><span class=""s1"">'tags'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""s1"">'life'</span><span class=""p"">,</span> <span class=""s1"">'love'</span><span class=""p"">],</span> <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""s1"">'André Gide'</span><span class=""p"">,</span> <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""s1"">'“It is better to be hated for what you are than to be loved for what you are not.”'</span><span class=""p"">}</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">09</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">57</span><span class=""p"">:</span><span class=""mi"">19</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">scraper</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Scraped</span> <span class=""kn"">from</span> <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span>
<span class=""p"">{</span><span class=""s1"">'tags'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""s1"">'edison'</span><span class=""p"">,</span> <span class=""s1"">'failure'</span><span class=""p"">,</span> <span class=""s1"">'inspirational'</span><span class=""p"">,</span> <span class=""s1"">'paraphrased'</span><span class=""p"">],</span> <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""s1"">'Thomas A. Edison'</span><span class=""p"">,</span> <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""s2"">""“I have not failed. I've just found 10,000 ways that won't work.”""</span><span class=""p"">}</span>
</pre></div>","import scrapy


class QuotesSpider(scrapy.Spider):
    name = ""quotes""

    def start_requests(self):
        urls = [
            'https://quotes.toscrape.com/page/1/',
            'https://quotes.toscrape.com/page/2/',
        ]
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)

    def parse(self, response):
        page = response.url.split(""/"")[-2]
        filename = f'quotes-{page}.html'
        with open(filename, 'wb') as f:
            f.write(response.body)
        self.log(f'Saved file {filename}')
,scrapy crawl quotes
,... (omitted for brevity)
2016-12-16 21:24:05 [scrapy.core.engine] INFO: Spider opened
2016-12-16 21:24:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-16 21:24:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://quotes.toscrape.com/robots.txt> (referer: None)
2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/1/> (referer: None)
2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/2/> (referer: None)
2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-1.html
2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-2.html
2016-12-16 21:24:05 [scrapy.core.engine] INFO: Closing spider (finished)
...
,import scrapy


class QuotesSpider(scrapy.Spider):
    name = ""quotes""
    start_urls = [
        'https://quotes.toscrape.com/page/1/',
        'https://quotes.toscrape.com/page/2/',
    ]

    def parse(self, response):
        page = response.url.split(""/"")[-2]
        filename = f'quotes-{page}.html'
        with open(filename, 'wb') as f:
            f.write(response.body)
,scrapy shell 'https://quotes.toscrape.com/page/1/'
,scrapy shell ""https://quotes.toscrape.com/page/1/""
,[ ... Scrapy log here ... ]
2016-09-19 12:09:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/1/> (referer: None)
[s] Available Scrapy objects:
[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)
[s]   crawler    <scrapy.crawler.Crawler object at 0x7fa91d888c90>
[s]   item       {}
[s]   request    <GET https://quotes.toscrape.com/page/1/>
[s]   response   <200 https://quotes.toscrape.com/page/1/>
[s]   settings   <scrapy.settings.Settings object at 0x7fa91d888c10>
[s]   spider     <DefaultSpider 'default' at 0x7fa91c8af990>
[s] Useful shortcuts:
[s]   shelp()           Shell help (print this help)
[s]   fetch(req_or_url) Fetch request (or URL) and update local objects
[s]   view(response)    View response in a browser
,>>> response.css('title')
[<Selector xpath='descendant-or-self::title' data='<title>Quotes to Scrape</title>'>]
,>>> response.css('title::text').getall()
['Quotes to Scrape']
,>>> response.css('title').getall()
['<title>Quotes to Scrape</title>']
,>>> response.css('title::text').get()
'Quotes to Scrape'
,>>> response.css('title::text')[0].get()
'Quotes to Scrape'
,>>> response.css('noelement')[0].get()
Traceback (most recent call last):
...
IndexError: list index out of range
,>>> response.css(""noelement"").get()
,>>> response.css('title::text').re(r'Quotes.*')
['Quotes to Scrape']
>>> response.css('title::text').re(r'Q\w+')
['Quotes']
>>> response.css('title::text').re(r'(\w+) to (\w+)')
['Quotes', 'Scrape']
,>>> response.xpath('//title')
[<Selector xpath='//title' data='<title>Quotes to Scrape</title>'>]
>>> response.xpath('//title/text()').get()
'Quotes to Scrape'
,<div class=""quote"">
    <span class=""text"">“The world as we have created it is a process of our
    thinking. It cannot be changed without changing our thinking.”</span>
    <span>
        by <small class=""author"">Albert Einstein</small>
        <a href=""/author/Albert-Einstein"">(about)</a>
    </span>
    <div class=""tags"">
        Tags:
        <a class=""tag"" href=""/tag/change/page/1/"">change</a>
        <a class=""tag"" href=""/tag/deep-thoughts/page/1/"">deep-thoughts</a>
        <a class=""tag"" href=""/tag/thinking/page/1/"">thinking</a>
        <a class=""tag"" href=""/tag/world/page/1/"">world</a>
    </div>
</div>
,scrapy shell 'https://quotes.toscrape.com'
,>>> response.css(""div.quote"")
[<Selector xpath=""descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"" data='<div class=""quote"" itemscope itemtype...'>,
 <Selector xpath=""descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"" data='<div class=""quote"" itemscope itemtype...'>,
 ...]
,>>> quote = response.css(""div.quote"")[0]
,>>> text = quote.css(""span.text::text"").get()
>>> text
'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'
>>> author = quote.css(""small.author::text"").get()
>>> author
'Albert Einstein'
,>>> tags = quote.css(""div.tags a.tag::text"").getall()
>>> tags
['change', 'deep-thoughts', 'thinking', 'world']
,>>> for quote in response.css(""div.quote""):
...     text = quote.css(""span.text::text"").get()
...     author = quote.css(""small.author::text"").get()
...     tags = quote.css(""div.tags a.tag::text"").getall()
...     print(dict(text=text, author=author, tags=tags))
{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}
{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}
...
,import scrapy


class QuotesSpider(scrapy.Spider):
    name = ""quotes""
    start_urls = [
        'https://quotes.toscrape.com/page/1/',
        'https://quotes.toscrape.com/page/2/',
    ]

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('small.author::text').get(),
                'tags': quote.css('div.tags a.tag::text').getall(),
            }
,2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>
{'tags': ['life', 'love'], 'author': 'André Gide', 'text': '“It is better to be hated for what you are than to be loved for what you are not.”'}
2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>
{'tags': ['edison', 'failure', 'inspirational', 'paraphrased'], 'author': 'Thomas A. Edison', 'text': ""“I have not failed. I've just found 10,000 ways that won't work.”""}
",25
https://docs.scrapy.org/en/latest/intro/tutorial.html,,###,3,How to run our spider,#how-to-run-our-spider,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">quotes</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">...</span> <span class=""p"">(</span><span class=""n"">omitted</span> <span class=""k"">for</span> <span class=""n"">brevity</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Spider</span> <span class=""n"">opened</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">logstats</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""mi"">0</span> <span class=""n"">pages</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">pages</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">),</span> <span class=""n"">scraped</span> <span class=""mi"">0</span> <span class=""n"">items</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">items</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">telnet</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Telnet</span> <span class=""n"">console</span> <span class=""n"">listening</span> <span class=""n"">on</span> <span class=""mf"">127.0.0.1</span><span class=""p"">:</span><span class=""mi"">6023</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">404</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">robots</span><span class=""o"">.</span><span class=""n"">txt</span><span class=""o"">&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">2</span><span class=""o"">/&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">quotes</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Saved</span> <span class=""n"">file</span> <span class=""n"">quotes</span><span class=""o"">-</span><span class=""mf"">1.</span><span class=""n"">html</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">quotes</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Saved</span> <span class=""n"">file</span> <span class=""n"">quotes</span><span class=""o"">-</span><span class=""mf"">2.</span><span class=""n"">html</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">24</span><span class=""p"">:</span><span class=""mi"">05</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Closing</span> <span class=""n"">spider</span> <span class=""p"">(</span><span class=""n"">finished</span><span class=""p"">)</span>
<span class=""o"">...</span>
</pre></div>","scrapy crawl quotes
,... (omitted for brevity)
2016-12-16 21:24:05 [scrapy.core.engine] INFO: Spider opened
2016-12-16 21:24:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-16 21:24:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://quotes.toscrape.com/robots.txt> (referer: None)
2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/1/> (referer: None)
2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/2/> (referer: None)
2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-1.html
2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-2.html
2016-12-16 21:24:05 [scrapy.core.engine] INFO: Closing spider (finished)
...
",2
https://docs.scrapy.org/en/latest/intro/tutorial.html,,####,4,What just happened under the hood?,#what-just-happened-under-the-hood,,,5
https://docs.scrapy.org/en/latest/intro/tutorial.html,,###,3,A shortcut to the start_requests method,#a-shortcut-to-the-start-requests-method,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""quotes""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/1/'</span><span class=""p"">,</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/2/'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">page</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""o"">.</span><span class=""n"">split</span><span class=""p"">(</span><span class=""s2"">""/""</span><span class=""p"">)[</span><span class=""o"">-</span><span class=""mi"">2</span><span class=""p"">]</span>
        <span class=""n"">filename</span> <span class=""o"">=</span> <span class=""sa"">f</span><span class=""s1"">'quotes-</span><span class=""si"">{</span><span class=""n"">page</span><span class=""si"">}</span><span class=""s1"">.html'</span>
        <span class=""k"">with</span> <span class=""nb"">open</span><span class=""p"">(</span><span class=""n"">filename</span><span class=""p"">,</span> <span class=""s1"">'wb'</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">f</span><span class=""p"">:</span>
            <span class=""n"">f</span><span class=""o"">.</span><span class=""n"">write</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">body</span><span class=""p"">)</span>
</pre></div>","import scrapy


class QuotesSpider(scrapy.Spider):
    name = ""quotes""
    start_urls = [
        'https://quotes.toscrape.com/page/1/',
        'https://quotes.toscrape.com/page/2/',
    ]

    def parse(self, response):
        page = response.url.split(""/"")[-2]
        filename = f'quotes-{page}.html'
        with open(filename, 'wb') as f:
            f.write(response.body)
",1
https://docs.scrapy.org/en/latest/intro/tutorial.html,,###,3,Extracting data,#extracting-data,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""s1"">'https://quotes.toscrape.com/page/1/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""s2"">""https://quotes.toscrape.com/page/1/""</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">[</span> <span class=""o"">...</span> <span class=""n"">Scrapy</span> <span class=""n"">log</span> <span class=""n"">here</span> <span class=""o"">...</span> <span class=""p"">]</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">09</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">12</span><span class=""p"">:</span><span class=""mi"">09</span><span class=""p"">:</span><span class=""mi"">27</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span> <span class=""n"">Available</span> <span class=""n"">Scrapy</span> <span class=""n"">objects</span><span class=""p"">:</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">scrapy</span>     <span class=""n"">scrapy</span> <span class=""n"">module</span> <span class=""p"">(</span><span class=""n"">contains</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">,</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Selector</span><span class=""p"">,</span> <span class=""n"">etc</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">crawler</span>    <span class=""o"">&lt;</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">Crawler</span> <span class=""nb"">object</span> <span class=""n"">at</span> <span class=""mh"">0x7fa91d888c90</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">item</span>       <span class=""p"">{}</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">request</span>    <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">response</span>   <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">settings</span>   <span class=""o"">&lt;</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">Settings</span> <span class=""nb"">object</span> <span class=""n"">at</span> <span class=""mh"">0x7fa91d888c10</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">spider</span>     <span class=""o"">&lt;</span><span class=""n"">DefaultSpider</span> <span class=""s1"">'default'</span> <span class=""n"">at</span> <span class=""mh"">0x7fa91c8af990</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span> <span class=""n"">Useful</span> <span class=""n"">shortcuts</span><span class=""p"">:</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">shelp</span><span class=""p"">()</span>           <span class=""n"">Shell</span> <span class=""n"">help</span> <span class=""p"">(</span><span class=""nb"">print</span> <span class=""n"">this</span> <span class=""n"">help</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">fetch</span><span class=""p"">(</span><span class=""n"">req_or_url</span><span class=""p"">)</span> <span class=""n"">Fetch</span> <span class=""n"">request</span> <span class=""p"">(</span><span class=""ow"">or</span> <span class=""n"">URL</span><span class=""p"">)</span> <span class=""ow"">and</span> <span class=""n"">update</span> <span class=""n"">local</span> <span class=""n"">objects</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">view</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">)</span>    <span class=""n"">View</span> <span class=""n"">response</span> <span class=""ow"">in</span> <span class=""n"">a</span> <span class=""n"">browser</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title'</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='descendant-or-self::title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['Quotes to Scrape']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['&lt;title&gt;Quotes to Scrape&lt;/title&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Quotes to Scrape'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Quotes to Scrape'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'noelement'</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gt"">Traceback (most recent call last):</span>
<span class=""c"">...</span>
<span class=""gr"">IndexError</span>: <span class=""n"">list index out of range</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""noelement""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'Quotes.*'</span><span class=""p"">)</span>
<span class=""go"">['Quotes to Scrape']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'Q\w+'</span><span class=""p"">)</span>
<span class=""go"">['Quotes']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'(\w+) to (\w+)'</span><span class=""p"">)</span>
<span class=""go"">['Quotes', 'Scrape']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title'</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='//title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Quotes to Scrape'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""quote""</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">span</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""text""</span><span class=""p"">&gt;</span>“The world as we have created it is a process of our
    thinking. It cannot be changed without changing our thinking.”<span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
        by <span class=""p"">&lt;</span><span class=""nt"">small</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""author""</span><span class=""p"">&gt;</span>Albert Einstein<span class=""p"">&lt;/</span><span class=""nt"">small</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/author/Albert-Einstein""</span><span class=""p"">&gt;</span>(about)<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tags""</span><span class=""p"">&gt;</span>
        Tags:
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tag""</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/tag/change/page/1/""</span><span class=""p"">&gt;</span>change<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tag""</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/tag/deep-thoughts/page/1/""</span><span class=""p"">&gt;</span>deep-thoughts<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tag""</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/tag/thinking/page/1/""</span><span class=""p"">&gt;</span>thinking<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tag""</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/tag/world/page/1/""</span><span class=""p"">&gt;</span>world<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""s1"">'https://quotes.toscrape.com'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.quote""</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath=""descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"" data='&lt;div class=""quote"" itemscope itemtype...'&gt;,</span>
<span class=""go""> &lt;Selector xpath=""descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"" data='&lt;div class=""quote"" itemscope itemtype...'&gt;,</span>
<span class=""go""> ...]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">quote</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.quote""</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">text</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""span.text::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">text</span>
<span class=""go"">'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">author</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""small.author::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">author</span>
<span class=""go"">'Albert Einstein'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">tags</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.tags a.tag::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">tags</span>
<span class=""go"">['change', 'deep-thoughts', 'thinking', 'world']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.quote""</span><span class=""p"">):</span>
<span class=""gp"">... </span>    <span class=""n"">text</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""span.text::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""n"">author</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""small.author::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""n"">tags</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.tags a.tag::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">text</span><span class=""p"">,</span> <span class=""n"">author</span><span class=""o"">=</span><span class=""n"">author</span><span class=""p"">,</span> <span class=""n"">tags</span><span class=""o"">=</span><span class=""n"">tags</span><span class=""p"">))</span>
<span class=""go"">{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}</span>
<span class=""go"">{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}</span>
<span class=""gp"">...</span>
</pre></div>","scrapy shell 'https://quotes.toscrape.com/page/1/'
,scrapy shell ""https://quotes.toscrape.com/page/1/""
,[ ... Scrapy log here ... ]
2016-09-19 12:09:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/1/> (referer: None)
[s] Available Scrapy objects:
[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)
[s]   crawler    <scrapy.crawler.Crawler object at 0x7fa91d888c90>
[s]   item       {}
[s]   request    <GET https://quotes.toscrape.com/page/1/>
[s]   response   <200 https://quotes.toscrape.com/page/1/>
[s]   settings   <scrapy.settings.Settings object at 0x7fa91d888c10>
[s]   spider     <DefaultSpider 'default' at 0x7fa91c8af990>
[s] Useful shortcuts:
[s]   shelp()           Shell help (print this help)
[s]   fetch(req_or_url) Fetch request (or URL) and update local objects
[s]   view(response)    View response in a browser
,>>> response.css('title')
[<Selector xpath='descendant-or-self::title' data='<title>Quotes to Scrape</title>'>]
,>>> response.css('title::text').getall()
['Quotes to Scrape']
,>>> response.css('title').getall()
['<title>Quotes to Scrape</title>']
,>>> response.css('title::text').get()
'Quotes to Scrape'
,>>> response.css('title::text')[0].get()
'Quotes to Scrape'
,>>> response.css('noelement')[0].get()
Traceback (most recent call last):
...
IndexError: list index out of range
,>>> response.css(""noelement"").get()
,>>> response.css('title::text').re(r'Quotes.*')
['Quotes to Scrape']
>>> response.css('title::text').re(r'Q\w+')
['Quotes']
>>> response.css('title::text').re(r'(\w+) to (\w+)')
['Quotes', 'Scrape']
,>>> response.xpath('//title')
[<Selector xpath='//title' data='<title>Quotes to Scrape</title>'>]
>>> response.xpath('//title/text()').get()
'Quotes to Scrape'
,<div class=""quote"">
    <span class=""text"">“The world as we have created it is a process of our
    thinking. It cannot be changed without changing our thinking.”</span>
    <span>
        by <small class=""author"">Albert Einstein</small>
        <a href=""/author/Albert-Einstein"">(about)</a>
    </span>
    <div class=""tags"">
        Tags:
        <a class=""tag"" href=""/tag/change/page/1/"">change</a>
        <a class=""tag"" href=""/tag/deep-thoughts/page/1/"">deep-thoughts</a>
        <a class=""tag"" href=""/tag/thinking/page/1/"">thinking</a>
        <a class=""tag"" href=""/tag/world/page/1/"">world</a>
    </div>
</div>
,scrapy shell 'https://quotes.toscrape.com'
,>>> response.css(""div.quote"")
[<Selector xpath=""descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"" data='<div class=""quote"" itemscope itemtype...'>,
 <Selector xpath=""descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"" data='<div class=""quote"" itemscope itemtype...'>,
 ...]
,>>> quote = response.css(""div.quote"")[0]
,>>> text = quote.css(""span.text::text"").get()
>>> text
'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'
>>> author = quote.css(""small.author::text"").get()
>>> author
'Albert Einstein'
,>>> tags = quote.css(""div.tags a.tag::text"").getall()
>>> tags
['change', 'deep-thoughts', 'thinking', 'world']
,>>> for quote in response.css(""div.quote""):
...     text = quote.css(""span.text::text"").get()
...     author = quote.css(""small.author::text"").get()
...     tags = quote.css(""div.tags a.tag::text"").getall()
...     print(dict(text=text, author=author, tags=tags))
{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}
{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}
...
",19
https://docs.scrapy.org/en/latest/intro/tutorial.html,,####,4,XPath: a brief intro,#xpath-a-brief-intro,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title'</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='//title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Quotes to Scrape'</span>
</pre></div>",">>> response.xpath('//title')
[<Selector xpath='//title' data='<title>Quotes to Scrape</title>'>]
>>> response.xpath('//title/text()').get()
'Quotes to Scrape'
",1
https://docs.scrapy.org/en/latest/intro/tutorial.html,,####,4,Extracting quotes and authors,#extracting-quotes-and-authors,"<div class=""highlight""><pre><span></span><span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""quote""</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">span</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""text""</span><span class=""p"">&gt;</span>“The world as we have created it is a process of our
    thinking. It cannot be changed without changing our thinking.”<span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
        by <span class=""p"">&lt;</span><span class=""nt"">small</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""author""</span><span class=""p"">&gt;</span>Albert Einstein<span class=""p"">&lt;/</span><span class=""nt"">small</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/author/Albert-Einstein""</span><span class=""p"">&gt;</span>(about)<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tags""</span><span class=""p"">&gt;</span>
        Tags:
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tag""</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/tag/change/page/1/""</span><span class=""p"">&gt;</span>change<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tag""</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/tag/deep-thoughts/page/1/""</span><span class=""p"">&gt;</span>deep-thoughts<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tag""</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/tag/thinking/page/1/""</span><span class=""p"">&gt;</span>thinking<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tag""</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/tag/world/page/1/""</span><span class=""p"">&gt;</span>world<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""s1"">'https://quotes.toscrape.com'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.quote""</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath=""descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"" data='&lt;div class=""quote"" itemscope itemtype...'&gt;,</span>
<span class=""go""> &lt;Selector xpath=""descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"" data='&lt;div class=""quote"" itemscope itemtype...'&gt;,</span>
<span class=""go""> ...]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">quote</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.quote""</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">text</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""span.text::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">text</span>
<span class=""go"">'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">author</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""small.author::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">author</span>
<span class=""go"">'Albert Einstein'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">tags</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.tags a.tag::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">tags</span>
<span class=""go"">['change', 'deep-thoughts', 'thinking', 'world']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.quote""</span><span class=""p"">):</span>
<span class=""gp"">... </span>    <span class=""n"">text</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""span.text::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""n"">author</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""small.author::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""n"">tags</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s2"">""div.tags a.tag::text""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">text</span><span class=""p"">,</span> <span class=""n"">author</span><span class=""o"">=</span><span class=""n"">author</span><span class=""p"">,</span> <span class=""n"">tags</span><span class=""o"">=</span><span class=""n"">tags</span><span class=""p"">))</span>
<span class=""go"">{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}</span>
<span class=""go"">{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}</span>
<span class=""gp"">...</span>
</pre></div>","<div class=""quote"">
    <span class=""text"">“The world as we have created it is a process of our
    thinking. It cannot be changed without changing our thinking.”</span>
    <span>
        by <small class=""author"">Albert Einstein</small>
        <a href=""/author/Albert-Einstein"">(about)</a>
    </span>
    <div class=""tags"">
        Tags:
        <a class=""tag"" href=""/tag/change/page/1/"">change</a>
        <a class=""tag"" href=""/tag/deep-thoughts/page/1/"">deep-thoughts</a>
        <a class=""tag"" href=""/tag/thinking/page/1/"">thinking</a>
        <a class=""tag"" href=""/tag/world/page/1/"">world</a>
    </div>
</div>
,scrapy shell 'https://quotes.toscrape.com'
,>>> response.css(""div.quote"")
[<Selector xpath=""descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"" data='<div class=""quote"" itemscope itemtype...'>,
 <Selector xpath=""descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]"" data='<div class=""quote"" itemscope itemtype...'>,
 ...]
,>>> quote = response.css(""div.quote"")[0]
,>>> text = quote.css(""span.text::text"").get()
>>> text
'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'
>>> author = quote.css(""small.author::text"").get()
>>> author
'Albert Einstein'
,>>> tags = quote.css(""div.tags a.tag::text"").getall()
>>> tags
['change', 'deep-thoughts', 'thinking', 'world']
,>>> for quote in response.css(""div.quote""):
...     text = quote.css(""span.text::text"").get()
...     author = quote.css(""small.author::text"").get()
...     tags = quote.css(""div.tags a.tag::text"").getall()
...     print(dict(text=text, author=author, tags=tags))
{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}
{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}
...
",7
https://docs.scrapy.org/en/latest/intro/tutorial.html,,###,3,Extracting data in our spider,#extracting-data-in-our-spider,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""quotes""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/1/'</span><span class=""p"">,</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/2/'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span>
                <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'small.author::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'tags'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.tags a.tag::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">(),</span>
            <span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">09</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">57</span><span class=""p"">:</span><span class=""mi"">19</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">scraper</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Scraped</span> <span class=""kn"">from</span> <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span>
<span class=""p"">{</span><span class=""s1"">'tags'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""s1"">'life'</span><span class=""p"">,</span> <span class=""s1"">'love'</span><span class=""p"">],</span> <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""s1"">'André Gide'</span><span class=""p"">,</span> <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""s1"">'“It is better to be hated for what you are than to be loved for what you are not.”'</span><span class=""p"">}</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">09</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">57</span><span class=""p"">:</span><span class=""mi"">19</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">scraper</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Scraped</span> <span class=""kn"">from</span> <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">/&gt;</span>
<span class=""p"">{</span><span class=""s1"">'tags'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""s1"">'edison'</span><span class=""p"">,</span> <span class=""s1"">'failure'</span><span class=""p"">,</span> <span class=""s1"">'inspirational'</span><span class=""p"">,</span> <span class=""s1"">'paraphrased'</span><span class=""p"">],</span> <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""s1"">'Thomas A. Edison'</span><span class=""p"">,</span> <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""s2"">""“I have not failed. I've just found 10,000 ways that won't work.”""</span><span class=""p"">}</span>
</pre></div>","import scrapy


class QuotesSpider(scrapy.Spider):
    name = ""quotes""
    start_urls = [
        'https://quotes.toscrape.com/page/1/',
        'https://quotes.toscrape.com/page/2/',
    ]

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('small.author::text').get(),
                'tags': quote.css('div.tags a.tag::text').getall(),
            }
,2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>
{'tags': ['life', 'love'], 'author': 'André Gide', 'text': '“It is better to be hated for what you are than to be loved for what you are not.”'}
2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://quotes.toscrape.com/page/1/>
{'tags': ['edison', 'failure', 'inspirational', 'paraphrased'], 'author': 'Thomas A. Edison', 'text': ""“I have not failed. I've just found 10,000 ways that won't work.”""}
",2
https://docs.scrapy.org/en/latest/intro/tutorial.html,,##,2,Storing the scraped data,#storing-the-scraped-data,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">quotes</span> <span class=""o"">-</span><span class=""n"">O</span> <span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">json</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">quotes</span> <span class=""o"">-</span><span class=""n"">o</span> <span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">jsonl</span>
</pre></div>","scrapy crawl quotes -O quotes.json
,scrapy crawl quotes -o quotes.jsonl
",2
https://docs.scrapy.org/en/latest/intro/tutorial.html,,##,2,Following links,#following-links,"<div class=""highlight""><pre><span></span><span class=""p"">&lt;</span><span class=""nt"">ul</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""pager""</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">li</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""next""</span><span class=""p"">&gt;</span>
        <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""/page/2/""</span><span class=""p"">&gt;</span>Next <span class=""p"">&lt;</span><span class=""nt"">span</span> <span class=""na"">aria-hidden</span><span class=""o"">=</span><span class=""s"">""true""</span><span class=""p"">&gt;</span><span class=""ni"">&amp;rarr;</span><span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;/</span><span class=""nt"">li</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;/</span><span class=""nt"">ul</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'&lt;a href=""/page/2/""&gt;Next &lt;span aria-hidden=""true""&gt;→&lt;/span&gt;&lt;/a&gt;'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'/page/2/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'href'</span><span class=""p"">]</span>
<span class=""go"">'/page/2/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""quotes""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/1/'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span>
                <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'small.author::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'tags'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.tags a.tag::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">(),</span>
            <span class=""p"">}</span>

        <span class=""n"">next_page</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">if</span> <span class=""n"">next_page</span> <span class=""ow"">is</span> <span class=""ow"">not</span> <span class=""kc"">None</span><span class=""p"">:</span>
            <span class=""n"">next_page</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">urljoin</span><span class=""p"">(</span><span class=""n"">next_page</span><span class=""p"">)</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">next_page</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""quotes""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/1/'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span>
                <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span small::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'tags'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.tags a.tag::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">(),</span>
            <span class=""p"">}</span>

        <span class=""n"">next_page</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">if</span> <span class=""n"">next_page</span> <span class=""ow"">is</span> <span class=""ow"">not</span> <span class=""kc"">None</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">next_page</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">href</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'ul.pager a::attr(href)'</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">href</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">a</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'ul.pager a'</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">a</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">anchors</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'ul.pager a'</span><span class=""p"">)</span>
<span class=""k"">yield from</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow_all</span><span class=""p"">(</span><span class=""n"">anchors</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">yield from</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow_all</span><span class=""p"">(</span><span class=""n"">css</span><span class=""o"">=</span><span class=""s1"">'ul.pager a'</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">AuthorSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'author'</span>

    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://quotes.toscrape.com/'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">author_page_links</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'.author + a'</span><span class=""p"">)</span>
        <span class=""k"">yield from</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow_all</span><span class=""p"">(</span><span class=""n"">author_page_links</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_author</span><span class=""p"">)</span>

        <span class=""n"">pagination_links</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a'</span><span class=""p"">)</span>
        <span class=""k"">yield from</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow_all</span><span class=""p"">(</span><span class=""n"">pagination_links</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse_author</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">def</span> <span class=""nf"">extract_with_css</span><span class=""p"">(</span><span class=""n"">query</span><span class=""p"">):</span>
            <span class=""k"">return</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""n"">query</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""n"">default</span><span class=""o"">=</span><span class=""s1"">''</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">strip</span><span class=""p"">()</span>

        <span class=""k"">yield</span> <span class=""p"">{</span>
            <span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""n"">extract_with_css</span><span class=""p"">(</span><span class=""s1"">'h3.author-title::text'</span><span class=""p"">),</span>
            <span class=""s1"">'birthdate'</span><span class=""p"">:</span> <span class=""n"">extract_with_css</span><span class=""p"">(</span><span class=""s1"">'.author-born-date::text'</span><span class=""p"">),</span>
            <span class=""s1"">'bio'</span><span class=""p"">:</span> <span class=""n"">extract_with_css</span><span class=""p"">(</span><span class=""s1"">'.author-description::text'</span><span class=""p"">),</span>
        <span class=""p"">}</span>
</pre></div>","<ul class=""pager"">
    <li class=""next"">
        <a href=""/page/2/"">Next <span aria-hidden=""true"">→</span></a>
    </li>
</ul>
,>>> response.css('li.next a').get()
'<a href=""/page/2/"">Next <span aria-hidden=""true"">→</span></a>'
,>>> response.css('li.next a::attr(href)').get()
'/page/2/'
,>>> response.css('li.next a').attrib['href']
'/page/2/'
,import scrapy


class QuotesSpider(scrapy.Spider):
    name = ""quotes""
    start_urls = [
        'https://quotes.toscrape.com/page/1/',
    ]

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('small.author::text').get(),
                'tags': quote.css('div.tags a.tag::text').getall(),
            }

        next_page = response.css('li.next a::attr(href)').get()
        if next_page is not None:
            next_page = response.urljoin(next_page)
            yield scrapy.Request(next_page, callback=self.parse)
,import scrapy


class QuotesSpider(scrapy.Spider):
    name = ""quotes""
    start_urls = [
        'https://quotes.toscrape.com/page/1/',
    ]

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('span small::text').get(),
                'tags': quote.css('div.tags a.tag::text').getall(),
            }

        next_page = response.css('li.next a::attr(href)').get()
        if next_page is not None:
            yield response.follow(next_page, callback=self.parse)
,for href in response.css('ul.pager a::attr(href)'):
    yield response.follow(href, callback=self.parse)
,for a in response.css('ul.pager a'):
    yield response.follow(a, callback=self.parse)
,anchors = response.css('ul.pager a')
yield from response.follow_all(anchors, callback=self.parse)
,yield from response.follow_all(css='ul.pager a', callback=self.parse)
,import scrapy


class AuthorSpider(scrapy.Spider):
    name = 'author'

    start_urls = ['https://quotes.toscrape.com/']

    def parse(self, response):
        author_page_links = response.css('.author + a')
        yield from response.follow_all(author_page_links, self.parse_author)

        pagination_links = response.css('li.next a')
        yield from response.follow_all(pagination_links, self.parse)

    def parse_author(self, response):
        def extract_with_css(query):
            return response.css(query).get(default='').strip()

        yield {
            'name': extract_with_css('h3.author-title::text'),
            'birthdate': extract_with_css('.author-born-date::text'),
            'bio': extract_with_css('.author-description::text'),
        }
",11
https://docs.scrapy.org/en/latest/intro/tutorial.html,,###,3,A shortcut for creating Requests,#a-shortcut-for-creating-requests,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""quotes""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'https://quotes.toscrape.com/page/1/'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span>
                <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span small::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'tags'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.tags a.tag::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">(),</span>
            <span class=""p"">}</span>

        <span class=""n"">next_page</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">if</span> <span class=""n"">next_page</span> <span class=""ow"">is</span> <span class=""ow"">not</span> <span class=""kc"">None</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">next_page</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">href</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'ul.pager a::attr(href)'</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">href</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">a</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'ul.pager a'</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">a</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">anchors</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'ul.pager a'</span><span class=""p"">)</span>
<span class=""k"">yield from</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow_all</span><span class=""p"">(</span><span class=""n"">anchors</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">yield from</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow_all</span><span class=""p"">(</span><span class=""n"">css</span><span class=""o"">=</span><span class=""s1"">'ul.pager a'</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>","import scrapy


class QuotesSpider(scrapy.Spider):
    name = ""quotes""
    start_urls = [
        'https://quotes.toscrape.com/page/1/',
    ]

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('span small::text').get(),
                'tags': quote.css('div.tags a.tag::text').getall(),
            }

        next_page = response.css('li.next a::attr(href)').get()
        if next_page is not None:
            yield response.follow(next_page, callback=self.parse)
,for href in response.css('ul.pager a::attr(href)'):
    yield response.follow(href, callback=self.parse)
,for a in response.css('ul.pager a'):
    yield response.follow(a, callback=self.parse)
,anchors = response.css('ul.pager a')
yield from response.follow_all(anchors, callback=self.parse)
,yield from response.follow_all(css='ul.pager a', callback=self.parse)
",5
https://docs.scrapy.org/en/latest/intro/tutorial.html,,###,3,More examples and patterns,#more-examples-and-patterns,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">AuthorSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'author'</span>

    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://quotes.toscrape.com/'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">author_page_links</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'.author + a'</span><span class=""p"">)</span>
        <span class=""k"">yield from</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow_all</span><span class=""p"">(</span><span class=""n"">author_page_links</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_author</span><span class=""p"">)</span>

        <span class=""n"">pagination_links</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a'</span><span class=""p"">)</span>
        <span class=""k"">yield from</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow_all</span><span class=""p"">(</span><span class=""n"">pagination_links</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse_author</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">def</span> <span class=""nf"">extract_with_css</span><span class=""p"">(</span><span class=""n"">query</span><span class=""p"">):</span>
            <span class=""k"">return</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""n"">query</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""n"">default</span><span class=""o"">=</span><span class=""s1"">''</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">strip</span><span class=""p"">()</span>

        <span class=""k"">yield</span> <span class=""p"">{</span>
            <span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""n"">extract_with_css</span><span class=""p"">(</span><span class=""s1"">'h3.author-title::text'</span><span class=""p"">),</span>
            <span class=""s1"">'birthdate'</span><span class=""p"">:</span> <span class=""n"">extract_with_css</span><span class=""p"">(</span><span class=""s1"">'.author-born-date::text'</span><span class=""p"">),</span>
            <span class=""s1"">'bio'</span><span class=""p"">:</span> <span class=""n"">extract_with_css</span><span class=""p"">(</span><span class=""s1"">'.author-description::text'</span><span class=""p"">),</span>
        <span class=""p"">}</span>
</pre></div>","import scrapy


class AuthorSpider(scrapy.Spider):
    name = 'author'

    start_urls = ['https://quotes.toscrape.com/']

    def parse(self, response):
        author_page_links = response.css('.author + a')
        yield from response.follow_all(author_page_links, self.parse_author)

        pagination_links = response.css('li.next a')
        yield from response.follow_all(pagination_links, self.parse)

    def parse_author(self, response):
        def extract_with_css(query):
            return response.css(query).get(default='').strip()

        yield {
            'name': extract_with_css('h3.author-title::text'),
            'birthdate': extract_with_css('.author-born-date::text'),
            'bio': extract_with_css('.author-description::text'),
        }
",1
https://docs.scrapy.org/en/latest/intro/tutorial.html,,##,2,Using spider arguments,#using-spider-arguments,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">quotes</span> <span class=""o"">-</span><span class=""n"">O</span> <span class=""n"">quotes</span><span class=""o"">-</span><span class=""n"">humor</span><span class=""o"">.</span><span class=""n"">json</span> <span class=""o"">-</span><span class=""n"">a</span> <span class=""n"">tag</span><span class=""o"">=</span><span class=""n"">humor</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""quotes""</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""n"">url</span> <span class=""o"">=</span> <span class=""s1"">'https://quotes.toscrape.com/'</span>
        <span class=""n"">tag</span> <span class=""o"">=</span> <span class=""nb"">getattr</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""s1"">'tag'</span><span class=""p"">,</span> <span class=""kc"">None</span><span class=""p"">)</span>
        <span class=""k"">if</span> <span class=""n"">tag</span> <span class=""ow"">is</span> <span class=""ow"">not</span> <span class=""kc"">None</span><span class=""p"">:</span>
            <span class=""n"">url</span> <span class=""o"">=</span> <span class=""n"">url</span> <span class=""o"">+</span> <span class=""s1"">'tag/'</span> <span class=""o"">+</span> <span class=""n"">tag</span>
        <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span>
                <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'small.author::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
            <span class=""p"">}</span>

        <span class=""n"">next_page</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.next a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">if</span> <span class=""n"">next_page</span> <span class=""ow"">is</span> <span class=""ow"">not</span> <span class=""kc"">None</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">next_page</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>","scrapy crawl quotes -O quotes-humor.json -a tag=humor
,import scrapy


class QuotesSpider(scrapy.Spider):
    name = ""quotes""

    def start_requests(self):
        url = 'https://quotes.toscrape.com/'
        tag = getattr(self, 'tag', None)
        if tag is not None:
            url = url + 'tag/' + tag
        yield scrapy.Request(url, self.parse)

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('small.author::text').get(),
            }

        next_page = response.css('li.next a::attr(href)').get()
        if next_page is not None:
            yield response.follow(next_page, self.parse)
",2
https://docs.scrapy.org/en/latest/intro/tutorial.html,,##,2,Next steps,#next-steps,,,16
https://docs.scrapy.org/en/latest/intro/examples.html,,#,1,Examples,#examples,,,1
https://docs.scrapy.org/en/latest/topics/commands.html,,#,1,Command line tool,#command-line-tool,"<div class=""highlight""><pre><span></span>scrapy.cfg
myproject/
    __init__.py
    items.py
    middlewares.py
    pipelines.py
    settings.py
    spiders/
        __init__.py
        spider1.py
        spider2.py
        ...
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">[settings]</span><span class=""w""></span>
<span class=""na"">default</span><span class=""w""> </span><span class=""o"">=</span><span class=""w""> </span><span class=""s"">myproject.settings</span><span class=""w""></span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">[settings]</span><span class=""w""></span>
<span class=""na"">default</span><span class=""w""> </span><span class=""o"">=</span><span class=""w""> </span><span class=""s"">myproject1.settings</span><span class=""w""></span>
<span class=""na"">project1</span><span class=""w""> </span><span class=""o"">=</span><span class=""w""> </span><span class=""s"">myproject1.settings</span><span class=""w""></span>
<span class=""na"">project2</span><span class=""w""> </span><span class=""o"">=</span><span class=""w""> </span><span class=""s"">myproject2.settings</span><span class=""w""></span>
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy settings --get BOT_NAME
Project 1 Bot
$ export SCRAPY_PROJECT=project2
$ scrapy settings --get BOT_NAME
Project 2 Bot
</pre></div>,<div class=""highlight""><pre><span></span>Scrapy X.Y - no active project

Usage:
  scrapy &lt;command&gt; [options] [args]

Available commands:
  crawl         Run a spider
  fetch         Fetch a URL using the Scrapy downloader
[...]
</pre></div>,<div class=""highlight""><pre><span></span>Scrapy X.Y - project: myproject

Usage:
  scrapy &lt;command&gt; [options] [args]

[...]
</pre></div>,<div class=""highlight""><pre><span></span>scrapy startproject myproject [project_dir]
</pre></div>,<div class=""highlight""><pre><span></span>cd project_dir
</pre></div>,<div class=""highlight""><pre><span></span>scrapy genspider mydomain mydomain.com
</pre></div>,<div class=""highlight""><pre><span></span>scrapy &lt;command&gt; -h
</pre></div>,<div class=""highlight""><pre><span></span>scrapy -h
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy startproject myproject
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy genspider -l
Available templates:
  basic
  crawl
  csvfeed
  xmlfeed

$ scrapy genspider example example.com
Created spider 'example' using template 'basic'

$ scrapy genspider -t crawl scrapyorg scrapy.org
Created spider 'scrapyorg' using template 'crawl'
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy crawl myspider
[ ... myspider starts crawling ... ]

$ scrapy -o myfile:csv myspider
[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]

$ scrapy -O myfile:json myspider
[ ... myspider starts crawling and saves the result in myfile in json format overwriting the original content... ]

$ scrapy -o myfile -t csv myspider
[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy check -l
first_spider
  * parse
  * parse_item
second_spider
  * parse
  * parse_item

$ scrapy check
[FAILED] first_spider:parse_item
&gt;&gt;&gt; 'RetailPricex' field is missing

[FAILED] first_spider:parse
&gt;&gt;&gt; Returned 92 requests, expected 0..4
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy list
spider1
spider2
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy edit spider1
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy fetch --nolog http://www.example.com/some/page.html
[ ... html content here ... ]

$ scrapy fetch --nolog --headers http://www.example.com/
{'Accept-Ranges': ['bytes'],
 'Age': ['1263   '],
 'Connection': ['close     '],
 'Content-Length': ['596'],
 'Content-Type': ['text/html; charset=UTF-8'],
 'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],
 'Etag': ['""573c1-254-48c9c87349680""'],
 'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],
 'Server': ['Apache/2.2.3 (CentOS)']}
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy view http://www.example.com/some/page.html
[ ... browser starts ... ]
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy shell http://www.example.com/some/page.html
[ ... scrapy shell starts ... ]

$ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)'
(200, 'http://www.example.com/')

# shell follows HTTP redirects by default
$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'
(200, 'http://example.com/')

# you can disable this with --no-redirect
# (only for the URL passed as command line argument)
$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'
(302, 'http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F')
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy parse http://www.example.com/ -c parse_item
[ ... scrapy log lines crawling example.com spider ... ]

&gt;&gt;&gt; STATUS DEPTH LEVEL 1 &lt;&lt;&lt;
# Scraped Items  ------------------------------------------------------------
[{'name': 'Example item',
 'category': 'Furniture',
 'length': '12 cm'}]

# Requests  -----------------------------------------------------------------
[]
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy settings --get BOT_NAME
scrapybot
$ scrapy settings --get DOWNLOAD_DELAY
0
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy runspider myspider.py
[ ... spider starts crawling ... ]
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">COMMANDS_MODULE</span> <span class=""o"">=</span> <span class=""s1"">'mybot.commands'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">setuptools</span> <span class=""kn"">import</span> <span class=""n"">setup</span><span class=""p"">,</span> <span class=""n"">find_packages</span>

<span class=""n"">setup</span><span class=""p"">(</span><span class=""n"">name</span><span class=""o"">=</span><span class=""s1"">'scrapy-mymodule'</span><span class=""p"">,</span>
  <span class=""n"">entry_points</span><span class=""o"">=</span><span class=""p"">{</span>
    <span class=""s1"">'scrapy.commands'</span><span class=""p"">:</span> <span class=""p"">[</span>
      <span class=""s1"">'my_command=my_scrapy_module.commands:MyCommand'</span><span class=""p"">,</span>
    <span class=""p"">],</span>
  <span class=""p"">},</span>
 <span class=""p"">)</span>
</pre></div>","scrapy.cfg
myproject/
    __init__.py
    items.py
    middlewares.py
    pipelines.py
    settings.py
    spiders/
        __init__.py
        spider1.py
        spider2.py
        ...
,[settings]
default = myproject.settings
,[settings]
default = myproject1.settings
project1 = myproject1.settings
project2 = myproject2.settings
,$ scrapy settings --get BOT_NAME
Project 1 Bot
$ export SCRAPY_PROJECT=project2
$ scrapy settings --get BOT_NAME
Project 2 Bot
,Scrapy X.Y - no active project

Usage:
  scrapy <command> [options] [args]

Available commands:
  crawl         Run a spider
  fetch         Fetch a URL using the Scrapy downloader
[...]
,Scrapy X.Y - project: myproject

Usage:
  scrapy <command> [options] [args]

[...]
,scrapy startproject myproject [project_dir]
,cd project_dir
,scrapy genspider mydomain mydomain.com
,scrapy <command> -h
,scrapy -h
,$ scrapy startproject myproject
,$ scrapy genspider -l
Available templates:
  basic
  crawl
  csvfeed
  xmlfeed

$ scrapy genspider example example.com
Created spider 'example' using template 'basic'

$ scrapy genspider -t crawl scrapyorg scrapy.org
Created spider 'scrapyorg' using template 'crawl'
,$ scrapy crawl myspider
[ ... myspider starts crawling ... ]

$ scrapy -o myfile:csv myspider
[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]

$ scrapy -O myfile:json myspider
[ ... myspider starts crawling and saves the result in myfile in json format overwriting the original content... ]

$ scrapy -o myfile -t csv myspider
[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]
,$ scrapy check -l
first_spider
  * parse
  * parse_item
second_spider
  * parse
  * parse_item

$ scrapy check
[FAILED] first_spider:parse_item
>>> 'RetailPricex' field is missing

[FAILED] first_spider:parse
>>> Returned 92 requests, expected 0..4
,$ scrapy list
spider1
spider2
,$ scrapy edit spider1
,$ scrapy fetch --nolog http://www.example.com/some/page.html
[ ... html content here ... ]

$ scrapy fetch --nolog --headers http://www.example.com/
{'Accept-Ranges': ['bytes'],
 'Age': ['1263   '],
 'Connection': ['close     '],
 'Content-Length': ['596'],
 'Content-Type': ['text/html; charset=UTF-8'],
 'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],
 'Etag': ['""573c1-254-48c9c87349680""'],
 'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],
 'Server': ['Apache/2.2.3 (CentOS)']}
,$ scrapy view http://www.example.com/some/page.html
[ ... browser starts ... ]
,$ scrapy shell http://www.example.com/some/page.html
[ ... scrapy shell starts ... ]

$ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)'
(200, 'http://www.example.com/')

# shell follows HTTP redirects by default
$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http://example.com/ -c '(response.status, response.url)'
(200, 'http://example.com/')

# you can disable this with --no-redirect
# (only for the URL passed as command line argument)
$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http://example.com/ -c '(response.status, response.url)'
(302, 'http://httpbin.org/redirect-to?url=http://example.com/')
,$ scrapy parse http://www.example.com/ -c parse_item
[ ... scrapy log lines crawling example.com spider ... ]

>>> STATUS DEPTH LEVEL 1 <<<
# Scraped Items  ------------------------------------------------------------
[{'name': 'Example item',
 'category': 'Furniture',
 'length': '12 cm'}]

# Requests  -----------------------------------------------------------------
[]
,$ scrapy settings --get BOT_NAME
scrapybot
$ scrapy settings --get DOWNLOAD_DELAY
0
,$ scrapy runspider myspider.py
[ ... spider starts crawling ... ]
,COMMANDS_MODULE = 'mybot.commands'
,from setuptools import setup, find_packages

setup(name='scrapy-mymodule',
  entry_points={
    'scrapy.commands': [
      'my_command=my_scrapy_module.commands:MyCommand',
    ],
  },
 )
",25
https://docs.scrapy.org/en/latest/topics/commands.html,,##,2,Configuration settings,#configuration-settings,,,2
https://docs.scrapy.org/en/latest/topics/commands.html,,##,2,Default structure of Scrapy projects,#default-structure-of-scrapy-projects,"<div class=""highlight""><pre><span></span>scrapy.cfg
myproject/
    __init__.py
    items.py
    middlewares.py
    pipelines.py
    settings.py
    spiders/
        __init__.py
        spider1.py
        spider2.py
        ...
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">[settings]</span><span class=""w""></span>
<span class=""na"">default</span><span class=""w""> </span><span class=""o"">=</span><span class=""w""> </span><span class=""s"">myproject.settings</span><span class=""w""></span>
</pre></div>","scrapy.cfg
myproject/
    __init__.py
    items.py
    middlewares.py
    pipelines.py
    settings.py
    spiders/
        __init__.py
        spider1.py
        spider2.py
        ...
,[settings]
default = myproject.settings
",2
https://docs.scrapy.org/en/latest/topics/commands.html,,##,2,Sharing the root directory between projects,#sharing-the-root-directory-between-projects,"<div class=""highlight""><pre><span></span><span class=""k"">[settings]</span><span class=""w""></span>
<span class=""na"">default</span><span class=""w""> </span><span class=""o"">=</span><span class=""w""> </span><span class=""s"">myproject1.settings</span><span class=""w""></span>
<span class=""na"">project1</span><span class=""w""> </span><span class=""o"">=</span><span class=""w""> </span><span class=""s"">myproject1.settings</span><span class=""w""></span>
<span class=""na"">project2</span><span class=""w""> </span><span class=""o"">=</span><span class=""w""> </span><span class=""s"">myproject2.settings</span><span class=""w""></span>
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy settings --get BOT_NAME
Project 1 Bot
$ export SCRAPY_PROJECT=project2
$ scrapy settings --get BOT_NAME
Project 2 Bot
</pre></div>","[settings]
default = myproject1.settings
project1 = myproject1.settings
project2 = myproject2.settings
,$ scrapy settings --get BOT_NAME
Project 1 Bot
$ export SCRAPY_PROJECT=project2
$ scrapy settings --get BOT_NAME
Project 2 Bot
",2
https://docs.scrapy.org/en/latest/topics/commands.html,,##,2,Using the scrapy tool,#using-the-scrapy-tool,"<div class=""highlight""><pre><span></span>Scrapy X.Y - no active project

Usage:
  scrapy &lt;command&gt; [options] [args]

Available commands:
  crawl         Run a spider
  fetch         Fetch a URL using the Scrapy downloader
[...]
</pre></div>,<div class=""highlight""><pre><span></span>Scrapy X.Y - project: myproject

Usage:
  scrapy &lt;command&gt; [options] [args]

[...]
</pre></div>,<div class=""highlight""><pre><span></span>scrapy startproject myproject [project_dir]
</pre></div>,<div class=""highlight""><pre><span></span>cd project_dir
</pre></div>,<div class=""highlight""><pre><span></span>scrapy genspider mydomain mydomain.com
</pre></div>","Scrapy X.Y - no active project

Usage:
  scrapy <command> [options] [args]

Available commands:
  crawl         Run a spider
  fetch         Fetch a URL using the Scrapy downloader
[...]
,Scrapy X.Y - project: myproject

Usage:
  scrapy <command> [options] [args]

[...]
,scrapy startproject myproject [project_dir]
,cd project_dir
,scrapy genspider mydomain mydomain.com
",5
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,Creating projects,#creating-projects,"<div class=""highlight""><pre><span></span>scrapy startproject myproject [project_dir]
</pre></div>,<div class=""highlight""><pre><span></span>cd project_dir
</pre></div>","scrapy startproject myproject [project_dir]
,cd project_dir
",2
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,Controlling projects,#controlling-projects,"<div class=""highlight""><pre><span></span>scrapy genspider mydomain mydomain.com
</pre></div>","scrapy genspider mydomain mydomain.com
",1
https://docs.scrapy.org/en/latest/topics/commands.html,,##,2,Available tool commands,#available-tool-commands,"<div class=""highlight""><pre><span></span>scrapy &lt;command&gt; -h
</pre></div>,<div class=""highlight""><pre><span></span>scrapy -h
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy startproject myproject
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy genspider -l
Available templates:
  basic
  crawl
  csvfeed
  xmlfeed

$ scrapy genspider example example.com
Created spider 'example' using template 'basic'

$ scrapy genspider -t crawl scrapyorg scrapy.org
Created spider 'scrapyorg' using template 'crawl'
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy crawl myspider
[ ... myspider starts crawling ... ]

$ scrapy -o myfile:csv myspider
[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]

$ scrapy -O myfile:json myspider
[ ... myspider starts crawling and saves the result in myfile in json format overwriting the original content... ]

$ scrapy -o myfile -t csv myspider
[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy check -l
first_spider
  * parse
  * parse_item
second_spider
  * parse
  * parse_item

$ scrapy check
[FAILED] first_spider:parse_item
&gt;&gt;&gt; 'RetailPricex' field is missing

[FAILED] first_spider:parse
&gt;&gt;&gt; Returned 92 requests, expected 0..4
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy list
spider1
spider2
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy edit spider1
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy fetch --nolog http://www.example.com/some/page.html
[ ... html content here ... ]

$ scrapy fetch --nolog --headers http://www.example.com/
{'Accept-Ranges': ['bytes'],
 'Age': ['1263   '],
 'Connection': ['close     '],
 'Content-Length': ['596'],
 'Content-Type': ['text/html; charset=UTF-8'],
 'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],
 'Etag': ['""573c1-254-48c9c87349680""'],
 'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],
 'Server': ['Apache/2.2.3 (CentOS)']}
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy view http://www.example.com/some/page.html
[ ... browser starts ... ]
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy shell http://www.example.com/some/page.html
[ ... scrapy shell starts ... ]

$ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)'
(200, 'http://www.example.com/')

# shell follows HTTP redirects by default
$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'
(200, 'http://example.com/')

# you can disable this with --no-redirect
# (only for the URL passed as command line argument)
$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'
(302, 'http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F')
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy parse http://www.example.com/ -c parse_item
[ ... scrapy log lines crawling example.com spider ... ]

&gt;&gt;&gt; STATUS DEPTH LEVEL 1 &lt;&lt;&lt;
# Scraped Items  ------------------------------------------------------------
[{'name': 'Example item',
 'category': 'Furniture',
 'length': '12 cm'}]

# Requests  -----------------------------------------------------------------
[]
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy settings --get BOT_NAME
scrapybot
$ scrapy settings --get DOWNLOAD_DELAY
0
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy runspider myspider.py
[ ... spider starts crawling ... ]
</pre></div>","scrapy <command> -h
,scrapy -h
,$ scrapy startproject myproject
,$ scrapy genspider -l
Available templates:
  basic
  crawl
  csvfeed
  xmlfeed

$ scrapy genspider example example.com
Created spider 'example' using template 'basic'

$ scrapy genspider -t crawl scrapyorg scrapy.org
Created spider 'scrapyorg' using template 'crawl'
,$ scrapy crawl myspider
[ ... myspider starts crawling ... ]

$ scrapy -o myfile:csv myspider
[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]

$ scrapy -O myfile:json myspider
[ ... myspider starts crawling and saves the result in myfile in json format overwriting the original content... ]

$ scrapy -o myfile -t csv myspider
[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]
,$ scrapy check -l
first_spider
  * parse
  * parse_item
second_spider
  * parse
  * parse_item

$ scrapy check
[FAILED] first_spider:parse_item
>>> 'RetailPricex' field is missing

[FAILED] first_spider:parse
>>> Returned 92 requests, expected 0..4
,$ scrapy list
spider1
spider2
,$ scrapy edit spider1
,$ scrapy fetch --nolog http://www.example.com/some/page.html
[ ... html content here ... ]

$ scrapy fetch --nolog --headers http://www.example.com/
{'Accept-Ranges': ['bytes'],
 'Age': ['1263   '],
 'Connection': ['close     '],
 'Content-Length': ['596'],
 'Content-Type': ['text/html; charset=UTF-8'],
 'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],
 'Etag': ['""573c1-254-48c9c87349680""'],
 'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],
 'Server': ['Apache/2.2.3 (CentOS)']}
,$ scrapy view http://www.example.com/some/page.html
[ ... browser starts ... ]
,$ scrapy shell http://www.example.com/some/page.html
[ ... scrapy shell starts ... ]

$ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)'
(200, 'http://www.example.com/')

# shell follows HTTP redirects by default
$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http://example.com/ -c '(response.status, response.url)'
(200, 'http://example.com/')

# you can disable this with --no-redirect
# (only for the URL passed as command line argument)
$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http://example.com/ -c '(response.status, response.url)'
(302, 'http://httpbin.org/redirect-to?url=http://example.com/')
,$ scrapy parse http://www.example.com/ -c parse_item
[ ... scrapy log lines crawling example.com spider ... ]

>>> STATUS DEPTH LEVEL 1 <<<
# Scraped Items  ------------------------------------------------------------
[{'name': 'Example item',
 'category': 'Furniture',
 'length': '12 cm'}]

# Requests  -----------------------------------------------------------------
[]
,$ scrapy settings --get BOT_NAME
scrapybot
$ scrapy settings --get DOWNLOAD_DELAY
0
,$ scrapy runspider myspider.py
[ ... spider starts crawling ... ]
",14
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,startproject,#startproject,"<div class=""highlight""><pre><span></span>$ scrapy startproject myproject
</pre></div>","$ scrapy startproject myproject
",1
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,genspider,#genspider,"<div class=""highlight""><pre><span></span>$ scrapy genspider -l
Available templates:
  basic
  crawl
  csvfeed
  xmlfeed

$ scrapy genspider example example.com
Created spider 'example' using template 'basic'

$ scrapy genspider -t crawl scrapyorg scrapy.org
Created spider 'scrapyorg' using template 'crawl'
</pre></div>","$ scrapy genspider -l
Available templates:
  basic
  crawl
  csvfeed
  xmlfeed

$ scrapy genspider example example.com
Created spider 'example' using template 'basic'

$ scrapy genspider -t crawl scrapyorg scrapy.org
Created spider 'scrapyorg' using template 'crawl'
",1
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,crawl,#crawl,"<div class=""highlight""><pre><span></span>$ scrapy crawl myspider
[ ... myspider starts crawling ... ]

$ scrapy -o myfile:csv myspider
[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]

$ scrapy -O myfile:json myspider
[ ... myspider starts crawling and saves the result in myfile in json format overwriting the original content... ]

$ scrapy -o myfile -t csv myspider
[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]
</pre></div>","$ scrapy crawl myspider
[ ... myspider starts crawling ... ]

$ scrapy -o myfile:csv myspider
[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]

$ scrapy -O myfile:json myspider
[ ... myspider starts crawling and saves the result in myfile in json format overwriting the original content... ]

$ scrapy -o myfile -t csv myspider
[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]
",1
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,check,#check,"<div class=""highlight""><pre><span></span>$ scrapy check -l
first_spider
  * parse
  * parse_item
second_spider
  * parse
  * parse_item

$ scrapy check
[FAILED] first_spider:parse_item
&gt;&gt;&gt; 'RetailPricex' field is missing

[FAILED] first_spider:parse
&gt;&gt;&gt; Returned 92 requests, expected 0..4
</pre></div>","$ scrapy check -l
first_spider
  * parse
  * parse_item
second_spider
  * parse
  * parse_item

$ scrapy check
[FAILED] first_spider:parse_item
>>> 'RetailPricex' field is missing

[FAILED] first_spider:parse
>>> Returned 92 requests, expected 0..4
",1
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,list,#list,"<div class=""highlight""><pre><span></span>$ scrapy list
spider1
spider2
</pre></div>","$ scrapy list
spider1
spider2
",1
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,edit,#edit,"<div class=""highlight""><pre><span></span>$ scrapy edit spider1
</pre></div>","$ scrapy edit spider1
",1
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,fetch,#fetch,"<div class=""highlight""><pre><span></span>$ scrapy fetch --nolog http://www.example.com/some/page.html
[ ... html content here ... ]

$ scrapy fetch --nolog --headers http://www.example.com/
{'Accept-Ranges': ['bytes'],
 'Age': ['1263   '],
 'Connection': ['close     '],
 'Content-Length': ['596'],
 'Content-Type': ['text/html; charset=UTF-8'],
 'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],
 'Etag': ['""573c1-254-48c9c87349680""'],
 'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],
 'Server': ['Apache/2.2.3 (CentOS)']}
</pre></div>","$ scrapy fetch --nolog http://www.example.com/some/page.html
[ ... html content here ... ]

$ scrapy fetch --nolog --headers http://www.example.com/
{'Accept-Ranges': ['bytes'],
 'Age': ['1263   '],
 'Connection': ['close     '],
 'Content-Length': ['596'],
 'Content-Type': ['text/html; charset=UTF-8'],
 'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],
 'Etag': ['""573c1-254-48c9c87349680""'],
 'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],
 'Server': ['Apache/2.2.3 (CentOS)']}
",1
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,view,#view,"<div class=""highlight""><pre><span></span>$ scrapy view http://www.example.com/some/page.html
[ ... browser starts ... ]
</pre></div>","$ scrapy view http://www.example.com/some/page.html
[ ... browser starts ... ]
",1
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,shell,#shell,"<div class=""highlight""><pre><span></span>$ scrapy shell http://www.example.com/some/page.html
[ ... scrapy shell starts ... ]

$ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)'
(200, 'http://www.example.com/')

# shell follows HTTP redirects by default
$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'
(200, 'http://example.com/')

# you can disable this with --no-redirect
# (only for the URL passed as command line argument)
$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'
(302, 'http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F')
</pre></div>","$ scrapy shell http://www.example.com/some/page.html
[ ... scrapy shell starts ... ]

$ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)'
(200, 'http://www.example.com/')

# shell follows HTTP redirects by default
$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http://example.com/ -c '(response.status, response.url)'
(200, 'http://example.com/')

# you can disable this with --no-redirect
# (only for the URL passed as command line argument)
$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http://example.com/ -c '(response.status, response.url)'
(302, 'http://httpbin.org/redirect-to?url=http://example.com/')
",1
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,parse,#parse,"<div class=""highlight""><pre><span></span>$ scrapy parse http://www.example.com/ -c parse_item
[ ... scrapy log lines crawling example.com spider ... ]

&gt;&gt;&gt; STATUS DEPTH LEVEL 1 &lt;&lt;&lt;
# Scraped Items  ------------------------------------------------------------
[{'name': 'Example item',
 'category': 'Furniture',
 'length': '12 cm'}]

# Requests  -----------------------------------------------------------------
[]
</pre></div>","$ scrapy parse http://www.example.com/ -c parse_item
[ ... scrapy log lines crawling example.com spider ... ]

>>> STATUS DEPTH LEVEL 1 <<<
# Scraped Items  ------------------------------------------------------------
[{'name': 'Example item',
 'category': 'Furniture',
 'length': '12 cm'}]

# Requests  -----------------------------------------------------------------
[]
",1
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,settings,#settings,"<div class=""highlight""><pre><span></span>$ scrapy settings --get BOT_NAME
scrapybot
$ scrapy settings --get DOWNLOAD_DELAY
0
</pre></div>","$ scrapy settings --get BOT_NAME
scrapybot
$ scrapy settings --get DOWNLOAD_DELAY
0
",1
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,runspider,#runspider,"<div class=""highlight""><pre><span></span>$ scrapy runspider myspider.py
[ ... spider starts crawling ... ]
</pre></div>","$ scrapy runspider myspider.py
[ ... spider starts crawling ... ]
",1
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,version,#version,,,21
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,bench,#bench,,,22
https://docs.scrapy.org/en/latest/topics/commands.html,,##,2,Custom project commands,#custom-project-commands,"<div class=""highlight""><pre><span></span><span class=""n"">COMMANDS_MODULE</span> <span class=""o"">=</span> <span class=""s1"">'mybot.commands'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">setuptools</span> <span class=""kn"">import</span> <span class=""n"">setup</span><span class=""p"">,</span> <span class=""n"">find_packages</span>

<span class=""n"">setup</span><span class=""p"">(</span><span class=""n"">name</span><span class=""o"">=</span><span class=""s1"">'scrapy-mymodule'</span><span class=""p"">,</span>
  <span class=""n"">entry_points</span><span class=""o"">=</span><span class=""p"">{</span>
    <span class=""s1"">'scrapy.commands'</span><span class=""p"">:</span> <span class=""p"">[</span>
      <span class=""s1"">'my_command=my_scrapy_module.commands:MyCommand'</span><span class=""p"">,</span>
    <span class=""p"">],</span>
  <span class=""p"">},</span>
 <span class=""p"">)</span>
</pre></div>","COMMANDS_MODULE = 'mybot.commands'
,from setuptools import setup, find_packages

setup(name='scrapy-mymodule',
  entry_points={
    'scrapy.commands': [
      'my_command=my_scrapy_module.commands:MyCommand',
    ],
  },
 )
",2
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,COMMANDS_MODULE,#commands-module,"<div class=""highlight""><pre><span></span><span class=""n"">COMMANDS_MODULE</span> <span class=""o"">=</span> <span class=""s1"">'mybot.commands'</span>
</pre></div>","COMMANDS_MODULE = 'mybot.commands'
",1
https://docs.scrapy.org/en/latest/topics/commands.html,,###,3,Register commands via setup.py entry points,#register-commands-via-setup-py-entry-points,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">setuptools</span> <span class=""kn"">import</span> <span class=""n"">setup</span><span class=""p"">,</span> <span class=""n"">find_packages</span>

<span class=""n"">setup</span><span class=""p"">(</span><span class=""n"">name</span><span class=""o"">=</span><span class=""s1"">'scrapy-mymodule'</span><span class=""p"">,</span>
  <span class=""n"">entry_points</span><span class=""o"">=</span><span class=""p"">{</span>
    <span class=""s1"">'scrapy.commands'</span><span class=""p"">:</span> <span class=""p"">[</span>
      <span class=""s1"">'my_command=my_scrapy_module.commands:MyCommand'</span><span class=""p"">,</span>
    <span class=""p"">],</span>
  <span class=""p"">},</span>
 <span class=""p"">)</span>
</pre></div>","from setuptools import setup, find_packages

setup(name='scrapy-mymodule',
  entry_points={
    'scrapy.commands': [
      'my_command=my_scrapy_module.commands:MyCommand',
    ],
  },
 )
",1
https://docs.scrapy.org/en/latest/topics/spiders.html,,#,1,Spiders,#spiders,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">FormRequest</span><span class=""p"">(</span><span class=""s2"">""http://www.example.com/login""</span><span class=""p"">,</span>
                                   <span class=""n"">formdata</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'user'</span><span class=""p"">:</span> <span class=""s1"">'john'</span><span class=""p"">,</span> <span class=""s1"">'pass'</span><span class=""p"">:</span> <span class=""s1"">'secret'</span><span class=""p"">},</span>
                                   <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logged_in</span><span class=""p"">)]</span>

    <span class=""k"">def</span> <span class=""nf"">logged_in</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""c1""># here you would extract links to follow and return Requests for</span>
        <span class=""c1""># each of them, with another callback</span>
        <span class=""k"">pass</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'http://www.example.com/1.html'</span><span class=""p"">,</span>
        <span class=""s1"">'http://www.example.com/2.html'</span><span class=""p"">,</span>
        <span class=""s1"">'http://www.example.com/3.html'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'A response from </span><span class=""si"">%s</span><span class=""s1""> just arrived!'</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'http://www.example.com/1.html'</span><span class=""p"">,</span>
        <span class=""s1"">'http://www.example.com/2.html'</span><span class=""p"">,</span>
        <span class=""s1"">'http://www.example.com/3.html'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">h3</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//h3'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">():</span>
            <span class=""k"">yield</span> <span class=""p"">{</span><span class=""s2"">""title""</span><span class=""p"">:</span> <span class=""n"">h3</span><span class=""p"">}</span>

        <span class=""k"">for</span> <span class=""n"">href</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a/@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">():</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">urljoin</span><span class=""p"">(</span><span class=""n"">href</span><span class=""p"">),</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.items</span> <span class=""kn"">import</span> <span class=""n"">MyItem</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s1"">'http://www.example.com/1.html'</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
        <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s1"">'http://www.example.com/2.html'</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
        <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s1"">'http://www.example.com/3.html'</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">h3</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//h3'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">():</span>
            <span class=""k"">yield</span> <span class=""n"">MyItem</span><span class=""p"">(</span><span class=""n"">title</span><span class=""o"">=</span><span class=""n"">h3</span><span class=""p"">)</span>

        <span class=""k"">for</span> <span class=""n"">href</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a/@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">():</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">urljoin</span><span class=""p"">(</span><span class=""n"">href</span><span class=""p"">),</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">myspider</span> <span class=""o"">-</span><span class=""n"">a</span> <span class=""n"">category</span><span class=""o"">=</span><span class=""n"">electronics</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">category</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""nb"">super</span><span class=""p"">(</span><span class=""n"">MySpider</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""p"">)</span><span class=""o"">.</span><span class=""fm"">__init__</span><span class=""p"">(</span><span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">)</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""sa"">f</span><span class=""s1"">'http://www.example.com/categories/</span><span class=""si"">{</span><span class=""n"">category</span><span class=""si"">}</span><span class=""s1"">'</span><span class=""p"">]</span>
        <span class=""c1""># ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s1"">'http://www.example.com/categories/</span><span class=""si"">{</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">category</span><span class=""si"">}</span><span class=""s1"">'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">process</span> <span class=""o"">=</span> <span class=""n"">CrawlerProcess</span><span class=""p"">()</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider</span><span class=""p"">,</span> <span class=""n"">category</span><span class=""o"">=</span><span class=""s2"">""electronics""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">myspider</span> <span class=""o"">-</span><span class=""n"">a</span> <span class=""n"">http_user</span><span class=""o"">=</span><span class=""n"">myuser</span> <span class=""o"">-</span><span class=""n"">a</span> <span class=""n"">http_pass</span><span class=""o"">=</span><span class=""n"">mypassword</span> <span class=""o"">-</span><span class=""n"">a</span> <span class=""n"">user_agent</span><span class=""o"">=</span><span class=""n"">mybot</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">TestItem</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""nb"">id</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">description</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">CrawlSpider</span><span class=""p"">,</span> <span class=""n"">Rule</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.linkextractors</span> <span class=""kn"">import</span> <span class=""n"">LinkExtractor</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">CrawlSpider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com'</span><span class=""p"">]</span>

    <span class=""n"">rules</span> <span class=""o"">=</span> <span class=""p"">(</span>
        <span class=""c1""># Extract links matching 'category.php' (but not matching 'subsection.php')</span>
        <span class=""c1""># and follow links from them (since no callback means follow=True by default).</span>
        <span class=""n"">Rule</span><span class=""p"">(</span><span class=""n"">LinkExtractor</span><span class=""p"">(</span><span class=""n"">allow</span><span class=""o"">=</span><span class=""p"">(</span><span class=""s1"">'category\.php'</span><span class=""p"">,</span> <span class=""p"">),</span> <span class=""n"">deny</span><span class=""o"">=</span><span class=""p"">(</span><span class=""s1"">'subsection\.php'</span><span class=""p"">,</span> <span class=""p"">))),</span>

        <span class=""c1""># Extract links matching 'item.php' and parse them with the spider's method parse_item</span>
        <span class=""n"">Rule</span><span class=""p"">(</span><span class=""n"">LinkExtractor</span><span class=""p"">(</span><span class=""n"">allow</span><span class=""o"">=</span><span class=""p"">(</span><span class=""s1"">'item\.php'</span><span class=""p"">,</span> <span class=""p"">)),</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""s1"">'parse_item'</span><span class=""p"">),</span>
    <span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Hi, this is an item page! </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
        <span class=""n"">item</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//td[@id=""item_id""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'ID: (\d+)'</span><span class=""p"">)</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//td[@id=""item_name""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'description'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//td[@id=""item_description""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'link_text'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">meta</span><span class=""p"">[</span><span class=""s1"">'link_text'</span><span class=""p"">]</span>
        <span class=""n"">url</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//td[@id=""additional_data""]/@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_additional_page</span><span class=""p"">,</span> <span class=""n"">cb_kwargs</span><span class=""o"">=</span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">item</span><span class=""o"">=</span><span class=""n"">item</span><span class=""p"">))</span>

    <span class=""k"">def</span> <span class=""nf"">parse_additional_page</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">):</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'additional_data'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p[@id=""additional_data""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">itertag</span> <span class=""o"">=</span> <span class=""s1"">'product'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">YourSpider</span><span class=""p"">(</span><span class=""n"">XMLFeedSpider</span><span class=""p"">):</span>

    <span class=""n"">namespaces</span> <span class=""o"">=</span> <span class=""p"">[(</span><span class=""s1"">'n'</span><span class=""p"">,</span> <span class=""s1"">'http://www.sitemaps.org/schemas/sitemap/0.9'</span><span class=""p"">)]</span>
    <span class=""n"">itertag</span> <span class=""o"">=</span> <span class=""s1"">'n:url'</span>
    <span class=""c1""># ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">XMLFeedSpider</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.items</span> <span class=""kn"">import</span> <span class=""n"">TestItem</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">XMLFeedSpider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/feed.xml'</span><span class=""p"">]</span>
    <span class=""n"">iterator</span> <span class=""o"">=</span> <span class=""s1"">'iternodes'</span>  <span class=""c1""># This is actually unnecessary, since it's the default value</span>
    <span class=""n"">itertag</span> <span class=""o"">=</span> <span class=""s1"">'item'</span>

    <span class=""k"">def</span> <span class=""nf"">parse_node</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">node</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Hi, this is a &lt;</span><span class=""si"">%s</span><span class=""s1"">&gt; node!: </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">itertag</span><span class=""p"">,</span> <span class=""s1"">''</span><span class=""o"">.</span><span class=""n"">join</span><span class=""p"">(</span><span class=""n"">node</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()))</span>

        <span class=""n"">item</span> <span class=""o"">=</span> <span class=""n"">TestItem</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">node</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'@id'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">node</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'description'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">node</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'description'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">CSVFeedSpider</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.items</span> <span class=""kn"">import</span> <span class=""n"">TestItem</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">CSVFeedSpider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/feed.csv'</span><span class=""p"">]</span>
    <span class=""n"">delimiter</span> <span class=""o"">=</span> <span class=""s1"">';'</span>
    <span class=""n"">quotechar</span> <span class=""o"">=</span> <span class=""s2"">""'""</span>
    <span class=""n"">headers</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">,</span> <span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'description'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse_row</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">row</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Hi, this is a row!: </span><span class=""si"">%r</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">row</span><span class=""p"">)</span>

        <span class=""n"">item</span> <span class=""o"">=</span> <span class=""n"">TestItem</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">row</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">row</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'description'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">row</span><span class=""p"">[</span><span class=""s1"">'description'</span><span class=""p"">]</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sitemap_rules</span> <span class=""o"">=</span> <span class=""p"">[(</span><span class=""s1"">'/product/'</span><span class=""p"">,</span> <span class=""s1"">'parse_product'</span><span class=""p"">)]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">url</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">loc</span><span class=""o"">&gt;</span><span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/&lt;/</span><span class=""n"">loc</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">xhtml</span><span class=""p"">:</span><span class=""n"">link</span> <span class=""n"">rel</span><span class=""o"">=</span><span class=""s2"">""alternate""</span> <span class=""n"">hreflang</span><span class=""o"">=</span><span class=""s2"">""de""</span> <span class=""n"">href</span><span class=""o"">=</span><span class=""s2"">""http://example.com/de""</span><span class=""o"">/&gt;</span>
<span class=""o"">&lt;/</span><span class=""n"">url</span><span class=""o"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">url</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">loc</span><span class=""o"">&gt;</span><span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/&lt;/</span><span class=""n"">loc</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">lastmod</span><span class=""o"">&gt;</span><span class=""mi"">2005</span><span class=""o"">-</span><span class=""mi"">01</span><span class=""o"">-</span><span class=""mi"">01</span><span class=""o"">&lt;/</span><span class=""n"">lastmod</span><span class=""o"">&gt;</span>
<span class=""o"">&lt;/</span><span class=""n"">url</span><span class=""o"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">datetime</span> <span class=""kn"">import</span> <span class=""n"">datetime</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">FilteredSitemapSpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'filtered_sitemap_spider'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://example.com/sitemap.xml'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">sitemap_filter</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">entries</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">entry</span> <span class=""ow"">in</span> <span class=""n"">entries</span><span class=""p"">:</span>
            <span class=""n"">date_time</span> <span class=""o"">=</span> <span class=""n"">datetime</span><span class=""o"">.</span><span class=""n"">strptime</span><span class=""p"">(</span><span class=""n"">entry</span><span class=""p"">[</span><span class=""s1"">'lastmod'</span><span class=""p"">],</span> <span class=""s1"">'%Y-%m-</span><span class=""si"">%d</span><span class=""s1"">'</span><span class=""p"">)</span>
            <span class=""k"">if</span> <span class=""n"">date_time</span><span class=""o"">.</span><span class=""n"">year</span> <span class=""o"">&gt;=</span> <span class=""mi"">2005</span><span class=""p"">:</span>
                <span class=""k"">yield</span> <span class=""n"">entry</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/sitemap.xml'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape item here ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/sitemap.xml'</span><span class=""p"">]</span>
    <span class=""n"">sitemap_rules</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""p"">(</span><span class=""s1"">'/product/'</span><span class=""p"">,</span> <span class=""s1"">'parse_product'</span><span class=""p"">),</span>
        <span class=""p"">(</span><span class=""s1"">'/category/'</span><span class=""p"">,</span> <span class=""s1"">'parse_category'</span><span class=""p"">),</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse_product</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape product ...</span>

    <span class=""k"">def</span> <span class=""nf"">parse_category</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape category ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/robots.txt'</span><span class=""p"">]</span>
    <span class=""n"">sitemap_rules</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""p"">(</span><span class=""s1"">'/shop/'</span><span class=""p"">,</span> <span class=""s1"">'parse_shop'</span><span class=""p"">),</span>
    <span class=""p"">]</span>
    <span class=""n"">sitemap_follow</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'/sitemap_shops'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse_shop</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape shop here ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/robots.txt'</span><span class=""p"">]</span>
    <span class=""n"">sitemap_rules</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""p"">(</span><span class=""s1"">'/shop/'</span><span class=""p"">,</span> <span class=""s1"">'parse_shop'</span><span class=""p"">),</span>
    <span class=""p"">]</span>

    <span class=""n"">other_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/about'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""n"">requests</span> <span class=""o"">=</span> <span class=""nb"">list</span><span class=""p"">(</span><span class=""nb"">super</span><span class=""p"">(</span><span class=""n"">MySpider</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">start_requests</span><span class=""p"">())</span>
        <span class=""n"">requests</span> <span class=""o"">+=</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">x</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_other</span><span class=""p"">)</span> <span class=""k"">for</span> <span class=""n"">x</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">other_urls</span><span class=""p"">]</span>
        <span class=""k"">return</span> <span class=""n"">requests</span>

    <span class=""k"">def</span> <span class=""nf"">parse_shop</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape shop here ...</span>

    <span class=""k"">def</span> <span class=""nf"">parse_other</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape other here ...</span>
</pre></div>","class MySpider(scrapy.Spider):
    name = 'myspider'

    def start_requests(self):
        return [scrapy.FormRequest(""http://www.example.com/login"",
                                   formdata={'user': 'john', 'pass': 'secret'},
                                   callback=self.logged_in)]

    def logged_in(self, response):
        # here you would extract links to follow and return Requests for
        # each of them, with another callback
        pass
,import scrapy


class MySpider(scrapy.Spider):
    name = 'example.com'
    allowed_domains = ['example.com']
    start_urls = [
        'http://www.example.com/1.html',
        'http://www.example.com/2.html',
        'http://www.example.com/3.html',
    ]

    def parse(self, response):
        self.logger.info('A response from %s just arrived!', response.url)
,import scrapy

class MySpider(scrapy.Spider):
    name = 'example.com'
    allowed_domains = ['example.com']
    start_urls = [
        'http://www.example.com/1.html',
        'http://www.example.com/2.html',
        'http://www.example.com/3.html',
    ]

    def parse(self, response):
        for h3 in response.xpath('//h3').getall():
            yield {""title"": h3}

        for href in response.xpath('//a/@href').getall():
            yield scrapy.Request(response.urljoin(href), self.parse)
,import scrapy
from myproject.items import MyItem

class MySpider(scrapy.Spider):
    name = 'example.com'
    allowed_domains = ['example.com']

    def start_requests(self):
        yield scrapy.Request('http://www.example.com/1.html', self.parse)
        yield scrapy.Request('http://www.example.com/2.html', self.parse)
        yield scrapy.Request('http://www.example.com/3.html', self.parse)

    def parse(self, response):
        for h3 in response.xpath('//h3').getall():
            yield MyItem(title=h3)

        for href in response.xpath('//a/@href').getall():
            yield scrapy.Request(response.urljoin(href), self.parse)
,scrapy crawl myspider -a category=electronics
,import scrapy

class MySpider(scrapy.Spider):
    name = 'myspider'

    def __init__(self, category=None, *args, **kwargs):
        super(MySpider, self).__init__(*args, **kwargs)
        self.start_urls = [f'http://www.example.com/categories/{category}']
        # ...
,import scrapy

class MySpider(scrapy.Spider):
    name = 'myspider'

    def start_requests(self):
        yield scrapy.Request(f'http://www.example.com/categories/{self.category}')
,process = CrawlerProcess()
process.crawl(MySpider, category=""electronics"")
,scrapy crawl myspider -a http_user=myuser -a http_pass=mypassword -a user_agent=mybot
,import scrapy

class TestItem(scrapy.Item):
    id = scrapy.Field()
    name = scrapy.Field()
    description = scrapy.Field()
,import scrapy
from scrapy.spiders import CrawlSpider, Rule
from scrapy.linkextractors import LinkExtractor

class MySpider(CrawlSpider):
    name = 'example.com'
    allowed_domains = ['example.com']
    start_urls = ['http://www.example.com']

    rules = (
        # Extract links matching 'category.php' (but not matching 'subsection.php')
        # and follow links from them (since no callback means follow=True by default).
        Rule(LinkExtractor(allow=('category\.php', ), deny=('subsection\.php', ))),

        # Extract links matching 'item.php' and parse them with the spider's method parse_item
        Rule(LinkExtractor(allow=('item\.php', )), callback='parse_item'),
    )

    def parse_item(self, response):
        self.logger.info('Hi, this is an item page! %s', response.url)
        item = scrapy.Item()
        item['id'] = response.xpath('//td[@id=""item_id""]/text()').re(r'ID: (\d+)')
        item['name'] = response.xpath('//td[@id=""item_name""]/text()').get()
        item['description'] = response.xpath('//td[@id=""item_description""]/text()').get()
        item['link_text'] = response.meta['link_text']
        url = response.xpath('//td[@id=""additional_data""]/@href').get()
        return response.follow(url, self.parse_additional_page, cb_kwargs=dict(item=item))

    def parse_additional_page(self, response, item):
        item['additional_data'] = response.xpath('//p[@id=""additional_data""]/text()').get()
        return item
,itertag = 'product'
,class YourSpider(XMLFeedSpider):

    namespaces = [('n', 'http://www.sitemaps.org/schemas/sitemap/0.9')]
    itertag = 'n:url'
    # ...
,from scrapy.spiders import XMLFeedSpider
from myproject.items import TestItem

class MySpider(XMLFeedSpider):
    name = 'example.com'
    allowed_domains = ['example.com']
    start_urls = ['http://www.example.com/feed.xml']
    iterator = 'iternodes'  # This is actually unnecessary, since it's the default value
    itertag = 'item'

    def parse_node(self, response, node):
        self.logger.info('Hi, this is a <%s> node!: %s', self.itertag, ''.join(node.getall()))

        item = TestItem()
        item['id'] = node.xpath('@id').get()
        item['name'] = node.xpath('name').get()
        item['description'] = node.xpath('description').get()
        return item
,from scrapy.spiders import CSVFeedSpider
from myproject.items import TestItem

class MySpider(CSVFeedSpider):
    name = 'example.com'
    allowed_domains = ['example.com']
    start_urls = ['http://www.example.com/feed.csv']
    delimiter = ';'
    quotechar = ""'""
    headers = ['id', 'name', 'description']

    def parse_row(self, response, row):
        self.logger.info('Hi, this is a row!: %r', row)

        item = TestItem()
        item['id'] = row['id']
        item['name'] = row['name']
        item['description'] = row['description']
        return item
,sitemap_rules = [('/product/', 'parse_product')]
,<url>
    <loc>http://example.com/</loc>
    <xhtml:link rel=""alternate"" hreflang=""de"" href=""http://example.com/de""/>
</url>
,<url>
    <loc>http://example.com/</loc>
    <lastmod>2005-01-01</lastmod>
</url>
,from datetime import datetime
from scrapy.spiders import SitemapSpider

class FilteredSitemapSpider(SitemapSpider):
    name = 'filtered_sitemap_spider'
    allowed_domains = ['example.com']
    sitemap_urls = ['http://example.com/sitemap.xml']

    def sitemap_filter(self, entries):
        for entry in entries:
            date_time = datetime.strptime(entry['lastmod'], '%Y-%m-%d')
            if date_time.year >= 2005:
                yield entry
,from scrapy.spiders import SitemapSpider

class MySpider(SitemapSpider):
    sitemap_urls = ['http://www.example.com/sitemap.xml']

    def parse(self, response):
        pass # ... scrape item here ...
,from scrapy.spiders import SitemapSpider

class MySpider(SitemapSpider):
    sitemap_urls = ['http://www.example.com/sitemap.xml']
    sitemap_rules = [
        ('/product/', 'parse_product'),
        ('/category/', 'parse_category'),
    ]

    def parse_product(self, response):
        pass # ... scrape product ...

    def parse_category(self, response):
        pass # ... scrape category ...
,from scrapy.spiders import SitemapSpider

class MySpider(SitemapSpider):
    sitemap_urls = ['http://www.example.com/robots.txt']
    sitemap_rules = [
        ('/shop/', 'parse_shop'),
    ]
    sitemap_follow = ['/sitemap_shops']

    def parse_shop(self, response):
        pass # ... scrape shop here ...
,from scrapy.spiders import SitemapSpider

class MySpider(SitemapSpider):
    sitemap_urls = ['http://www.example.com/robots.txt']
    sitemap_rules = [
        ('/shop/', 'parse_shop'),
    ]

    other_urls = ['http://www.example.com/about']

    def start_requests(self):
        requests = list(super(MySpider, self).start_requests())
        requests += [scrapy.Request(x, self.parse_other) for x in self.other_urls]
        return requests

    def parse_shop(self, response):
        pass # ... scrape shop here ...

    def parse_other(self, response):
        pass # ... scrape other here ...
",23
https://docs.scrapy.org/en/latest/topics/spiders.html,,##,2,scrapy.Spider,#scrapy-spider,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">FormRequest</span><span class=""p"">(</span><span class=""s2"">""http://www.example.com/login""</span><span class=""p"">,</span>
                                   <span class=""n"">formdata</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'user'</span><span class=""p"">:</span> <span class=""s1"">'john'</span><span class=""p"">,</span> <span class=""s1"">'pass'</span><span class=""p"">:</span> <span class=""s1"">'secret'</span><span class=""p"">},</span>
                                   <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logged_in</span><span class=""p"">)]</span>

    <span class=""k"">def</span> <span class=""nf"">logged_in</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""c1""># here you would extract links to follow and return Requests for</span>
        <span class=""c1""># each of them, with another callback</span>
        <span class=""k"">pass</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'http://www.example.com/1.html'</span><span class=""p"">,</span>
        <span class=""s1"">'http://www.example.com/2.html'</span><span class=""p"">,</span>
        <span class=""s1"">'http://www.example.com/3.html'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'A response from </span><span class=""si"">%s</span><span class=""s1""> just arrived!'</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s1"">'http://www.example.com/1.html'</span><span class=""p"">,</span>
        <span class=""s1"">'http://www.example.com/2.html'</span><span class=""p"">,</span>
        <span class=""s1"">'http://www.example.com/3.html'</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">h3</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//h3'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">():</span>
            <span class=""k"">yield</span> <span class=""p"">{</span><span class=""s2"">""title""</span><span class=""p"">:</span> <span class=""n"">h3</span><span class=""p"">}</span>

        <span class=""k"">for</span> <span class=""n"">href</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a/@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">():</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">urljoin</span><span class=""p"">(</span><span class=""n"">href</span><span class=""p"">),</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.items</span> <span class=""kn"">import</span> <span class=""n"">MyItem</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s1"">'http://www.example.com/1.html'</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
        <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s1"">'http://www.example.com/2.html'</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
        <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s1"">'http://www.example.com/3.html'</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">h3</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//h3'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">():</span>
            <span class=""k"">yield</span> <span class=""n"">MyItem</span><span class=""p"">(</span><span class=""n"">title</span><span class=""o"">=</span><span class=""n"">h3</span><span class=""p"">)</span>

        <span class=""k"">for</span> <span class=""n"">href</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a/@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">():</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">urljoin</span><span class=""p"">(</span><span class=""n"">href</span><span class=""p"">),</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>","class MySpider(scrapy.Spider):
    name = 'myspider'

    def start_requests(self):
        return [scrapy.FormRequest(""http://www.example.com/login"",
                                   formdata={'user': 'john', 'pass': 'secret'},
                                   callback=self.logged_in)]

    def logged_in(self, response):
        # here you would extract links to follow and return Requests for
        # each of them, with another callback
        pass
,import scrapy


class MySpider(scrapy.Spider):
    name = 'example.com'
    allowed_domains = ['example.com']
    start_urls = [
        'http://www.example.com/1.html',
        'http://www.example.com/2.html',
        'http://www.example.com/3.html',
    ]

    def parse(self, response):
        self.logger.info('A response from %s just arrived!', response.url)
,import scrapy

class MySpider(scrapy.Spider):
    name = 'example.com'
    allowed_domains = ['example.com']
    start_urls = [
        'http://www.example.com/1.html',
        'http://www.example.com/2.html',
        'http://www.example.com/3.html',
    ]

    def parse(self, response):
        for h3 in response.xpath('//h3').getall():
            yield {""title"": h3}

        for href in response.xpath('//a/@href').getall():
            yield scrapy.Request(response.urljoin(href), self.parse)
,import scrapy
from myproject.items import MyItem

class MySpider(scrapy.Spider):
    name = 'example.com'
    allowed_domains = ['example.com']

    def start_requests(self):
        yield scrapy.Request('http://www.example.com/1.html', self.parse)
        yield scrapy.Request('http://www.example.com/2.html', self.parse)
        yield scrapy.Request('http://www.example.com/3.html', self.parse)

    def parse(self, response):
        for h3 in response.xpath('//h3').getall():
            yield MyItem(title=h3)

        for href in response.xpath('//a/@href').getall():
            yield scrapy.Request(response.urljoin(href), self.parse)
",4
https://docs.scrapy.org/en/latest/topics/spiders.html,,##,2,Spider arguments,#spider-arguments,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">myspider</span> <span class=""o"">-</span><span class=""n"">a</span> <span class=""n"">category</span><span class=""o"">=</span><span class=""n"">electronics</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">category</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""nb"">super</span><span class=""p"">(</span><span class=""n"">MySpider</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""p"">)</span><span class=""o"">.</span><span class=""fm"">__init__</span><span class=""p"">(</span><span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">)</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""sa"">f</span><span class=""s1"">'http://www.example.com/categories/</span><span class=""si"">{</span><span class=""n"">category</span><span class=""si"">}</span><span class=""s1"">'</span><span class=""p"">]</span>
        <span class=""c1""># ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s1"">'http://www.example.com/categories/</span><span class=""si"">{</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">category</span><span class=""si"">}</span><span class=""s1"">'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">process</span> <span class=""o"">=</span> <span class=""n"">CrawlerProcess</span><span class=""p"">()</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider</span><span class=""p"">,</span> <span class=""n"">category</span><span class=""o"">=</span><span class=""s2"">""electronics""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">myspider</span> <span class=""o"">-</span><span class=""n"">a</span> <span class=""n"">http_user</span><span class=""o"">=</span><span class=""n"">myuser</span> <span class=""o"">-</span><span class=""n"">a</span> <span class=""n"">http_pass</span><span class=""o"">=</span><span class=""n"">mypassword</span> <span class=""o"">-</span><span class=""n"">a</span> <span class=""n"">user_agent</span><span class=""o"">=</span><span class=""n"">mybot</span>
</pre></div>","scrapy crawl myspider -a category=electronics
,import scrapy

class MySpider(scrapy.Spider):
    name = 'myspider'

    def __init__(self, category=None, *args, **kwargs):
        super(MySpider, self).__init__(*args, **kwargs)
        self.start_urls = [f'http://www.example.com/categories/{category}']
        # ...
,import scrapy

class MySpider(scrapy.Spider):
    name = 'myspider'

    def start_requests(self):
        yield scrapy.Request(f'http://www.example.com/categories/{self.category}')
,process = CrawlerProcess()
process.crawl(MySpider, category=""electronics"")
,scrapy crawl myspider -a http_user=myuser -a http_pass=mypassword -a user_agent=mybot
",5
https://docs.scrapy.org/en/latest/topics/spiders.html,,##,2,Generic Spiders,#generic-spiders,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">TestItem</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""nb"">id</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">description</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">CrawlSpider</span><span class=""p"">,</span> <span class=""n"">Rule</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.linkextractors</span> <span class=""kn"">import</span> <span class=""n"">LinkExtractor</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">CrawlSpider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com'</span><span class=""p"">]</span>

    <span class=""n"">rules</span> <span class=""o"">=</span> <span class=""p"">(</span>
        <span class=""c1""># Extract links matching 'category.php' (but not matching 'subsection.php')</span>
        <span class=""c1""># and follow links from them (since no callback means follow=True by default).</span>
        <span class=""n"">Rule</span><span class=""p"">(</span><span class=""n"">LinkExtractor</span><span class=""p"">(</span><span class=""n"">allow</span><span class=""o"">=</span><span class=""p"">(</span><span class=""s1"">'category\.php'</span><span class=""p"">,</span> <span class=""p"">),</span> <span class=""n"">deny</span><span class=""o"">=</span><span class=""p"">(</span><span class=""s1"">'subsection\.php'</span><span class=""p"">,</span> <span class=""p"">))),</span>

        <span class=""c1""># Extract links matching 'item.php' and parse them with the spider's method parse_item</span>
        <span class=""n"">Rule</span><span class=""p"">(</span><span class=""n"">LinkExtractor</span><span class=""p"">(</span><span class=""n"">allow</span><span class=""o"">=</span><span class=""p"">(</span><span class=""s1"">'item\.php'</span><span class=""p"">,</span> <span class=""p"">)),</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""s1"">'parse_item'</span><span class=""p"">),</span>
    <span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Hi, this is an item page! </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
        <span class=""n"">item</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//td[@id=""item_id""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'ID: (\d+)'</span><span class=""p"">)</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//td[@id=""item_name""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'description'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//td[@id=""item_description""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'link_text'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">meta</span><span class=""p"">[</span><span class=""s1"">'link_text'</span><span class=""p"">]</span>
        <span class=""n"">url</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//td[@id=""additional_data""]/@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_additional_page</span><span class=""p"">,</span> <span class=""n"">cb_kwargs</span><span class=""o"">=</span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">item</span><span class=""o"">=</span><span class=""n"">item</span><span class=""p"">))</span>

    <span class=""k"">def</span> <span class=""nf"">parse_additional_page</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">):</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'additional_data'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p[@id=""additional_data""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">itertag</span> <span class=""o"">=</span> <span class=""s1"">'product'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">YourSpider</span><span class=""p"">(</span><span class=""n"">XMLFeedSpider</span><span class=""p"">):</span>

    <span class=""n"">namespaces</span> <span class=""o"">=</span> <span class=""p"">[(</span><span class=""s1"">'n'</span><span class=""p"">,</span> <span class=""s1"">'http://www.sitemaps.org/schemas/sitemap/0.9'</span><span class=""p"">)]</span>
    <span class=""n"">itertag</span> <span class=""o"">=</span> <span class=""s1"">'n:url'</span>
    <span class=""c1""># ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">XMLFeedSpider</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.items</span> <span class=""kn"">import</span> <span class=""n"">TestItem</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">XMLFeedSpider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/feed.xml'</span><span class=""p"">]</span>
    <span class=""n"">iterator</span> <span class=""o"">=</span> <span class=""s1"">'iternodes'</span>  <span class=""c1""># This is actually unnecessary, since it's the default value</span>
    <span class=""n"">itertag</span> <span class=""o"">=</span> <span class=""s1"">'item'</span>

    <span class=""k"">def</span> <span class=""nf"">parse_node</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">node</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Hi, this is a &lt;</span><span class=""si"">%s</span><span class=""s1"">&gt; node!: </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">itertag</span><span class=""p"">,</span> <span class=""s1"">''</span><span class=""o"">.</span><span class=""n"">join</span><span class=""p"">(</span><span class=""n"">node</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()))</span>

        <span class=""n"">item</span> <span class=""o"">=</span> <span class=""n"">TestItem</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">node</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'@id'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">node</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'description'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">node</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'description'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">CSVFeedSpider</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.items</span> <span class=""kn"">import</span> <span class=""n"">TestItem</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">CSVFeedSpider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/feed.csv'</span><span class=""p"">]</span>
    <span class=""n"">delimiter</span> <span class=""o"">=</span> <span class=""s1"">';'</span>
    <span class=""n"">quotechar</span> <span class=""o"">=</span> <span class=""s2"">""'""</span>
    <span class=""n"">headers</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">,</span> <span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'description'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse_row</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">row</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Hi, this is a row!: </span><span class=""si"">%r</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">row</span><span class=""p"">)</span>

        <span class=""n"">item</span> <span class=""o"">=</span> <span class=""n"">TestItem</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">row</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">row</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'description'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">row</span><span class=""p"">[</span><span class=""s1"">'description'</span><span class=""p"">]</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sitemap_rules</span> <span class=""o"">=</span> <span class=""p"">[(</span><span class=""s1"">'/product/'</span><span class=""p"">,</span> <span class=""s1"">'parse_product'</span><span class=""p"">)]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">url</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">loc</span><span class=""o"">&gt;</span><span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/&lt;/</span><span class=""n"">loc</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">xhtml</span><span class=""p"">:</span><span class=""n"">link</span> <span class=""n"">rel</span><span class=""o"">=</span><span class=""s2"">""alternate""</span> <span class=""n"">hreflang</span><span class=""o"">=</span><span class=""s2"">""de""</span> <span class=""n"">href</span><span class=""o"">=</span><span class=""s2"">""http://example.com/de""</span><span class=""o"">/&gt;</span>
<span class=""o"">&lt;/</span><span class=""n"">url</span><span class=""o"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">url</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">loc</span><span class=""o"">&gt;</span><span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/&lt;/</span><span class=""n"">loc</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">lastmod</span><span class=""o"">&gt;</span><span class=""mi"">2005</span><span class=""o"">-</span><span class=""mi"">01</span><span class=""o"">-</span><span class=""mi"">01</span><span class=""o"">&lt;/</span><span class=""n"">lastmod</span><span class=""o"">&gt;</span>
<span class=""o"">&lt;/</span><span class=""n"">url</span><span class=""o"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">datetime</span> <span class=""kn"">import</span> <span class=""n"">datetime</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">FilteredSitemapSpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'filtered_sitemap_spider'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://example.com/sitemap.xml'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">sitemap_filter</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">entries</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">entry</span> <span class=""ow"">in</span> <span class=""n"">entries</span><span class=""p"">:</span>
            <span class=""n"">date_time</span> <span class=""o"">=</span> <span class=""n"">datetime</span><span class=""o"">.</span><span class=""n"">strptime</span><span class=""p"">(</span><span class=""n"">entry</span><span class=""p"">[</span><span class=""s1"">'lastmod'</span><span class=""p"">],</span> <span class=""s1"">'%Y-%m-</span><span class=""si"">%d</span><span class=""s1"">'</span><span class=""p"">)</span>
            <span class=""k"">if</span> <span class=""n"">date_time</span><span class=""o"">.</span><span class=""n"">year</span> <span class=""o"">&gt;=</span> <span class=""mi"">2005</span><span class=""p"">:</span>
                <span class=""k"">yield</span> <span class=""n"">entry</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/sitemap.xml'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape item here ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/sitemap.xml'</span><span class=""p"">]</span>
    <span class=""n"">sitemap_rules</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""p"">(</span><span class=""s1"">'/product/'</span><span class=""p"">,</span> <span class=""s1"">'parse_product'</span><span class=""p"">),</span>
        <span class=""p"">(</span><span class=""s1"">'/category/'</span><span class=""p"">,</span> <span class=""s1"">'parse_category'</span><span class=""p"">),</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse_product</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape product ...</span>

    <span class=""k"">def</span> <span class=""nf"">parse_category</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape category ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/robots.txt'</span><span class=""p"">]</span>
    <span class=""n"">sitemap_rules</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""p"">(</span><span class=""s1"">'/shop/'</span><span class=""p"">,</span> <span class=""s1"">'parse_shop'</span><span class=""p"">),</span>
    <span class=""p"">]</span>
    <span class=""n"">sitemap_follow</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'/sitemap_shops'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse_shop</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape shop here ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/robots.txt'</span><span class=""p"">]</span>
    <span class=""n"">sitemap_rules</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""p"">(</span><span class=""s1"">'/shop/'</span><span class=""p"">,</span> <span class=""s1"">'parse_shop'</span><span class=""p"">),</span>
    <span class=""p"">]</span>

    <span class=""n"">other_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/about'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""n"">requests</span> <span class=""o"">=</span> <span class=""nb"">list</span><span class=""p"">(</span><span class=""nb"">super</span><span class=""p"">(</span><span class=""n"">MySpider</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">start_requests</span><span class=""p"">())</span>
        <span class=""n"">requests</span> <span class=""o"">+=</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">x</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_other</span><span class=""p"">)</span> <span class=""k"">for</span> <span class=""n"">x</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">other_urls</span><span class=""p"">]</span>
        <span class=""k"">return</span> <span class=""n"">requests</span>

    <span class=""k"">def</span> <span class=""nf"">parse_shop</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape shop here ...</span>

    <span class=""k"">def</span> <span class=""nf"">parse_other</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape other here ...</span>
</pre></div>","import scrapy

class TestItem(scrapy.Item):
    id = scrapy.Field()
    name = scrapy.Field()
    description = scrapy.Field()
,import scrapy
from scrapy.spiders import CrawlSpider, Rule
from scrapy.linkextractors import LinkExtractor

class MySpider(CrawlSpider):
    name = 'example.com'
    allowed_domains = ['example.com']
    start_urls = ['http://www.example.com']

    rules = (
        # Extract links matching 'category.php' (but not matching 'subsection.php')
        # and follow links from them (since no callback means follow=True by default).
        Rule(LinkExtractor(allow=('category\.php', ), deny=('subsection\.php', ))),

        # Extract links matching 'item.php' and parse them with the spider's method parse_item
        Rule(LinkExtractor(allow=('item\.php', )), callback='parse_item'),
    )

    def parse_item(self, response):
        self.logger.info('Hi, this is an item page! %s', response.url)
        item = scrapy.Item()
        item['id'] = response.xpath('//td[@id=""item_id""]/text()').re(r'ID: (\d+)')
        item['name'] = response.xpath('//td[@id=""item_name""]/text()').get()
        item['description'] = response.xpath('//td[@id=""item_description""]/text()').get()
        item['link_text'] = response.meta['link_text']
        url = response.xpath('//td[@id=""additional_data""]/@href').get()
        return response.follow(url, self.parse_additional_page, cb_kwargs=dict(item=item))

    def parse_additional_page(self, response, item):
        item['additional_data'] = response.xpath('//p[@id=""additional_data""]/text()').get()
        return item
,itertag = 'product'
,class YourSpider(XMLFeedSpider):

    namespaces = [('n', 'http://www.sitemaps.org/schemas/sitemap/0.9')]
    itertag = 'n:url'
    # ...
,from scrapy.spiders import XMLFeedSpider
from myproject.items import TestItem

class MySpider(XMLFeedSpider):
    name = 'example.com'
    allowed_domains = ['example.com']
    start_urls = ['http://www.example.com/feed.xml']
    iterator = 'iternodes'  # This is actually unnecessary, since it's the default value
    itertag = 'item'

    def parse_node(self, response, node):
        self.logger.info('Hi, this is a <%s> node!: %s', self.itertag, ''.join(node.getall()))

        item = TestItem()
        item['id'] = node.xpath('@id').get()
        item['name'] = node.xpath('name').get()
        item['description'] = node.xpath('description').get()
        return item
,from scrapy.spiders import CSVFeedSpider
from myproject.items import TestItem

class MySpider(CSVFeedSpider):
    name = 'example.com'
    allowed_domains = ['example.com']
    start_urls = ['http://www.example.com/feed.csv']
    delimiter = ';'
    quotechar = ""'""
    headers = ['id', 'name', 'description']

    def parse_row(self, response, row):
        self.logger.info('Hi, this is a row!: %r', row)

        item = TestItem()
        item['id'] = row['id']
        item['name'] = row['name']
        item['description'] = row['description']
        return item
,sitemap_rules = [('/product/', 'parse_product')]
,<url>
    <loc>http://example.com/</loc>
    <xhtml:link rel=""alternate"" hreflang=""de"" href=""http://example.com/de""/>
</url>
,<url>
    <loc>http://example.com/</loc>
    <lastmod>2005-01-01</lastmod>
</url>
,from datetime import datetime
from scrapy.spiders import SitemapSpider

class FilteredSitemapSpider(SitemapSpider):
    name = 'filtered_sitemap_spider'
    allowed_domains = ['example.com']
    sitemap_urls = ['http://example.com/sitemap.xml']

    def sitemap_filter(self, entries):
        for entry in entries:
            date_time = datetime.strptime(entry['lastmod'], '%Y-%m-%d')
            if date_time.year >= 2005:
                yield entry
,from scrapy.spiders import SitemapSpider

class MySpider(SitemapSpider):
    sitemap_urls = ['http://www.example.com/sitemap.xml']

    def parse(self, response):
        pass # ... scrape item here ...
,from scrapy.spiders import SitemapSpider

class MySpider(SitemapSpider):
    sitemap_urls = ['http://www.example.com/sitemap.xml']
    sitemap_rules = [
        ('/product/', 'parse_product'),
        ('/category/', 'parse_category'),
    ]

    def parse_product(self, response):
        pass # ... scrape product ...

    def parse_category(self, response):
        pass # ... scrape category ...
,from scrapy.spiders import SitemapSpider

class MySpider(SitemapSpider):
    sitemap_urls = ['http://www.example.com/robots.txt']
    sitemap_rules = [
        ('/shop/', 'parse_shop'),
    ]
    sitemap_follow = ['/sitemap_shops']

    def parse_shop(self, response):
        pass # ... scrape shop here ...
,from scrapy.spiders import SitemapSpider

class MySpider(SitemapSpider):
    sitemap_urls = ['http://www.example.com/robots.txt']
    sitemap_rules = [
        ('/shop/', 'parse_shop'),
    ]

    other_urls = ['http://www.example.com/about']

    def start_requests(self):
        requests = list(super(MySpider, self).start_requests())
        requests += [scrapy.Request(x, self.parse_other) for x in self.other_urls]
        return requests

    def parse_shop(self, response):
        pass # ... scrape shop here ...

    def parse_other(self, response):
        pass # ... scrape other here ...
",14
https://docs.scrapy.org/en/latest/topics/spiders.html,,###,3,CrawlSpider,#crawlspider,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">CrawlSpider</span><span class=""p"">,</span> <span class=""n"">Rule</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.linkextractors</span> <span class=""kn"">import</span> <span class=""n"">LinkExtractor</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">CrawlSpider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com'</span><span class=""p"">]</span>

    <span class=""n"">rules</span> <span class=""o"">=</span> <span class=""p"">(</span>
        <span class=""c1""># Extract links matching 'category.php' (but not matching 'subsection.php')</span>
        <span class=""c1""># and follow links from them (since no callback means follow=True by default).</span>
        <span class=""n"">Rule</span><span class=""p"">(</span><span class=""n"">LinkExtractor</span><span class=""p"">(</span><span class=""n"">allow</span><span class=""o"">=</span><span class=""p"">(</span><span class=""s1"">'category\.php'</span><span class=""p"">,</span> <span class=""p"">),</span> <span class=""n"">deny</span><span class=""o"">=</span><span class=""p"">(</span><span class=""s1"">'subsection\.php'</span><span class=""p"">,</span> <span class=""p"">))),</span>

        <span class=""c1""># Extract links matching 'item.php' and parse them with the spider's method parse_item</span>
        <span class=""n"">Rule</span><span class=""p"">(</span><span class=""n"">LinkExtractor</span><span class=""p"">(</span><span class=""n"">allow</span><span class=""o"">=</span><span class=""p"">(</span><span class=""s1"">'item\.php'</span><span class=""p"">,</span> <span class=""p"">)),</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""s1"">'parse_item'</span><span class=""p"">),</span>
    <span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Hi, this is an item page! </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
        <span class=""n"">item</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//td[@id=""item_id""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'ID: (\d+)'</span><span class=""p"">)</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//td[@id=""item_name""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'description'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//td[@id=""item_description""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'link_text'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">meta</span><span class=""p"">[</span><span class=""s1"">'link_text'</span><span class=""p"">]</span>
        <span class=""n"">url</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//td[@id=""additional_data""]/@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_additional_page</span><span class=""p"">,</span> <span class=""n"">cb_kwargs</span><span class=""o"">=</span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">item</span><span class=""o"">=</span><span class=""n"">item</span><span class=""p"">))</span>

    <span class=""k"">def</span> <span class=""nf"">parse_additional_page</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">):</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'additional_data'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p[@id=""additional_data""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>","import scrapy
from scrapy.spiders import CrawlSpider, Rule
from scrapy.linkextractors import LinkExtractor

class MySpider(CrawlSpider):
    name = 'example.com'
    allowed_domains = ['example.com']
    start_urls = ['http://www.example.com']

    rules = (
        # Extract links matching 'category.php' (but not matching 'subsection.php')
        # and follow links from them (since no callback means follow=True by default).
        Rule(LinkExtractor(allow=('category\.php', ), deny=('subsection\.php', ))),

        # Extract links matching 'item.php' and parse them with the spider's method parse_item
        Rule(LinkExtractor(allow=('item\.php', )), callback='parse_item'),
    )

    def parse_item(self, response):
        self.logger.info('Hi, this is an item page! %s', response.url)
        item = scrapy.Item()
        item['id'] = response.xpath('//td[@id=""item_id""]/text()').re(r'ID: (\d+)')
        item['name'] = response.xpath('//td[@id=""item_name""]/text()').get()
        item['description'] = response.xpath('//td[@id=""item_description""]/text()').get()
        item['link_text'] = response.meta['link_text']
        url = response.xpath('//td[@id=""additional_data""]/@href').get()
        return response.follow(url, self.parse_additional_page, cb_kwargs=dict(item=item))

    def parse_additional_page(self, response, item):
        item['additional_data'] = response.xpath('//p[@id=""additional_data""]/text()').get()
        return item
",1
https://docs.scrapy.org/en/latest/topics/spiders.html,,####,4,Crawling rules,#crawling-rules,,,6
https://docs.scrapy.org/en/latest/topics/spiders.html,,####,4,CrawlSpider example,#crawlspider-example,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">CrawlSpider</span><span class=""p"">,</span> <span class=""n"">Rule</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.linkextractors</span> <span class=""kn"">import</span> <span class=""n"">LinkExtractor</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">CrawlSpider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com'</span><span class=""p"">]</span>

    <span class=""n"">rules</span> <span class=""o"">=</span> <span class=""p"">(</span>
        <span class=""c1""># Extract links matching 'category.php' (but not matching 'subsection.php')</span>
        <span class=""c1""># and follow links from them (since no callback means follow=True by default).</span>
        <span class=""n"">Rule</span><span class=""p"">(</span><span class=""n"">LinkExtractor</span><span class=""p"">(</span><span class=""n"">allow</span><span class=""o"">=</span><span class=""p"">(</span><span class=""s1"">'category\.php'</span><span class=""p"">,</span> <span class=""p"">),</span> <span class=""n"">deny</span><span class=""o"">=</span><span class=""p"">(</span><span class=""s1"">'subsection\.php'</span><span class=""p"">,</span> <span class=""p"">))),</span>

        <span class=""c1""># Extract links matching 'item.php' and parse them with the spider's method parse_item</span>
        <span class=""n"">Rule</span><span class=""p"">(</span><span class=""n"">LinkExtractor</span><span class=""p"">(</span><span class=""n"">allow</span><span class=""o"">=</span><span class=""p"">(</span><span class=""s1"">'item\.php'</span><span class=""p"">,</span> <span class=""p"">)),</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""s1"">'parse_item'</span><span class=""p"">),</span>
    <span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Hi, this is an item page! </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
        <span class=""n"">item</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//td[@id=""item_id""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'ID: (\d+)'</span><span class=""p"">)</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//td[@id=""item_name""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'description'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//td[@id=""item_description""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'link_text'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">meta</span><span class=""p"">[</span><span class=""s1"">'link_text'</span><span class=""p"">]</span>
        <span class=""n"">url</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//td[@id=""additional_data""]/@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_additional_page</span><span class=""p"">,</span> <span class=""n"">cb_kwargs</span><span class=""o"">=</span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">item</span><span class=""o"">=</span><span class=""n"">item</span><span class=""p"">))</span>

    <span class=""k"">def</span> <span class=""nf"">parse_additional_page</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">):</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'additional_data'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p[@id=""additional_data""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>","import scrapy
from scrapy.spiders import CrawlSpider, Rule
from scrapy.linkextractors import LinkExtractor

class MySpider(CrawlSpider):
    name = 'example.com'
    allowed_domains = ['example.com']
    start_urls = ['http://www.example.com']

    rules = (
        # Extract links matching 'category.php' (but not matching 'subsection.php')
        # and follow links from them (since no callback means follow=True by default).
        Rule(LinkExtractor(allow=('category\.php', ), deny=('subsection\.php', ))),

        # Extract links matching 'item.php' and parse them with the spider's method parse_item
        Rule(LinkExtractor(allow=('item\.php', )), callback='parse_item'),
    )

    def parse_item(self, response):
        self.logger.info('Hi, this is an item page! %s', response.url)
        item = scrapy.Item()
        item['id'] = response.xpath('//td[@id=""item_id""]/text()').re(r'ID: (\d+)')
        item['name'] = response.xpath('//td[@id=""item_name""]/text()').get()
        item['description'] = response.xpath('//td[@id=""item_description""]/text()').get()
        item['link_text'] = response.meta['link_text']
        url = response.xpath('//td[@id=""additional_data""]/@href').get()
        return response.follow(url, self.parse_additional_page, cb_kwargs=dict(item=item))

    def parse_additional_page(self, response, item):
        item['additional_data'] = response.xpath('//p[@id=""additional_data""]/text()').get()
        return item
",1
https://docs.scrapy.org/en/latest/topics/spiders.html,,###,3,XMLFeedSpider,#xmlfeedspider,"<div class=""highlight""><pre><span></span><span class=""n"">itertag</span> <span class=""o"">=</span> <span class=""s1"">'product'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">YourSpider</span><span class=""p"">(</span><span class=""n"">XMLFeedSpider</span><span class=""p"">):</span>

    <span class=""n"">namespaces</span> <span class=""o"">=</span> <span class=""p"">[(</span><span class=""s1"">'n'</span><span class=""p"">,</span> <span class=""s1"">'http://www.sitemaps.org/schemas/sitemap/0.9'</span><span class=""p"">)]</span>
    <span class=""n"">itertag</span> <span class=""o"">=</span> <span class=""s1"">'n:url'</span>
    <span class=""c1""># ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">XMLFeedSpider</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.items</span> <span class=""kn"">import</span> <span class=""n"">TestItem</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">XMLFeedSpider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/feed.xml'</span><span class=""p"">]</span>
    <span class=""n"">iterator</span> <span class=""o"">=</span> <span class=""s1"">'iternodes'</span>  <span class=""c1""># This is actually unnecessary, since it's the default value</span>
    <span class=""n"">itertag</span> <span class=""o"">=</span> <span class=""s1"">'item'</span>

    <span class=""k"">def</span> <span class=""nf"">parse_node</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">node</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Hi, this is a &lt;</span><span class=""si"">%s</span><span class=""s1"">&gt; node!: </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">itertag</span><span class=""p"">,</span> <span class=""s1"">''</span><span class=""o"">.</span><span class=""n"">join</span><span class=""p"">(</span><span class=""n"">node</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()))</span>

        <span class=""n"">item</span> <span class=""o"">=</span> <span class=""n"">TestItem</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">node</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'@id'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">node</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'description'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">node</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'description'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>","itertag = 'product'
,class YourSpider(XMLFeedSpider):

    namespaces = [('n', 'http://www.sitemaps.org/schemas/sitemap/0.9')]
    itertag = 'n:url'
    # ...
,from scrapy.spiders import XMLFeedSpider
from myproject.items import TestItem

class MySpider(XMLFeedSpider):
    name = 'example.com'
    allowed_domains = ['example.com']
    start_urls = ['http://www.example.com/feed.xml']
    iterator = 'iternodes'  # This is actually unnecessary, since it's the default value
    itertag = 'item'

    def parse_node(self, response, node):
        self.logger.info('Hi, this is a <%s> node!: %s', self.itertag, ''.join(node.getall()))

        item = TestItem()
        item['id'] = node.xpath('@id').get()
        item['name'] = node.xpath('name').get()
        item['description'] = node.xpath('description').get()
        return item
",3
https://docs.scrapy.org/en/latest/topics/spiders.html,,####,4,XMLFeedSpider example,#xmlfeedspider-example,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">XMLFeedSpider</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.items</span> <span class=""kn"">import</span> <span class=""n"">TestItem</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">XMLFeedSpider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/feed.xml'</span><span class=""p"">]</span>
    <span class=""n"">iterator</span> <span class=""o"">=</span> <span class=""s1"">'iternodes'</span>  <span class=""c1""># This is actually unnecessary, since it's the default value</span>
    <span class=""n"">itertag</span> <span class=""o"">=</span> <span class=""s1"">'item'</span>

    <span class=""k"">def</span> <span class=""nf"">parse_node</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">node</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Hi, this is a &lt;</span><span class=""si"">%s</span><span class=""s1"">&gt; node!: </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">itertag</span><span class=""p"">,</span> <span class=""s1"">''</span><span class=""o"">.</span><span class=""n"">join</span><span class=""p"">(</span><span class=""n"">node</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()))</span>

        <span class=""n"">item</span> <span class=""o"">=</span> <span class=""n"">TestItem</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">node</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'@id'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">node</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'description'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">node</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'description'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>","from scrapy.spiders import XMLFeedSpider
from myproject.items import TestItem

class MySpider(XMLFeedSpider):
    name = 'example.com'
    allowed_domains = ['example.com']
    start_urls = ['http://www.example.com/feed.xml']
    iterator = 'iternodes'  # This is actually unnecessary, since it's the default value
    itertag = 'item'

    def parse_node(self, response, node):
        self.logger.info('Hi, this is a <%s> node!: %s', self.itertag, ''.join(node.getall()))

        item = TestItem()
        item['id'] = node.xpath('@id').get()
        item['name'] = node.xpath('name').get()
        item['description'] = node.xpath('description').get()
        return item
",1
https://docs.scrapy.org/en/latest/topics/spiders.html,,###,3,CSVFeedSpider,#csvfeedspider,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">CSVFeedSpider</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.items</span> <span class=""kn"">import</span> <span class=""n"">TestItem</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">CSVFeedSpider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/feed.csv'</span><span class=""p"">]</span>
    <span class=""n"">delimiter</span> <span class=""o"">=</span> <span class=""s1"">';'</span>
    <span class=""n"">quotechar</span> <span class=""o"">=</span> <span class=""s2"">""'""</span>
    <span class=""n"">headers</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">,</span> <span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'description'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse_row</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">row</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Hi, this is a row!: </span><span class=""si"">%r</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">row</span><span class=""p"">)</span>

        <span class=""n"">item</span> <span class=""o"">=</span> <span class=""n"">TestItem</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">row</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">row</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'description'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">row</span><span class=""p"">[</span><span class=""s1"">'description'</span><span class=""p"">]</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>","from scrapy.spiders import CSVFeedSpider
from myproject.items import TestItem

class MySpider(CSVFeedSpider):
    name = 'example.com'
    allowed_domains = ['example.com']
    start_urls = ['http://www.example.com/feed.csv']
    delimiter = ';'
    quotechar = ""'""
    headers = ['id', 'name', 'description']

    def parse_row(self, response, row):
        self.logger.info('Hi, this is a row!: %r', row)

        item = TestItem()
        item['id'] = row['id']
        item['name'] = row['name']
        item['description'] = row['description']
        return item
",1
https://docs.scrapy.org/en/latest/topics/spiders.html,,####,4,CSVFeedSpider example,#csvfeedspider-example,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">CSVFeedSpider</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.items</span> <span class=""kn"">import</span> <span class=""n"">TestItem</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">CSVFeedSpider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/feed.csv'</span><span class=""p"">]</span>
    <span class=""n"">delimiter</span> <span class=""o"">=</span> <span class=""s1"">';'</span>
    <span class=""n"">quotechar</span> <span class=""o"">=</span> <span class=""s2"">""'""</span>
    <span class=""n"">headers</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">,</span> <span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'description'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse_row</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">row</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Hi, this is a row!: </span><span class=""si"">%r</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">row</span><span class=""p"">)</span>

        <span class=""n"">item</span> <span class=""o"">=</span> <span class=""n"">TestItem</span><span class=""p"">()</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">row</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">row</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span>
        <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'description'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">row</span><span class=""p"">[</span><span class=""s1"">'description'</span><span class=""p"">]</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>","from scrapy.spiders import CSVFeedSpider
from myproject.items import TestItem

class MySpider(CSVFeedSpider):
    name = 'example.com'
    allowed_domains = ['example.com']
    start_urls = ['http://www.example.com/feed.csv']
    delimiter = ';'
    quotechar = ""'""
    headers = ['id', 'name', 'description']

    def parse_row(self, response, row):
        self.logger.info('Hi, this is a row!: %r', row)

        item = TestItem()
        item['id'] = row['id']
        item['name'] = row['name']
        item['description'] = row['description']
        return item
",1
https://docs.scrapy.org/en/latest/topics/spiders.html,,###,3,SitemapSpider,#sitemapspider,"<div class=""highlight""><pre><span></span><span class=""n"">sitemap_rules</span> <span class=""o"">=</span> <span class=""p"">[(</span><span class=""s1"">'/product/'</span><span class=""p"">,</span> <span class=""s1"">'parse_product'</span><span class=""p"">)]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">url</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">loc</span><span class=""o"">&gt;</span><span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/&lt;/</span><span class=""n"">loc</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">xhtml</span><span class=""p"">:</span><span class=""n"">link</span> <span class=""n"">rel</span><span class=""o"">=</span><span class=""s2"">""alternate""</span> <span class=""n"">hreflang</span><span class=""o"">=</span><span class=""s2"">""de""</span> <span class=""n"">href</span><span class=""o"">=</span><span class=""s2"">""http://example.com/de""</span><span class=""o"">/&gt;</span>
<span class=""o"">&lt;/</span><span class=""n"">url</span><span class=""o"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">url</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">loc</span><span class=""o"">&gt;</span><span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/&lt;/</span><span class=""n"">loc</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">lastmod</span><span class=""o"">&gt;</span><span class=""mi"">2005</span><span class=""o"">-</span><span class=""mi"">01</span><span class=""o"">-</span><span class=""mi"">01</span><span class=""o"">&lt;/</span><span class=""n"">lastmod</span><span class=""o"">&gt;</span>
<span class=""o"">&lt;/</span><span class=""n"">url</span><span class=""o"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">datetime</span> <span class=""kn"">import</span> <span class=""n"">datetime</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">FilteredSitemapSpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'filtered_sitemap_spider'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'example.com'</span><span class=""p"">]</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://example.com/sitemap.xml'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">sitemap_filter</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">entries</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">entry</span> <span class=""ow"">in</span> <span class=""n"">entries</span><span class=""p"">:</span>
            <span class=""n"">date_time</span> <span class=""o"">=</span> <span class=""n"">datetime</span><span class=""o"">.</span><span class=""n"">strptime</span><span class=""p"">(</span><span class=""n"">entry</span><span class=""p"">[</span><span class=""s1"">'lastmod'</span><span class=""p"">],</span> <span class=""s1"">'%Y-%m-</span><span class=""si"">%d</span><span class=""s1"">'</span><span class=""p"">)</span>
            <span class=""k"">if</span> <span class=""n"">date_time</span><span class=""o"">.</span><span class=""n"">year</span> <span class=""o"">&gt;=</span> <span class=""mi"">2005</span><span class=""p"">:</span>
                <span class=""k"">yield</span> <span class=""n"">entry</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/sitemap.xml'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape item here ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/sitemap.xml'</span><span class=""p"">]</span>
    <span class=""n"">sitemap_rules</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""p"">(</span><span class=""s1"">'/product/'</span><span class=""p"">,</span> <span class=""s1"">'parse_product'</span><span class=""p"">),</span>
        <span class=""p"">(</span><span class=""s1"">'/category/'</span><span class=""p"">,</span> <span class=""s1"">'parse_category'</span><span class=""p"">),</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse_product</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape product ...</span>

    <span class=""k"">def</span> <span class=""nf"">parse_category</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape category ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/robots.txt'</span><span class=""p"">]</span>
    <span class=""n"">sitemap_rules</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""p"">(</span><span class=""s1"">'/shop/'</span><span class=""p"">,</span> <span class=""s1"">'parse_shop'</span><span class=""p"">),</span>
    <span class=""p"">]</span>
    <span class=""n"">sitemap_follow</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'/sitemap_shops'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse_shop</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape shop here ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/robots.txt'</span><span class=""p"">]</span>
    <span class=""n"">sitemap_rules</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""p"">(</span><span class=""s1"">'/shop/'</span><span class=""p"">,</span> <span class=""s1"">'parse_shop'</span><span class=""p"">),</span>
    <span class=""p"">]</span>

    <span class=""n"">other_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/about'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""n"">requests</span> <span class=""o"">=</span> <span class=""nb"">list</span><span class=""p"">(</span><span class=""nb"">super</span><span class=""p"">(</span><span class=""n"">MySpider</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">start_requests</span><span class=""p"">())</span>
        <span class=""n"">requests</span> <span class=""o"">+=</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">x</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_other</span><span class=""p"">)</span> <span class=""k"">for</span> <span class=""n"">x</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">other_urls</span><span class=""p"">]</span>
        <span class=""k"">return</span> <span class=""n"">requests</span>

    <span class=""k"">def</span> <span class=""nf"">parse_shop</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape shop here ...</span>

    <span class=""k"">def</span> <span class=""nf"">parse_other</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape other here ...</span>
</pre></div>","sitemap_rules = [('/product/', 'parse_product')]
,<url>
    <loc>http://example.com/</loc>
    <xhtml:link rel=""alternate"" hreflang=""de"" href=""http://example.com/de""/>
</url>
,<url>
    <loc>http://example.com/</loc>
    <lastmod>2005-01-01</lastmod>
</url>
,from datetime import datetime
from scrapy.spiders import SitemapSpider

class FilteredSitemapSpider(SitemapSpider):
    name = 'filtered_sitemap_spider'
    allowed_domains = ['example.com']
    sitemap_urls = ['http://example.com/sitemap.xml']

    def sitemap_filter(self, entries):
        for entry in entries:
            date_time = datetime.strptime(entry['lastmod'], '%Y-%m-%d')
            if date_time.year >= 2005:
                yield entry
,from scrapy.spiders import SitemapSpider

class MySpider(SitemapSpider):
    sitemap_urls = ['http://www.example.com/sitemap.xml']

    def parse(self, response):
        pass # ... scrape item here ...
,from scrapy.spiders import SitemapSpider

class MySpider(SitemapSpider):
    sitemap_urls = ['http://www.example.com/sitemap.xml']
    sitemap_rules = [
        ('/product/', 'parse_product'),
        ('/category/', 'parse_category'),
    ]

    def parse_product(self, response):
        pass # ... scrape product ...

    def parse_category(self, response):
        pass # ... scrape category ...
,from scrapy.spiders import SitemapSpider

class MySpider(SitemapSpider):
    sitemap_urls = ['http://www.example.com/robots.txt']
    sitemap_rules = [
        ('/shop/', 'parse_shop'),
    ]
    sitemap_follow = ['/sitemap_shops']

    def parse_shop(self, response):
        pass # ... scrape shop here ...
,from scrapy.spiders import SitemapSpider

class MySpider(SitemapSpider):
    sitemap_urls = ['http://www.example.com/robots.txt']
    sitemap_rules = [
        ('/shop/', 'parse_shop'),
    ]

    other_urls = ['http://www.example.com/about']

    def start_requests(self):
        requests = list(super(MySpider, self).start_requests())
        requests += [scrapy.Request(x, self.parse_other) for x in self.other_urls]
        return requests

    def parse_shop(self, response):
        pass # ... scrape shop here ...

    def parse_other(self, response):
        pass # ... scrape other here ...
",8
https://docs.scrapy.org/en/latest/topics/spiders.html,,####,4,SitemapSpider examples,#sitemapspider-examples,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/sitemap.xml'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape item here ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/sitemap.xml'</span><span class=""p"">]</span>
    <span class=""n"">sitemap_rules</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""p"">(</span><span class=""s1"">'/product/'</span><span class=""p"">,</span> <span class=""s1"">'parse_product'</span><span class=""p"">),</span>
        <span class=""p"">(</span><span class=""s1"">'/category/'</span><span class=""p"">,</span> <span class=""s1"">'parse_category'</span><span class=""p"">),</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse_product</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape product ...</span>

    <span class=""k"">def</span> <span class=""nf"">parse_category</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape category ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/robots.txt'</span><span class=""p"">]</span>
    <span class=""n"">sitemap_rules</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""p"">(</span><span class=""s1"">'/shop/'</span><span class=""p"">,</span> <span class=""s1"">'parse_shop'</span><span class=""p"">),</span>
    <span class=""p"">]</span>
    <span class=""n"">sitemap_follow</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'/sitemap_shops'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse_shop</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape shop here ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">SitemapSpider</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">SitemapSpider</span><span class=""p"">):</span>
    <span class=""n"">sitemap_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/robots.txt'</span><span class=""p"">]</span>
    <span class=""n"">sitemap_rules</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""p"">(</span><span class=""s1"">'/shop/'</span><span class=""p"">,</span> <span class=""s1"">'parse_shop'</span><span class=""p"">),</span>
    <span class=""p"">]</span>

    <span class=""n"">other_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/about'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""n"">requests</span> <span class=""o"">=</span> <span class=""nb"">list</span><span class=""p"">(</span><span class=""nb"">super</span><span class=""p"">(</span><span class=""n"">MySpider</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">start_requests</span><span class=""p"">())</span>
        <span class=""n"">requests</span> <span class=""o"">+=</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">x</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_other</span><span class=""p"">)</span> <span class=""k"">for</span> <span class=""n"">x</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">other_urls</span><span class=""p"">]</span>
        <span class=""k"">return</span> <span class=""n"">requests</span>

    <span class=""k"">def</span> <span class=""nf"">parse_shop</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape shop here ...</span>

    <span class=""k"">def</span> <span class=""nf"">parse_other</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span> <span class=""c1""># ... scrape other here ...</span>
</pre></div>","from scrapy.spiders import SitemapSpider

class MySpider(SitemapSpider):
    sitemap_urls = ['http://www.example.com/sitemap.xml']

    def parse(self, response):
        pass # ... scrape item here ...
,from scrapy.spiders import SitemapSpider

class MySpider(SitemapSpider):
    sitemap_urls = ['http://www.example.com/sitemap.xml']
    sitemap_rules = [
        ('/product/', 'parse_product'),
        ('/category/', 'parse_category'),
    ]

    def parse_product(self, response):
        pass # ... scrape product ...

    def parse_category(self, response):
        pass # ... scrape category ...
,from scrapy.spiders import SitemapSpider

class MySpider(SitemapSpider):
    sitemap_urls = ['http://www.example.com/robots.txt']
    sitemap_rules = [
        ('/shop/', 'parse_shop'),
    ]
    sitemap_follow = ['/sitemap_shops']

    def parse_shop(self, response):
        pass # ... scrape shop here ...
,from scrapy.spiders import SitemapSpider

class MySpider(SitemapSpider):
    sitemap_urls = ['http://www.example.com/robots.txt']
    sitemap_rules = [
        ('/shop/', 'parse_shop'),
    ]

    other_urls = ['http://www.example.com/about']

    def start_requests(self):
        requests = list(super(MySpider, self).start_requests())
        requests += [scrapy.Request(x, self.parse_other) for x in self.other_urls]
        return requests

    def parse_shop(self, response):
        pass # ... scrape shop here ...

    def parse_other(self, response):
        pass # ... scrape other here ...
",4
https://docs.scrapy.org/en/latest/topics/selectors.html,,#,1,Selectors,#selectors,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">selector</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//span/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'good'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//span/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'good'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'good'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.selector</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">body</span> <span class=""o"">=</span> <span class=""s1"">'&lt;html&gt;&lt;body&gt;&lt;span&gt;good&lt;/span&gt;&lt;/body&gt;&lt;/html&gt;'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">body</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//span/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'good'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.selector</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.http</span> <span class=""kn"">import</span> <span class=""n"">HtmlResponse</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span> <span class=""o"">=</span> <span class=""n"">HtmlResponse</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""s1"">'http://example.com'</span><span class=""p"">,</span> <span class=""n"">body</span><span class=""o"">=</span><span class=""n"">body</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">=</span><span class=""n"">response</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//span/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'good'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""cp"">&lt;!DOCTYPE html&gt;</span>

<span class=""p"">&lt;</span><span class=""nt"">html</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">head</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">base</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'http://example.com/'</span> <span class=""p"">/&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">title</span><span class=""p"">&gt;</span>Example website<span class=""p"">&lt;/</span><span class=""nt"">title</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;/</span><span class=""nt"">head</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">body</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">id</span><span class=""o"">=</span><span class=""s"">'images'</span><span class=""p"">&gt;</span>
      <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'image1.html'</span><span class=""p"">&gt;</span>Name: My image 1 <span class=""p"">&lt;</span><span class=""nt"">br</span> <span class=""p"">/&gt;&lt;</span><span class=""nt"">img</span> <span class=""na"">src</span><span class=""o"">=</span><span class=""s"">'image1_thumb.jpg'</span> <span class=""na"">alt</span><span class=""o"">=</span><span class=""s"">'image1'</span><span class=""p"">/&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
      <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'image2.html'</span><span class=""p"">&gt;</span>Name: My image 2 <span class=""p"">&lt;</span><span class=""nt"">br</span> <span class=""p"">/&gt;&lt;</span><span class=""nt"">img</span> <span class=""na"">src</span><span class=""o"">=</span><span class=""s"">'image2_thumb.jpg'</span> <span class=""na"">alt</span><span class=""o"">=</span><span class=""s"">'image2'</span><span class=""p"">/&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
      <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'image3.html'</span><span class=""p"">&gt;</span>Name: My image 3 <span class=""p"">&lt;</span><span class=""nt"">br</span> <span class=""p"">/&gt;&lt;</span><span class=""nt"">img</span> <span class=""na"">src</span><span class=""o"">=</span><span class=""s"">'image3_thumb.jpg'</span> <span class=""na"">alt</span><span class=""o"">=</span><span class=""s"">'image3'</span><span class=""p"">/&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
      <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'image4.html'</span><span class=""p"">&gt;</span>Name: My image 4 <span class=""p"">&lt;</span><span class=""nt"">br</span> <span class=""p"">/&gt;&lt;</span><span class=""nt"">img</span> <span class=""na"">src</span><span class=""o"">=</span><span class=""s"">'image4_thumb.jpg'</span> <span class=""na"">alt</span><span class=""o"">=</span><span class=""s"">'image4'</span><span class=""p"">/&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
      <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'image5.html'</span><span class=""p"">&gt;</span>Name: My image 5 <span class=""p"">&lt;</span><span class=""nt"">br</span> <span class=""p"">/&gt;&lt;</span><span class=""nt"">img</span> <span class=""na"">src</span><span class=""o"">=</span><span class=""s"">'image5_thumb.jpg'</span> <span class=""na"">alt</span><span class=""o"">=</span><span class=""s"">'image5'</span><span class=""p"">/&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;/</span><span class=""nt"">body</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;/</span><span class=""nt"">html</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span>scrapy shell https://docs.scrapy.org/en/latest/_static/selectors-sample1.html
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='//title/text()' data='Example website'&gt;]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['Example website']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Example website'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Example website'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'@src'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1_thumb.jpg',</span>
<span class=""go""> 'image2_thumb.jpg',</span>
<span class=""go""> 'image3_thumb.jpg',</span>
<span class=""go""> 'image4_thumb.jpg',</span>
<span class=""go""> 'image5_thumb.jpg']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[@id=""images""]/a/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Name: My image 1 '</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[@id=""not-exists""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span> <span class=""ow"">is</span> <span class=""kc"">None</span>
<span class=""go"">True</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[@id=""not-exists""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""n"">default</span><span class=""o"">=</span><span class=""s1"">'not-found'</span><span class=""p"">)</span>
<span class=""go"">'not-found'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""p"">[</span><span class=""n"">img</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'src'</span><span class=""p"">]</span> <span class=""k"">for</span> <span class=""n"">img</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img'</span><span class=""p"">)]</span>
<span class=""go"">['image1_thumb.jpg',</span>
<span class=""go""> 'image2_thumb.jpg',</span>
<span class=""go""> 'image3_thumb.jpg',</span>
<span class=""go""> 'image4_thumb.jpg',</span>
<span class=""go""> 'image5_thumb.jpg']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'src'</span><span class=""p"">]</span>
<span class=""go"">'image1_thumb.jpg'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'base'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'href'</span><span class=""p"">]</span>
<span class=""go"">'http://example.com/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//base/@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'http://example.com/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'base::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'http://example.com/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'base'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'href'</span><span class=""p"">]</span>
<span class=""go"">'http://example.com/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[contains(@href, ""image"")]/@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html',</span>
<span class=""go""> 'image2.html',</span>
<span class=""go""> 'image3.html',</span>
<span class=""go""> 'image4.html',</span>
<span class=""go""> 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a[href*=image]::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html',</span>
<span class=""go""> 'image2.html',</span>
<span class=""go""> 'image3.html',</span>
<span class=""go""> 'image4.html',</span>
<span class=""go""> 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[contains(@href, ""image"")]/img/@src'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1_thumb.jpg',</span>
<span class=""go""> 'image2_thumb.jpg',</span>
<span class=""go""> 'image3_thumb.jpg',</span>
<span class=""go""> 'image4_thumb.jpg',</span>
<span class=""go""> 'image5_thumb.jpg']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a[href*=image] img::attr(src)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1_thumb.jpg',</span>
<span class=""go""> 'image2_thumb.jpg',</span>
<span class=""go""> 'image3_thumb.jpg',</span>
<span class=""go""> 'image4_thumb.jpg',</span>
<span class=""go""> 'image5_thumb.jpg']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Example website'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'#images *::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['\n   ',</span>
<span class=""go""> 'Name: My image 1 ',</span>
<span class=""go""> '\n   ',</span>
<span class=""go""> 'Name: My image 2 ',</span>
<span class=""go""> '\n   ',</span>
<span class=""go""> 'Name: My image 3 ',</span>
<span class=""go""> '\n   ',</span>
<span class=""go""> 'Name: My image 4 ',</span>
<span class=""go""> '\n   ',</span>
<span class=""go""> 'Name: My image 5 ',</span>
<span class=""go""> '\n  ']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">[]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""n"">default</span><span class=""o"">=</span><span class=""s1"">''</span><span class=""p"">)</span>
<span class=""go"">''</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html',</span>
<span class=""go""> 'image2.html',</span>
<span class=""go""> 'image3.html',</span>
<span class=""go""> 'image4.html',</span>
<span class=""go""> 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">links</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[contains(@href, ""image"")]'</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">links</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['&lt;a href=""image1.html""&gt;Name: My image 1 &lt;br&gt;&lt;img src=""image1_thumb.jpg""&gt;&lt;/a&gt;',</span>
<span class=""go""> '&lt;a href=""image2.html""&gt;Name: My image 2 &lt;br&gt;&lt;img src=""image2_thumb.jpg""&gt;&lt;/a&gt;',</span>
<span class=""go""> '&lt;a href=""image3.html""&gt;Name: My image 3 &lt;br&gt;&lt;img src=""image3_thumb.jpg""&gt;&lt;/a&gt;',</span>
<span class=""go""> '&lt;a href=""image4.html""&gt;Name: My image 4 &lt;br&gt;&lt;img src=""image4_thumb.jpg""&gt;&lt;/a&gt;',</span>
<span class=""go""> '&lt;a href=""image5.html""&gt;Name: My image 5 &lt;br&gt;&lt;img src=""image5_thumb.jpg""&gt;&lt;/a&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">index</span><span class=""p"">,</span> <span class=""n"">link</span> <span class=""ow"">in</span> <span class=""nb"">enumerate</span><span class=""p"">(</span><span class=""n"">links</span><span class=""p"">):</span>
<span class=""gp"">... </span>    <span class=""n"">href_xpath</span> <span class=""o"">=</span> <span class=""n"">link</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""n"">img_xpath</span> <span class=""o"">=</span> <span class=""n"">link</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'img/@src'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s1"">'Link number </span><span class=""si"">{</span><span class=""n"">index</span><span class=""si"">}</span><span class=""s1""> points to url </span><span class=""si"">{</span><span class=""n"">href_xpath</span><span class=""si"">!r}</span><span class=""s1""> and image </span><span class=""si"">{</span><span class=""n"">img_xpath</span><span class=""si"">!r}</span><span class=""s1"">'</span><span class=""p"">)</span>
<span class=""go"">Link number 0 points to url 'image1.html' and image 'image1_thumb.jpg'</span>
<span class=""go"">Link number 1 points to url 'image2.html' and image 'image2_thumb.jpg'</span>
<span class=""go"">Link number 2 points to url 'image3.html' and image 'image3_thumb.jpg'</span>
<span class=""go"">Link number 3 points to url 'image4.html' and image 'image4_thumb.jpg'</span>
<span class=""go"">Link number 4 points to url 'image5.html' and image 'image5_thumb.jpg'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//a/@href""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""p"">[</span><span class=""n"">a</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'href'</span><span class=""p"">]</span> <span class=""k"">for</span> <span class=""n"">a</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a'</span><span class=""p"">)]</span>
<span class=""go"">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'base'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span>
<span class=""go"">{'href': 'http://example.com/'}</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'base'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'href'</span><span class=""p"">]</span>
<span class=""go"">'http://example.com/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'foo'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span>
<span class=""go"">{}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[contains(@href, ""image"")]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'Name:\s*(.*)'</span><span class=""p"">)</span>
<span class=""go"">['My image 1',</span>
<span class=""go""> 'My image 2',</span>
<span class=""go""> 'My image 3',</span>
<span class=""go""> 'My image 4',</span>
<span class=""go""> 'My image 5']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[contains(@href, ""image"")]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re_first</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'Name:\s*(.*)'</span><span class=""p"">)</span>
<span class=""go"">'My image 1'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'image1.html'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">extract_first</span><span class=""p"">()</span>
<span class=""go"">'image1.html'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">extract</span><span class=""p"">()</span>
<span class=""go"">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'image1.html'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">extract</span><span class=""p"">()</span>
<span class=""go"">'image1.html'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">divs</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">p</span> <span class=""ow"">in</span> <span class=""n"">divs</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p'</span><span class=""p"">):</span>  <span class=""c1""># this is wrong - gets all &lt;p&gt; from the whole document</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">p</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">())</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">p</span> <span class=""ow"">in</span> <span class=""n"">divs</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'.//p'</span><span class=""p"">):</span>  <span class=""c1""># extracts all &lt;p&gt; inside</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">p</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">())</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">p</span> <span class=""ow"">in</span> <span class=""n"">divs</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'p'</span><span class=""p"">):</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">p</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">())</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">*</span><span class=""p"">[</span><span class=""n"">contains</span><span class=""p"">(</span><span class=""n"">concat</span><span class=""p"">(</span><span class=""s1"">' '</span><span class=""p"">,</span> <span class=""n"">normalize</span><span class=""o"">-</span><span class=""n"">space</span><span class=""p"">(</span><span class=""nd"">@class</span><span class=""p"">),</span> <span class=""s1"">' '</span><span class=""p"">),</span> <span class=""s1"">' someclass '</span><span class=""p"">)]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""s1"">'&lt;div class=""hero shout""&gt;&lt;time datetime=""2014-07-23 19:00""&gt;Special date&lt;/time&gt;&lt;/div&gt;'</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'.shout'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'./time/@datetime'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['2014-07-23 19:00']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""s2"">""""""</span>
<span class=""go"">....:     &lt;ul class=""list""&gt;</span>
<span class=""go"">....:         &lt;li&gt;1&lt;/li&gt;</span>
<span class=""go"">....:         &lt;li&gt;2&lt;/li&gt;</span>
<span class=""go"">....:         &lt;li&gt;3&lt;/li&gt;</span>
<span class=""go"">....:     &lt;/ul&gt;</span>
<span class=""go"">....:     &lt;ul class=""list""&gt;</span>
<span class=""go"">....:         &lt;li&gt;4&lt;/li&gt;</span>
<span class=""go"">....:         &lt;li&gt;5&lt;/li&gt;</span>
<span class=""go"">....:         &lt;li&gt;6&lt;/li&gt;</span>
<span class=""go"">....:     &lt;/ul&gt;"""""")</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xp</span> <span class=""o"">=</span> <span class=""k"">lambda</span> <span class=""n"">x</span><span class=""p"">:</span> <span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""n"">x</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xp</span><span class=""p"">(</span><span class=""s2"">""//li[1]""</span><span class=""p"">)</span>
<span class=""go"">['&lt;li&gt;1&lt;/li&gt;', '&lt;li&gt;4&lt;/li&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xp</span><span class=""p"">(</span><span class=""s2"">""(//li)[1]""</span><span class=""p"">)</span>
<span class=""go"">['&lt;li&gt;1&lt;/li&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xp</span><span class=""p"">(</span><span class=""s2"">""//ul/li[1]""</span><span class=""p"">)</span>
<span class=""go"">['&lt;li&gt;1&lt;/li&gt;', '&lt;li&gt;4&lt;/li&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xp</span><span class=""p"">(</span><span class=""s2"">""(//ul/li)[1]""</span><span class=""p"">)</span>
<span class=""go"">['&lt;li&gt;1&lt;/li&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""s1"">'&lt;a href=""#""&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a//text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span> <span class=""c1""># take a peek at the node-set</span>
<span class=""go"">['Click here to go to the ', 'Next Page']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""string(//a[1]//text())""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span> <span class=""c1""># convert it to string</span>
<span class=""go"">['Click here to go to the ']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//a[1]""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span> <span class=""c1""># select the first node</span>
<span class=""go"">['&lt;a href=""#""&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""string(//a[1])""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span> <span class=""c1""># convert it to string</span>
<span class=""go"">['Click here to go to the Next Page']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//a[contains(.//text(), 'Next Page')]""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">[]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//a[contains(., 'Next Page')]""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['&lt;a href=""#""&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""c1""># `$val` used in the expression, a `val` argument needs to be passed</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[@id=$val]/a/text()'</span><span class=""p"">,</span> <span class=""n"">val</span><span class=""o"">=</span><span class=""s1"">'images'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Name: My image 1 '</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[count(a)=$cnt]/@id'</span><span class=""p"">,</span> <span class=""n"">cnt</span><span class=""o"">=</span><span class=""mi"">5</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'images'</span>
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy shell https://feeds.feedburner.com/PythonInsider
</pre></div>,<div class=""highlight""><pre><span></span>&lt;?xml <span class=""nv"">version</span><span class=""o"">=</span><span class=""s2"">""1.0""</span> <span class=""nv"">encoding</span><span class=""o"">=</span><span class=""s2"">""UTF-8""</span>?&gt;
&lt;?xml-stylesheet ...
&lt;feed <span class=""nv"">xmlns</span><span class=""o"">=</span><span class=""s2"">""http://www.w3.org/2005/Atom""</span>
      xmlns:openSearch<span class=""o"">=</span><span class=""s2"">""http://a9.com/-/spec/opensearchrss/1.0/""</span>
      xmlns:blogger<span class=""o"">=</span><span class=""s2"">""http://schemas.google.com/blogger/2008""</span>
      xmlns:georss<span class=""o"">=</span><span class=""s2"">""http://www.georss.org/georss""</span>
      xmlns:gd<span class=""o"">=</span><span class=""s2"">""http://schemas.google.com/g/2005""</span>
      xmlns:thr<span class=""o"">=</span><span class=""s2"">""http://purl.org/syndication/thread/1.0""</span>
      xmlns:feedburner<span class=""o"">=</span><span class=""s2"">""http://rssnamespace.org/feedburner/ext/1.0""</span>&gt;
  ...
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//link""</span><span class=""p"">)</span>
<span class=""go"">[]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">selector</span><span class=""o"">.</span><span class=""n"">remove_namespaces</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//link""</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='//link' data='&lt;link rel=""alternate"" type=""text/html"" h'&gt;,</span>
<span class=""go"">    &lt;Selector xpath='//link' data='&lt;link rel=""next"" type=""application/atom+'&gt;,</span>
<span class=""go"">    ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">doc</span> <span class=""o"">=</span> <span class=""s2"">""""""</span>
<span class=""gp"">... </span><span class=""s2"">&lt;div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;ul&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-0""&gt;&lt;a href=""link1.html""&gt;first item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-1""&gt;&lt;a href=""link2.html""&gt;second item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-inactive""&gt;&lt;a href=""link3.html""&gt;third item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-1""&gt;&lt;a href=""link4.html""&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-0""&gt;&lt;a href=""link5.html""&gt;fifth item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;/ul&gt;</span>
<span class=""gp"">... </span><span class=""s2"">&lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">""""""</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">doc</span><span class=""p"">,</span> <span class=""nb"">type</span><span class=""o"">=</span><span class=""s2"">""html""</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//li//@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//li[re:test(@class, ""item-\d$"")]//@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['link1.html', 'link2.html', 'link4.html', 'link5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">doc</span> <span class=""o"">=</span> <span class=""s2"">""""""</span>
<span class=""gp"">... </span><span class=""s2"">&lt;div itemscope itemtype=""http://schema.org/Product""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;span itemprop=""name""&gt;Kenmore White 17"" Microwave&lt;/span&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;img src=""kenmore-microwave-17in.jpg"" alt='Kenmore 17"" Microwave' /&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;div itemprop=""aggregateRating""</span>
<span class=""gp"">... </span><span class=""s2"">    itemscope itemtype=""http://schema.org/AggregateRating""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">   Rated &lt;span itemprop=""ratingValue""&gt;3.5&lt;/span&gt;/5</span>
<span class=""gp"">... </span><span class=""s2"">   based on &lt;span itemprop=""reviewCount""&gt;11&lt;/span&gt; customer reviews</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;/div&gt;</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  &lt;div itemprop=""offers"" itemscope itemtype=""http://schema.org/Offer""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""price""&gt;$55.00&lt;/span&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;link itemprop=""availability"" href=""http://schema.org/InStock"" /&gt;In stock</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;/div&gt;</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  Product description:</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;span itemprop=""description""&gt;0.7 cubic feet countertop microwave.</span>
<span class=""gp"">... </span><span class=""s2"">  Has six preset cooking categories and convenience features like</span>
<span class=""gp"">... </span><span class=""s2"">  Add-A-Minute and Child Lock.&lt;/span&gt;</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  Customer reviews:</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  &lt;div itemprop=""review"" itemscope itemtype=""http://schema.org/Review""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""name""&gt;Not a happy camper&lt;/span&gt; -</span>
<span class=""gp"">... </span><span class=""s2"">    by &lt;span itemprop=""author""&gt;Ellie&lt;/span&gt;,</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;meta itemprop=""datePublished"" content=""2011-04-01""&gt;April 1, 2011</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;div itemprop=""reviewRating"" itemscope itemtype=""http://schema.org/Rating""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;meta itemprop=""worstRating"" content = ""1""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;span itemprop=""ratingValue""&gt;1&lt;/span&gt;/</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;span itemprop=""bestRating""&gt;5&lt;/span&gt;stars</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""description""&gt;The lamp burned out and now I have to replace</span>
<span class=""gp"">... </span><span class=""s2"">    it. &lt;/span&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;/div&gt;</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  &lt;div itemprop=""review"" itemscope itemtype=""http://schema.org/Review""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""name""&gt;Value purchase&lt;/span&gt; -</span>
<span class=""gp"">... </span><span class=""s2"">    by &lt;span itemprop=""author""&gt;Lucas&lt;/span&gt;,</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;meta itemprop=""datePublished"" content=""2011-03-25""&gt;March 25, 2011</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;div itemprop=""reviewRating"" itemscope itemtype=""http://schema.org/Rating""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;meta itemprop=""worstRating"" content = ""1""/&gt;</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;span itemprop=""ratingValue""&gt;4&lt;/span&gt;/</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;span itemprop=""bestRating""&gt;5&lt;/span&gt;stars</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""description""&gt;Great microwave for the price. It is small and</span>
<span class=""gp"">... </span><span class=""s2"">    fits in my apartment.&lt;/span&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  ...</span>
<span class=""gp"">... </span><span class=""s2"">&lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">""""""</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">doc</span><span class=""p"">,</span> <span class=""nb"">type</span><span class=""o"">=</span><span class=""s2"">""html""</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">scope</span> <span class=""ow"">in</span> <span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[@itemscope]'</span><span class=""p"">):</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""s2"">""current scope:""</span><span class=""p"">,</span> <span class=""n"">scope</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'@itemtype'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">())</span>
<span class=""gp"">... </span>    <span class=""n"">props</span> <span class=""o"">=</span> <span class=""n"">scope</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'''</span>
<span class=""gp"">... </span><span class=""s1"">                set:difference(./descendant::*/@itemprop,</span>
<span class=""gp"">... </span><span class=""s1"">                               .//*[@itemscope]/*/@itemprop)'''</span><span class=""p"">)</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s2"">""    properties: </span><span class=""si"">{</span><span class=""n"">props</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span><span class=""si"">}</span><span class=""s2"">""</span><span class=""p"">)</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""s2"">""""</span><span class=""p"">)</span>

<span class=""go"">current scope: ['http://schema.org/Product']</span>
<span class=""go"">    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']</span>

<span class=""go"">current scope: ['http://schema.org/AggregateRating']</span>
<span class=""go"">    properties: ['ratingValue', 'reviewCount']</span>

<span class=""go"">current scope: ['http://schema.org/Offer']</span>
<span class=""go"">    properties: ['price', 'availability']</span>

<span class=""go"">current scope: ['http://schema.org/Review']</span>
<span class=""go"">    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']</span>

<span class=""go"">current scope: ['http://schema.org/Rating']</span>
<span class=""go"">    properties: ['worstRating', 'ratingValue', 'bestRating']</span>

<span class=""go"">current scope: ['http://schema.org/Review']</span>
<span class=""go"">    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']</span>

<span class=""go"">current scope: ['http://schema.org/Rating']</span>
<span class=""go"">    properties: ['worstRating', 'ratingValue', 'bestRating']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">&lt;</span><span class=""nt"">p</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""foo bar-baz""</span><span class=""p"">&gt;</span>First<span class=""p"">&lt;/</span><span class=""nt"">p</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;</span><span class=""nt"">p</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""foo""</span><span class=""p"">&gt;</span>Second<span class=""p"">&lt;/</span><span class=""nt"">p</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;</span><span class=""nt"">p</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""bar""</span><span class=""p"">&gt;</span>Third<span class=""p"">&lt;/</span><span class=""nt"">p</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;</span><span class=""nt"">p</span><span class=""p"">&gt;</span>Fourth<span class=""p"">&lt;/</span><span class=""nt"">p</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p[has-class(""foo"")]'</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='//p[has-class(""foo"")]' data='&lt;p class=""foo bar-baz""&gt;First&lt;/p&gt;'&gt;,</span>
<span class=""go""> &lt;Selector xpath='//p[has-class(""foo"")]' data='&lt;p class=""foo""&gt;Second&lt;/p&gt;'&gt;]</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p[has-class(""foo"", ""bar-baz"")]'</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='//p[has-class(""foo"", ""bar-baz"")]' data='&lt;p class=""foo bar-baz""&gt;First&lt;/p&gt;'&gt;]</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p[has-class(""foo"", ""bar"")]'</span><span class=""p"">)</span>
<span class=""go"">[]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">selector</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[href=$url]'</span><span class=""p"">,</span> <span class=""n"">url</span><span class=""o"">=</span><span class=""s2"">""http://www.example.com""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">selector</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[href=$url]'</span><span class=""p"">,</span> <span class=""n"">url</span><span class=""o"">=</span><span class=""s2"">""http://www.example.com""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">html_response</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//h1""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//h1""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>         <span class=""c1""># this includes the h1 tag</span>
<span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//h1/text()""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>  <span class=""c1""># this excludes the h1 tag</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">node</span> <span class=""ow"">in</span> <span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//p""</span><span class=""p"">):</span>
    <span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">node</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'class'</span><span class=""p"">])</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">xml_response</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//product""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">register_namespace</span><span class=""p"">(</span><span class=""s2"">""g""</span><span class=""p"">,</span> <span class=""s2"">""http://base.google.com/ns/1.0""</span><span class=""p"">)</span>
<span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//g:price""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
</pre></div>",">>> response.selector.xpath('//span/text()').get()
'good'
,>>> response.xpath('//span/text()').get()
'good'
>>> response.css('span::text').get()
'good'
,>>> from scrapy.selector import Selector
>>> body = '<html><body><span>good</span></body></html>'
>>> Selector(text=body).xpath('//span/text()').get()
'good'
,>>> from scrapy.selector import Selector
>>> from scrapy.http import HtmlResponse
>>> response = HtmlResponse(url='http://example.com', body=body)
>>> Selector(response=response).xpath('//span/text()').get()
'good'
,<!DOCTYPE html>

<html>
  <head>
    <base href='http://example.com/' />
    <title>Example website</title>
  </head>
  <body>
    <div id='images'>
      <a href='image1.html'>Name: My image 1 <br /><img src='image1_thumb.jpg' alt='image1'/></a>
      <a href='image2.html'>Name: My image 2 <br /><img src='image2_thumb.jpg' alt='image2'/></a>
      <a href='image3.html'>Name: My image 3 <br /><img src='image3_thumb.jpg' alt='image3'/></a>
      <a href='image4.html'>Name: My image 4 <br /><img src='image4_thumb.jpg' alt='image4'/></a>
      <a href='image5.html'>Name: My image 5 <br /><img src='image5_thumb.jpg' alt='image5'/></a>
    </div>
  </body>
</html>
,scrapy shell https://docs.scrapy.org/en/latest/_static/selectors-sample1.html
,>>> response.xpath('//title/text()')
[<Selector xpath='//title/text()' data='Example website'>]
,>>> response.xpath('//title/text()').getall()
['Example website']
>>> response.xpath('//title/text()').get()
'Example website'
,>>> response.css('title::text').get()
'Example website'
,>>> response.css('img').xpath('@src').getall()
['image1_thumb.jpg',
 'image2_thumb.jpg',
 'image3_thumb.jpg',
 'image4_thumb.jpg',
 'image5_thumb.jpg']
,>>> response.xpath('//div[@id=""images""]/a/text()').get()
'Name: My image 1 '
,>>> response.xpath('//div[@id=""not-exists""]/text()').get() is None
True
,>>> response.xpath('//div[@id=""not-exists""]/text()').get(default='not-found')
'not-found'
,>>> [img.attrib['src'] for img in response.css('img')]
['image1_thumb.jpg',
 'image2_thumb.jpg',
 'image3_thumb.jpg',
 'image4_thumb.jpg',
 'image5_thumb.jpg']
,>>> response.css('img').attrib['src']
'image1_thumb.jpg'
,>>> response.css('base').attrib['href']
'http://example.com/'
,>>> response.xpath('//base/@href').get()
'http://example.com/'
,>>> response.css('base::attr(href)').get()
'http://example.com/'
,>>> response.css('base').attrib['href']
'http://example.com/'
,>>> response.xpath('//a[contains(@href, ""image"")]/@href').getall()
['image1.html',
 'image2.html',
 'image3.html',
 'image4.html',
 'image5.html']
,>>> response.css('a[href*=image]::attr(href)').getall()
['image1.html',
 'image2.html',
 'image3.html',
 'image4.html',
 'image5.html']
,>>> response.xpath('//a[contains(@href, ""image"")]/img/@src').getall()
['image1_thumb.jpg',
 'image2_thumb.jpg',
 'image3_thumb.jpg',
 'image4_thumb.jpg',
 'image5_thumb.jpg']
,>>> response.css('a[href*=image] img::attr(src)').getall()
['image1_thumb.jpg',
 'image2_thumb.jpg',
 'image3_thumb.jpg',
 'image4_thumb.jpg',
 'image5_thumb.jpg']
,>>> response.css('title::text').get()
'Example website'
,>>> response.css('#images *::text').getall()
['\n   ',
 'Name: My image 1 ',
 '\n   ',
 'Name: My image 2 ',
 '\n   ',
 'Name: My image 3 ',
 '\n   ',
 'Name: My image 4 ',
 '\n   ',
 'Name: My image 5 ',
 '\n  ']
,>>> response.css('img::text').getall()
[]
,>>> response.css('img::text').get()
>>> response.css('img::text').get(default='')
''
,>>> response.css('a::attr(href)').getall()
['image1.html',
 'image2.html',
 'image3.html',
 'image4.html',
 'image5.html']
,>>> links = response.xpath('//a[contains(@href, ""image"")]')
>>> links.getall()
['<a href=""image1.html"">Name: My image 1 <br><img src=""image1_thumb.jpg""></a>',
 '<a href=""image2.html"">Name: My image 2 <br><img src=""image2_thumb.jpg""></a>',
 '<a href=""image3.html"">Name: My image 3 <br><img src=""image3_thumb.jpg""></a>',
 '<a href=""image4.html"">Name: My image 4 <br><img src=""image4_thumb.jpg""></a>',
 '<a href=""image5.html"">Name: My image 5 <br><img src=""image5_thumb.jpg""></a>']
,>>> for index, link in enumerate(links):
...     href_xpath = link.xpath('@href').get()
...     img_xpath = link.xpath('img/@src').get()
...     print(f'Link number {index} points to url {href_xpath!r} and image {img_xpath!r}')
Link number 0 points to url 'image1.html' and image 'image1_thumb.jpg'
Link number 1 points to url 'image2.html' and image 'image2_thumb.jpg'
Link number 2 points to url 'image3.html' and image 'image3_thumb.jpg'
Link number 3 points to url 'image4.html' and image 'image4_thumb.jpg'
Link number 4 points to url 'image5.html' and image 'image5_thumb.jpg'
,>>> response.xpath(""//a/@href"").getall()
['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']
,>>> response.css('a::attr(href)').getall()
['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']
,>>> [a.attrib['href'] for a in response.css('a')]
['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']
,>>> response.css('base').attrib
{'href': 'http://example.com/'}
>>> response.css('base').attrib['href']
'http://example.com/'
,>>> response.css('foo').attrib
{}
,>>> response.xpath('//a[contains(@href, ""image"")]/text()').re(r'Name:\s*(.*)')
['My image 1',
 'My image 2',
 'My image 3',
 'My image 4',
 'My image 5']
,>>> response.xpath('//a[contains(@href, ""image"")]/text()').re_first(r'Name:\s*(.*)')
'My image 1'
,>>> response.css('a::attr(href)').get()
'image1.html'
>>> response.css('a::attr(href)').extract_first()
'image1.html'
,>>> response.css('a::attr(href)').getall()
['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']
>>> response.css('a::attr(href)').extract()
['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']
,>>> response.css('a::attr(href)')[0].get()
'image1.html'
>>> response.css('a::attr(href)')[0].extract()
'image1.html'
,>>> response.css('a::attr(href)')[0].getall()
['image1.html']
,>>> divs = response.xpath('//div')
,>>> for p in divs.xpath('//p'):  # this is wrong - gets all <p> from the whole document
...     print(p.get())
,>>> for p in divs.xpath('.//p'):  # extracts all <p> inside
...     print(p.get())
,>>> for p in divs.xpath('p'):
...     print(p.get())
,*[contains(concat(' ', normalize-space(@class), ' '), ' someclass ')]
,>>> from scrapy import Selector
>>> sel = Selector(text='<div class=""hero shout""><time datetime=""2014-07-23 19:00"">Special date</time></div>')
>>> sel.css('.shout').xpath('./time/@datetime').getall()
['2014-07-23 19:00']
,>>> from scrapy import Selector
>>> sel = Selector(text=""""""
....:     <ul class=""list"">
....:         <li>1</li>
....:         <li>2</li>
....:         <li>3</li>
....:     </ul>
....:     <ul class=""list"">
....:         <li>4</li>
....:         <li>5</li>
....:         <li>6</li>
....:     </ul>"""""")
>>> xp = lambda x: sel.xpath(x).getall()
,>>> xp(""//li[1]"")
['<li>1</li>', '<li>4</li>']
,>>> xp(""(//li)[1]"")
['<li>1</li>']
,>>> xp(""//ul/li[1]"")
['<li>1</li>', '<li>4</li>']
,>>> xp(""(//ul/li)[1]"")
['<li>1</li>']
,>>> from scrapy import Selector
>>> sel = Selector(text='<a href=""#"">Click here to go to the <strong>Next Page</strong></a>')
,>>> sel.xpath('//a//text()').getall() # take a peek at the node-set
['Click here to go to the ', 'Next Page']
>>> sel.xpath(""string(//a[1]//text())"").getall() # convert it to string
['Click here to go to the ']
,>>> sel.xpath(""//a[1]"").getall() # select the first node
['<a href=""#"">Click here to go to the <strong>Next Page</strong></a>']
>>> sel.xpath(""string(//a[1])"").getall() # convert it to string
['Click here to go to the Next Page']
,>>> sel.xpath(""//a[contains(.//text(), 'Next Page')]"").getall()
[]
,>>> sel.xpath(""//a[contains(., 'Next Page')]"").getall()
['<a href=""#"">Click here to go to the <strong>Next Page</strong></a>']
,>>> # `$val` used in the expression, a `val` argument needs to be passed
>>> response.xpath('//div[@id=$val]/a/text()', val='images').get()
'Name: My image 1 '
,>>> response.xpath('//div[count(a)=$cnt]/@id', cnt=5).get()
'images'
,$ scrapy shell https://feeds.feedburner.com/PythonInsider
,<?xml version=""1.0"" encoding=""UTF-8""?>
<?xml-stylesheet ...
<feed xmlns=""http://www.w3.org/2005/Atom""
      xmlns:openSearch=""http://a9.com/-/spec/opensearchrss/1.0/""
      xmlns:blogger=""http://schemas.google.com/blogger/2008""
      xmlns:georss=""http://www.georss.org/georss""
      xmlns:gd=""http://schemas.google.com/g/2005""
      xmlns:thr=""http://purl.org/syndication/thread/1.0""
      xmlns:feedburner=""http://rssnamespace.org/feedburner/ext/1.0"">
  ...
,>>> response.xpath(""//link"")
[]
,>>> response.selector.remove_namespaces()
>>> response.xpath(""//link"")
[<Selector xpath='//link' data='<link rel=""alternate"" type=""text/html"" h'>,
    <Selector xpath='//link' data='<link rel=""next"" type=""application/atom+'>,
    ...
,>>> from scrapy import Selector
>>> doc = """"""
... <div>
...     <ul>
...         <li class=""item-0""><a href=""link1.html"">first item</a></li>
...         <li class=""item-1""><a href=""link2.html"">second item</a></li>
...         <li class=""item-inactive""><a href=""link3.html"">third item</a></li>
...         <li class=""item-1""><a href=""link4.html"">fourth item</a></li>
...         <li class=""item-0""><a href=""link5.html"">fifth item</a></li>
...     </ul>
... </div>
... """"""
>>> sel = Selector(text=doc, type=""html"")
>>> sel.xpath('//li//@href').getall()
['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']
>>> sel.xpath('//li[re:test(@class, ""item-\d$"")]//@href').getall()
['link1.html', 'link2.html', 'link4.html', 'link5.html']
,>>> doc = """"""
... <div itemscope itemtype=""http://schema.org/Product"">
...   <span itemprop=""name"">Kenmore White 17"" Microwave</span>
...   <img src=""kenmore-microwave-17in.jpg"" alt='Kenmore 17"" Microwave' />
...   <div itemprop=""aggregateRating""
...     itemscope itemtype=""http://schema.org/AggregateRating"">
...    Rated <span itemprop=""ratingValue"">3.5</span>/5
...    based on <span itemprop=""reviewCount"">11</span> customer reviews
...   </div>
...
...   <div itemprop=""offers"" itemscope itemtype=""http://schema.org/Offer"">
...     <span itemprop=""price"">$55.00</span>
...     <link itemprop=""availability"" href=""http://schema.org/InStock"" />In stock
...   </div>
...
...   Product description:
...   <span itemprop=""description"">0.7 cubic feet countertop microwave.
...   Has six preset cooking categories and convenience features like
...   Add-A-Minute and Child Lock.</span>
...
...   Customer reviews:
...
...   <div itemprop=""review"" itemscope itemtype=""http://schema.org/Review"">
...     <span itemprop=""name"">Not a happy camper</span> -
...     by <span itemprop=""author"">Ellie</span>,
...     <meta itemprop=""datePublished"" content=""2011-04-01"">April 1, 2011
...     <div itemprop=""reviewRating"" itemscope itemtype=""http://schema.org/Rating"">
...       <meta itemprop=""worstRating"" content = ""1"">
...       <span itemprop=""ratingValue"">1</span>/
...       <span itemprop=""bestRating"">5</span>stars
...     </div>
...     <span itemprop=""description"">The lamp burned out and now I have to replace
...     it. </span>
...   </div>
...
...   <div itemprop=""review"" itemscope itemtype=""http://schema.org/Review"">
...     <span itemprop=""name"">Value purchase</span> -
...     by <span itemprop=""author"">Lucas</span>,
...     <meta itemprop=""datePublished"" content=""2011-03-25"">March 25, 2011
...     <div itemprop=""reviewRating"" itemscope itemtype=""http://schema.org/Rating"">
...       <meta itemprop=""worstRating"" content = ""1""/>
...       <span itemprop=""ratingValue"">4</span>/
...       <span itemprop=""bestRating"">5</span>stars
...     </div>
...     <span itemprop=""description"">Great microwave for the price. It is small and
...     fits in my apartment.</span>
...   </div>
...   ...
... </div>
... """"""
>>> sel = Selector(text=doc, type=""html"")
>>> for scope in sel.xpath('//div[@itemscope]'):
...     print(""current scope:"", scope.xpath('@itemtype').getall())
...     props = scope.xpath('''
...                 set:difference(./descendant::*/@itemprop,
...                                .//*[@itemscope]/*/@itemprop)''')
...     print(f""    properties: {props.getall()}"")
...     print("""")

current scope: ['http://schema.org/Product']
    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']

current scope: ['http://schema.org/AggregateRating']
    properties: ['ratingValue', 'reviewCount']

current scope: ['http://schema.org/Offer']
    properties: ['price', 'availability']

current scope: ['http://schema.org/Review']
    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']

current scope: ['http://schema.org/Rating']
    properties: ['worstRating', 'ratingValue', 'bestRating']

current scope: ['http://schema.org/Review']
    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']

current scope: ['http://schema.org/Rating']
    properties: ['worstRating', 'ratingValue', 'bestRating']
,<p class=""foo bar-baz"">First</p>
<p class=""foo"">Second</p>
<p class=""bar"">Third</p>
<p>Fourth</p>
,>>> response.xpath('//p[has-class(""foo"")]')
[<Selector xpath='//p[has-class(""foo"")]' data='<p class=""foo bar-baz"">First</p>'>,
 <Selector xpath='//p[has-class(""foo"")]' data='<p class=""foo"">Second</p>'>]
>>> response.xpath('//p[has-class(""foo"", ""bar-baz"")]')
[<Selector xpath='//p[has-class(""foo"", ""bar-baz"")]' data='<p class=""foo bar-baz"">First</p>'>]
>>> response.xpath('//p[has-class(""foo"", ""bar"")]')
[]
,selector.xpath('//a[href=$url]', url=""http://www.example.com"")
,selector.xpath('//a[href=$url]', url=""http://www.example.com"")
,sel = Selector(html_response)
,sel.xpath(""//h1"")
,sel.xpath(""//h1"").getall()         # this includes the h1 tag
sel.xpath(""//h1/text()"").getall()  # this excludes the h1 tag
,for node in sel.xpath(""//p""):
    print(node.attrib['class'])
,sel = Selector(xml_response)
,sel.xpath(""//product"")
,sel.register_namespace(""g"", ""http://base.google.com/ns/1.0"")
sel.xpath(""//g:price"").getall()
",76
https://docs.scrapy.org/en/latest/topics/selectors.html,,##,2,Using selectors,#using-selectors,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">selector</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//span/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'good'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//span/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'good'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'good'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.selector</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">body</span> <span class=""o"">=</span> <span class=""s1"">'&lt;html&gt;&lt;body&gt;&lt;span&gt;good&lt;/span&gt;&lt;/body&gt;&lt;/html&gt;'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">body</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//span/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'good'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.selector</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.http</span> <span class=""kn"">import</span> <span class=""n"">HtmlResponse</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span> <span class=""o"">=</span> <span class=""n"">HtmlResponse</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""s1"">'http://example.com'</span><span class=""p"">,</span> <span class=""n"">body</span><span class=""o"">=</span><span class=""n"">body</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">=</span><span class=""n"">response</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//span/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'good'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""cp"">&lt;!DOCTYPE html&gt;</span>

<span class=""p"">&lt;</span><span class=""nt"">html</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">head</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">base</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'http://example.com/'</span> <span class=""p"">/&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">title</span><span class=""p"">&gt;</span>Example website<span class=""p"">&lt;/</span><span class=""nt"">title</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;/</span><span class=""nt"">head</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">body</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">id</span><span class=""o"">=</span><span class=""s"">'images'</span><span class=""p"">&gt;</span>
      <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'image1.html'</span><span class=""p"">&gt;</span>Name: My image 1 <span class=""p"">&lt;</span><span class=""nt"">br</span> <span class=""p"">/&gt;&lt;</span><span class=""nt"">img</span> <span class=""na"">src</span><span class=""o"">=</span><span class=""s"">'image1_thumb.jpg'</span> <span class=""na"">alt</span><span class=""o"">=</span><span class=""s"">'image1'</span><span class=""p"">/&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
      <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'image2.html'</span><span class=""p"">&gt;</span>Name: My image 2 <span class=""p"">&lt;</span><span class=""nt"">br</span> <span class=""p"">/&gt;&lt;</span><span class=""nt"">img</span> <span class=""na"">src</span><span class=""o"">=</span><span class=""s"">'image2_thumb.jpg'</span> <span class=""na"">alt</span><span class=""o"">=</span><span class=""s"">'image2'</span><span class=""p"">/&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
      <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'image3.html'</span><span class=""p"">&gt;</span>Name: My image 3 <span class=""p"">&lt;</span><span class=""nt"">br</span> <span class=""p"">/&gt;&lt;</span><span class=""nt"">img</span> <span class=""na"">src</span><span class=""o"">=</span><span class=""s"">'image3_thumb.jpg'</span> <span class=""na"">alt</span><span class=""o"">=</span><span class=""s"">'image3'</span><span class=""p"">/&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
      <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'image4.html'</span><span class=""p"">&gt;</span>Name: My image 4 <span class=""p"">&lt;</span><span class=""nt"">br</span> <span class=""p"">/&gt;&lt;</span><span class=""nt"">img</span> <span class=""na"">src</span><span class=""o"">=</span><span class=""s"">'image4_thumb.jpg'</span> <span class=""na"">alt</span><span class=""o"">=</span><span class=""s"">'image4'</span><span class=""p"">/&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
      <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'image5.html'</span><span class=""p"">&gt;</span>Name: My image 5 <span class=""p"">&lt;</span><span class=""nt"">br</span> <span class=""p"">/&gt;&lt;</span><span class=""nt"">img</span> <span class=""na"">src</span><span class=""o"">=</span><span class=""s"">'image5_thumb.jpg'</span> <span class=""na"">alt</span><span class=""o"">=</span><span class=""s"">'image5'</span><span class=""p"">/&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;/</span><span class=""nt"">body</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;/</span><span class=""nt"">html</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span>scrapy shell https://docs.scrapy.org/en/latest/_static/selectors-sample1.html
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='//title/text()' data='Example website'&gt;]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['Example website']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Example website'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Example website'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'@src'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1_thumb.jpg',</span>
<span class=""go""> 'image2_thumb.jpg',</span>
<span class=""go""> 'image3_thumb.jpg',</span>
<span class=""go""> 'image4_thumb.jpg',</span>
<span class=""go""> 'image5_thumb.jpg']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[@id=""images""]/a/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Name: My image 1 '</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[@id=""not-exists""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span> <span class=""ow"">is</span> <span class=""kc"">None</span>
<span class=""go"">True</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[@id=""not-exists""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""n"">default</span><span class=""o"">=</span><span class=""s1"">'not-found'</span><span class=""p"">)</span>
<span class=""go"">'not-found'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""p"">[</span><span class=""n"">img</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'src'</span><span class=""p"">]</span> <span class=""k"">for</span> <span class=""n"">img</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img'</span><span class=""p"">)]</span>
<span class=""go"">['image1_thumb.jpg',</span>
<span class=""go""> 'image2_thumb.jpg',</span>
<span class=""go""> 'image3_thumb.jpg',</span>
<span class=""go""> 'image4_thumb.jpg',</span>
<span class=""go""> 'image5_thumb.jpg']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'src'</span><span class=""p"">]</span>
<span class=""go"">'image1_thumb.jpg'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'base'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'href'</span><span class=""p"">]</span>
<span class=""go"">'http://example.com/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//base/@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'http://example.com/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'base::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'http://example.com/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'base'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'href'</span><span class=""p"">]</span>
<span class=""go"">'http://example.com/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[contains(@href, ""image"")]/@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html',</span>
<span class=""go""> 'image2.html',</span>
<span class=""go""> 'image3.html',</span>
<span class=""go""> 'image4.html',</span>
<span class=""go""> 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a[href*=image]::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html',</span>
<span class=""go""> 'image2.html',</span>
<span class=""go""> 'image3.html',</span>
<span class=""go""> 'image4.html',</span>
<span class=""go""> 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[contains(@href, ""image"")]/img/@src'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1_thumb.jpg',</span>
<span class=""go""> 'image2_thumb.jpg',</span>
<span class=""go""> 'image3_thumb.jpg',</span>
<span class=""go""> 'image4_thumb.jpg',</span>
<span class=""go""> 'image5_thumb.jpg']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a[href*=image] img::attr(src)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1_thumb.jpg',</span>
<span class=""go""> 'image2_thumb.jpg',</span>
<span class=""go""> 'image3_thumb.jpg',</span>
<span class=""go""> 'image4_thumb.jpg',</span>
<span class=""go""> 'image5_thumb.jpg']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Example website'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'#images *::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['\n   ',</span>
<span class=""go""> 'Name: My image 1 ',</span>
<span class=""go""> '\n   ',</span>
<span class=""go""> 'Name: My image 2 ',</span>
<span class=""go""> '\n   ',</span>
<span class=""go""> 'Name: My image 3 ',</span>
<span class=""go""> '\n   ',</span>
<span class=""go""> 'Name: My image 4 ',</span>
<span class=""go""> '\n   ',</span>
<span class=""go""> 'Name: My image 5 ',</span>
<span class=""go""> '\n  ']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">[]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""n"">default</span><span class=""o"">=</span><span class=""s1"">''</span><span class=""p"">)</span>
<span class=""go"">''</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html',</span>
<span class=""go""> 'image2.html',</span>
<span class=""go""> 'image3.html',</span>
<span class=""go""> 'image4.html',</span>
<span class=""go""> 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">links</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[contains(@href, ""image"")]'</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">links</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['&lt;a href=""image1.html""&gt;Name: My image 1 &lt;br&gt;&lt;img src=""image1_thumb.jpg""&gt;&lt;/a&gt;',</span>
<span class=""go""> '&lt;a href=""image2.html""&gt;Name: My image 2 &lt;br&gt;&lt;img src=""image2_thumb.jpg""&gt;&lt;/a&gt;',</span>
<span class=""go""> '&lt;a href=""image3.html""&gt;Name: My image 3 &lt;br&gt;&lt;img src=""image3_thumb.jpg""&gt;&lt;/a&gt;',</span>
<span class=""go""> '&lt;a href=""image4.html""&gt;Name: My image 4 &lt;br&gt;&lt;img src=""image4_thumb.jpg""&gt;&lt;/a&gt;',</span>
<span class=""go""> '&lt;a href=""image5.html""&gt;Name: My image 5 &lt;br&gt;&lt;img src=""image5_thumb.jpg""&gt;&lt;/a&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">index</span><span class=""p"">,</span> <span class=""n"">link</span> <span class=""ow"">in</span> <span class=""nb"">enumerate</span><span class=""p"">(</span><span class=""n"">links</span><span class=""p"">):</span>
<span class=""gp"">... </span>    <span class=""n"">href_xpath</span> <span class=""o"">=</span> <span class=""n"">link</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""n"">img_xpath</span> <span class=""o"">=</span> <span class=""n"">link</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'img/@src'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s1"">'Link number </span><span class=""si"">{</span><span class=""n"">index</span><span class=""si"">}</span><span class=""s1""> points to url </span><span class=""si"">{</span><span class=""n"">href_xpath</span><span class=""si"">!r}</span><span class=""s1""> and image </span><span class=""si"">{</span><span class=""n"">img_xpath</span><span class=""si"">!r}</span><span class=""s1"">'</span><span class=""p"">)</span>
<span class=""go"">Link number 0 points to url 'image1.html' and image 'image1_thumb.jpg'</span>
<span class=""go"">Link number 1 points to url 'image2.html' and image 'image2_thumb.jpg'</span>
<span class=""go"">Link number 2 points to url 'image3.html' and image 'image3_thumb.jpg'</span>
<span class=""go"">Link number 3 points to url 'image4.html' and image 'image4_thumb.jpg'</span>
<span class=""go"">Link number 4 points to url 'image5.html' and image 'image5_thumb.jpg'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//a/@href""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""p"">[</span><span class=""n"">a</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'href'</span><span class=""p"">]</span> <span class=""k"">for</span> <span class=""n"">a</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a'</span><span class=""p"">)]</span>
<span class=""go"">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'base'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span>
<span class=""go"">{'href': 'http://example.com/'}</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'base'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'href'</span><span class=""p"">]</span>
<span class=""go"">'http://example.com/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'foo'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span>
<span class=""go"">{}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[contains(@href, ""image"")]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'Name:\s*(.*)'</span><span class=""p"">)</span>
<span class=""go"">['My image 1',</span>
<span class=""go""> 'My image 2',</span>
<span class=""go""> 'My image 3',</span>
<span class=""go""> 'My image 4',</span>
<span class=""go""> 'My image 5']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[contains(@href, ""image"")]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re_first</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'Name:\s*(.*)'</span><span class=""p"">)</span>
<span class=""go"">'My image 1'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'image1.html'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">extract_first</span><span class=""p"">()</span>
<span class=""go"">'image1.html'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">extract</span><span class=""p"">()</span>
<span class=""go"">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'image1.html'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">extract</span><span class=""p"">()</span>
<span class=""go"">'image1.html'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html']</span>
</pre></div>",">>> response.selector.xpath('//span/text()').get()
'good'
,>>> response.xpath('//span/text()').get()
'good'
>>> response.css('span::text').get()
'good'
,>>> from scrapy.selector import Selector
>>> body = '<html><body><span>good</span></body></html>'
>>> Selector(text=body).xpath('//span/text()').get()
'good'
,>>> from scrapy.selector import Selector
>>> from scrapy.http import HtmlResponse
>>> response = HtmlResponse(url='http://example.com', body=body)
>>> Selector(response=response).xpath('//span/text()').get()
'good'
,<!DOCTYPE html>

<html>
  <head>
    <base href='http://example.com/' />
    <title>Example website</title>
  </head>
  <body>
    <div id='images'>
      <a href='image1.html'>Name: My image 1 <br /><img src='image1_thumb.jpg' alt='image1'/></a>
      <a href='image2.html'>Name: My image 2 <br /><img src='image2_thumb.jpg' alt='image2'/></a>
      <a href='image3.html'>Name: My image 3 <br /><img src='image3_thumb.jpg' alt='image3'/></a>
      <a href='image4.html'>Name: My image 4 <br /><img src='image4_thumb.jpg' alt='image4'/></a>
      <a href='image5.html'>Name: My image 5 <br /><img src='image5_thumb.jpg' alt='image5'/></a>
    </div>
  </body>
</html>
,scrapy shell https://docs.scrapy.org/en/latest/_static/selectors-sample1.html
,>>> response.xpath('//title/text()')
[<Selector xpath='//title/text()' data='Example website'>]
,>>> response.xpath('//title/text()').getall()
['Example website']
>>> response.xpath('//title/text()').get()
'Example website'
,>>> response.css('title::text').get()
'Example website'
,>>> response.css('img').xpath('@src').getall()
['image1_thumb.jpg',
 'image2_thumb.jpg',
 'image3_thumb.jpg',
 'image4_thumb.jpg',
 'image5_thumb.jpg']
,>>> response.xpath('//div[@id=""images""]/a/text()').get()
'Name: My image 1 '
,>>> response.xpath('//div[@id=""not-exists""]/text()').get() is None
True
,>>> response.xpath('//div[@id=""not-exists""]/text()').get(default='not-found')
'not-found'
,>>> [img.attrib['src'] for img in response.css('img')]
['image1_thumb.jpg',
 'image2_thumb.jpg',
 'image3_thumb.jpg',
 'image4_thumb.jpg',
 'image5_thumb.jpg']
,>>> response.css('img').attrib['src']
'image1_thumb.jpg'
,>>> response.css('base').attrib['href']
'http://example.com/'
,>>> response.xpath('//base/@href').get()
'http://example.com/'
,>>> response.css('base::attr(href)').get()
'http://example.com/'
,>>> response.css('base').attrib['href']
'http://example.com/'
,>>> response.xpath('//a[contains(@href, ""image"")]/@href').getall()
['image1.html',
 'image2.html',
 'image3.html',
 'image4.html',
 'image5.html']
,>>> response.css('a[href*=image]::attr(href)').getall()
['image1.html',
 'image2.html',
 'image3.html',
 'image4.html',
 'image5.html']
,>>> response.xpath('//a[contains(@href, ""image"")]/img/@src').getall()
['image1_thumb.jpg',
 'image2_thumb.jpg',
 'image3_thumb.jpg',
 'image4_thumb.jpg',
 'image5_thumb.jpg']
,>>> response.css('a[href*=image] img::attr(src)').getall()
['image1_thumb.jpg',
 'image2_thumb.jpg',
 'image3_thumb.jpg',
 'image4_thumb.jpg',
 'image5_thumb.jpg']
,>>> response.css('title::text').get()
'Example website'
,>>> response.css('#images *::text').getall()
['\n   ',
 'Name: My image 1 ',
 '\n   ',
 'Name: My image 2 ',
 '\n   ',
 'Name: My image 3 ',
 '\n   ',
 'Name: My image 4 ',
 '\n   ',
 'Name: My image 5 ',
 '\n  ']
,>>> response.css('img::text').getall()
[]
,>>> response.css('img::text').get()
>>> response.css('img::text').get(default='')
''
,>>> response.css('a::attr(href)').getall()
['image1.html',
 'image2.html',
 'image3.html',
 'image4.html',
 'image5.html']
,>>> links = response.xpath('//a[contains(@href, ""image"")]')
>>> links.getall()
['<a href=""image1.html"">Name: My image 1 <br><img src=""image1_thumb.jpg""></a>',
 '<a href=""image2.html"">Name: My image 2 <br><img src=""image2_thumb.jpg""></a>',
 '<a href=""image3.html"">Name: My image 3 <br><img src=""image3_thumb.jpg""></a>',
 '<a href=""image4.html"">Name: My image 4 <br><img src=""image4_thumb.jpg""></a>',
 '<a href=""image5.html"">Name: My image 5 <br><img src=""image5_thumb.jpg""></a>']
,>>> for index, link in enumerate(links):
...     href_xpath = link.xpath('@href').get()
...     img_xpath = link.xpath('img/@src').get()
...     print(f'Link number {index} points to url {href_xpath!r} and image {img_xpath!r}')
Link number 0 points to url 'image1.html' and image 'image1_thumb.jpg'
Link number 1 points to url 'image2.html' and image 'image2_thumb.jpg'
Link number 2 points to url 'image3.html' and image 'image3_thumb.jpg'
Link number 3 points to url 'image4.html' and image 'image4_thumb.jpg'
Link number 4 points to url 'image5.html' and image 'image5_thumb.jpg'
,>>> response.xpath(""//a/@href"").getall()
['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']
,>>> response.css('a::attr(href)').getall()
['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']
,>>> [a.attrib['href'] for a in response.css('a')]
['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']
,>>> response.css('base').attrib
{'href': 'http://example.com/'}
>>> response.css('base').attrib['href']
'http://example.com/'
,>>> response.css('foo').attrib
{}
,>>> response.xpath('//a[contains(@href, ""image"")]/text()').re(r'Name:\s*(.*)')
['My image 1',
 'My image 2',
 'My image 3',
 'My image 4',
 'My image 5']
,>>> response.xpath('//a[contains(@href, ""image"")]/text()').re_first(r'Name:\s*(.*)')
'My image 1'
,>>> response.css('a::attr(href)').get()
'image1.html'
>>> response.css('a::attr(href)').extract_first()
'image1.html'
,>>> response.css('a::attr(href)').getall()
['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']
>>> response.css('a::attr(href)').extract()
['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']
,>>> response.css('a::attr(href)')[0].get()
'image1.html'
>>> response.css('a::attr(href)')[0].extract()
'image1.html'
,>>> response.css('a::attr(href)')[0].getall()
['image1.html']
",41
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,Constructing selectors,#constructing-selectors,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">selector</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//span/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'good'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//span/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'good'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'good'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.selector</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">body</span> <span class=""o"">=</span> <span class=""s1"">'&lt;html&gt;&lt;body&gt;&lt;span&gt;good&lt;/span&gt;&lt;/body&gt;&lt;/html&gt;'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">body</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//span/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'good'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.selector</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.http</span> <span class=""kn"">import</span> <span class=""n"">HtmlResponse</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span> <span class=""o"">=</span> <span class=""n"">HtmlResponse</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""s1"">'http://example.com'</span><span class=""p"">,</span> <span class=""n"">body</span><span class=""o"">=</span><span class=""n"">body</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">=</span><span class=""n"">response</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//span/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'good'</span>
</pre></div>",">>> response.selector.xpath('//span/text()').get()
'good'
,>>> response.xpath('//span/text()').get()
'good'
>>> response.css('span::text').get()
'good'
,>>> from scrapy.selector import Selector
>>> body = '<html><body><span>good</span></body></html>'
>>> Selector(text=body).xpath('//span/text()').get()
'good'
,>>> from scrapy.selector import Selector
>>> from scrapy.http import HtmlResponse
>>> response = HtmlResponse(url='http://example.com', body=body)
>>> Selector(response=response).xpath('//span/text()').get()
'good'
",4
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,Using selectors,#id1,"<div class=""highlight""><pre><span></span><span class=""cp"">&lt;!DOCTYPE html&gt;</span>

<span class=""p"">&lt;</span><span class=""nt"">html</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">head</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">base</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'http://example.com/'</span> <span class=""p"">/&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">title</span><span class=""p"">&gt;</span>Example website<span class=""p"">&lt;/</span><span class=""nt"">title</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;/</span><span class=""nt"">head</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">body</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">id</span><span class=""o"">=</span><span class=""s"">'images'</span><span class=""p"">&gt;</span>
      <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'image1.html'</span><span class=""p"">&gt;</span>Name: My image 1 <span class=""p"">&lt;</span><span class=""nt"">br</span> <span class=""p"">/&gt;&lt;</span><span class=""nt"">img</span> <span class=""na"">src</span><span class=""o"">=</span><span class=""s"">'image1_thumb.jpg'</span> <span class=""na"">alt</span><span class=""o"">=</span><span class=""s"">'image1'</span><span class=""p"">/&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
      <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'image2.html'</span><span class=""p"">&gt;</span>Name: My image 2 <span class=""p"">&lt;</span><span class=""nt"">br</span> <span class=""p"">/&gt;&lt;</span><span class=""nt"">img</span> <span class=""na"">src</span><span class=""o"">=</span><span class=""s"">'image2_thumb.jpg'</span> <span class=""na"">alt</span><span class=""o"">=</span><span class=""s"">'image2'</span><span class=""p"">/&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
      <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'image3.html'</span><span class=""p"">&gt;</span>Name: My image 3 <span class=""p"">&lt;</span><span class=""nt"">br</span> <span class=""p"">/&gt;&lt;</span><span class=""nt"">img</span> <span class=""na"">src</span><span class=""o"">=</span><span class=""s"">'image3_thumb.jpg'</span> <span class=""na"">alt</span><span class=""o"">=</span><span class=""s"">'image3'</span><span class=""p"">/&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
      <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'image4.html'</span><span class=""p"">&gt;</span>Name: My image 4 <span class=""p"">&lt;</span><span class=""nt"">br</span> <span class=""p"">/&gt;&lt;</span><span class=""nt"">img</span> <span class=""na"">src</span><span class=""o"">=</span><span class=""s"">'image4_thumb.jpg'</span> <span class=""na"">alt</span><span class=""o"">=</span><span class=""s"">'image4'</span><span class=""p"">/&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
      <span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">'image5.html'</span><span class=""p"">&gt;</span>Name: My image 5 <span class=""p"">&lt;</span><span class=""nt"">br</span> <span class=""p"">/&gt;&lt;</span><span class=""nt"">img</span> <span class=""na"">src</span><span class=""o"">=</span><span class=""s"">'image5_thumb.jpg'</span> <span class=""na"">alt</span><span class=""o"">=</span><span class=""s"">'image5'</span><span class=""p"">/&gt;&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
    <span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;/</span><span class=""nt"">body</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;/</span><span class=""nt"">html</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span>scrapy shell https://docs.scrapy.org/en/latest/_static/selectors-sample1.html
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='//title/text()' data='Example website'&gt;]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['Example website']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Example website'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Example website'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'@src'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1_thumb.jpg',</span>
<span class=""go""> 'image2_thumb.jpg',</span>
<span class=""go""> 'image3_thumb.jpg',</span>
<span class=""go""> 'image4_thumb.jpg',</span>
<span class=""go""> 'image5_thumb.jpg']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[@id=""images""]/a/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Name: My image 1 '</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[@id=""not-exists""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span> <span class=""ow"">is</span> <span class=""kc"">None</span>
<span class=""go"">True</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[@id=""not-exists""]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""n"">default</span><span class=""o"">=</span><span class=""s1"">'not-found'</span><span class=""p"">)</span>
<span class=""go"">'not-found'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""p"">[</span><span class=""n"">img</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'src'</span><span class=""p"">]</span> <span class=""k"">for</span> <span class=""n"">img</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img'</span><span class=""p"">)]</span>
<span class=""go"">['image1_thumb.jpg',</span>
<span class=""go""> 'image2_thumb.jpg',</span>
<span class=""go""> 'image3_thumb.jpg',</span>
<span class=""go""> 'image4_thumb.jpg',</span>
<span class=""go""> 'image5_thumb.jpg']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'src'</span><span class=""p"">]</span>
<span class=""go"">'image1_thumb.jpg'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'base'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'href'</span><span class=""p"">]</span>
<span class=""go"">'http://example.com/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//base/@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'http://example.com/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'base::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'http://example.com/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'base'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'href'</span><span class=""p"">]</span>
<span class=""go"">'http://example.com/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[contains(@href, ""image"")]/@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html',</span>
<span class=""go""> 'image2.html',</span>
<span class=""go""> 'image3.html',</span>
<span class=""go""> 'image4.html',</span>
<span class=""go""> 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a[href*=image]::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html',</span>
<span class=""go""> 'image2.html',</span>
<span class=""go""> 'image3.html',</span>
<span class=""go""> 'image4.html',</span>
<span class=""go""> 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[contains(@href, ""image"")]/img/@src'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1_thumb.jpg',</span>
<span class=""go""> 'image2_thumb.jpg',</span>
<span class=""go""> 'image3_thumb.jpg',</span>
<span class=""go""> 'image4_thumb.jpg',</span>
<span class=""go""> 'image5_thumb.jpg']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a[href*=image] img::attr(src)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1_thumb.jpg',</span>
<span class=""go""> 'image2_thumb.jpg',</span>
<span class=""go""> 'image3_thumb.jpg',</span>
<span class=""go""> 'image4_thumb.jpg',</span>
<span class=""go""> 'image5_thumb.jpg']</span>
</pre></div>","<!DOCTYPE html>

<html>
  <head>
    <base href='http://example.com/' />
    <title>Example website</title>
  </head>
  <body>
    <div id='images'>
      <a href='image1.html'>Name: My image 1 <br /><img src='image1_thumb.jpg' alt='image1'/></a>
      <a href='image2.html'>Name: My image 2 <br /><img src='image2_thumb.jpg' alt='image2'/></a>
      <a href='image3.html'>Name: My image 3 <br /><img src='image3_thumb.jpg' alt='image3'/></a>
      <a href='image4.html'>Name: My image 4 <br /><img src='image4_thumb.jpg' alt='image4'/></a>
      <a href='image5.html'>Name: My image 5 <br /><img src='image5_thumb.jpg' alt='image5'/></a>
    </div>
  </body>
</html>
,scrapy shell https://docs.scrapy.org/en/latest/_static/selectors-sample1.html
,>>> response.xpath('//title/text()')
[<Selector xpath='//title/text()' data='Example website'>]
,>>> response.xpath('//title/text()').getall()
['Example website']
>>> response.xpath('//title/text()').get()
'Example website'
,>>> response.css('title::text').get()
'Example website'
,>>> response.css('img').xpath('@src').getall()
['image1_thumb.jpg',
 'image2_thumb.jpg',
 'image3_thumb.jpg',
 'image4_thumb.jpg',
 'image5_thumb.jpg']
,>>> response.xpath('//div[@id=""images""]/a/text()').get()
'Name: My image 1 '
,>>> response.xpath('//div[@id=""not-exists""]/text()').get() is None
True
,>>> response.xpath('//div[@id=""not-exists""]/text()').get(default='not-found')
'not-found'
,>>> [img.attrib['src'] for img in response.css('img')]
['image1_thumb.jpg',
 'image2_thumb.jpg',
 'image3_thumb.jpg',
 'image4_thumb.jpg',
 'image5_thumb.jpg']
,>>> response.css('img').attrib['src']
'image1_thumb.jpg'
,>>> response.css('base').attrib['href']
'http://example.com/'
,>>> response.xpath('//base/@href').get()
'http://example.com/'
,>>> response.css('base::attr(href)').get()
'http://example.com/'
,>>> response.css('base').attrib['href']
'http://example.com/'
,>>> response.xpath('//a[contains(@href, ""image"")]/@href').getall()
['image1.html',
 'image2.html',
 'image3.html',
 'image4.html',
 'image5.html']
,>>> response.css('a[href*=image]::attr(href)').getall()
['image1.html',
 'image2.html',
 'image3.html',
 'image4.html',
 'image5.html']
,>>> response.xpath('//a[contains(@href, ""image"")]/img/@src').getall()
['image1_thumb.jpg',
 'image2_thumb.jpg',
 'image3_thumb.jpg',
 'image4_thumb.jpg',
 'image5_thumb.jpg']
,>>> response.css('a[href*=image] img::attr(src)').getall()
['image1_thumb.jpg',
 'image2_thumb.jpg',
 'image3_thumb.jpg',
 'image4_thumb.jpg',
 'image5_thumb.jpg']
",19
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,Extensions to CSS Selectors,#extensions-to-css-selectors,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'title::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Example website'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'#images *::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['\n   ',</span>
<span class=""go""> 'Name: My image 1 ',</span>
<span class=""go""> '\n   ',</span>
<span class=""go""> 'Name: My image 2 ',</span>
<span class=""go""> '\n   ',</span>
<span class=""go""> 'Name: My image 3 ',</span>
<span class=""go""> '\n   ',</span>
<span class=""go""> 'Name: My image 4 ',</span>
<span class=""go""> '\n   ',</span>
<span class=""go""> 'Name: My image 5 ',</span>
<span class=""go""> '\n  ']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">[]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'img::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""n"">default</span><span class=""o"">=</span><span class=""s1"">''</span><span class=""p"">)</span>
<span class=""go"">''</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html',</span>
<span class=""go""> 'image2.html',</span>
<span class=""go""> 'image3.html',</span>
<span class=""go""> 'image4.html',</span>
<span class=""go""> 'image5.html']</span>
</pre></div>",">>> response.css('title::text').get()
'Example website'
,>>> response.css('#images *::text').getall()
['\n   ',
 'Name: My image 1 ',
 '\n   ',
 'Name: My image 2 ',
 '\n   ',
 'Name: My image 3 ',
 '\n   ',
 'Name: My image 4 ',
 '\n   ',
 'Name: My image 5 ',
 '\n  ']
,>>> response.css('img::text').getall()
[]
,>>> response.css('img::text').get()
>>> response.css('img::text').get(default='')
''
,>>> response.css('a::attr(href)').getall()
['image1.html',
 'image2.html',
 'image3.html',
 'image4.html',
 'image5.html']
",5
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,Nesting selectors,#nesting-selectors,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">links</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[contains(@href, ""image"")]'</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">links</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['&lt;a href=""image1.html""&gt;Name: My image 1 &lt;br&gt;&lt;img src=""image1_thumb.jpg""&gt;&lt;/a&gt;',</span>
<span class=""go""> '&lt;a href=""image2.html""&gt;Name: My image 2 &lt;br&gt;&lt;img src=""image2_thumb.jpg""&gt;&lt;/a&gt;',</span>
<span class=""go""> '&lt;a href=""image3.html""&gt;Name: My image 3 &lt;br&gt;&lt;img src=""image3_thumb.jpg""&gt;&lt;/a&gt;',</span>
<span class=""go""> '&lt;a href=""image4.html""&gt;Name: My image 4 &lt;br&gt;&lt;img src=""image4_thumb.jpg""&gt;&lt;/a&gt;',</span>
<span class=""go""> '&lt;a href=""image5.html""&gt;Name: My image 5 &lt;br&gt;&lt;img src=""image5_thumb.jpg""&gt;&lt;/a&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">index</span><span class=""p"">,</span> <span class=""n"">link</span> <span class=""ow"">in</span> <span class=""nb"">enumerate</span><span class=""p"">(</span><span class=""n"">links</span><span class=""p"">):</span>
<span class=""gp"">... </span>    <span class=""n"">href_xpath</span> <span class=""o"">=</span> <span class=""n"">link</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""n"">img_xpath</span> <span class=""o"">=</span> <span class=""n"">link</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'img/@src'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s1"">'Link number </span><span class=""si"">{</span><span class=""n"">index</span><span class=""si"">}</span><span class=""s1""> points to url </span><span class=""si"">{</span><span class=""n"">href_xpath</span><span class=""si"">!r}</span><span class=""s1""> and image </span><span class=""si"">{</span><span class=""n"">img_xpath</span><span class=""si"">!r}</span><span class=""s1"">'</span><span class=""p"">)</span>
<span class=""go"">Link number 0 points to url 'image1.html' and image 'image1_thumb.jpg'</span>
<span class=""go"">Link number 1 points to url 'image2.html' and image 'image2_thumb.jpg'</span>
<span class=""go"">Link number 2 points to url 'image3.html' and image 'image3_thumb.jpg'</span>
<span class=""go"">Link number 3 points to url 'image4.html' and image 'image4_thumb.jpg'</span>
<span class=""go"">Link number 4 points to url 'image5.html' and image 'image5_thumb.jpg'</span>
</pre></div>",">>> links = response.xpath('//a[contains(@href, ""image"")]')
>>> links.getall()
['<a href=""image1.html"">Name: My image 1 <br><img src=""image1_thumb.jpg""></a>',
 '<a href=""image2.html"">Name: My image 2 <br><img src=""image2_thumb.jpg""></a>',
 '<a href=""image3.html"">Name: My image 3 <br><img src=""image3_thumb.jpg""></a>',
 '<a href=""image4.html"">Name: My image 4 <br><img src=""image4_thumb.jpg""></a>',
 '<a href=""image5.html"">Name: My image 5 <br><img src=""image5_thumb.jpg""></a>']
,>>> for index, link in enumerate(links):
...     href_xpath = link.xpath('@href').get()
...     img_xpath = link.xpath('img/@src').get()
...     print(f'Link number {index} points to url {href_xpath!r} and image {img_xpath!r}')
Link number 0 points to url 'image1.html' and image 'image1_thumb.jpg'
Link number 1 points to url 'image2.html' and image 'image2_thumb.jpg'
Link number 2 points to url 'image3.html' and image 'image3_thumb.jpg'
Link number 3 points to url 'image4.html' and image 'image4_thumb.jpg'
Link number 4 points to url 'image5.html' and image 'image5_thumb.jpg'
",2
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,Selecting element attributes,#selecting-element-attributes,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//a/@href""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""p"">[</span><span class=""n"">a</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'href'</span><span class=""p"">]</span> <span class=""k"">for</span> <span class=""n"">a</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a'</span><span class=""p"">)]</span>
<span class=""go"">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'base'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span>
<span class=""go"">{'href': 'http://example.com/'}</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'base'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'href'</span><span class=""p"">]</span>
<span class=""go"">'http://example.com/'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'foo'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">attrib</span>
<span class=""go"">{}</span>
</pre></div>",">>> response.xpath(""//a/@href"").getall()
['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']
,>>> response.css('a::attr(href)').getall()
['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']
,>>> [a.attrib['href'] for a in response.css('a')]
['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']
,>>> response.css('base').attrib
{'href': 'http://example.com/'}
>>> response.css('base').attrib['href']
'http://example.com/'
,>>> response.css('foo').attrib
{}
",5
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,Using selectors with regular expressions,#using-selectors-with-regular-expressions,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[contains(@href, ""image"")]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'Name:\s*(.*)'</span><span class=""p"">)</span>
<span class=""go"">['My image 1',</span>
<span class=""go""> 'My image 2',</span>
<span class=""go""> 'My image 3',</span>
<span class=""go""> 'My image 4',</span>
<span class=""go""> 'My image 5']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[contains(@href, ""image"")]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re_first</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'Name:\s*(.*)'</span><span class=""p"">)</span>
<span class=""go"">'My image 1'</span>
</pre></div>",">>> response.xpath('//a[contains(@href, ""image"")]/text()').re(r'Name:\s*(.*)')
['My image 1',
 'My image 2',
 'My image 3',
 'My image 4',
 'My image 5']
,>>> response.xpath('//a[contains(@href, ""image"")]/text()').re_first(r'Name:\s*(.*)')
'My image 1'
",2
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,extract() and extract_first(),#extract-and-extract-first,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'image1.html'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">extract_first</span><span class=""p"">()</span>
<span class=""go"">'image1.html'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">extract</span><span class=""p"">()</span>
<span class=""go"">['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'image1.html'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">extract</span><span class=""p"">()</span>
<span class=""go"">'image1.html'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'a::attr(href)'</span><span class=""p"">)[</span><span class=""mi"">0</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['image1.html']</span>
</pre></div>",">>> response.css('a::attr(href)').get()
'image1.html'
>>> response.css('a::attr(href)').extract_first()
'image1.html'
,>>> response.css('a::attr(href)').getall()
['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']
>>> response.css('a::attr(href)').extract()
['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']
,>>> response.css('a::attr(href)')[0].get()
'image1.html'
>>> response.css('a::attr(href)')[0].extract()
'image1.html'
,>>> response.css('a::attr(href)')[0].getall()
['image1.html']
",4
https://docs.scrapy.org/en/latest/topics/selectors.html,,##,2,Working with XPaths,#working-with-xpaths,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">divs</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">p</span> <span class=""ow"">in</span> <span class=""n"">divs</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p'</span><span class=""p"">):</span>  <span class=""c1""># this is wrong - gets all &lt;p&gt; from the whole document</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">p</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">())</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">p</span> <span class=""ow"">in</span> <span class=""n"">divs</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'.//p'</span><span class=""p"">):</span>  <span class=""c1""># extracts all &lt;p&gt; inside</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">p</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">())</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">p</span> <span class=""ow"">in</span> <span class=""n"">divs</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'p'</span><span class=""p"">):</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">p</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">())</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">*</span><span class=""p"">[</span><span class=""n"">contains</span><span class=""p"">(</span><span class=""n"">concat</span><span class=""p"">(</span><span class=""s1"">' '</span><span class=""p"">,</span> <span class=""n"">normalize</span><span class=""o"">-</span><span class=""n"">space</span><span class=""p"">(</span><span class=""nd"">@class</span><span class=""p"">),</span> <span class=""s1"">' '</span><span class=""p"">),</span> <span class=""s1"">' someclass '</span><span class=""p"">)]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""s1"">'&lt;div class=""hero shout""&gt;&lt;time datetime=""2014-07-23 19:00""&gt;Special date&lt;/time&gt;&lt;/div&gt;'</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'.shout'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'./time/@datetime'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['2014-07-23 19:00']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""s2"">""""""</span>
<span class=""go"">....:     &lt;ul class=""list""&gt;</span>
<span class=""go"">....:         &lt;li&gt;1&lt;/li&gt;</span>
<span class=""go"">....:         &lt;li&gt;2&lt;/li&gt;</span>
<span class=""go"">....:         &lt;li&gt;3&lt;/li&gt;</span>
<span class=""go"">....:     &lt;/ul&gt;</span>
<span class=""go"">....:     &lt;ul class=""list""&gt;</span>
<span class=""go"">....:         &lt;li&gt;4&lt;/li&gt;</span>
<span class=""go"">....:         &lt;li&gt;5&lt;/li&gt;</span>
<span class=""go"">....:         &lt;li&gt;6&lt;/li&gt;</span>
<span class=""go"">....:     &lt;/ul&gt;"""""")</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xp</span> <span class=""o"">=</span> <span class=""k"">lambda</span> <span class=""n"">x</span><span class=""p"">:</span> <span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""n"">x</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xp</span><span class=""p"">(</span><span class=""s2"">""//li[1]""</span><span class=""p"">)</span>
<span class=""go"">['&lt;li&gt;1&lt;/li&gt;', '&lt;li&gt;4&lt;/li&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xp</span><span class=""p"">(</span><span class=""s2"">""(//li)[1]""</span><span class=""p"">)</span>
<span class=""go"">['&lt;li&gt;1&lt;/li&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xp</span><span class=""p"">(</span><span class=""s2"">""//ul/li[1]""</span><span class=""p"">)</span>
<span class=""go"">['&lt;li&gt;1&lt;/li&gt;', '&lt;li&gt;4&lt;/li&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xp</span><span class=""p"">(</span><span class=""s2"">""(//ul/li)[1]""</span><span class=""p"">)</span>
<span class=""go"">['&lt;li&gt;1&lt;/li&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""s1"">'&lt;a href=""#""&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a//text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span> <span class=""c1""># take a peek at the node-set</span>
<span class=""go"">['Click here to go to the ', 'Next Page']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""string(//a[1]//text())""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span> <span class=""c1""># convert it to string</span>
<span class=""go"">['Click here to go to the ']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//a[1]""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span> <span class=""c1""># select the first node</span>
<span class=""go"">['&lt;a href=""#""&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""string(//a[1])""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span> <span class=""c1""># convert it to string</span>
<span class=""go"">['Click here to go to the Next Page']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//a[contains(.//text(), 'Next Page')]""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">[]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//a[contains(., 'Next Page')]""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['&lt;a href=""#""&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""c1""># `$val` used in the expression, a `val` argument needs to be passed</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[@id=$val]/a/text()'</span><span class=""p"">,</span> <span class=""n"">val</span><span class=""o"">=</span><span class=""s1"">'images'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Name: My image 1 '</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[count(a)=$cnt]/@id'</span><span class=""p"">,</span> <span class=""n"">cnt</span><span class=""o"">=</span><span class=""mi"">5</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'images'</span>
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy shell https://feeds.feedburner.com/PythonInsider
</pre></div>,<div class=""highlight""><pre><span></span>&lt;?xml <span class=""nv"">version</span><span class=""o"">=</span><span class=""s2"">""1.0""</span> <span class=""nv"">encoding</span><span class=""o"">=</span><span class=""s2"">""UTF-8""</span>?&gt;
&lt;?xml-stylesheet ...
&lt;feed <span class=""nv"">xmlns</span><span class=""o"">=</span><span class=""s2"">""http://www.w3.org/2005/Atom""</span>
      xmlns:openSearch<span class=""o"">=</span><span class=""s2"">""http://a9.com/-/spec/opensearchrss/1.0/""</span>
      xmlns:blogger<span class=""o"">=</span><span class=""s2"">""http://schemas.google.com/blogger/2008""</span>
      xmlns:georss<span class=""o"">=</span><span class=""s2"">""http://www.georss.org/georss""</span>
      xmlns:gd<span class=""o"">=</span><span class=""s2"">""http://schemas.google.com/g/2005""</span>
      xmlns:thr<span class=""o"">=</span><span class=""s2"">""http://purl.org/syndication/thread/1.0""</span>
      xmlns:feedburner<span class=""o"">=</span><span class=""s2"">""http://rssnamespace.org/feedburner/ext/1.0""</span>&gt;
  ...
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//link""</span><span class=""p"">)</span>
<span class=""go"">[]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">selector</span><span class=""o"">.</span><span class=""n"">remove_namespaces</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//link""</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='//link' data='&lt;link rel=""alternate"" type=""text/html"" h'&gt;,</span>
<span class=""go"">    &lt;Selector xpath='//link' data='&lt;link rel=""next"" type=""application/atom+'&gt;,</span>
<span class=""go"">    ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">doc</span> <span class=""o"">=</span> <span class=""s2"">""""""</span>
<span class=""gp"">... </span><span class=""s2"">&lt;div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;ul&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-0""&gt;&lt;a href=""link1.html""&gt;first item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-1""&gt;&lt;a href=""link2.html""&gt;second item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-inactive""&gt;&lt;a href=""link3.html""&gt;third item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-1""&gt;&lt;a href=""link4.html""&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-0""&gt;&lt;a href=""link5.html""&gt;fifth item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;/ul&gt;</span>
<span class=""gp"">... </span><span class=""s2"">&lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">""""""</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">doc</span><span class=""p"">,</span> <span class=""nb"">type</span><span class=""o"">=</span><span class=""s2"">""html""</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//li//@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//li[re:test(@class, ""item-\d$"")]//@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['link1.html', 'link2.html', 'link4.html', 'link5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">doc</span> <span class=""o"">=</span> <span class=""s2"">""""""</span>
<span class=""gp"">... </span><span class=""s2"">&lt;div itemscope itemtype=""http://schema.org/Product""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;span itemprop=""name""&gt;Kenmore White 17"" Microwave&lt;/span&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;img src=""kenmore-microwave-17in.jpg"" alt='Kenmore 17"" Microwave' /&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;div itemprop=""aggregateRating""</span>
<span class=""gp"">... </span><span class=""s2"">    itemscope itemtype=""http://schema.org/AggregateRating""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">   Rated &lt;span itemprop=""ratingValue""&gt;3.5&lt;/span&gt;/5</span>
<span class=""gp"">... </span><span class=""s2"">   based on &lt;span itemprop=""reviewCount""&gt;11&lt;/span&gt; customer reviews</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;/div&gt;</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  &lt;div itemprop=""offers"" itemscope itemtype=""http://schema.org/Offer""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""price""&gt;$55.00&lt;/span&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;link itemprop=""availability"" href=""http://schema.org/InStock"" /&gt;In stock</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;/div&gt;</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  Product description:</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;span itemprop=""description""&gt;0.7 cubic feet countertop microwave.</span>
<span class=""gp"">... </span><span class=""s2"">  Has six preset cooking categories and convenience features like</span>
<span class=""gp"">... </span><span class=""s2"">  Add-A-Minute and Child Lock.&lt;/span&gt;</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  Customer reviews:</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  &lt;div itemprop=""review"" itemscope itemtype=""http://schema.org/Review""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""name""&gt;Not a happy camper&lt;/span&gt; -</span>
<span class=""gp"">... </span><span class=""s2"">    by &lt;span itemprop=""author""&gt;Ellie&lt;/span&gt;,</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;meta itemprop=""datePublished"" content=""2011-04-01""&gt;April 1, 2011</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;div itemprop=""reviewRating"" itemscope itemtype=""http://schema.org/Rating""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;meta itemprop=""worstRating"" content = ""1""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;span itemprop=""ratingValue""&gt;1&lt;/span&gt;/</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;span itemprop=""bestRating""&gt;5&lt;/span&gt;stars</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""description""&gt;The lamp burned out and now I have to replace</span>
<span class=""gp"">... </span><span class=""s2"">    it. &lt;/span&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;/div&gt;</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  &lt;div itemprop=""review"" itemscope itemtype=""http://schema.org/Review""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""name""&gt;Value purchase&lt;/span&gt; -</span>
<span class=""gp"">... </span><span class=""s2"">    by &lt;span itemprop=""author""&gt;Lucas&lt;/span&gt;,</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;meta itemprop=""datePublished"" content=""2011-03-25""&gt;March 25, 2011</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;div itemprop=""reviewRating"" itemscope itemtype=""http://schema.org/Rating""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;meta itemprop=""worstRating"" content = ""1""/&gt;</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;span itemprop=""ratingValue""&gt;4&lt;/span&gt;/</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;span itemprop=""bestRating""&gt;5&lt;/span&gt;stars</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""description""&gt;Great microwave for the price. It is small and</span>
<span class=""gp"">... </span><span class=""s2"">    fits in my apartment.&lt;/span&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  ...</span>
<span class=""gp"">... </span><span class=""s2"">&lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">""""""</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">doc</span><span class=""p"">,</span> <span class=""nb"">type</span><span class=""o"">=</span><span class=""s2"">""html""</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">scope</span> <span class=""ow"">in</span> <span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[@itemscope]'</span><span class=""p"">):</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""s2"">""current scope:""</span><span class=""p"">,</span> <span class=""n"">scope</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'@itemtype'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">())</span>
<span class=""gp"">... </span>    <span class=""n"">props</span> <span class=""o"">=</span> <span class=""n"">scope</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'''</span>
<span class=""gp"">... </span><span class=""s1"">                set:difference(./descendant::*/@itemprop,</span>
<span class=""gp"">... </span><span class=""s1"">                               .//*[@itemscope]/*/@itemprop)'''</span><span class=""p"">)</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s2"">""    properties: </span><span class=""si"">{</span><span class=""n"">props</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span><span class=""si"">}</span><span class=""s2"">""</span><span class=""p"">)</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""s2"">""""</span><span class=""p"">)</span>

<span class=""go"">current scope: ['http://schema.org/Product']</span>
<span class=""go"">    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']</span>

<span class=""go"">current scope: ['http://schema.org/AggregateRating']</span>
<span class=""go"">    properties: ['ratingValue', 'reviewCount']</span>

<span class=""go"">current scope: ['http://schema.org/Offer']</span>
<span class=""go"">    properties: ['price', 'availability']</span>

<span class=""go"">current scope: ['http://schema.org/Review']</span>
<span class=""go"">    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']</span>

<span class=""go"">current scope: ['http://schema.org/Rating']</span>
<span class=""go"">    properties: ['worstRating', 'ratingValue', 'bestRating']</span>

<span class=""go"">current scope: ['http://schema.org/Review']</span>
<span class=""go"">    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']</span>

<span class=""go"">current scope: ['http://schema.org/Rating']</span>
<span class=""go"">    properties: ['worstRating', 'ratingValue', 'bestRating']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">&lt;</span><span class=""nt"">p</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""foo bar-baz""</span><span class=""p"">&gt;</span>First<span class=""p"">&lt;/</span><span class=""nt"">p</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;</span><span class=""nt"">p</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""foo""</span><span class=""p"">&gt;</span>Second<span class=""p"">&lt;/</span><span class=""nt"">p</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;</span><span class=""nt"">p</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""bar""</span><span class=""p"">&gt;</span>Third<span class=""p"">&lt;/</span><span class=""nt"">p</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;</span><span class=""nt"">p</span><span class=""p"">&gt;</span>Fourth<span class=""p"">&lt;/</span><span class=""nt"">p</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p[has-class(""foo"")]'</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='//p[has-class(""foo"")]' data='&lt;p class=""foo bar-baz""&gt;First&lt;/p&gt;'&gt;,</span>
<span class=""go""> &lt;Selector xpath='//p[has-class(""foo"")]' data='&lt;p class=""foo""&gt;Second&lt;/p&gt;'&gt;]</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p[has-class(""foo"", ""bar-baz"")]'</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='//p[has-class(""foo"", ""bar-baz"")]' data='&lt;p class=""foo bar-baz""&gt;First&lt;/p&gt;'&gt;]</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p[has-class(""foo"", ""bar"")]'</span><span class=""p"">)</span>
<span class=""go"">[]</span>
</pre></div>",">>> divs = response.xpath('//div')
,>>> for p in divs.xpath('//p'):  # this is wrong - gets all <p> from the whole document
...     print(p.get())
,>>> for p in divs.xpath('.//p'):  # extracts all <p> inside
...     print(p.get())
,>>> for p in divs.xpath('p'):
...     print(p.get())
,*[contains(concat(' ', normalize-space(@class), ' '), ' someclass ')]
,>>> from scrapy import Selector
>>> sel = Selector(text='<div class=""hero shout""><time datetime=""2014-07-23 19:00"">Special date</time></div>')
>>> sel.css('.shout').xpath('./time/@datetime').getall()
['2014-07-23 19:00']
,>>> from scrapy import Selector
>>> sel = Selector(text=""""""
....:     <ul class=""list"">
....:         <li>1</li>
....:         <li>2</li>
....:         <li>3</li>
....:     </ul>
....:     <ul class=""list"">
....:         <li>4</li>
....:         <li>5</li>
....:         <li>6</li>
....:     </ul>"""""")
>>> xp = lambda x: sel.xpath(x).getall()
,>>> xp(""//li[1]"")
['<li>1</li>', '<li>4</li>']
,>>> xp(""(//li)[1]"")
['<li>1</li>']
,>>> xp(""//ul/li[1]"")
['<li>1</li>', '<li>4</li>']
,>>> xp(""(//ul/li)[1]"")
['<li>1</li>']
,>>> from scrapy import Selector
>>> sel = Selector(text='<a href=""#"">Click here to go to the <strong>Next Page</strong></a>')
,>>> sel.xpath('//a//text()').getall() # take a peek at the node-set
['Click here to go to the ', 'Next Page']
>>> sel.xpath(""string(//a[1]//text())"").getall() # convert it to string
['Click here to go to the ']
,>>> sel.xpath(""//a[1]"").getall() # select the first node
['<a href=""#"">Click here to go to the <strong>Next Page</strong></a>']
>>> sel.xpath(""string(//a[1])"").getall() # convert it to string
['Click here to go to the Next Page']
,>>> sel.xpath(""//a[contains(.//text(), 'Next Page')]"").getall()
[]
,>>> sel.xpath(""//a[contains(., 'Next Page')]"").getall()
['<a href=""#"">Click here to go to the <strong>Next Page</strong></a>']
,>>> # `$val` used in the expression, a `val` argument needs to be passed
>>> response.xpath('//div[@id=$val]/a/text()', val='images').get()
'Name: My image 1 '
,>>> response.xpath('//div[count(a)=$cnt]/@id', cnt=5).get()
'images'
,$ scrapy shell https://feeds.feedburner.com/PythonInsider
,<?xml version=""1.0"" encoding=""UTF-8""?>
<?xml-stylesheet ...
<feed xmlns=""http://www.w3.org/2005/Atom""
      xmlns:openSearch=""http://a9.com/-/spec/opensearchrss/1.0/""
      xmlns:blogger=""http://schemas.google.com/blogger/2008""
      xmlns:georss=""http://www.georss.org/georss""
      xmlns:gd=""http://schemas.google.com/g/2005""
      xmlns:thr=""http://purl.org/syndication/thread/1.0""
      xmlns:feedburner=""http://rssnamespace.org/feedburner/ext/1.0"">
  ...
,>>> response.xpath(""//link"")
[]
,>>> response.selector.remove_namespaces()
>>> response.xpath(""//link"")
[<Selector xpath='//link' data='<link rel=""alternate"" type=""text/html"" h'>,
    <Selector xpath='//link' data='<link rel=""next"" type=""application/atom+'>,
    ...
,>>> from scrapy import Selector
>>> doc = """"""
... <div>
...     <ul>
...         <li class=""item-0""><a href=""link1.html"">first item</a></li>
...         <li class=""item-1""><a href=""link2.html"">second item</a></li>
...         <li class=""item-inactive""><a href=""link3.html"">third item</a></li>
...         <li class=""item-1""><a href=""link4.html"">fourth item</a></li>
...         <li class=""item-0""><a href=""link5.html"">fifth item</a></li>
...     </ul>
... </div>
... """"""
>>> sel = Selector(text=doc, type=""html"")
>>> sel.xpath('//li//@href').getall()
['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']
>>> sel.xpath('//li[re:test(@class, ""item-\d$"")]//@href').getall()
['link1.html', 'link2.html', 'link4.html', 'link5.html']
,>>> doc = """"""
... <div itemscope itemtype=""http://schema.org/Product"">
...   <span itemprop=""name"">Kenmore White 17"" Microwave</span>
...   <img src=""kenmore-microwave-17in.jpg"" alt='Kenmore 17"" Microwave' />
...   <div itemprop=""aggregateRating""
...     itemscope itemtype=""http://schema.org/AggregateRating"">
...    Rated <span itemprop=""ratingValue"">3.5</span>/5
...    based on <span itemprop=""reviewCount"">11</span> customer reviews
...   </div>
...
...   <div itemprop=""offers"" itemscope itemtype=""http://schema.org/Offer"">
...     <span itemprop=""price"">$55.00</span>
...     <link itemprop=""availability"" href=""http://schema.org/InStock"" />In stock
...   </div>
...
...   Product description:
...   <span itemprop=""description"">0.7 cubic feet countertop microwave.
...   Has six preset cooking categories and convenience features like
...   Add-A-Minute and Child Lock.</span>
...
...   Customer reviews:
...
...   <div itemprop=""review"" itemscope itemtype=""http://schema.org/Review"">
...     <span itemprop=""name"">Not a happy camper</span> -
...     by <span itemprop=""author"">Ellie</span>,
...     <meta itemprop=""datePublished"" content=""2011-04-01"">April 1, 2011
...     <div itemprop=""reviewRating"" itemscope itemtype=""http://schema.org/Rating"">
...       <meta itemprop=""worstRating"" content = ""1"">
...       <span itemprop=""ratingValue"">1</span>/
...       <span itemprop=""bestRating"">5</span>stars
...     </div>
...     <span itemprop=""description"">The lamp burned out and now I have to replace
...     it. </span>
...   </div>
...
...   <div itemprop=""review"" itemscope itemtype=""http://schema.org/Review"">
...     <span itemprop=""name"">Value purchase</span> -
...     by <span itemprop=""author"">Lucas</span>,
...     <meta itemprop=""datePublished"" content=""2011-03-25"">March 25, 2011
...     <div itemprop=""reviewRating"" itemscope itemtype=""http://schema.org/Rating"">
...       <meta itemprop=""worstRating"" content = ""1""/>
...       <span itemprop=""ratingValue"">4</span>/
...       <span itemprop=""bestRating"">5</span>stars
...     </div>
...     <span itemprop=""description"">Great microwave for the price. It is small and
...     fits in my apartment.</span>
...   </div>
...   ...
... </div>
... """"""
>>> sel = Selector(text=doc, type=""html"")
>>> for scope in sel.xpath('//div[@itemscope]'):
...     print(""current scope:"", scope.xpath('@itemtype').getall())
...     props = scope.xpath('''
...                 set:difference(./descendant::*/@itemprop,
...                                .//*[@itemscope]/*/@itemprop)''')
...     print(f""    properties: {props.getall()}"")
...     print("""")

current scope: ['http://schema.org/Product']
    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']

current scope: ['http://schema.org/AggregateRating']
    properties: ['ratingValue', 'reviewCount']

current scope: ['http://schema.org/Offer']
    properties: ['price', 'availability']

current scope: ['http://schema.org/Review']
    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']

current scope: ['http://schema.org/Rating']
    properties: ['worstRating', 'ratingValue', 'bestRating']

current scope: ['http://schema.org/Review']
    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']

current scope: ['http://schema.org/Rating']
    properties: ['worstRating', 'ratingValue', 'bestRating']
,<p class=""foo bar-baz"">First</p>
<p class=""foo"">Second</p>
<p class=""bar"">Third</p>
<p>Fourth</p>
,>>> response.xpath('//p[has-class(""foo"")]')
[<Selector xpath='//p[has-class(""foo"")]' data='<p class=""foo bar-baz"">First</p>'>,
 <Selector xpath='//p[has-class(""foo"")]' data='<p class=""foo"">Second</p>'>]
>>> response.xpath('//p[has-class(""foo"", ""bar-baz"")]')
[<Selector xpath='//p[has-class(""foo"", ""bar-baz"")]' data='<p class=""foo bar-baz"">First</p>'>]
>>> response.xpath('//p[has-class(""foo"", ""bar"")]')
[]
",26
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,Working with relative XPaths,#working-with-relative-xpaths,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">divs</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">p</span> <span class=""ow"">in</span> <span class=""n"">divs</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p'</span><span class=""p"">):</span>  <span class=""c1""># this is wrong - gets all &lt;p&gt; from the whole document</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">p</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">())</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">p</span> <span class=""ow"">in</span> <span class=""n"">divs</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'.//p'</span><span class=""p"">):</span>  <span class=""c1""># extracts all &lt;p&gt; inside</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">p</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">())</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">p</span> <span class=""ow"">in</span> <span class=""n"">divs</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'p'</span><span class=""p"">):</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">p</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">())</span>
</pre></div>",">>> divs = response.xpath('//div')
,>>> for p in divs.xpath('//p'):  # this is wrong - gets all <p> from the whole document
...     print(p.get())
,>>> for p in divs.xpath('.//p'):  # extracts all <p> inside
...     print(p.get())
,>>> for p in divs.xpath('p'):
...     print(p.get())
",4
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,"When querying by class, consider using CSS",#when-querying-by-class-consider-using-css,"<div class=""highlight""><pre><span></span><span class=""o"">*</span><span class=""p"">[</span><span class=""n"">contains</span><span class=""p"">(</span><span class=""n"">concat</span><span class=""p"">(</span><span class=""s1"">' '</span><span class=""p"">,</span> <span class=""n"">normalize</span><span class=""o"">-</span><span class=""n"">space</span><span class=""p"">(</span><span class=""nd"">@class</span><span class=""p"">),</span> <span class=""s1"">' '</span><span class=""p"">),</span> <span class=""s1"">' someclass '</span><span class=""p"">)]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""s1"">'&lt;div class=""hero shout""&gt;&lt;time datetime=""2014-07-23 19:00""&gt;Special date&lt;/time&gt;&lt;/div&gt;'</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'.shout'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'./time/@datetime'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['2014-07-23 19:00']</span>
</pre></div>","*[contains(concat(' ', normalize-space(@class), ' '), ' someclass ')]
,>>> from scrapy import Selector
>>> sel = Selector(text='<div class=""hero shout""><time datetime=""2014-07-23 19:00"">Special date</time></div>')
>>> sel.css('.shout').xpath('./time/@datetime').getall()
['2014-07-23 19:00']
",2
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,Beware of the difference between //node[1] and (//node)[1],#beware-of-the-difference-between-node-1-and-node-1,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""s2"">""""""</span>
<span class=""go"">....:     &lt;ul class=""list""&gt;</span>
<span class=""go"">....:         &lt;li&gt;1&lt;/li&gt;</span>
<span class=""go"">....:         &lt;li&gt;2&lt;/li&gt;</span>
<span class=""go"">....:         &lt;li&gt;3&lt;/li&gt;</span>
<span class=""go"">....:     &lt;/ul&gt;</span>
<span class=""go"">....:     &lt;ul class=""list""&gt;</span>
<span class=""go"">....:         &lt;li&gt;4&lt;/li&gt;</span>
<span class=""go"">....:         &lt;li&gt;5&lt;/li&gt;</span>
<span class=""go"">....:         &lt;li&gt;6&lt;/li&gt;</span>
<span class=""go"">....:     &lt;/ul&gt;"""""")</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xp</span> <span class=""o"">=</span> <span class=""k"">lambda</span> <span class=""n"">x</span><span class=""p"">:</span> <span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""n"">x</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xp</span><span class=""p"">(</span><span class=""s2"">""//li[1]""</span><span class=""p"">)</span>
<span class=""go"">['&lt;li&gt;1&lt;/li&gt;', '&lt;li&gt;4&lt;/li&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xp</span><span class=""p"">(</span><span class=""s2"">""(//li)[1]""</span><span class=""p"">)</span>
<span class=""go"">['&lt;li&gt;1&lt;/li&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xp</span><span class=""p"">(</span><span class=""s2"">""//ul/li[1]""</span><span class=""p"">)</span>
<span class=""go"">['&lt;li&gt;1&lt;/li&gt;', '&lt;li&gt;4&lt;/li&gt;']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xp</span><span class=""p"">(</span><span class=""s2"">""(//ul/li)[1]""</span><span class=""p"">)</span>
<span class=""go"">['&lt;li&gt;1&lt;/li&gt;']</span>
</pre></div>",">>> from scrapy import Selector
>>> sel = Selector(text=""""""
....:     <ul class=""list"">
....:         <li>1</li>
....:         <li>2</li>
....:         <li>3</li>
....:     </ul>
....:     <ul class=""list"">
....:         <li>4</li>
....:         <li>5</li>
....:         <li>6</li>
....:     </ul>"""""")
>>> xp = lambda x: sel.xpath(x).getall()
,>>> xp(""//li[1]"")
['<li>1</li>', '<li>4</li>']
,>>> xp(""(//li)[1]"")
['<li>1</li>']
,>>> xp(""//ul/li[1]"")
['<li>1</li>', '<li>4</li>']
,>>> xp(""(//ul/li)[1]"")
['<li>1</li>']
",5
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,Using text nodes in a condition,#using-text-nodes-in-a-condition,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""s1"">'&lt;a href=""#""&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a//text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span> <span class=""c1""># take a peek at the node-set</span>
<span class=""go"">['Click here to go to the ', 'Next Page']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""string(//a[1]//text())""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span> <span class=""c1""># convert it to string</span>
<span class=""go"">['Click here to go to the ']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//a[1]""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span> <span class=""c1""># select the first node</span>
<span class=""go"">['&lt;a href=""#""&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""string(//a[1])""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span> <span class=""c1""># convert it to string</span>
<span class=""go"">['Click here to go to the Next Page']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//a[contains(.//text(), 'Next Page')]""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">[]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//a[contains(., 'Next Page')]""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['&lt;a href=""#""&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;']</span>
</pre></div>",">>> from scrapy import Selector
>>> sel = Selector(text='<a href=""#"">Click here to go to the <strong>Next Page</strong></a>')
,>>> sel.xpath('//a//text()').getall() # take a peek at the node-set
['Click here to go to the ', 'Next Page']
>>> sel.xpath(""string(//a[1]//text())"").getall() # convert it to string
['Click here to go to the ']
,>>> sel.xpath(""//a[1]"").getall() # select the first node
['<a href=""#"">Click here to go to the <strong>Next Page</strong></a>']
>>> sel.xpath(""string(//a[1])"").getall() # convert it to string
['Click here to go to the Next Page']
,>>> sel.xpath(""//a[contains(.//text(), 'Next Page')]"").getall()
[]
,>>> sel.xpath(""//a[contains(., 'Next Page')]"").getall()
['<a href=""#"">Click here to go to the <strong>Next Page</strong></a>']
",5
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,Variables in XPath expressions,#variables-in-xpath-expressions,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""c1""># `$val` used in the expression, a `val` argument needs to be passed</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[@id=$val]/a/text()'</span><span class=""p"">,</span> <span class=""n"">val</span><span class=""o"">=</span><span class=""s1"">'images'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Name: My image 1 '</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[count(a)=$cnt]/@id'</span><span class=""p"">,</span> <span class=""n"">cnt</span><span class=""o"">=</span><span class=""mi"">5</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'images'</span>
</pre></div>",">>> # `$val` used in the expression, a `val` argument needs to be passed
>>> response.xpath('//div[@id=$val]/a/text()', val='images').get()
'Name: My image 1 '
,>>> response.xpath('//div[count(a)=$cnt]/@id', cnt=5).get()
'images'
",2
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,Removing namespaces,#removing-namespaces,"<div class=""highlight""><pre><span></span>$ scrapy shell https://feeds.feedburner.com/PythonInsider
</pre></div>,<div class=""highlight""><pre><span></span>&lt;?xml <span class=""nv"">version</span><span class=""o"">=</span><span class=""s2"">""1.0""</span> <span class=""nv"">encoding</span><span class=""o"">=</span><span class=""s2"">""UTF-8""</span>?&gt;
&lt;?xml-stylesheet ...
&lt;feed <span class=""nv"">xmlns</span><span class=""o"">=</span><span class=""s2"">""http://www.w3.org/2005/Atom""</span>
      xmlns:openSearch<span class=""o"">=</span><span class=""s2"">""http://a9.com/-/spec/opensearchrss/1.0/""</span>
      xmlns:blogger<span class=""o"">=</span><span class=""s2"">""http://schemas.google.com/blogger/2008""</span>
      xmlns:georss<span class=""o"">=</span><span class=""s2"">""http://www.georss.org/georss""</span>
      xmlns:gd<span class=""o"">=</span><span class=""s2"">""http://schemas.google.com/g/2005""</span>
      xmlns:thr<span class=""o"">=</span><span class=""s2"">""http://purl.org/syndication/thread/1.0""</span>
      xmlns:feedburner<span class=""o"">=</span><span class=""s2"">""http://rssnamespace.org/feedburner/ext/1.0""</span>&gt;
  ...
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//link""</span><span class=""p"">)</span>
<span class=""go"">[]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">selector</span><span class=""o"">.</span><span class=""n"">remove_namespaces</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//link""</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='//link' data='&lt;link rel=""alternate"" type=""text/html"" h'&gt;,</span>
<span class=""go"">    &lt;Selector xpath='//link' data='&lt;link rel=""next"" type=""application/atom+'&gt;,</span>
<span class=""go"">    ...</span>
</pre></div>","$ scrapy shell https://feeds.feedburner.com/PythonInsider
,<?xml version=""1.0"" encoding=""UTF-8""?>
<?xml-stylesheet ...
<feed xmlns=""http://www.w3.org/2005/Atom""
      xmlns:openSearch=""http://a9.com/-/spec/opensearchrss/1.0/""
      xmlns:blogger=""http://schemas.google.com/blogger/2008""
      xmlns:georss=""http://www.georss.org/georss""
      xmlns:gd=""http://schemas.google.com/g/2005""
      xmlns:thr=""http://purl.org/syndication/thread/1.0""
      xmlns:feedburner=""http://rssnamespace.org/feedburner/ext/1.0"">
  ...
,>>> response.xpath(""//link"")
[]
,>>> response.selector.remove_namespaces()
>>> response.xpath(""//link"")
[<Selector xpath='//link' data='<link rel=""alternate"" type=""text/html"" h'>,
    <Selector xpath='//link' data='<link rel=""next"" type=""application/atom+'>,
    ...
",4
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,Using EXSLT extensions,#using-exslt-extensions,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">doc</span> <span class=""o"">=</span> <span class=""s2"">""""""</span>
<span class=""gp"">... </span><span class=""s2"">&lt;div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;ul&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-0""&gt;&lt;a href=""link1.html""&gt;first item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-1""&gt;&lt;a href=""link2.html""&gt;second item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-inactive""&gt;&lt;a href=""link3.html""&gt;third item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-1""&gt;&lt;a href=""link4.html""&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-0""&gt;&lt;a href=""link5.html""&gt;fifth item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;/ul&gt;</span>
<span class=""gp"">... </span><span class=""s2"">&lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">""""""</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">doc</span><span class=""p"">,</span> <span class=""nb"">type</span><span class=""o"">=</span><span class=""s2"">""html""</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//li//@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//li[re:test(@class, ""item-\d$"")]//@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['link1.html', 'link2.html', 'link4.html', 'link5.html']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">doc</span> <span class=""o"">=</span> <span class=""s2"">""""""</span>
<span class=""gp"">... </span><span class=""s2"">&lt;div itemscope itemtype=""http://schema.org/Product""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;span itemprop=""name""&gt;Kenmore White 17"" Microwave&lt;/span&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;img src=""kenmore-microwave-17in.jpg"" alt='Kenmore 17"" Microwave' /&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;div itemprop=""aggregateRating""</span>
<span class=""gp"">... </span><span class=""s2"">    itemscope itemtype=""http://schema.org/AggregateRating""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">   Rated &lt;span itemprop=""ratingValue""&gt;3.5&lt;/span&gt;/5</span>
<span class=""gp"">... </span><span class=""s2"">   based on &lt;span itemprop=""reviewCount""&gt;11&lt;/span&gt; customer reviews</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;/div&gt;</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  &lt;div itemprop=""offers"" itemscope itemtype=""http://schema.org/Offer""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""price""&gt;$55.00&lt;/span&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;link itemprop=""availability"" href=""http://schema.org/InStock"" /&gt;In stock</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;/div&gt;</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  Product description:</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;span itemprop=""description""&gt;0.7 cubic feet countertop microwave.</span>
<span class=""gp"">... </span><span class=""s2"">  Has six preset cooking categories and convenience features like</span>
<span class=""gp"">... </span><span class=""s2"">  Add-A-Minute and Child Lock.&lt;/span&gt;</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  Customer reviews:</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  &lt;div itemprop=""review"" itemscope itemtype=""http://schema.org/Review""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""name""&gt;Not a happy camper&lt;/span&gt; -</span>
<span class=""gp"">... </span><span class=""s2"">    by &lt;span itemprop=""author""&gt;Ellie&lt;/span&gt;,</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;meta itemprop=""datePublished"" content=""2011-04-01""&gt;April 1, 2011</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;div itemprop=""reviewRating"" itemscope itemtype=""http://schema.org/Rating""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;meta itemprop=""worstRating"" content = ""1""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;span itemprop=""ratingValue""&gt;1&lt;/span&gt;/</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;span itemprop=""bestRating""&gt;5&lt;/span&gt;stars</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""description""&gt;The lamp burned out and now I have to replace</span>
<span class=""gp"">... </span><span class=""s2"">    it. &lt;/span&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;/div&gt;</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  &lt;div itemprop=""review"" itemscope itemtype=""http://schema.org/Review""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""name""&gt;Value purchase&lt;/span&gt; -</span>
<span class=""gp"">... </span><span class=""s2"">    by &lt;span itemprop=""author""&gt;Lucas&lt;/span&gt;,</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;meta itemprop=""datePublished"" content=""2011-03-25""&gt;March 25, 2011</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;div itemprop=""reviewRating"" itemscope itemtype=""http://schema.org/Rating""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;meta itemprop=""worstRating"" content = ""1""/&gt;</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;span itemprop=""ratingValue""&gt;4&lt;/span&gt;/</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;span itemprop=""bestRating""&gt;5&lt;/span&gt;stars</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""description""&gt;Great microwave for the price. It is small and</span>
<span class=""gp"">... </span><span class=""s2"">    fits in my apartment.&lt;/span&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  ...</span>
<span class=""gp"">... </span><span class=""s2"">&lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">""""""</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">doc</span><span class=""p"">,</span> <span class=""nb"">type</span><span class=""o"">=</span><span class=""s2"">""html""</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">scope</span> <span class=""ow"">in</span> <span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[@itemscope]'</span><span class=""p"">):</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""s2"">""current scope:""</span><span class=""p"">,</span> <span class=""n"">scope</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'@itemtype'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">())</span>
<span class=""gp"">... </span>    <span class=""n"">props</span> <span class=""o"">=</span> <span class=""n"">scope</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'''</span>
<span class=""gp"">... </span><span class=""s1"">                set:difference(./descendant::*/@itemprop,</span>
<span class=""gp"">... </span><span class=""s1"">                               .//*[@itemscope]/*/@itemprop)'''</span><span class=""p"">)</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s2"">""    properties: </span><span class=""si"">{</span><span class=""n"">props</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span><span class=""si"">}</span><span class=""s2"">""</span><span class=""p"">)</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""s2"">""""</span><span class=""p"">)</span>

<span class=""go"">current scope: ['http://schema.org/Product']</span>
<span class=""go"">    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']</span>

<span class=""go"">current scope: ['http://schema.org/AggregateRating']</span>
<span class=""go"">    properties: ['ratingValue', 'reviewCount']</span>

<span class=""go"">current scope: ['http://schema.org/Offer']</span>
<span class=""go"">    properties: ['price', 'availability']</span>

<span class=""go"">current scope: ['http://schema.org/Review']</span>
<span class=""go"">    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']</span>

<span class=""go"">current scope: ['http://schema.org/Rating']</span>
<span class=""go"">    properties: ['worstRating', 'ratingValue', 'bestRating']</span>

<span class=""go"">current scope: ['http://schema.org/Review']</span>
<span class=""go"">    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']</span>

<span class=""go"">current scope: ['http://schema.org/Rating']</span>
<span class=""go"">    properties: ['worstRating', 'ratingValue', 'bestRating']</span>
</pre></div>",">>> from scrapy import Selector
>>> doc = """"""
... <div>
...     <ul>
...         <li class=""item-0""><a href=""link1.html"">first item</a></li>
...         <li class=""item-1""><a href=""link2.html"">second item</a></li>
...         <li class=""item-inactive""><a href=""link3.html"">third item</a></li>
...         <li class=""item-1""><a href=""link4.html"">fourth item</a></li>
...         <li class=""item-0""><a href=""link5.html"">fifth item</a></li>
...     </ul>
... </div>
... """"""
>>> sel = Selector(text=doc, type=""html"")
>>> sel.xpath('//li//@href').getall()
['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']
>>> sel.xpath('//li[re:test(@class, ""item-\d$"")]//@href').getall()
['link1.html', 'link2.html', 'link4.html', 'link5.html']
,>>> doc = """"""
... <div itemscope itemtype=""http://schema.org/Product"">
...   <span itemprop=""name"">Kenmore White 17"" Microwave</span>
...   <img src=""kenmore-microwave-17in.jpg"" alt='Kenmore 17"" Microwave' />
...   <div itemprop=""aggregateRating""
...     itemscope itemtype=""http://schema.org/AggregateRating"">
...    Rated <span itemprop=""ratingValue"">3.5</span>/5
...    based on <span itemprop=""reviewCount"">11</span> customer reviews
...   </div>
...
...   <div itemprop=""offers"" itemscope itemtype=""http://schema.org/Offer"">
...     <span itemprop=""price"">$55.00</span>
...     <link itemprop=""availability"" href=""http://schema.org/InStock"" />In stock
...   </div>
...
...   Product description:
...   <span itemprop=""description"">0.7 cubic feet countertop microwave.
...   Has six preset cooking categories and convenience features like
...   Add-A-Minute and Child Lock.</span>
...
...   Customer reviews:
...
...   <div itemprop=""review"" itemscope itemtype=""http://schema.org/Review"">
...     <span itemprop=""name"">Not a happy camper</span> -
...     by <span itemprop=""author"">Ellie</span>,
...     <meta itemprop=""datePublished"" content=""2011-04-01"">April 1, 2011
...     <div itemprop=""reviewRating"" itemscope itemtype=""http://schema.org/Rating"">
...       <meta itemprop=""worstRating"" content = ""1"">
...       <span itemprop=""ratingValue"">1</span>/
...       <span itemprop=""bestRating"">5</span>stars
...     </div>
...     <span itemprop=""description"">The lamp burned out and now I have to replace
...     it. </span>
...   </div>
...
...   <div itemprop=""review"" itemscope itemtype=""http://schema.org/Review"">
...     <span itemprop=""name"">Value purchase</span> -
...     by <span itemprop=""author"">Lucas</span>,
...     <meta itemprop=""datePublished"" content=""2011-03-25"">March 25, 2011
...     <div itemprop=""reviewRating"" itemscope itemtype=""http://schema.org/Rating"">
...       <meta itemprop=""worstRating"" content = ""1""/>
...       <span itemprop=""ratingValue"">4</span>/
...       <span itemprop=""bestRating"">5</span>stars
...     </div>
...     <span itemprop=""description"">Great microwave for the price. It is small and
...     fits in my apartment.</span>
...   </div>
...   ...
... </div>
... """"""
>>> sel = Selector(text=doc, type=""html"")
>>> for scope in sel.xpath('//div[@itemscope]'):
...     print(""current scope:"", scope.xpath('@itemtype').getall())
...     props = scope.xpath('''
...                 set:difference(./descendant::*/@itemprop,
...                                .//*[@itemscope]/*/@itemprop)''')
...     print(f""    properties: {props.getall()}"")
...     print("""")

current scope: ['http://schema.org/Product']
    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']

current scope: ['http://schema.org/AggregateRating']
    properties: ['ratingValue', 'reviewCount']

current scope: ['http://schema.org/Offer']
    properties: ['price', 'availability']

current scope: ['http://schema.org/Review']
    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']

current scope: ['http://schema.org/Rating']
    properties: ['worstRating', 'ratingValue', 'bestRating']

current scope: ['http://schema.org/Review']
    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']

current scope: ['http://schema.org/Rating']
    properties: ['worstRating', 'ratingValue', 'bestRating']
",2
https://docs.scrapy.org/en/latest/topics/selectors.html,,####,4,Regular expressions,#regular-expressions,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">doc</span> <span class=""o"">=</span> <span class=""s2"">""""""</span>
<span class=""gp"">... </span><span class=""s2"">&lt;div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;ul&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-0""&gt;&lt;a href=""link1.html""&gt;first item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-1""&gt;&lt;a href=""link2.html""&gt;second item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-inactive""&gt;&lt;a href=""link3.html""&gt;third item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-1""&gt;&lt;a href=""link4.html""&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">        &lt;li class=""item-0""&gt;&lt;a href=""link5.html""&gt;fifth item&lt;/a&gt;&lt;/li&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;/ul&gt;</span>
<span class=""gp"">... </span><span class=""s2"">&lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">""""""</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">doc</span><span class=""p"">,</span> <span class=""nb"">type</span><span class=""o"">=</span><span class=""s2"">""html""</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//li//@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//li[re:test(@class, ""item-\d$"")]//@href'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['link1.html', 'link2.html', 'link4.html', 'link5.html']</span>
</pre></div>",">>> from scrapy import Selector
>>> doc = """"""
... <div>
...     <ul>
...         <li class=""item-0""><a href=""link1.html"">first item</a></li>
...         <li class=""item-1""><a href=""link2.html"">second item</a></li>
...         <li class=""item-inactive""><a href=""link3.html"">third item</a></li>
...         <li class=""item-1""><a href=""link4.html"">fourth item</a></li>
...         <li class=""item-0""><a href=""link5.html"">fifth item</a></li>
...     </ul>
... </div>
... """"""
>>> sel = Selector(text=doc, type=""html"")
>>> sel.xpath('//li//@href').getall()
['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']
>>> sel.xpath('//li[re:test(@class, ""item-\d$"")]//@href').getall()
['link1.html', 'link2.html', 'link4.html', 'link5.html']
",1
https://docs.scrapy.org/en/latest/topics/selectors.html,,####,4,Set operations,#set-operations,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">doc</span> <span class=""o"">=</span> <span class=""s2"">""""""</span>
<span class=""gp"">... </span><span class=""s2"">&lt;div itemscope itemtype=""http://schema.org/Product""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;span itemprop=""name""&gt;Kenmore White 17"" Microwave&lt;/span&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;img src=""kenmore-microwave-17in.jpg"" alt='Kenmore 17"" Microwave' /&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;div itemprop=""aggregateRating""</span>
<span class=""gp"">... </span><span class=""s2"">    itemscope itemtype=""http://schema.org/AggregateRating""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">   Rated &lt;span itemprop=""ratingValue""&gt;3.5&lt;/span&gt;/5</span>
<span class=""gp"">... </span><span class=""s2"">   based on &lt;span itemprop=""reviewCount""&gt;11&lt;/span&gt; customer reviews</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;/div&gt;</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  &lt;div itemprop=""offers"" itemscope itemtype=""http://schema.org/Offer""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""price""&gt;$55.00&lt;/span&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;link itemprop=""availability"" href=""http://schema.org/InStock"" /&gt;In stock</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;/div&gt;</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  Product description:</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;span itemprop=""description""&gt;0.7 cubic feet countertop microwave.</span>
<span class=""gp"">... </span><span class=""s2"">  Has six preset cooking categories and convenience features like</span>
<span class=""gp"">... </span><span class=""s2"">  Add-A-Minute and Child Lock.&lt;/span&gt;</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  Customer reviews:</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  &lt;div itemprop=""review"" itemscope itemtype=""http://schema.org/Review""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""name""&gt;Not a happy camper&lt;/span&gt; -</span>
<span class=""gp"">... </span><span class=""s2"">    by &lt;span itemprop=""author""&gt;Ellie&lt;/span&gt;,</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;meta itemprop=""datePublished"" content=""2011-04-01""&gt;April 1, 2011</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;div itemprop=""reviewRating"" itemscope itemtype=""http://schema.org/Rating""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;meta itemprop=""worstRating"" content = ""1""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;span itemprop=""ratingValue""&gt;1&lt;/span&gt;/</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;span itemprop=""bestRating""&gt;5&lt;/span&gt;stars</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""description""&gt;The lamp burned out and now I have to replace</span>
<span class=""gp"">... </span><span class=""s2"">    it. &lt;/span&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;/div&gt;</span>
<span class=""gp"">...</span><span class=""s2""></span>
<span class=""gp"">... </span><span class=""s2"">  &lt;div itemprop=""review"" itemscope itemtype=""http://schema.org/Review""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""name""&gt;Value purchase&lt;/span&gt; -</span>
<span class=""gp"">... </span><span class=""s2"">    by &lt;span itemprop=""author""&gt;Lucas&lt;/span&gt;,</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;meta itemprop=""datePublished"" content=""2011-03-25""&gt;March 25, 2011</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;div itemprop=""reviewRating"" itemscope itemtype=""http://schema.org/Rating""&gt;</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;meta itemprop=""worstRating"" content = ""1""/&gt;</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;span itemprop=""ratingValue""&gt;4&lt;/span&gt;/</span>
<span class=""gp"">... </span><span class=""s2"">      &lt;span itemprop=""bestRating""&gt;5&lt;/span&gt;stars</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">    &lt;span itemprop=""description""&gt;Great microwave for the price. It is small and</span>
<span class=""gp"">... </span><span class=""s2"">    fits in my apartment.&lt;/span&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  &lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">  ...</span>
<span class=""gp"">... </span><span class=""s2"">&lt;/div&gt;</span>
<span class=""gp"">... </span><span class=""s2"">""""""</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">doc</span><span class=""p"">,</span> <span class=""nb"">type</span><span class=""o"">=</span><span class=""s2"">""html""</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">for</span> <span class=""n"">scope</span> <span class=""ow"">in</span> <span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//div[@itemscope]'</span><span class=""p"">):</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""s2"">""current scope:""</span><span class=""p"">,</span> <span class=""n"">scope</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'@itemtype'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">())</span>
<span class=""gp"">... </span>    <span class=""n"">props</span> <span class=""o"">=</span> <span class=""n"">scope</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'''</span>
<span class=""gp"">... </span><span class=""s1"">                set:difference(./descendant::*/@itemprop,</span>
<span class=""gp"">... </span><span class=""s1"">                               .//*[@itemscope]/*/@itemprop)'''</span><span class=""p"">)</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s2"">""    properties: </span><span class=""si"">{</span><span class=""n"">props</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span><span class=""si"">}</span><span class=""s2"">""</span><span class=""p"">)</span>
<span class=""gp"">... </span>    <span class=""nb"">print</span><span class=""p"">(</span><span class=""s2"">""""</span><span class=""p"">)</span>

<span class=""go"">current scope: ['http://schema.org/Product']</span>
<span class=""go"">    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']</span>

<span class=""go"">current scope: ['http://schema.org/AggregateRating']</span>
<span class=""go"">    properties: ['ratingValue', 'reviewCount']</span>

<span class=""go"">current scope: ['http://schema.org/Offer']</span>
<span class=""go"">    properties: ['price', 'availability']</span>

<span class=""go"">current scope: ['http://schema.org/Review']</span>
<span class=""go"">    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']</span>

<span class=""go"">current scope: ['http://schema.org/Rating']</span>
<span class=""go"">    properties: ['worstRating', 'ratingValue', 'bestRating']</span>

<span class=""go"">current scope: ['http://schema.org/Review']</span>
<span class=""go"">    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']</span>

<span class=""go"">current scope: ['http://schema.org/Rating']</span>
<span class=""go"">    properties: ['worstRating', 'ratingValue', 'bestRating']</span>
</pre></div>",">>> doc = """"""
... <div itemscope itemtype=""http://schema.org/Product"">
...   <span itemprop=""name"">Kenmore White 17"" Microwave</span>
...   <img src=""kenmore-microwave-17in.jpg"" alt='Kenmore 17"" Microwave' />
...   <div itemprop=""aggregateRating""
...     itemscope itemtype=""http://schema.org/AggregateRating"">
...    Rated <span itemprop=""ratingValue"">3.5</span>/5
...    based on <span itemprop=""reviewCount"">11</span> customer reviews
...   </div>
...
...   <div itemprop=""offers"" itemscope itemtype=""http://schema.org/Offer"">
...     <span itemprop=""price"">$55.00</span>
...     <link itemprop=""availability"" href=""http://schema.org/InStock"" />In stock
...   </div>
...
...   Product description:
...   <span itemprop=""description"">0.7 cubic feet countertop microwave.
...   Has six preset cooking categories and convenience features like
...   Add-A-Minute and Child Lock.</span>
...
...   Customer reviews:
...
...   <div itemprop=""review"" itemscope itemtype=""http://schema.org/Review"">
...     <span itemprop=""name"">Not a happy camper</span> -
...     by <span itemprop=""author"">Ellie</span>,
...     <meta itemprop=""datePublished"" content=""2011-04-01"">April 1, 2011
...     <div itemprop=""reviewRating"" itemscope itemtype=""http://schema.org/Rating"">
...       <meta itemprop=""worstRating"" content = ""1"">
...       <span itemprop=""ratingValue"">1</span>/
...       <span itemprop=""bestRating"">5</span>stars
...     </div>
...     <span itemprop=""description"">The lamp burned out and now I have to replace
...     it. </span>
...   </div>
...
...   <div itemprop=""review"" itemscope itemtype=""http://schema.org/Review"">
...     <span itemprop=""name"">Value purchase</span> -
...     by <span itemprop=""author"">Lucas</span>,
...     <meta itemprop=""datePublished"" content=""2011-03-25"">March 25, 2011
...     <div itemprop=""reviewRating"" itemscope itemtype=""http://schema.org/Rating"">
...       <meta itemprop=""worstRating"" content = ""1""/>
...       <span itemprop=""ratingValue"">4</span>/
...       <span itemprop=""bestRating"">5</span>stars
...     </div>
...     <span itemprop=""description"">Great microwave for the price. It is small and
...     fits in my apartment.</span>
...   </div>
...   ...
... </div>
... """"""
>>> sel = Selector(text=doc, type=""html"")
>>> for scope in sel.xpath('//div[@itemscope]'):
...     print(""current scope:"", scope.xpath('@itemtype').getall())
...     props = scope.xpath('''
...                 set:difference(./descendant::*/@itemprop,
...                                .//*[@itemscope]/*/@itemprop)''')
...     print(f""    properties: {props.getall()}"")
...     print("""")

current scope: ['http://schema.org/Product']
    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']

current scope: ['http://schema.org/AggregateRating']
    properties: ['ratingValue', 'reviewCount']

current scope: ['http://schema.org/Offer']
    properties: ['price', 'availability']

current scope: ['http://schema.org/Review']
    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']

current scope: ['http://schema.org/Rating']
    properties: ['worstRating', 'ratingValue', 'bestRating']

current scope: ['http://schema.org/Review']
    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']

current scope: ['http://schema.org/Rating']
    properties: ['worstRating', 'ratingValue', 'bestRating']
",1
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,Other XPath extensions,#other-xpath-extensions,"<div class=""highlight""><pre><span></span><span class=""p"">&lt;</span><span class=""nt"">p</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""foo bar-baz""</span><span class=""p"">&gt;</span>First<span class=""p"">&lt;/</span><span class=""nt"">p</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;</span><span class=""nt"">p</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""foo""</span><span class=""p"">&gt;</span>Second<span class=""p"">&lt;/</span><span class=""nt"">p</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;</span><span class=""nt"">p</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""bar""</span><span class=""p"">&gt;</span>Third<span class=""p"">&lt;/</span><span class=""nt"">p</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;</span><span class=""nt"">p</span><span class=""p"">&gt;</span>Fourth<span class=""p"">&lt;/</span><span class=""nt"">p</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p[has-class(""foo"")]'</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='//p[has-class(""foo"")]' data='&lt;p class=""foo bar-baz""&gt;First&lt;/p&gt;'&gt;,</span>
<span class=""go""> &lt;Selector xpath='//p[has-class(""foo"")]' data='&lt;p class=""foo""&gt;Second&lt;/p&gt;'&gt;]</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p[has-class(""foo"", ""bar-baz"")]'</span><span class=""p"">)</span>
<span class=""go"">[&lt;Selector xpath='//p[has-class(""foo"", ""bar-baz"")]' data='&lt;p class=""foo bar-baz""&gt;First&lt;/p&gt;'&gt;]</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p[has-class(""foo"", ""bar"")]'</span><span class=""p"">)</span>
<span class=""go"">[]</span>
</pre></div>","<p class=""foo bar-baz"">First</p>
<p class=""foo"">Second</p>
<p class=""bar"">Third</p>
<p>Fourth</p>
,>>> response.xpath('//p[has-class(""foo"")]')
[<Selector xpath='//p[has-class(""foo"")]' data='<p class=""foo bar-baz"">First</p>'>,
 <Selector xpath='//p[has-class(""foo"")]' data='<p class=""foo"">Second</p>'>]
>>> response.xpath('//p[has-class(""foo"", ""bar-baz"")]')
[<Selector xpath='//p[has-class(""foo"", ""bar-baz"")]' data='<p class=""foo bar-baz"">First</p>'>]
>>> response.xpath('//p[has-class(""foo"", ""bar"")]')
[]
",2
https://docs.scrapy.org/en/latest/topics/selectors.html,,##,2,Built-in Selectors reference,#module-scrapy.selector,"<div class=""highlight""><pre><span></span><span class=""n"">selector</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[href=$url]'</span><span class=""p"">,</span> <span class=""n"">url</span><span class=""o"">=</span><span class=""s2"">""http://www.example.com""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">selector</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[href=$url]'</span><span class=""p"">,</span> <span class=""n"">url</span><span class=""o"">=</span><span class=""s2"">""http://www.example.com""</span><span class=""p"">)</span>
</pre></div>","selector.xpath('//a[href=$url]', url=""http://www.example.com"")
,selector.xpath('//a[href=$url]', url=""http://www.example.com"")
",2
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,Selector objects,#selector-objects,"<div class=""highlight""><pre><span></span><span class=""n"">selector</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[href=$url]'</span><span class=""p"">,</span> <span class=""n"">url</span><span class=""o"">=</span><span class=""s2"">""http://www.example.com""</span><span class=""p"">)</span>
</pre></div>","selector.xpath('//a[href=$url]', url=""http://www.example.com"")
",1
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,SelectorList objects,#selectorlist-objects,"<div class=""highlight""><pre><span></span><span class=""n"">selector</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//a[href=$url]'</span><span class=""p"">,</span> <span class=""n"">url</span><span class=""o"">=</span><span class=""s2"">""http://www.example.com""</span><span class=""p"">)</span>
</pre></div>","selector.xpath('//a[href=$url]', url=""http://www.example.com"")
",1
https://docs.scrapy.org/en/latest/topics/selectors.html,,##,2,Examples,#examples,"<div class=""highlight""><pre><span></span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">html_response</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//h1""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//h1""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>         <span class=""c1""># this includes the h1 tag</span>
<span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//h1/text()""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>  <span class=""c1""># this excludes the h1 tag</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">node</span> <span class=""ow"">in</span> <span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//p""</span><span class=""p"">):</span>
    <span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">node</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'class'</span><span class=""p"">])</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">xml_response</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//product""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">register_namespace</span><span class=""p"">(</span><span class=""s2"">""g""</span><span class=""p"">,</span> <span class=""s2"">""http://base.google.com/ns/1.0""</span><span class=""p"">)</span>
<span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//g:price""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
</pre></div>","sel = Selector(html_response)
,sel.xpath(""//h1"")
,sel.xpath(""//h1"").getall()         # this includes the h1 tag
sel.xpath(""//h1/text()"").getall()  # this excludes the h1 tag
,for node in sel.xpath(""//p""):
    print(node.attrib['class'])
,sel = Selector(xml_response)
,sel.xpath(""//product"")
,sel.register_namespace(""g"", ""http://base.google.com/ns/1.0"")
sel.xpath(""//g:price"").getall()
",7
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,Selector examples on HTML response,#selector-examples-on-html-response,"<div class=""highlight""><pre><span></span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">html_response</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//h1""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//h1""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>         <span class=""c1""># this includes the h1 tag</span>
<span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//h1/text()""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>  <span class=""c1""># this excludes the h1 tag</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">node</span> <span class=""ow"">in</span> <span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//p""</span><span class=""p"">):</span>
    <span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">node</span><span class=""o"">.</span><span class=""n"">attrib</span><span class=""p"">[</span><span class=""s1"">'class'</span><span class=""p"">])</span>
</pre></div>","sel = Selector(html_response)
,sel.xpath(""//h1"")
,sel.xpath(""//h1"").getall()         # this includes the h1 tag
sel.xpath(""//h1/text()"").getall()  # this excludes the h1 tag
,for node in sel.xpath(""//p""):
    print(node.attrib['class'])
",4
https://docs.scrapy.org/en/latest/topics/selectors.html,,###,3,Selector examples on XML response,#selector-examples-on-xml-response,"<div class=""highlight""><pre><span></span><span class=""n"">sel</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">xml_response</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//product""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">register_namespace</span><span class=""p"">(</span><span class=""s2"">""g""</span><span class=""p"">,</span> <span class=""s2"">""http://base.google.com/ns/1.0""</span><span class=""p"">)</span>
<span class=""n"">sel</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s2"">""//g:price""</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
</pre></div>","sel = Selector(xml_response)
,sel.xpath(""//product"")
,sel.register_namespace(""g"", ""http://base.google.com/ns/1.0"")
sel.xpath(""//g:price"").getall()
",3
https://docs.scrapy.org/en/latest/topics/items.html,,#,1,Items,#module-scrapy.item,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.item</span> <span class=""kn"">import</span> <span class=""n"">Item</span><span class=""p"">,</span> <span class=""n"">Field</span>

<span class=""k"">class</span> <span class=""nc"">CustomItem</span><span class=""p"">(</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""n"">one_field</span> <span class=""o"">=</span> <span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">another_field</span> <span class=""o"">=</span> <span class=""n"">Field</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">dataclasses</span> <span class=""kn"">import</span> <span class=""n"">dataclass</span>

<span class=""nd"">@dataclass</span>
<span class=""k"">class</span> <span class=""nc"">CustomItem</span><span class=""p"">:</span>
    <span class=""n"">one_field</span><span class=""p"">:</span> <span class=""nb"">str</span>
    <span class=""n"">another_field</span><span class=""p"">:</span> <span class=""nb"">int</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">attr</span>

<span class=""nd"">@attr</span><span class=""o"">.</span><span class=""n"">s</span>
<span class=""k"">class</span> <span class=""nc"">CustomItem</span><span class=""p"">:</span>
    <span class=""n"">one_field</span> <span class=""o"">=</span> <span class=""n"">attr</span><span class=""o"">.</span><span class=""n"">ib</span><span class=""p"">()</span>
    <span class=""n"">another_field</span> <span class=""o"">=</span> <span class=""n"">attr</span><span class=""o"">.</span><span class=""n"">ib</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">Product</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">price</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">stock</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">tags</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">last_updated</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">(</span><span class=""n"">serializer</span><span class=""o"">=</span><span class=""nb"">str</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span> <span class=""o"">=</span> <span class=""n"">Product</span><span class=""p"">(</span><span class=""n"">name</span><span class=""o"">=</span><span class=""s1"">'Desktop PC'</span><span class=""p"">,</span> <span class=""n"">price</span><span class=""o"">=</span><span class=""mi"">1000</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">product</span><span class=""p"">)</span>
<span class=""go"">Product(name='Desktop PC', price=1000)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span>
<span class=""go"">Desktop PC</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">)</span>
<span class=""go"">Desktop PC</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'price'</span><span class=""p"">]</span>
<span class=""go"">1000</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'last_updated'</span><span class=""p"">]</span>
<span class=""gt"">Traceback (most recent call last):</span>
    <span class=""o"">...</span>
<span class=""gr"">KeyError</span>: <span class=""n"">'last_updated'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'last_updated'</span><span class=""p"">,</span> <span class=""s1"">'not set'</span><span class=""p"">)</span>
<span class=""go"">not set</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'lala'</span><span class=""p"">]</span> <span class=""c1""># getting unknown field</span>
<span class=""gt"">Traceback (most recent call last):</span>
    <span class=""o"">...</span>
<span class=""gr"">KeyError</span>: <span class=""n"">'lala'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'lala'</span><span class=""p"">,</span> <span class=""s1"">'unknown field'</span><span class=""p"">)</span>
<span class=""go"">'unknown field'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""s1"">'name'</span> <span class=""ow"">in</span> <span class=""n"">product</span>  <span class=""c1""># is name field populated?</span>
<span class=""go"">True</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""s1"">'last_updated'</span> <span class=""ow"">in</span> <span class=""n"">product</span>  <span class=""c1""># is last_updated populated?</span>
<span class=""go"">False</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""s1"">'last_updated'</span> <span class=""ow"">in</span> <span class=""n"">product</span><span class=""o"">.</span><span class=""n"">fields</span>  <span class=""c1""># is last_updated a declared field?</span>
<span class=""go"">True</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""s1"">'lala'</span> <span class=""ow"">in</span> <span class=""n"">product</span><span class=""o"">.</span><span class=""n"">fields</span>  <span class=""c1""># is lala a declared field?</span>
<span class=""go"">False</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'last_updated'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""s1"">'today'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'last_updated'</span><span class=""p"">]</span>
<span class=""go"">today</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'lala'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""s1"">'test'</span> <span class=""c1""># setting unknown field</span>
<span class=""gt"">Traceback (most recent call last):</span>
    <span class=""o"">...</span>
<span class=""gr"">KeyError</span>: <span class=""n"">'Product does not support field: lala'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">keys</span><span class=""p"">()</span>
<span class=""go"">['price', 'name']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">items</span><span class=""p"">()</span>
<span class=""go"">[('price', 1000), ('name', 'Desktop PC')]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">product</span><span class=""p"">)</span> <span class=""c1""># create a dict from all populated values</span>
<span class=""go"">{'price': 1000, 'name': 'Desktop PC'}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">Product</span><span class=""p"">({</span><span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""s1"">'Laptop PC'</span><span class=""p"">,</span> <span class=""s1"">'price'</span><span class=""p"">:</span> <span class=""mi"">1500</span><span class=""p"">})</span>
<span class=""go"">Product(price=1500, name='Laptop PC')</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">Product</span><span class=""p"">({</span><span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""s1"">'Laptop PC'</span><span class=""p"">,</span> <span class=""s1"">'lala'</span><span class=""p"">:</span> <span class=""mi"">1500</span><span class=""p"">})</span> <span class=""c1""># warning: unknown field in dict</span>
<span class=""gt"">Traceback (most recent call last):</span>
    <span class=""o"">...</span>
<span class=""gr"">KeyError</span>: <span class=""n"">'Product does not support field: lala'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">DiscountedProduct</span><span class=""p"">(</span><span class=""n"">Product</span><span class=""p"">):</span>
    <span class=""n"">discount_percent</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">(</span><span class=""n"">serializer</span><span class=""o"">=</span><span class=""nb"">str</span><span class=""p"">)</span>
    <span class=""n"">discount_expiration_date</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">SpecificProduct</span><span class=""p"">(</span><span class=""n"">Product</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">(</span><span class=""n"">Product</span><span class=""o"">.</span><span class=""n"">fields</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">],</span> <span class=""n"">serializer</span><span class=""o"">=</span><span class=""n"">my_serializer</span><span class=""p"">)</span>
</pre></div>","from scrapy.item import Item, Field

class CustomItem(Item):
    one_field = Field()
    another_field = Field()
,from dataclasses import dataclass

@dataclass
class CustomItem:
    one_field: str
    another_field: int
,import attr

@attr.s
class CustomItem:
    one_field = attr.ib()
    another_field = attr.ib()
,import scrapy

class Product(scrapy.Item):
    name = scrapy.Field()
    price = scrapy.Field()
    stock = scrapy.Field()
    tags = scrapy.Field()
    last_updated = scrapy.Field(serializer=str)
,>>> product = Product(name='Desktop PC', price=1000)
>>> print(product)
Product(name='Desktop PC', price=1000)
,>>> product['name']
Desktop PC
>>> product.get('name')
Desktop PC
,>>> product['price']
1000
,>>> product['last_updated']
Traceback (most recent call last):
    ...
KeyError: 'last_updated'
,>>> product.get('last_updated', 'not set')
not set
,>>> product['lala'] # getting unknown field
Traceback (most recent call last):
    ...
KeyError: 'lala'
,>>> product.get('lala', 'unknown field')
'unknown field'
,>>> 'name' in product  # is name field populated?
True
,>>> 'last_updated' in product  # is last_updated populated?
False
,>>> 'last_updated' in product.fields  # is last_updated a declared field?
True
,>>> 'lala' in product.fields  # is lala a declared field?
False
,>>> product['last_updated'] = 'today'
>>> product['last_updated']
today
,>>> product['lala'] = 'test' # setting unknown field
Traceback (most recent call last):
    ...
KeyError: 'Product does not support field: lala'
,>>> product.keys()
['price', 'name']
,>>> product.items()
[('price', 1000), ('name', 'Desktop PC')]
,>>> dict(product) # create a dict from all populated values
{'price': 1000, 'name': 'Desktop PC'}
,>>> Product({'name': 'Laptop PC', 'price': 1500})
Product(price=1500, name='Laptop PC')
,>>> Product({'name': 'Laptop PC', 'lala': 1500}) # warning: unknown field in dict
Traceback (most recent call last):
    ...
KeyError: 'Product does not support field: lala'
,class DiscountedProduct(Product):
    discount_percent = scrapy.Field(serializer=str)
    discount_expiration_date = scrapy.Field()
,class SpecificProduct(Product):
    name = scrapy.Field(Product.fields['name'], serializer=my_serializer)
",24
https://docs.scrapy.org/en/latest/topics/items.html,,##,2,Item Types,#item-types,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.item</span> <span class=""kn"">import</span> <span class=""n"">Item</span><span class=""p"">,</span> <span class=""n"">Field</span>

<span class=""k"">class</span> <span class=""nc"">CustomItem</span><span class=""p"">(</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""n"">one_field</span> <span class=""o"">=</span> <span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">another_field</span> <span class=""o"">=</span> <span class=""n"">Field</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">dataclasses</span> <span class=""kn"">import</span> <span class=""n"">dataclass</span>

<span class=""nd"">@dataclass</span>
<span class=""k"">class</span> <span class=""nc"">CustomItem</span><span class=""p"">:</span>
    <span class=""n"">one_field</span><span class=""p"">:</span> <span class=""nb"">str</span>
    <span class=""n"">another_field</span><span class=""p"">:</span> <span class=""nb"">int</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">attr</span>

<span class=""nd"">@attr</span><span class=""o"">.</span><span class=""n"">s</span>
<span class=""k"">class</span> <span class=""nc"">CustomItem</span><span class=""p"">:</span>
    <span class=""n"">one_field</span> <span class=""o"">=</span> <span class=""n"">attr</span><span class=""o"">.</span><span class=""n"">ib</span><span class=""p"">()</span>
    <span class=""n"">another_field</span> <span class=""o"">=</span> <span class=""n"">attr</span><span class=""o"">.</span><span class=""n"">ib</span><span class=""p"">()</span>
</pre></div>","from scrapy.item import Item, Field

class CustomItem(Item):
    one_field = Field()
    another_field = Field()
,from dataclasses import dataclass

@dataclass
class CustomItem:
    one_field: str
    another_field: int
,import attr

@attr.s
class CustomItem:
    one_field = attr.ib()
    another_field = attr.ib()
",3
https://docs.scrapy.org/en/latest/topics/items.html,,###,3,Dictionaries,#dictionaries,,,3
https://docs.scrapy.org/en/latest/topics/items.html,,###,3,Item objects,#item-objects,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.item</span> <span class=""kn"">import</span> <span class=""n"">Item</span><span class=""p"">,</span> <span class=""n"">Field</span>

<span class=""k"">class</span> <span class=""nc"">CustomItem</span><span class=""p"">(</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""n"">one_field</span> <span class=""o"">=</span> <span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">another_field</span> <span class=""o"">=</span> <span class=""n"">Field</span><span class=""p"">()</span>
</pre></div>","from scrapy.item import Item, Field

class CustomItem(Item):
    one_field = Field()
    another_field = Field()
",1
https://docs.scrapy.org/en/latest/topics/items.html,,###,3,Dataclass objects,#dataclass-objects,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">dataclasses</span> <span class=""kn"">import</span> <span class=""n"">dataclass</span>

<span class=""nd"">@dataclass</span>
<span class=""k"">class</span> <span class=""nc"">CustomItem</span><span class=""p"">:</span>
    <span class=""n"">one_field</span><span class=""p"">:</span> <span class=""nb"">str</span>
    <span class=""n"">another_field</span><span class=""p"">:</span> <span class=""nb"">int</span>
</pre></div>","from dataclasses import dataclass

@dataclass
class CustomItem:
    one_field: str
    another_field: int
",1
https://docs.scrapy.org/en/latest/topics/items.html,,###,3,attr.s objects,#attr-s-objects,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">attr</span>

<span class=""nd"">@attr</span><span class=""o"">.</span><span class=""n"">s</span>
<span class=""k"">class</span> <span class=""nc"">CustomItem</span><span class=""p"">:</span>
    <span class=""n"">one_field</span> <span class=""o"">=</span> <span class=""n"">attr</span><span class=""o"">.</span><span class=""n"">ib</span><span class=""p"">()</span>
    <span class=""n"">another_field</span> <span class=""o"">=</span> <span class=""n"">attr</span><span class=""o"">.</span><span class=""n"">ib</span><span class=""p"">()</span>
</pre></div>","import attr

@attr.s
class CustomItem:
    one_field = attr.ib()
    another_field = attr.ib()
",1
https://docs.scrapy.org/en/latest/topics/items.html,,##,2,Working with Item objects,#working-with-item-objects,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">Product</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">price</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">stock</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">tags</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">last_updated</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">(</span><span class=""n"">serializer</span><span class=""o"">=</span><span class=""nb"">str</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span> <span class=""o"">=</span> <span class=""n"">Product</span><span class=""p"">(</span><span class=""n"">name</span><span class=""o"">=</span><span class=""s1"">'Desktop PC'</span><span class=""p"">,</span> <span class=""n"">price</span><span class=""o"">=</span><span class=""mi"">1000</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">product</span><span class=""p"">)</span>
<span class=""go"">Product(name='Desktop PC', price=1000)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span>
<span class=""go"">Desktop PC</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">)</span>
<span class=""go"">Desktop PC</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'price'</span><span class=""p"">]</span>
<span class=""go"">1000</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'last_updated'</span><span class=""p"">]</span>
<span class=""gt"">Traceback (most recent call last):</span>
    <span class=""o"">...</span>
<span class=""gr"">KeyError</span>: <span class=""n"">'last_updated'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'last_updated'</span><span class=""p"">,</span> <span class=""s1"">'not set'</span><span class=""p"">)</span>
<span class=""go"">not set</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'lala'</span><span class=""p"">]</span> <span class=""c1""># getting unknown field</span>
<span class=""gt"">Traceback (most recent call last):</span>
    <span class=""o"">...</span>
<span class=""gr"">KeyError</span>: <span class=""n"">'lala'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'lala'</span><span class=""p"">,</span> <span class=""s1"">'unknown field'</span><span class=""p"">)</span>
<span class=""go"">'unknown field'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""s1"">'name'</span> <span class=""ow"">in</span> <span class=""n"">product</span>  <span class=""c1""># is name field populated?</span>
<span class=""go"">True</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""s1"">'last_updated'</span> <span class=""ow"">in</span> <span class=""n"">product</span>  <span class=""c1""># is last_updated populated?</span>
<span class=""go"">False</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""s1"">'last_updated'</span> <span class=""ow"">in</span> <span class=""n"">product</span><span class=""o"">.</span><span class=""n"">fields</span>  <span class=""c1""># is last_updated a declared field?</span>
<span class=""go"">True</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""s1"">'lala'</span> <span class=""ow"">in</span> <span class=""n"">product</span><span class=""o"">.</span><span class=""n"">fields</span>  <span class=""c1""># is lala a declared field?</span>
<span class=""go"">False</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'last_updated'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""s1"">'today'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'last_updated'</span><span class=""p"">]</span>
<span class=""go"">today</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'lala'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""s1"">'test'</span> <span class=""c1""># setting unknown field</span>
<span class=""gt"">Traceback (most recent call last):</span>
    <span class=""o"">...</span>
<span class=""gr"">KeyError</span>: <span class=""n"">'Product does not support field: lala'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">keys</span><span class=""p"">()</span>
<span class=""go"">['price', 'name']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">items</span><span class=""p"">()</span>
<span class=""go"">[('price', 1000), ('name', 'Desktop PC')]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">product</span><span class=""p"">)</span> <span class=""c1""># create a dict from all populated values</span>
<span class=""go"">{'price': 1000, 'name': 'Desktop PC'}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">Product</span><span class=""p"">({</span><span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""s1"">'Laptop PC'</span><span class=""p"">,</span> <span class=""s1"">'price'</span><span class=""p"">:</span> <span class=""mi"">1500</span><span class=""p"">})</span>
<span class=""go"">Product(price=1500, name='Laptop PC')</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">Product</span><span class=""p"">({</span><span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""s1"">'Laptop PC'</span><span class=""p"">,</span> <span class=""s1"">'lala'</span><span class=""p"">:</span> <span class=""mi"">1500</span><span class=""p"">})</span> <span class=""c1""># warning: unknown field in dict</span>
<span class=""gt"">Traceback (most recent call last):</span>
    <span class=""o"">...</span>
<span class=""gr"">KeyError</span>: <span class=""n"">'Product does not support field: lala'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">DiscountedProduct</span><span class=""p"">(</span><span class=""n"">Product</span><span class=""p"">):</span>
    <span class=""n"">discount_percent</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">(</span><span class=""n"">serializer</span><span class=""o"">=</span><span class=""nb"">str</span><span class=""p"">)</span>
    <span class=""n"">discount_expiration_date</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">SpecificProduct</span><span class=""p"">(</span><span class=""n"">Product</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">(</span><span class=""n"">Product</span><span class=""o"">.</span><span class=""n"">fields</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">],</span> <span class=""n"">serializer</span><span class=""o"">=</span><span class=""n"">my_serializer</span><span class=""p"">)</span>
</pre></div>","import scrapy

class Product(scrapy.Item):
    name = scrapy.Field()
    price = scrapy.Field()
    stock = scrapy.Field()
    tags = scrapy.Field()
    last_updated = scrapy.Field(serializer=str)
,>>> product = Product(name='Desktop PC', price=1000)
>>> print(product)
Product(name='Desktop PC', price=1000)
,>>> product['name']
Desktop PC
>>> product.get('name')
Desktop PC
,>>> product['price']
1000
,>>> product['last_updated']
Traceback (most recent call last):
    ...
KeyError: 'last_updated'
,>>> product.get('last_updated', 'not set')
not set
,>>> product['lala'] # getting unknown field
Traceback (most recent call last):
    ...
KeyError: 'lala'
,>>> product.get('lala', 'unknown field')
'unknown field'
,>>> 'name' in product  # is name field populated?
True
,>>> 'last_updated' in product  # is last_updated populated?
False
,>>> 'last_updated' in product.fields  # is last_updated a declared field?
True
,>>> 'lala' in product.fields  # is lala a declared field?
False
,>>> product['last_updated'] = 'today'
>>> product['last_updated']
today
,>>> product['lala'] = 'test' # setting unknown field
Traceback (most recent call last):
    ...
KeyError: 'Product does not support field: lala'
,>>> product.keys()
['price', 'name']
,>>> product.items()
[('price', 1000), ('name', 'Desktop PC')]
,>>> dict(product) # create a dict from all populated values
{'price': 1000, 'name': 'Desktop PC'}
,>>> Product({'name': 'Laptop PC', 'price': 1500})
Product(price=1500, name='Laptop PC')
,>>> Product({'name': 'Laptop PC', 'lala': 1500}) # warning: unknown field in dict
Traceback (most recent call last):
    ...
KeyError: 'Product does not support field: lala'
,class DiscountedProduct(Product):
    discount_percent = scrapy.Field(serializer=str)
    discount_expiration_date = scrapy.Field()
,class SpecificProduct(Product):
    name = scrapy.Field(Product.fields['name'], serializer=my_serializer)
",21
https://docs.scrapy.org/en/latest/topics/items.html,,###,3,Declaring Item subclasses,#declaring-item-subclasses,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">Product</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">price</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">stock</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">tags</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">last_updated</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">(</span><span class=""n"">serializer</span><span class=""o"">=</span><span class=""nb"">str</span><span class=""p"">)</span>
</pre></div>","import scrapy

class Product(scrapy.Item):
    name = scrapy.Field()
    price = scrapy.Field()
    stock = scrapy.Field()
    tags = scrapy.Field()
    last_updated = scrapy.Field(serializer=str)
",1
https://docs.scrapy.org/en/latest/topics/items.html,,###,3,Declaring fields,#declaring-fields,,,9
https://docs.scrapy.org/en/latest/topics/items.html,,###,3,Working with Item objects,#id3,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span> <span class=""o"">=</span> <span class=""n"">Product</span><span class=""p"">(</span><span class=""n"">name</span><span class=""o"">=</span><span class=""s1"">'Desktop PC'</span><span class=""p"">,</span> <span class=""n"">price</span><span class=""o"">=</span><span class=""mi"">1000</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">product</span><span class=""p"">)</span>
<span class=""go"">Product(name='Desktop PC', price=1000)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span>
<span class=""go"">Desktop PC</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">)</span>
<span class=""go"">Desktop PC</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'price'</span><span class=""p"">]</span>
<span class=""go"">1000</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'last_updated'</span><span class=""p"">]</span>
<span class=""gt"">Traceback (most recent call last):</span>
    <span class=""o"">...</span>
<span class=""gr"">KeyError</span>: <span class=""n"">'last_updated'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'last_updated'</span><span class=""p"">,</span> <span class=""s1"">'not set'</span><span class=""p"">)</span>
<span class=""go"">not set</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'lala'</span><span class=""p"">]</span> <span class=""c1""># getting unknown field</span>
<span class=""gt"">Traceback (most recent call last):</span>
    <span class=""o"">...</span>
<span class=""gr"">KeyError</span>: <span class=""n"">'lala'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'lala'</span><span class=""p"">,</span> <span class=""s1"">'unknown field'</span><span class=""p"">)</span>
<span class=""go"">'unknown field'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""s1"">'name'</span> <span class=""ow"">in</span> <span class=""n"">product</span>  <span class=""c1""># is name field populated?</span>
<span class=""go"">True</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""s1"">'last_updated'</span> <span class=""ow"">in</span> <span class=""n"">product</span>  <span class=""c1""># is last_updated populated?</span>
<span class=""go"">False</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""s1"">'last_updated'</span> <span class=""ow"">in</span> <span class=""n"">product</span><span class=""o"">.</span><span class=""n"">fields</span>  <span class=""c1""># is last_updated a declared field?</span>
<span class=""go"">True</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""s1"">'lala'</span> <span class=""ow"">in</span> <span class=""n"">product</span><span class=""o"">.</span><span class=""n"">fields</span>  <span class=""c1""># is lala a declared field?</span>
<span class=""go"">False</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'last_updated'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""s1"">'today'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'last_updated'</span><span class=""p"">]</span>
<span class=""go"">today</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'lala'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""s1"">'test'</span> <span class=""c1""># setting unknown field</span>
<span class=""gt"">Traceback (most recent call last):</span>
    <span class=""o"">...</span>
<span class=""gr"">KeyError</span>: <span class=""n"">'Product does not support field: lala'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">keys</span><span class=""p"">()</span>
<span class=""go"">['price', 'name']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">items</span><span class=""p"">()</span>
<span class=""go"">[('price', 1000), ('name', 'Desktop PC')]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">product</span><span class=""p"">)</span> <span class=""c1""># create a dict from all populated values</span>
<span class=""go"">{'price': 1000, 'name': 'Desktop PC'}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">Product</span><span class=""p"">({</span><span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""s1"">'Laptop PC'</span><span class=""p"">,</span> <span class=""s1"">'price'</span><span class=""p"">:</span> <span class=""mi"">1500</span><span class=""p"">})</span>
<span class=""go"">Product(price=1500, name='Laptop PC')</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">Product</span><span class=""p"">({</span><span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""s1"">'Laptop PC'</span><span class=""p"">,</span> <span class=""s1"">'lala'</span><span class=""p"">:</span> <span class=""mi"">1500</span><span class=""p"">})</span> <span class=""c1""># warning: unknown field in dict</span>
<span class=""gt"">Traceback (most recent call last):</span>
    <span class=""o"">...</span>
<span class=""gr"">KeyError</span>: <span class=""n"">'Product does not support field: lala'</span>
</pre></div>",">>> product = Product(name='Desktop PC', price=1000)
>>> print(product)
Product(name='Desktop PC', price=1000)
,>>> product['name']
Desktop PC
>>> product.get('name')
Desktop PC
,>>> product['price']
1000
,>>> product['last_updated']
Traceback (most recent call last):
    ...
KeyError: 'last_updated'
,>>> product.get('last_updated', 'not set')
not set
,>>> product['lala'] # getting unknown field
Traceback (most recent call last):
    ...
KeyError: 'lala'
,>>> product.get('lala', 'unknown field')
'unknown field'
,>>> 'name' in product  # is name field populated?
True
,>>> 'last_updated' in product  # is last_updated populated?
False
,>>> 'last_updated' in product.fields  # is last_updated a declared field?
True
,>>> 'lala' in product.fields  # is lala a declared field?
False
,>>> product['last_updated'] = 'today'
>>> product['last_updated']
today
,>>> product['lala'] = 'test' # setting unknown field
Traceback (most recent call last):
    ...
KeyError: 'Product does not support field: lala'
,>>> product.keys()
['price', 'name']
,>>> product.items()
[('price', 1000), ('name', 'Desktop PC')]
,>>> dict(product) # create a dict from all populated values
{'price': 1000, 'name': 'Desktop PC'}
,>>> Product({'name': 'Laptop PC', 'price': 1500})
Product(price=1500, name='Laptop PC')
,>>> Product({'name': 'Laptop PC', 'lala': 1500}) # warning: unknown field in dict
Traceback (most recent call last):
    ...
KeyError: 'Product does not support field: lala'
",18
https://docs.scrapy.org/en/latest/topics/items.html,,####,4,Creating items,#creating-items,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span> <span class=""o"">=</span> <span class=""n"">Product</span><span class=""p"">(</span><span class=""n"">name</span><span class=""o"">=</span><span class=""s1"">'Desktop PC'</span><span class=""p"">,</span> <span class=""n"">price</span><span class=""o"">=</span><span class=""mi"">1000</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">product</span><span class=""p"">)</span>
<span class=""go"">Product(name='Desktop PC', price=1000)</span>
</pre></div>",">>> product = Product(name='Desktop PC', price=1000)
>>> print(product)
Product(name='Desktop PC', price=1000)
",1
https://docs.scrapy.org/en/latest/topics/items.html,,####,4,Getting field values,#getting-field-values,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">]</span>
<span class=""go"">Desktop PC</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">)</span>
<span class=""go"">Desktop PC</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'price'</span><span class=""p"">]</span>
<span class=""go"">1000</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'last_updated'</span><span class=""p"">]</span>
<span class=""gt"">Traceback (most recent call last):</span>
    <span class=""o"">...</span>
<span class=""gr"">KeyError</span>: <span class=""n"">'last_updated'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'last_updated'</span><span class=""p"">,</span> <span class=""s1"">'not set'</span><span class=""p"">)</span>
<span class=""go"">not set</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'lala'</span><span class=""p"">]</span> <span class=""c1""># getting unknown field</span>
<span class=""gt"">Traceback (most recent call last):</span>
    <span class=""o"">...</span>
<span class=""gr"">KeyError</span>: <span class=""n"">'lala'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'lala'</span><span class=""p"">,</span> <span class=""s1"">'unknown field'</span><span class=""p"">)</span>
<span class=""go"">'unknown field'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""s1"">'name'</span> <span class=""ow"">in</span> <span class=""n"">product</span>  <span class=""c1""># is name field populated?</span>
<span class=""go"">True</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""s1"">'last_updated'</span> <span class=""ow"">in</span> <span class=""n"">product</span>  <span class=""c1""># is last_updated populated?</span>
<span class=""go"">False</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""s1"">'last_updated'</span> <span class=""ow"">in</span> <span class=""n"">product</span><span class=""o"">.</span><span class=""n"">fields</span>  <span class=""c1""># is last_updated a declared field?</span>
<span class=""go"">True</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""s1"">'lala'</span> <span class=""ow"">in</span> <span class=""n"">product</span><span class=""o"">.</span><span class=""n"">fields</span>  <span class=""c1""># is lala a declared field?</span>
<span class=""go"">False</span>
</pre></div>",">>> product['name']
Desktop PC
>>> product.get('name')
Desktop PC
,>>> product['price']
1000
,>>> product['last_updated']
Traceback (most recent call last):
    ...
KeyError: 'last_updated'
,>>> product.get('last_updated', 'not set')
not set
,>>> product['lala'] # getting unknown field
Traceback (most recent call last):
    ...
KeyError: 'lala'
,>>> product.get('lala', 'unknown field')
'unknown field'
,>>> 'name' in product  # is name field populated?
True
,>>> 'last_updated' in product  # is last_updated populated?
False
,>>> 'last_updated' in product.fields  # is last_updated a declared field?
True
,>>> 'lala' in product.fields  # is lala a declared field?
False
",10
https://docs.scrapy.org/en/latest/topics/items.html,,####,4,Setting field values,#setting-field-values,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'last_updated'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""s1"">'today'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'last_updated'</span><span class=""p"">]</span>
<span class=""go"">today</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""p"">[</span><span class=""s1"">'lala'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""s1"">'test'</span> <span class=""c1""># setting unknown field</span>
<span class=""gt"">Traceback (most recent call last):</span>
    <span class=""o"">...</span>
<span class=""gr"">KeyError</span>: <span class=""n"">'Product does not support field: lala'</span>
</pre></div>",">>> product['last_updated'] = 'today'
>>> product['last_updated']
today
,>>> product['lala'] = 'test' # setting unknown field
Traceback (most recent call last):
    ...
KeyError: 'Product does not support field: lala'
",2
https://docs.scrapy.org/en/latest/topics/items.html,,####,4,Accessing all populated values,#accessing-all-populated-values,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">keys</span><span class=""p"">()</span>
<span class=""go"">['price', 'name']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">product</span><span class=""o"">.</span><span class=""n"">items</span><span class=""p"">()</span>
<span class=""go"">[('price', 1000), ('name', 'Desktop PC')]</span>
</pre></div>",">>> product.keys()
['price', 'name']
,>>> product.items()
[('price', 1000), ('name', 'Desktop PC')]
",2
https://docs.scrapy.org/en/latest/topics/items.html,,####,4,Copying items,#copying-items,,,15
https://docs.scrapy.org/en/latest/topics/items.html,,####,4,Other common tasks,#other-common-tasks,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">product</span><span class=""p"">)</span> <span class=""c1""># create a dict from all populated values</span>
<span class=""go"">{'price': 1000, 'name': 'Desktop PC'}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">Product</span><span class=""p"">({</span><span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""s1"">'Laptop PC'</span><span class=""p"">,</span> <span class=""s1"">'price'</span><span class=""p"">:</span> <span class=""mi"">1500</span><span class=""p"">})</span>
<span class=""go"">Product(price=1500, name='Laptop PC')</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">Product</span><span class=""p"">({</span><span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""s1"">'Laptop PC'</span><span class=""p"">,</span> <span class=""s1"">'lala'</span><span class=""p"">:</span> <span class=""mi"">1500</span><span class=""p"">})</span> <span class=""c1""># warning: unknown field in dict</span>
<span class=""gt"">Traceback (most recent call last):</span>
    <span class=""o"">...</span>
<span class=""gr"">KeyError</span>: <span class=""n"">'Product does not support field: lala'</span>
</pre></div>",">>> dict(product) # create a dict from all populated values
{'price': 1000, 'name': 'Desktop PC'}
,>>> Product({'name': 'Laptop PC', 'price': 1500})
Product(price=1500, name='Laptop PC')
,>>> Product({'name': 'Laptop PC', 'lala': 1500}) # warning: unknown field in dict
Traceback (most recent call last):
    ...
KeyError: 'Product does not support field: lala'
",3
https://docs.scrapy.org/en/latest/topics/items.html,,###,3,Extending Item subclasses,#extending-item-subclasses,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">DiscountedProduct</span><span class=""p"">(</span><span class=""n"">Product</span><span class=""p"">):</span>
    <span class=""n"">discount_percent</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">(</span><span class=""n"">serializer</span><span class=""o"">=</span><span class=""nb"">str</span><span class=""p"">)</span>
    <span class=""n"">discount_expiration_date</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">SpecificProduct</span><span class=""p"">(</span><span class=""n"">Product</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">(</span><span class=""n"">Product</span><span class=""o"">.</span><span class=""n"">fields</span><span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">],</span> <span class=""n"">serializer</span><span class=""o"">=</span><span class=""n"">my_serializer</span><span class=""p"">)</span>
</pre></div>","class DiscountedProduct(Product):
    discount_percent = scrapy.Field(serializer=str)
    discount_expiration_date = scrapy.Field()
,class SpecificProduct(Product):
    name = scrapy.Field(Product.fields['name'], serializer=my_serializer)
",2
https://docs.scrapy.org/en/latest/topics/items.html,,##,2,Supporting All Item Types,#supporting-all-item-types,,,18
https://docs.scrapy.org/en/latest/topics/items.html,,##,2,Other classes related to items,#other-classes-related-to-items,,,19
https://docs.scrapy.org/en/latest/topics/loaders.html,,#,1,Item Loaders,#module-scrapy.loader,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.loader</span> <span class=""kn"">import</span> <span class=""n"">ItemLoader</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.items</span> <span class=""kn"">import</span> <span class=""n"">Product</span>

<span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""n"">l</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">item</span><span class=""o"">=</span><span class=""n"">Product</span><span class=""p"">(),</span> <span class=""n"">response</span><span class=""o"">=</span><span class=""n"">response</span><span class=""p"">)</span>
    <span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'//div[@class=""product_name""]'</span><span class=""p"">)</span>
    <span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'//div[@class=""product_title""]'</span><span class=""p"">)</span>
    <span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'price'</span><span class=""p"">,</span> <span class=""s1"">'//p[@id=""price""]'</span><span class=""p"">)</span>
    <span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_css</span><span class=""p"">(</span><span class=""s1"">'stock'</span><span class=""p"">,</span> <span class=""s1"">'p#stock'</span><span class=""p"">)</span>
    <span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""s1"">'last_updated'</span><span class=""p"">,</span> <span class=""s1"">'today'</span><span class=""p"">)</span> <span class=""c1""># you can also use literal values</span>
    <span class=""k"">return</span> <span class=""n"">l</span><span class=""o"">.</span><span class=""n"">load_item</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">dataclasses</span> <span class=""kn"">import</span> <span class=""n"">dataclass</span><span class=""p"">,</span> <span class=""n"">field</span>
<span class=""kn"">from</span> <span class=""nn"">typing</span> <span class=""kn"">import</span> <span class=""n"">Optional</span>

<span class=""nd"">@dataclass</span>
<span class=""k"">class</span> <span class=""nc"">InventoryItem</span><span class=""p"">:</span>
    <span class=""n"">name</span><span class=""p"">:</span> <span class=""n"">Optional</span><span class=""p"">[</span><span class=""nb"">str</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">field</span><span class=""p"">(</span><span class=""n"">default</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">)</span>
    <span class=""n"">price</span><span class=""p"">:</span> <span class=""n"">Optional</span><span class=""p"">[</span><span class=""nb"">float</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">field</span><span class=""p"">(</span><span class=""n"">default</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">)</span>
    <span class=""n"">stock</span><span class=""p"">:</span> <span class=""n"">Optional</span><span class=""p"">[</span><span class=""nb"">int</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">field</span><span class=""p"">(</span><span class=""n"">default</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">l</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">Product</span><span class=""p"">(),</span> <span class=""n"">some_selector</span><span class=""p"">)</span>
<span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""n"">xpath1</span><span class=""p"">)</span> <span class=""c1""># (1)</span>
<span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""n"">xpath2</span><span class=""p"">)</span> <span class=""c1""># (2)</span>
<span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_css</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""n"">css</span><span class=""p"">)</span> <span class=""c1""># (3)</span>
<span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'test'</span><span class=""p"">)</span> <span class=""c1""># (4)</span>
<span class=""k"">return</span> <span class=""n"">l</span><span class=""o"">.</span><span class=""n"">load_item</span><span class=""p"">()</span> <span class=""c1""># (5)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemloaders.processors</span> <span class=""kn"">import</span> <span class=""n"">TakeFirst</span><span class=""p"">,</span> <span class=""n"">MapCompose</span><span class=""p"">,</span> <span class=""n"">Join</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.loader</span> <span class=""kn"">import</span> <span class=""n"">ItemLoader</span>

<span class=""k"">class</span> <span class=""nc"">ProductLoader</span><span class=""p"">(</span><span class=""n"">ItemLoader</span><span class=""p"">):</span>

    <span class=""n"">default_output_processor</span> <span class=""o"">=</span> <span class=""n"">TakeFirst</span><span class=""p"">()</span>

    <span class=""n"">name_in</span> <span class=""o"">=</span> <span class=""n"">MapCompose</span><span class=""p"">(</span><span class=""nb"">str</span><span class=""o"">.</span><span class=""n"">title</span><span class=""p"">)</span>
    <span class=""n"">name_out</span> <span class=""o"">=</span> <span class=""n"">Join</span><span class=""p"">()</span>

    <span class=""n"">price_in</span> <span class=""o"">=</span> <span class=""n"">MapCompose</span><span class=""p"">(</span><span class=""nb"">str</span><span class=""o"">.</span><span class=""n"">strip</span><span class=""p"">)</span>

    <span class=""c1""># ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">itemloaders.processors</span> <span class=""kn"">import</span> <span class=""n"">Join</span><span class=""p"">,</span> <span class=""n"">MapCompose</span><span class=""p"">,</span> <span class=""n"">TakeFirst</span>
<span class=""kn"">from</span> <span class=""nn"">w3lib.html</span> <span class=""kn"">import</span> <span class=""n"">remove_tags</span>

<span class=""k"">def</span> <span class=""nf"">filter_price</span><span class=""p"">(</span><span class=""n"">value</span><span class=""p"">):</span>
    <span class=""k"">if</span> <span class=""n"">value</span><span class=""o"">.</span><span class=""n"">isdigit</span><span class=""p"">():</span>
        <span class=""k"">return</span> <span class=""n"">value</span>

<span class=""k"">class</span> <span class=""nc"">Product</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">(</span>
        <span class=""n"">input_processor</span><span class=""o"">=</span><span class=""n"">MapCompose</span><span class=""p"">(</span><span class=""n"">remove_tags</span><span class=""p"">),</span>
        <span class=""n"">output_processor</span><span class=""o"">=</span><span class=""n"">Join</span><span class=""p"">(),</span>
    <span class=""p"">)</span>
    <span class=""n"">price</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">(</span>
        <span class=""n"">input_processor</span><span class=""o"">=</span><span class=""n"">MapCompose</span><span class=""p"">(</span><span class=""n"">remove_tags</span><span class=""p"">,</span> <span class=""n"">filter_price</span><span class=""p"">),</span>
        <span class=""n"">output_processor</span><span class=""o"">=</span><span class=""n"">TakeFirst</span><span class=""p"">(),</span>
    <span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.loader</span> <span class=""kn"">import</span> <span class=""n"">ItemLoader</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">il</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">item</span><span class=""o"">=</span><span class=""n"">Product</span><span class=""p"">())</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">il</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""p"">[</span><span class=""s1"">'Welcome to my'</span><span class=""p"">,</span> <span class=""s1"">'&lt;strong&gt;website&lt;/strong&gt;'</span><span class=""p"">])</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">il</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""s1"">'price'</span><span class=""p"">,</span> <span class=""p"">[</span><span class=""s1"">'&amp;euro;'</span><span class=""p"">,</span> <span class=""s1"">'&lt;span&gt;1000&lt;/span&gt;'</span><span class=""p"">])</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">il</span><span class=""o"">.</span><span class=""n"">load_item</span><span class=""p"">()</span>
<span class=""go"">{'name': 'Welcome to my website', 'price': '1000'}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse_length</span><span class=""p"">(</span><span class=""n"">text</span><span class=""p"">,</span> <span class=""n"">loader_context</span><span class=""p"">):</span>
    <span class=""n"">unit</span> <span class=""o"">=</span> <span class=""n"">loader_context</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'unit'</span><span class=""p"">,</span> <span class=""s1"">'m'</span><span class=""p"">)</span>
    <span class=""c1""># ... length parsing code goes here ...</span>
    <span class=""k"">return</span> <span class=""n"">parsed_length</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">loader</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">product</span><span class=""p"">)</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">context</span><span class=""p"">[</span><span class=""s1"">'unit'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""s1"">'cm'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">loader</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">product</span><span class=""p"">,</span> <span class=""n"">unit</span><span class=""o"">=</span><span class=""s1"">'cm'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">ProductLoader</span><span class=""p"">(</span><span class=""n"">ItemLoader</span><span class=""p"">):</span>
    <span class=""n"">length_out</span> <span class=""o"">=</span> <span class=""n"">MapCompose</span><span class=""p"">(</span><span class=""n"">parse_length</span><span class=""p"">,</span> <span class=""n"">unit</span><span class=""o"">=</span><span class=""s1"">'cm'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># HTML snippet: &lt;p class=""product-name""&gt;Color TV&lt;/p&gt;</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_css</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'p.product-name'</span><span class=""p"">)</span>
<span class=""c1""># HTML snippet: &lt;p id=""price""&gt;the price is $1200&lt;/p&gt;</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_css</span><span class=""p"">(</span><span class=""s1"">'price'</span><span class=""p"">,</span> <span class=""s1"">'p#price'</span><span class=""p"">,</span> <span class=""n"">re</span><span class=""o"">=</span><span class=""s1"">'the price is (.*)'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'Color TV'</span><span class=""p"">)</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""s1"">'colours'</span><span class=""p"">,</span> <span class=""p"">[</span><span class=""s1"">'white'</span><span class=""p"">,</span> <span class=""s1"">'blue'</span><span class=""p"">])</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""s1"">'length'</span><span class=""p"">,</span> <span class=""s1"">'100'</span><span class=""p"">)</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'name: foo'</span><span class=""p"">,</span> <span class=""n"">TakeFirst</span><span class=""p"">(),</span> <span class=""n"">re</span><span class=""o"">=</span><span class=""s1"">'name: (.+)'</span><span class=""p"">)</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""p"">{</span><span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""s1"">'foo'</span><span class=""p"">,</span> <span class=""s1"">'sex'</span><span class=""p"">:</span> <span class=""s1"">'male'</span><span class=""p"">})</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># HTML snippet: &lt;p class=""product-name""&gt;Color TV&lt;/p&gt;</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'//p[@class=""product-name""]'</span><span class=""p"">)</span>
<span class=""c1""># HTML snippet: &lt;p id=""price""&gt;the price is $1200&lt;/p&gt;</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'price'</span><span class=""p"">,</span> <span class=""s1"">'//p[@id=""price""]'</span><span class=""p"">,</span> <span class=""n"">re</span><span class=""o"">=</span><span class=""s1"">'the price is (.*)'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># HTML snippet: &lt;p class=""product-name""&gt;Color TV&lt;/p&gt;</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">get_css</span><span class=""p"">(</span><span class=""s1"">'p.product-name'</span><span class=""p"">)</span>
<span class=""c1""># HTML snippet: &lt;p id=""price""&gt;the price is $1200&lt;/p&gt;</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">get_css</span><span class=""p"">(</span><span class=""s1"">'p#price'</span><span class=""p"">,</span> <span class=""n"">TakeFirst</span><span class=""p"">(),</span> <span class=""n"">re</span><span class=""o"">=</span><span class=""s1"">'the price is (.*)'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">itemloaders</span> <span class=""kn"">import</span> <span class=""n"">ItemLoader</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">itemloaders.processors</span> <span class=""kn"">import</span> <span class=""n"">TakeFirst</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">loader</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">get_value</span><span class=""p"">(</span><span class=""s1"">'name: foo'</span><span class=""p"">,</span> <span class=""n"">TakeFirst</span><span class=""p"">(),</span> <span class=""nb"">str</span><span class=""o"">.</span><span class=""n"">upper</span><span class=""p"">,</span> <span class=""n"">re</span><span class=""o"">=</span><span class=""s1"">'name: (.+)'</span><span class=""p"">)</span>
<span class=""go"">'FOO'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># HTML snippet: &lt;p class=""product-name""&gt;Color TV&lt;/p&gt;</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">get_xpath</span><span class=""p"">(</span><span class=""s1"">'//p[@class=""product-name""]'</span><span class=""p"">)</span>
<span class=""c1""># HTML snippet: &lt;p id=""price""&gt;the price is $1200&lt;/p&gt;</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">get_xpath</span><span class=""p"">(</span><span class=""s1"">'//p[@id=""price""]'</span><span class=""p"">,</span> <span class=""n"">TakeFirst</span><span class=""p"">(),</span> <span class=""n"">re</span><span class=""o"">=</span><span class=""s1"">'the price is (.*)'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">footer</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">a</span> <span class=""n"">class</span><span class=""o"">=</span><span class=""s2"">""social""</span> <span class=""n"">href</span><span class=""o"">=</span><span class=""s2"">""https://facebook.com/whatever""</span><span class=""o"">&gt;</span><span class=""n"">Like</span> <span class=""n"">Us</span><span class=""o"">&lt;/</span><span class=""n"">a</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">a</span> <span class=""n"">class</span><span class=""o"">=</span><span class=""s2"">""social""</span> <span class=""n"">href</span><span class=""o"">=</span><span class=""s2"">""https://twitter.com/whatever""</span><span class=""o"">&gt;</span><span class=""n"">Follow</span> <span class=""n"">Us</span><span class=""o"">&lt;/</span><span class=""n"">a</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">a</span> <span class=""n"">class</span><span class=""o"">=</span><span class=""s2"">""email""</span> <span class=""n"">href</span><span class=""o"">=</span><span class=""s2"">""mailto:whatever@example.com""</span><span class=""o"">&gt;</span><span class=""n"">Email</span> <span class=""n"">Us</span><span class=""o"">&lt;/</span><span class=""n"">a</span><span class=""o"">&gt;</span>
<span class=""o"">&lt;/</span><span class=""n"">footer</span><span class=""o"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">loader</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">item</span><span class=""o"">=</span><span class=""n"">Item</span><span class=""p"">())</span>
<span class=""c1""># load stuff not in the footer</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'social'</span><span class=""p"">,</span> <span class=""s1"">'//footer/a[@class = ""social""]/@href'</span><span class=""p"">)</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'email'</span><span class=""p"">,</span> <span class=""s1"">'//footer/a[@class = ""email""]/@href'</span><span class=""p"">)</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">load_item</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">loader</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">item</span><span class=""o"">=</span><span class=""n"">Item</span><span class=""p"">())</span>
<span class=""c1""># load stuff not in the footer</span>
<span class=""n"">footer_loader</span> <span class=""o"">=</span> <span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">nested_xpath</span><span class=""p"">(</span><span class=""s1"">'//footer'</span><span class=""p"">)</span>
<span class=""n"">footer_loader</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'social'</span><span class=""p"">,</span> <span class=""s1"">'a[@class = ""social""]/@href'</span><span class=""p"">)</span>
<span class=""n"">footer_loader</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'email'</span><span class=""p"">,</span> <span class=""s1"">'a[@class = ""email""]/@href'</span><span class=""p"">)</span>
<span class=""c1""># no need to call footer_loader.load_item()</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">load_item</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemloaders.processors</span> <span class=""kn"">import</span> <span class=""n"">MapCompose</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.ItemLoaders</span> <span class=""kn"">import</span> <span class=""n"">ProductLoader</span>

<span class=""k"">def</span> <span class=""nf"">strip_dashes</span><span class=""p"">(</span><span class=""n"">x</span><span class=""p"">):</span>
    <span class=""k"">return</span> <span class=""n"">x</span><span class=""o"">.</span><span class=""n"">strip</span><span class=""p"">(</span><span class=""s1"">'-'</span><span class=""p"">)</span>

<span class=""k"">class</span> <span class=""nc"">SiteSpecificLoader</span><span class=""p"">(</span><span class=""n"">ProductLoader</span><span class=""p"">):</span>
    <span class=""n"">name_in</span> <span class=""o"">=</span> <span class=""n"">MapCompose</span><span class=""p"">(</span><span class=""n"">strip_dashes</span><span class=""p"">,</span> <span class=""n"">ProductLoader</span><span class=""o"">.</span><span class=""n"">name_in</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemloaders.processors</span> <span class=""kn"">import</span> <span class=""n"">MapCompose</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.ItemLoaders</span> <span class=""kn"">import</span> <span class=""n"">ProductLoader</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.utils.xml</span> <span class=""kn"">import</span> <span class=""n"">remove_cdata</span>

<span class=""k"">class</span> <span class=""nc"">XmlProductLoader</span><span class=""p"">(</span><span class=""n"">ProductLoader</span><span class=""p"">):</span>
    <span class=""n"">name_in</span> <span class=""o"">=</span> <span class=""n"">MapCompose</span><span class=""p"">(</span><span class=""n"">remove_cdata</span><span class=""p"">,</span> <span class=""n"">ProductLoader</span><span class=""o"">.</span><span class=""n"">name_in</span><span class=""p"">)</span>
</pre></div>","from scrapy.loader import ItemLoader
from myproject.items import Product

def parse(self, response):
    l = ItemLoader(item=Product(), response=response)
    l.add_xpath('name', '//div[@class=""product_name""]')
    l.add_xpath('name', '//div[@class=""product_title""]')
    l.add_xpath('price', '//p[@id=""price""]')
    l.add_css('stock', 'p#stock')
    l.add_value('last_updated', 'today') # you can also use literal values
    return l.load_item()
,from dataclasses import dataclass, field
from typing import Optional

@dataclass
class InventoryItem:
    name: Optional[str] = field(default=None)
    price: Optional[float] = field(default=None)
    stock: Optional[int] = field(default=None)
,l = ItemLoader(Product(), some_selector)
l.add_xpath('name', xpath1) # (1)
l.add_xpath('name', xpath2) # (2)
l.add_css('name', css) # (3)
l.add_value('name', 'test') # (4)
return l.load_item() # (5)
,from itemloaders.processors import TakeFirst, MapCompose, Join
from scrapy.loader import ItemLoader

class ProductLoader(ItemLoader):

    default_output_processor = TakeFirst()

    name_in = MapCompose(str.title)
    name_out = Join()

    price_in = MapCompose(str.strip)

    # ...
,import scrapy
from itemloaders.processors import Join, MapCompose, TakeFirst
from w3lib.html import remove_tags

def filter_price(value):
    if value.isdigit():
        return value

class Product(scrapy.Item):
    name = scrapy.Field(
        input_processor=MapCompose(remove_tags),
        output_processor=Join(),
    )
    price = scrapy.Field(
        input_processor=MapCompose(remove_tags, filter_price),
        output_processor=TakeFirst(),
    )
,>>> from scrapy.loader import ItemLoader
>>> il = ItemLoader(item=Product())
>>> il.add_value('name', ['Welcome to my', '<strong>website</strong>'])
>>> il.add_value('price', ['€', '<span>1000</span>'])
>>> il.load_item()
{'name': 'Welcome to my website', 'price': '1000'}
,def parse_length(text, loader_context):
    unit = loader_context.get('unit', 'm')
    # ... length parsing code goes here ...
    return parsed_length
,loader = ItemLoader(product)
loader.context['unit'] = 'cm'
,loader = ItemLoader(product, unit='cm')
,class ProductLoader(ItemLoader):
    length_out = MapCompose(parse_length, unit='cm')
,# HTML snippet: <p class=""product-name"">Color TV</p>
loader.add_css('name', 'p.product-name')
# HTML snippet: <p id=""price"">the price is $1200</p>
loader.add_css('price', 'p#price', re='the price is (.*)')
,loader.add_value('name', 'Color TV')
loader.add_value('colours', ['white', 'blue'])
loader.add_value('length', '100')
loader.add_value('name', 'name: foo', TakeFirst(), re='name: (.+)')
loader.add_value(None, {'name': 'foo', 'sex': 'male'})
,# HTML snippet: <p class=""product-name"">Color TV</p>
loader.add_xpath('name', '//p[@class=""product-name""]')
# HTML snippet: <p id=""price"">the price is $1200</p>
loader.add_xpath('price', '//p[@id=""price""]', re='the price is (.*)')
,# HTML snippet: <p class=""product-name"">Color TV</p>
loader.get_css('p.product-name')
# HTML snippet: <p id=""price"">the price is $1200</p>
loader.get_css('p#price', TakeFirst(), re='the price is (.*)')
,>>> from itemloaders import ItemLoader
>>> from itemloaders.processors import TakeFirst
>>> loader = ItemLoader()
>>> loader.get_value('name: foo', TakeFirst(), str.upper, re='name: (.+)')
'FOO'
,# HTML snippet: <p class=""product-name"">Color TV</p>
loader.get_xpath('//p[@class=""product-name""]')
# HTML snippet: <p id=""price"">the price is $1200</p>
loader.get_xpath('//p[@id=""price""]', TakeFirst(), re='the price is (.*)')
,<footer>
    <a class=""social"" href=""https://facebook.com/whatever"">Like Us</a>
    <a class=""social"" href=""https://twitter.com/whatever"">Follow Us</a>
    <a class=""email"" href=""mailto:whatever@example.com"">Email Us</a>
</footer>
,loader = ItemLoader(item=Item())
# load stuff not in the footer
loader.add_xpath('social', '//footer/a[@class = ""social""]/@href')
loader.add_xpath('email', '//footer/a[@class = ""email""]/@href')
loader.load_item()
,loader = ItemLoader(item=Item())
# load stuff not in the footer
footer_loader = loader.nested_xpath('//footer')
footer_loader.add_xpath('social', 'a[@class = ""social""]/@href')
footer_loader.add_xpath('email', 'a[@class = ""email""]/@href')
# no need to call footer_loader.load_item()
loader.load_item()
,from itemloaders.processors import MapCompose
from myproject.ItemLoaders import ProductLoader

def strip_dashes(x):
    return x.strip('-')

class SiteSpecificLoader(ProductLoader):
    name_in = MapCompose(strip_dashes, ProductLoader.name_in)
,from itemloaders.processors import MapCompose
from myproject.ItemLoaders import ProductLoader
from myproject.utils.xml import remove_cdata

class XmlProductLoader(ProductLoader):
    name_in = MapCompose(remove_cdata, ProductLoader.name_in)
",21
https://docs.scrapy.org/en/latest/topics/loaders.html,,##,2,Using Item Loaders to populate items,#using-item-loaders-to-populate-items,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.loader</span> <span class=""kn"">import</span> <span class=""n"">ItemLoader</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.items</span> <span class=""kn"">import</span> <span class=""n"">Product</span>

<span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""n"">l</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">item</span><span class=""o"">=</span><span class=""n"">Product</span><span class=""p"">(),</span> <span class=""n"">response</span><span class=""o"">=</span><span class=""n"">response</span><span class=""p"">)</span>
    <span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'//div[@class=""product_name""]'</span><span class=""p"">)</span>
    <span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'//div[@class=""product_title""]'</span><span class=""p"">)</span>
    <span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'price'</span><span class=""p"">,</span> <span class=""s1"">'//p[@id=""price""]'</span><span class=""p"">)</span>
    <span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_css</span><span class=""p"">(</span><span class=""s1"">'stock'</span><span class=""p"">,</span> <span class=""s1"">'p#stock'</span><span class=""p"">)</span>
    <span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""s1"">'last_updated'</span><span class=""p"">,</span> <span class=""s1"">'today'</span><span class=""p"">)</span> <span class=""c1""># you can also use literal values</span>
    <span class=""k"">return</span> <span class=""n"">l</span><span class=""o"">.</span><span class=""n"">load_item</span><span class=""p"">()</span>
</pre></div>","from scrapy.loader import ItemLoader
from myproject.items import Product

def parse(self, response):
    l = ItemLoader(item=Product(), response=response)
    l.add_xpath('name', '//div[@class=""product_name""]')
    l.add_xpath('name', '//div[@class=""product_title""]')
    l.add_xpath('price', '//p[@id=""price""]')
    l.add_css('stock', 'p#stock')
    l.add_value('last_updated', 'today') # you can also use literal values
    return l.load_item()
",1
https://docs.scrapy.org/en/latest/topics/loaders.html,,##,2,Working with dataclass items,#working-with-dataclass-items,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">dataclasses</span> <span class=""kn"">import</span> <span class=""n"">dataclass</span><span class=""p"">,</span> <span class=""n"">field</span>
<span class=""kn"">from</span> <span class=""nn"">typing</span> <span class=""kn"">import</span> <span class=""n"">Optional</span>

<span class=""nd"">@dataclass</span>
<span class=""k"">class</span> <span class=""nc"">InventoryItem</span><span class=""p"">:</span>
    <span class=""n"">name</span><span class=""p"">:</span> <span class=""n"">Optional</span><span class=""p"">[</span><span class=""nb"">str</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">field</span><span class=""p"">(</span><span class=""n"">default</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">)</span>
    <span class=""n"">price</span><span class=""p"">:</span> <span class=""n"">Optional</span><span class=""p"">[</span><span class=""nb"">float</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">field</span><span class=""p"">(</span><span class=""n"">default</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">)</span>
    <span class=""n"">stock</span><span class=""p"">:</span> <span class=""n"">Optional</span><span class=""p"">[</span><span class=""nb"">int</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">field</span><span class=""p"">(</span><span class=""n"">default</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">)</span>
</pre></div>","from dataclasses import dataclass, field
from typing import Optional

@dataclass
class InventoryItem:
    name: Optional[str] = field(default=None)
    price: Optional[float] = field(default=None)
    stock: Optional[int] = field(default=None)
",1
https://docs.scrapy.org/en/latest/topics/loaders.html,,##,2,Input and Output processors,#input-and-output-processors,"<div class=""highlight""><pre><span></span><span class=""n"">l</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">Product</span><span class=""p"">(),</span> <span class=""n"">some_selector</span><span class=""p"">)</span>
<span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""n"">xpath1</span><span class=""p"">)</span> <span class=""c1""># (1)</span>
<span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""n"">xpath2</span><span class=""p"">)</span> <span class=""c1""># (2)</span>
<span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_css</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""n"">css</span><span class=""p"">)</span> <span class=""c1""># (3)</span>
<span class=""n"">l</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'test'</span><span class=""p"">)</span> <span class=""c1""># (4)</span>
<span class=""k"">return</span> <span class=""n"">l</span><span class=""o"">.</span><span class=""n"">load_item</span><span class=""p"">()</span> <span class=""c1""># (5)</span>
</pre></div>","l = ItemLoader(Product(), some_selector)
l.add_xpath('name', xpath1) # (1)
l.add_xpath('name', xpath2) # (2)
l.add_css('name', css) # (3)
l.add_value('name', 'test') # (4)
return l.load_item() # (5)
",1
https://docs.scrapy.org/en/latest/topics/loaders.html,,##,2,Declaring Item Loaders,#declaring-item-loaders,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemloaders.processors</span> <span class=""kn"">import</span> <span class=""n"">TakeFirst</span><span class=""p"">,</span> <span class=""n"">MapCompose</span><span class=""p"">,</span> <span class=""n"">Join</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.loader</span> <span class=""kn"">import</span> <span class=""n"">ItemLoader</span>

<span class=""k"">class</span> <span class=""nc"">ProductLoader</span><span class=""p"">(</span><span class=""n"">ItemLoader</span><span class=""p"">):</span>

    <span class=""n"">default_output_processor</span> <span class=""o"">=</span> <span class=""n"">TakeFirst</span><span class=""p"">()</span>

    <span class=""n"">name_in</span> <span class=""o"">=</span> <span class=""n"">MapCompose</span><span class=""p"">(</span><span class=""nb"">str</span><span class=""o"">.</span><span class=""n"">title</span><span class=""p"">)</span>
    <span class=""n"">name_out</span> <span class=""o"">=</span> <span class=""n"">Join</span><span class=""p"">()</span>

    <span class=""n"">price_in</span> <span class=""o"">=</span> <span class=""n"">MapCompose</span><span class=""p"">(</span><span class=""nb"">str</span><span class=""o"">.</span><span class=""n"">strip</span><span class=""p"">)</span>

    <span class=""c1""># ...</span>
</pre></div>","from itemloaders.processors import TakeFirst, MapCompose, Join
from scrapy.loader import ItemLoader

class ProductLoader(ItemLoader):

    default_output_processor = TakeFirst()

    name_in = MapCompose(str.title)
    name_out = Join()

    price_in = MapCompose(str.strip)

    # ...
",1
https://docs.scrapy.org/en/latest/topics/loaders.html,,##,2,Declaring Input and Output Processors,#declaring-input-and-output-processors,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">itemloaders.processors</span> <span class=""kn"">import</span> <span class=""n"">Join</span><span class=""p"">,</span> <span class=""n"">MapCompose</span><span class=""p"">,</span> <span class=""n"">TakeFirst</span>
<span class=""kn"">from</span> <span class=""nn"">w3lib.html</span> <span class=""kn"">import</span> <span class=""n"">remove_tags</span>

<span class=""k"">def</span> <span class=""nf"">filter_price</span><span class=""p"">(</span><span class=""n"">value</span><span class=""p"">):</span>
    <span class=""k"">if</span> <span class=""n"">value</span><span class=""o"">.</span><span class=""n"">isdigit</span><span class=""p"">():</span>
        <span class=""k"">return</span> <span class=""n"">value</span>

<span class=""k"">class</span> <span class=""nc"">Product</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">(</span>
        <span class=""n"">input_processor</span><span class=""o"">=</span><span class=""n"">MapCompose</span><span class=""p"">(</span><span class=""n"">remove_tags</span><span class=""p"">),</span>
        <span class=""n"">output_processor</span><span class=""o"">=</span><span class=""n"">Join</span><span class=""p"">(),</span>
    <span class=""p"">)</span>
    <span class=""n"">price</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">(</span>
        <span class=""n"">input_processor</span><span class=""o"">=</span><span class=""n"">MapCompose</span><span class=""p"">(</span><span class=""n"">remove_tags</span><span class=""p"">,</span> <span class=""n"">filter_price</span><span class=""p"">),</span>
        <span class=""n"">output_processor</span><span class=""o"">=</span><span class=""n"">TakeFirst</span><span class=""p"">(),</span>
    <span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.loader</span> <span class=""kn"">import</span> <span class=""n"">ItemLoader</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">il</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">item</span><span class=""o"">=</span><span class=""n"">Product</span><span class=""p"">())</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">il</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""p"">[</span><span class=""s1"">'Welcome to my'</span><span class=""p"">,</span> <span class=""s1"">'&lt;strong&gt;website&lt;/strong&gt;'</span><span class=""p"">])</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">il</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""s1"">'price'</span><span class=""p"">,</span> <span class=""p"">[</span><span class=""s1"">'&amp;euro;'</span><span class=""p"">,</span> <span class=""s1"">'&lt;span&gt;1000&lt;/span&gt;'</span><span class=""p"">])</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">il</span><span class=""o"">.</span><span class=""n"">load_item</span><span class=""p"">()</span>
<span class=""go"">{'name': 'Welcome to my website', 'price': '1000'}</span>
</pre></div>","import scrapy
from itemloaders.processors import Join, MapCompose, TakeFirst
from w3lib.html import remove_tags

def filter_price(value):
    if value.isdigit():
        return value

class Product(scrapy.Item):
    name = scrapy.Field(
        input_processor=MapCompose(remove_tags),
        output_processor=Join(),
    )
    price = scrapy.Field(
        input_processor=MapCompose(remove_tags, filter_price),
        output_processor=TakeFirst(),
    )
,>>> from scrapy.loader import ItemLoader
>>> il = ItemLoader(item=Product())
>>> il.add_value('name', ['Welcome to my', '<strong>website</strong>'])
>>> il.add_value('price', ['€', '<span>1000</span>'])
>>> il.load_item()
{'name': 'Welcome to my website', 'price': '1000'}
",2
https://docs.scrapy.org/en/latest/topics/loaders.html,,##,2,Item Loader Context,#item-loader-context,"<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse_length</span><span class=""p"">(</span><span class=""n"">text</span><span class=""p"">,</span> <span class=""n"">loader_context</span><span class=""p"">):</span>
    <span class=""n"">unit</span> <span class=""o"">=</span> <span class=""n"">loader_context</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'unit'</span><span class=""p"">,</span> <span class=""s1"">'m'</span><span class=""p"">)</span>
    <span class=""c1""># ... length parsing code goes here ...</span>
    <span class=""k"">return</span> <span class=""n"">parsed_length</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">loader</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">product</span><span class=""p"">)</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">context</span><span class=""p"">[</span><span class=""s1"">'unit'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""s1"">'cm'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">loader</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">product</span><span class=""p"">,</span> <span class=""n"">unit</span><span class=""o"">=</span><span class=""s1"">'cm'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">ProductLoader</span><span class=""p"">(</span><span class=""n"">ItemLoader</span><span class=""p"">):</span>
    <span class=""n"">length_out</span> <span class=""o"">=</span> <span class=""n"">MapCompose</span><span class=""p"">(</span><span class=""n"">parse_length</span><span class=""p"">,</span> <span class=""n"">unit</span><span class=""o"">=</span><span class=""s1"">'cm'</span><span class=""p"">)</span>
</pre></div>","def parse_length(text, loader_context):
    unit = loader_context.get('unit', 'm')
    # ... length parsing code goes here ...
    return parsed_length
,loader = ItemLoader(product)
loader.context['unit'] = 'cm'
,loader = ItemLoader(product, unit='cm')
,class ProductLoader(ItemLoader):
    length_out = MapCompose(parse_length, unit='cm')
",4
https://docs.scrapy.org/en/latest/topics/loaders.html,,##,2,ItemLoader objects,#itemloader-objects,"<div class=""highlight""><pre><span></span><span class=""c1""># HTML snippet: &lt;p class=""product-name""&gt;Color TV&lt;/p&gt;</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_css</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'p.product-name'</span><span class=""p"">)</span>
<span class=""c1""># HTML snippet: &lt;p id=""price""&gt;the price is $1200&lt;/p&gt;</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_css</span><span class=""p"">(</span><span class=""s1"">'price'</span><span class=""p"">,</span> <span class=""s1"">'p#price'</span><span class=""p"">,</span> <span class=""n"">re</span><span class=""o"">=</span><span class=""s1"">'the price is (.*)'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'Color TV'</span><span class=""p"">)</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""s1"">'colours'</span><span class=""p"">,</span> <span class=""p"">[</span><span class=""s1"">'white'</span><span class=""p"">,</span> <span class=""s1"">'blue'</span><span class=""p"">])</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""s1"">'length'</span><span class=""p"">,</span> <span class=""s1"">'100'</span><span class=""p"">)</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'name: foo'</span><span class=""p"">,</span> <span class=""n"">TakeFirst</span><span class=""p"">(),</span> <span class=""n"">re</span><span class=""o"">=</span><span class=""s1"">'name: (.+)'</span><span class=""p"">)</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_value</span><span class=""p"">(</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""p"">{</span><span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""s1"">'foo'</span><span class=""p"">,</span> <span class=""s1"">'sex'</span><span class=""p"">:</span> <span class=""s1"">'male'</span><span class=""p"">})</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># HTML snippet: &lt;p class=""product-name""&gt;Color TV&lt;/p&gt;</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'//p[@class=""product-name""]'</span><span class=""p"">)</span>
<span class=""c1""># HTML snippet: &lt;p id=""price""&gt;the price is $1200&lt;/p&gt;</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'price'</span><span class=""p"">,</span> <span class=""s1"">'//p[@id=""price""]'</span><span class=""p"">,</span> <span class=""n"">re</span><span class=""o"">=</span><span class=""s1"">'the price is (.*)'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># HTML snippet: &lt;p class=""product-name""&gt;Color TV&lt;/p&gt;</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">get_css</span><span class=""p"">(</span><span class=""s1"">'p.product-name'</span><span class=""p"">)</span>
<span class=""c1""># HTML snippet: &lt;p id=""price""&gt;the price is $1200&lt;/p&gt;</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">get_css</span><span class=""p"">(</span><span class=""s1"">'p#price'</span><span class=""p"">,</span> <span class=""n"">TakeFirst</span><span class=""p"">(),</span> <span class=""n"">re</span><span class=""o"">=</span><span class=""s1"">'the price is (.*)'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">itemloaders</span> <span class=""kn"">import</span> <span class=""n"">ItemLoader</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">itemloaders.processors</span> <span class=""kn"">import</span> <span class=""n"">TakeFirst</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">loader</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">get_value</span><span class=""p"">(</span><span class=""s1"">'name: foo'</span><span class=""p"">,</span> <span class=""n"">TakeFirst</span><span class=""p"">(),</span> <span class=""nb"">str</span><span class=""o"">.</span><span class=""n"">upper</span><span class=""p"">,</span> <span class=""n"">re</span><span class=""o"">=</span><span class=""s1"">'name: (.+)'</span><span class=""p"">)</span>
<span class=""go"">'FOO'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># HTML snippet: &lt;p class=""product-name""&gt;Color TV&lt;/p&gt;</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">get_xpath</span><span class=""p"">(</span><span class=""s1"">'//p[@class=""product-name""]'</span><span class=""p"">)</span>
<span class=""c1""># HTML snippet: &lt;p id=""price""&gt;the price is $1200&lt;/p&gt;</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">get_xpath</span><span class=""p"">(</span><span class=""s1"">'//p[@id=""price""]'</span><span class=""p"">,</span> <span class=""n"">TakeFirst</span><span class=""p"">(),</span> <span class=""n"">re</span><span class=""o"">=</span><span class=""s1"">'the price is (.*)'</span><span class=""p"">)</span>
</pre></div>","# HTML snippet: <p class=""product-name"">Color TV</p>
loader.add_css('name', 'p.product-name')
# HTML snippet: <p id=""price"">the price is $1200</p>
loader.add_css('price', 'p#price', re='the price is (.*)')
,loader.add_value('name', 'Color TV')
loader.add_value('colours', ['white', 'blue'])
loader.add_value('length', '100')
loader.add_value('name', 'name: foo', TakeFirst(), re='name: (.+)')
loader.add_value(None, {'name': 'foo', 'sex': 'male'})
,# HTML snippet: <p class=""product-name"">Color TV</p>
loader.add_xpath('name', '//p[@class=""product-name""]')
# HTML snippet: <p id=""price"">the price is $1200</p>
loader.add_xpath('price', '//p[@id=""price""]', re='the price is (.*)')
,# HTML snippet: <p class=""product-name"">Color TV</p>
loader.get_css('p.product-name')
# HTML snippet: <p id=""price"">the price is $1200</p>
loader.get_css('p#price', TakeFirst(), re='the price is (.*)')
,>>> from itemloaders import ItemLoader
>>> from itemloaders.processors import TakeFirst
>>> loader = ItemLoader()
>>> loader.get_value('name: foo', TakeFirst(), str.upper, re='name: (.+)')
'FOO'
,# HTML snippet: <p class=""product-name"">Color TV</p>
loader.get_xpath('//p[@class=""product-name""]')
# HTML snippet: <p id=""price"">the price is $1200</p>
loader.get_xpath('//p[@id=""price""]', TakeFirst(), re='the price is (.*)')
",6
https://docs.scrapy.org/en/latest/topics/loaders.html,,##,2,Nested Loaders,#nested-loaders,"<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">footer</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">a</span> <span class=""n"">class</span><span class=""o"">=</span><span class=""s2"">""social""</span> <span class=""n"">href</span><span class=""o"">=</span><span class=""s2"">""https://facebook.com/whatever""</span><span class=""o"">&gt;</span><span class=""n"">Like</span> <span class=""n"">Us</span><span class=""o"">&lt;/</span><span class=""n"">a</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">a</span> <span class=""n"">class</span><span class=""o"">=</span><span class=""s2"">""social""</span> <span class=""n"">href</span><span class=""o"">=</span><span class=""s2"">""https://twitter.com/whatever""</span><span class=""o"">&gt;</span><span class=""n"">Follow</span> <span class=""n"">Us</span><span class=""o"">&lt;/</span><span class=""n"">a</span><span class=""o"">&gt;</span>
    <span class=""o"">&lt;</span><span class=""n"">a</span> <span class=""n"">class</span><span class=""o"">=</span><span class=""s2"">""email""</span> <span class=""n"">href</span><span class=""o"">=</span><span class=""s2"">""mailto:whatever@example.com""</span><span class=""o"">&gt;</span><span class=""n"">Email</span> <span class=""n"">Us</span><span class=""o"">&lt;/</span><span class=""n"">a</span><span class=""o"">&gt;</span>
<span class=""o"">&lt;/</span><span class=""n"">footer</span><span class=""o"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">loader</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">item</span><span class=""o"">=</span><span class=""n"">Item</span><span class=""p"">())</span>
<span class=""c1""># load stuff not in the footer</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'social'</span><span class=""p"">,</span> <span class=""s1"">'//footer/a[@class = ""social""]/@href'</span><span class=""p"">)</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'email'</span><span class=""p"">,</span> <span class=""s1"">'//footer/a[@class = ""email""]/@href'</span><span class=""p"">)</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">load_item</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">loader</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">item</span><span class=""o"">=</span><span class=""n"">Item</span><span class=""p"">())</span>
<span class=""c1""># load stuff not in the footer</span>
<span class=""n"">footer_loader</span> <span class=""o"">=</span> <span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">nested_xpath</span><span class=""p"">(</span><span class=""s1"">'//footer'</span><span class=""p"">)</span>
<span class=""n"">footer_loader</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'social'</span><span class=""p"">,</span> <span class=""s1"">'a[@class = ""social""]/@href'</span><span class=""p"">)</span>
<span class=""n"">footer_loader</span><span class=""o"">.</span><span class=""n"">add_xpath</span><span class=""p"">(</span><span class=""s1"">'email'</span><span class=""p"">,</span> <span class=""s1"">'a[@class = ""email""]/@href'</span><span class=""p"">)</span>
<span class=""c1""># no need to call footer_loader.load_item()</span>
<span class=""n"">loader</span><span class=""o"">.</span><span class=""n"">load_item</span><span class=""p"">()</span>
</pre></div>","<footer>
    <a class=""social"" href=""https://facebook.com/whatever"">Like Us</a>
    <a class=""social"" href=""https://twitter.com/whatever"">Follow Us</a>
    <a class=""email"" href=""mailto:whatever@example.com"">Email Us</a>
</footer>
,loader = ItemLoader(item=Item())
# load stuff not in the footer
loader.add_xpath('social', '//footer/a[@class = ""social""]/@href')
loader.add_xpath('email', '//footer/a[@class = ""email""]/@href')
loader.load_item()
,loader = ItemLoader(item=Item())
# load stuff not in the footer
footer_loader = loader.nested_xpath('//footer')
footer_loader.add_xpath('social', 'a[@class = ""social""]/@href')
footer_loader.add_xpath('email', 'a[@class = ""email""]/@href')
# no need to call footer_loader.load_item()
loader.load_item()
",3
https://docs.scrapy.org/en/latest/topics/loaders.html,,##,2,Reusing and extending Item Loaders,#reusing-and-extending-item-loaders,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemloaders.processors</span> <span class=""kn"">import</span> <span class=""n"">MapCompose</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.ItemLoaders</span> <span class=""kn"">import</span> <span class=""n"">ProductLoader</span>

<span class=""k"">def</span> <span class=""nf"">strip_dashes</span><span class=""p"">(</span><span class=""n"">x</span><span class=""p"">):</span>
    <span class=""k"">return</span> <span class=""n"">x</span><span class=""o"">.</span><span class=""n"">strip</span><span class=""p"">(</span><span class=""s1"">'-'</span><span class=""p"">)</span>

<span class=""k"">class</span> <span class=""nc"">SiteSpecificLoader</span><span class=""p"">(</span><span class=""n"">ProductLoader</span><span class=""p"">):</span>
    <span class=""n"">name_in</span> <span class=""o"">=</span> <span class=""n"">MapCompose</span><span class=""p"">(</span><span class=""n"">strip_dashes</span><span class=""p"">,</span> <span class=""n"">ProductLoader</span><span class=""o"">.</span><span class=""n"">name_in</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemloaders.processors</span> <span class=""kn"">import</span> <span class=""n"">MapCompose</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.ItemLoaders</span> <span class=""kn"">import</span> <span class=""n"">ProductLoader</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.utils.xml</span> <span class=""kn"">import</span> <span class=""n"">remove_cdata</span>

<span class=""k"">class</span> <span class=""nc"">XmlProductLoader</span><span class=""p"">(</span><span class=""n"">ProductLoader</span><span class=""p"">):</span>
    <span class=""n"">name_in</span> <span class=""o"">=</span> <span class=""n"">MapCompose</span><span class=""p"">(</span><span class=""n"">remove_cdata</span><span class=""p"">,</span> <span class=""n"">ProductLoader</span><span class=""o"">.</span><span class=""n"">name_in</span><span class=""p"">)</span>
</pre></div>","from itemloaders.processors import MapCompose
from myproject.ItemLoaders import ProductLoader

def strip_dashes(x):
    return x.strip('-')

class SiteSpecificLoader(ProductLoader):
    name_in = MapCompose(strip_dashes, ProductLoader.name_in)
,from itemloaders.processors import MapCompose
from myproject.ItemLoaders import ProductLoader
from myproject.utils.xml import remove_cdata

class XmlProductLoader(ProductLoader):
    name_in = MapCompose(remove_cdata, ProductLoader.name_in)
",2
https://docs.scrapy.org/en/latest/topics/shell.html,,#,1,Scrapy shell,#scrapy-shell,"<div class=""highlight""><pre><span></span><span class=""p"">[</span><span class=""n"">settings</span><span class=""p"">]</span>
<span class=""n"">shell</span> <span class=""o"">=</span> <span class=""n"">bpython</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""o"">&lt;</span><span class=""n"">url</span><span class=""o"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># UNIX-style</span>
<span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""o"">./</span><span class=""n"">path</span><span class=""o"">/</span><span class=""n"">to</span><span class=""o"">/</span><span class=""n"">file</span><span class=""o"">.</span><span class=""n"">html</span>
<span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""o"">../</span><span class=""n"">other</span><span class=""o"">/</span><span class=""n"">path</span><span class=""o"">/</span><span class=""n"">to</span><span class=""o"">/</span><span class=""n"">file</span><span class=""o"">.</span><span class=""n"">html</span>
<span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""o"">/</span><span class=""n"">absolute</span><span class=""o"">/</span><span class=""n"">path</span><span class=""o"">/</span><span class=""n"">to</span><span class=""o"">/</span><span class=""n"">file</span><span class=""o"">.</span><span class=""n"">html</span>

<span class=""c1""># File URI</span>
<span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""n"">file</span><span class=""p"">:</span><span class=""o"">///</span><span class=""n"">absolute</span><span class=""o"">/</span><span class=""n"">path</span><span class=""o"">/</span><span class=""n"">to</span><span class=""o"">/</span><span class=""n"">file</span><span class=""o"">.</span><span class=""n"">html</span>
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy shell index.html
[ ... scrapy shell starts ... ]
[ ... traceback ... ]
twisted.internet.error.DNSLookupError: DNS lookup failed:
address 'index.html' not found: [Errno -5] No address associated with hostname.
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""s1"">'https://scrapy.org'</span> <span class=""o"">--</span><span class=""n"">nolog</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""s2"">""https://scrapy.org""</span> <span class=""o"">--</span><span class=""n"">nolog</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span> <span class=""n"">Available</span> <span class=""n"">Scrapy</span> <span class=""n"">objects</span><span class=""p"">:</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">scrapy</span>     <span class=""n"">scrapy</span> <span class=""n"">module</span> <span class=""p"">(</span><span class=""n"">contains</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">,</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Selector</span><span class=""p"">,</span> <span class=""n"">etc</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">crawler</span>    <span class=""o"">&lt;</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">Crawler</span> <span class=""nb"">object</span> <span class=""n"">at</span> <span class=""mh"">0x7f07395dd690</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">item</span>       <span class=""p"">{}</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">request</span>    <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">org</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">response</span>   <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">org</span><span class=""o"">/&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">settings</span>   <span class=""o"">&lt;</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">Settings</span> <span class=""nb"">object</span> <span class=""n"">at</span> <span class=""mh"">0x7f07395dd710</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">spider</span>     <span class=""o"">&lt;</span><span class=""n"">DefaultSpider</span> <span class=""s1"">'default'</span> <span class=""n"">at</span> <span class=""mh"">0x7f0735891690</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span> <span class=""n"">Useful</span> <span class=""n"">shortcuts</span><span class=""p"">:</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">fetch</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">[,</span> <span class=""n"">redirect</span><span class=""o"">=</span><span class=""kc"">True</span><span class=""p"">])</span> <span class=""n"">Fetch</span> <span class=""n"">URL</span> <span class=""ow"">and</span> <span class=""n"">update</span> <span class=""n"">local</span> <span class=""n"">objects</span> <span class=""p"">(</span><span class=""n"">by</span> <span class=""n"">default</span><span class=""p"">,</span> <span class=""n"">redirects</span> <span class=""n"">are</span> <span class=""n"">followed</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">fetch</span><span class=""p"">(</span><span class=""n"">req</span><span class=""p"">)</span>                  <span class=""n"">Fetch</span> <span class=""n"">a</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span> <span class=""ow"">and</span> <span class=""n"">update</span> <span class=""n"">local</span> <span class=""n"">objects</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">shelp</span><span class=""p"">()</span>           <span class=""n"">Shell</span> <span class=""n"">help</span> <span class=""p"">(</span><span class=""nb"">print</span> <span class=""n"">this</span> <span class=""n"">help</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">view</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">)</span>    <span class=""n"">View</span> <span class=""n"">response</span> <span class=""ow"">in</span> <span class=""n"">a</span> <span class=""n"">browser</span>

<span class=""o"">&gt;&gt;&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Scrapy | A Fast and Powerful Scraping and Web Crawling Framework'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">fetch</span><span class=""p"">(</span><span class=""s2"">""https://old.reddit.com/""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'reddit: the front page of the internet'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">replace</span><span class=""p"">(</span><span class=""n"">method</span><span class=""o"">=</span><span class=""s2"">""POST""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">fetch</span><span class=""p"">(</span><span class=""n"">request</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">status</span>
<span class=""go"">404</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">pprint</span> <span class=""kn"">import</span> <span class=""n"">pprint</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">pprint</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">headers</span><span class=""p"">)</span>
<span class=""go"">{'Accept-Ranges': ['bytes'],</span>
<span class=""go""> 'Cache-Control': ['max-age=0, must-revalidate'],</span>
<span class=""go""> 'Content-Type': ['text/html; charset=UTF-8'],</span>
<span class=""go""> 'Date': ['Thu, 08 Dec 2016 16:21:19 GMT'],</span>
<span class=""go""> 'Server': ['snooserv'],</span>
<span class=""go""> 'Set-Cookie': ['loid=KqNLou0V9SKMX4qb4n; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',</span>
<span class=""go"">                'loidcreated=2016-12-08T16%3A21%3A19.445Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',</span>
<span class=""go"">                'loid=vi0ZVe4NkxNWdlH7r7; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',</span>
<span class=""go"">                'loidcreated=2016-12-08T16%3A21%3A19.459Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure'],</span>
<span class=""go""> 'Vary': ['accept-encoding'],</span>
<span class=""go""> 'Via': ['1.1 varnish'],</span>
<span class=""go""> 'X-Cache': ['MISS'],</span>
<span class=""go""> 'X-Cache-Hits': ['0'],</span>
<span class=""go""> 'X-Content-Type-Options': ['nosniff'],</span>
<span class=""go""> 'X-Frame-Options': ['SAMEORIGIN'],</span>
<span class=""go""> 'X-Moose': ['majestic'],</span>
<span class=""go""> 'X-Served-By': ['cache-cdg8730-CDG'],</span>
<span class=""go""> 'X-Timer': ['S1481214079.394283,VS0,VE159'],</span>
<span class=""go""> 'X-Ua-Compatible': ['IE=edge'],</span>
<span class=""go""> 'X-Xss-Protection': ['1; mode=block']}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""myspider""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s2"">""http://example.com""</span><span class=""p"">,</span>
        <span class=""s2"">""http://example.org""</span><span class=""p"">,</span>
        <span class=""s2"">""http://example.net""</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""c1""># We want to inspect one specific response.</span>
        <span class=""k"">if</span> <span class=""s2"">"".org""</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">:</span>
            <span class=""kn"">from</span> <span class=""nn"">scrapy.shell</span> <span class=""kn"">import</span> <span class=""n"">inspect_response</span>
            <span class=""n"">inspect_response</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""p"">)</span>

        <span class=""c1""># Rest of parsing code.</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">2014</span><span class=""o"">-</span><span class=""mi"">01</span><span class=""o"">-</span><span class=""mi"">23</span> <span class=""mi"">17</span><span class=""p"">:</span><span class=""mi"">48</span><span class=""p"">:</span><span class=""mi"">31</span><span class=""o"">-</span><span class=""mi"">0400</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""mi"">2014</span><span class=""o"">-</span><span class=""mi"">01</span><span class=""o"">-</span><span class=""mi"">23</span> <span class=""mi"">17</span><span class=""p"">:</span><span class=""mi"">48</span><span class=""p"">:</span><span class=""mi"">31</span><span class=""o"">-</span><span class=""mi"">0400</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">org</span><span class=""o"">&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span> <span class=""n"">Available</span> <span class=""n"">Scrapy</span> <span class=""n"">objects</span><span class=""p"">:</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">crawler</span>    <span class=""o"">&lt;</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">Crawler</span> <span class=""nb"">object</span> <span class=""n"">at</span> <span class=""mh"">0x1e16b50</span><span class=""o"">&gt;</span>
<span class=""o"">...</span>

<span class=""o"">&gt;&gt;&gt;</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span>
<span class=""s1"">'http://example.org'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//h1[@class=""fn""]'</span><span class=""p"">)</span>
<span class=""go"">[]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">view</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">)</span>
<span class=""go"">True</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""o"">^</span><span class=""n"">D</span>
<span class=""go"">2014-01-23 17:50:03-0400 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://example.net&gt; (referer: None)</span>
<span class=""gp"">...</span>
</pre></div>","[settings]
shell = bpython
,scrapy shell <url>
,# UNIX-style
scrapy shell ./path/to/file.html
scrapy shell ../other/path/to/file.html
scrapy shell /absolute/path/to/file.html

# File URI
scrapy shell file:///absolute/path/to/file.html
,$ scrapy shell index.html
[ ... scrapy shell starts ... ]
[ ... traceback ... ]
twisted.internet.error.DNSLookupError: DNS lookup failed:
address 'index.html' not found: [Errno -5] No address associated with hostname.
,scrapy shell 'https://scrapy.org' --nolog
,scrapy shell ""https://scrapy.org"" --nolog
,[s] Available Scrapy objects:
[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)
[s]   crawler    <scrapy.crawler.Crawler object at 0x7f07395dd690>
[s]   item       {}
[s]   request    <GET https://scrapy.org>
[s]   response   <200 https://scrapy.org/>
[s]   settings   <scrapy.settings.Settings object at 0x7f07395dd710>
[s]   spider     <DefaultSpider 'default' at 0x7f0735891690>
[s] Useful shortcuts:
[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)
[s]   fetch(req)                  Fetch a scrapy.Request and update local objects
[s]   shelp()           Shell help (print this help)
[s]   view(response)    View response in a browser

>>>
,>>> response.xpath('//title/text()').get()
'Scrapy | A Fast and Powerful Scraping and Web Crawling Framework'
,>>> fetch(""https://old.reddit.com/"")
,>>> response.xpath('//title/text()').get()
'reddit: the front page of the internet'
,>>> request = request.replace(method=""POST"")
,>>> fetch(request)
,>>> response.status
404
,>>> from pprint import pprint
,>>> pprint(response.headers)
{'Accept-Ranges': ['bytes'],
 'Cache-Control': ['max-age=0, must-revalidate'],
 'Content-Type': ['text/html; charset=UTF-8'],
 'Date': ['Thu, 08 Dec 2016 16:21:19 GMT'],
 'Server': ['snooserv'],
 'Set-Cookie': ['loid=KqNLou0V9SKMX4qb4n; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',
                'loidcreated=2016-12-08T16:21:19.445Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',
                'loid=vi0ZVe4NkxNWdlH7r7; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',
                'loidcreated=2016-12-08T16:21:19.459Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure'],
 'Vary': ['accept-encoding'],
 'Via': ['1.1 varnish'],
 'X-Cache': ['MISS'],
 'X-Cache-Hits': ['0'],
 'X-Content-Type-Options': ['nosniff'],
 'X-Frame-Options': ['SAMEORIGIN'],
 'X-Moose': ['majestic'],
 'X-Served-By': ['cache-cdg8730-CDG'],
 'X-Timer': ['S1481214079.394283,VS0,VE159'],
 'X-Ua-Compatible': ['IE=edge'],
 'X-Xss-Protection': ['1; mode=block']}
,import scrapy


class MySpider(scrapy.Spider):
    name = ""myspider""
    start_urls = [
        ""http://example.com"",
        ""http://example.org"",
        ""http://example.net"",
    ]

    def parse(self, response):
        # We want to inspect one specific response.
        if "".org"" in response.url:
            from scrapy.shell import inspect_response
            inspect_response(response, self)

        # Rest of parsing code.
,2014-01-23 17:48:31-0400 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://example.com> (referer: None)
2014-01-23 17:48:31-0400 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://example.org> (referer: None)
[s] Available Scrapy objects:
[s]   crawler    <scrapy.crawler.Crawler object at 0x1e16b50>
...

>>> response.url
'http://example.org'
,>>> response.xpath('//h1[@class=""fn""]')
[]
,>>> view(response)
True
,>>> ^D
2014-01-23 17:50:03-0400 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://example.net> (referer: None)
...
",20
https://docs.scrapy.org/en/latest/topics/shell.html,,##,2,Configuring the shell,#configuring-the-shell,"<div class=""highlight""><pre><span></span><span class=""p"">[</span><span class=""n"">settings</span><span class=""p"">]</span>
<span class=""n"">shell</span> <span class=""o"">=</span> <span class=""n"">bpython</span>
</pre></div>","[settings]
shell = bpython
",1
https://docs.scrapy.org/en/latest/topics/shell.html,,##,2,Launch the shell,#launch-the-shell,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""o"">&lt;</span><span class=""n"">url</span><span class=""o"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># UNIX-style</span>
<span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""o"">./</span><span class=""n"">path</span><span class=""o"">/</span><span class=""n"">to</span><span class=""o"">/</span><span class=""n"">file</span><span class=""o"">.</span><span class=""n"">html</span>
<span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""o"">../</span><span class=""n"">other</span><span class=""o"">/</span><span class=""n"">path</span><span class=""o"">/</span><span class=""n"">to</span><span class=""o"">/</span><span class=""n"">file</span><span class=""o"">.</span><span class=""n"">html</span>
<span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""o"">/</span><span class=""n"">absolute</span><span class=""o"">/</span><span class=""n"">path</span><span class=""o"">/</span><span class=""n"">to</span><span class=""o"">/</span><span class=""n"">file</span><span class=""o"">.</span><span class=""n"">html</span>

<span class=""c1""># File URI</span>
<span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""n"">file</span><span class=""p"">:</span><span class=""o"">///</span><span class=""n"">absolute</span><span class=""o"">/</span><span class=""n"">path</span><span class=""o"">/</span><span class=""n"">to</span><span class=""o"">/</span><span class=""n"">file</span><span class=""o"">.</span><span class=""n"">html</span>
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy shell index.html
[ ... scrapy shell starts ... ]
[ ... traceback ... ]
twisted.internet.error.DNSLookupError: DNS lookup failed:
address 'index.html' not found: [Errno -5] No address associated with hostname.
</pre></div>","scrapy shell <url>
,# UNIX-style
scrapy shell ./path/to/file.html
scrapy shell ../other/path/to/file.html
scrapy shell /absolute/path/to/file.html

# File URI
scrapy shell file:///absolute/path/to/file.html
,$ scrapy shell index.html
[ ... scrapy shell starts ... ]
[ ... traceback ... ]
twisted.internet.error.DNSLookupError: DNS lookup failed:
address 'index.html' not found: [Errno -5] No address associated with hostname.
",3
https://docs.scrapy.org/en/latest/topics/shell.html,,##,2,Using the shell,#using-the-shell,,,4
https://docs.scrapy.org/en/latest/topics/shell.html,,###,3,Available Shortcuts,#available-shortcuts,,,5
https://docs.scrapy.org/en/latest/topics/shell.html,,###,3,Available Scrapy objects,#available-scrapy-objects,,,6
https://docs.scrapy.org/en/latest/topics/shell.html,,##,2,Example of shell session,#example-of-shell-session,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""s1"">'https://scrapy.org'</span> <span class=""o"">--</span><span class=""n"">nolog</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">shell</span> <span class=""s2"">""https://scrapy.org""</span> <span class=""o"">--</span><span class=""n"">nolog</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span> <span class=""n"">Available</span> <span class=""n"">Scrapy</span> <span class=""n"">objects</span><span class=""p"">:</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">scrapy</span>     <span class=""n"">scrapy</span> <span class=""n"">module</span> <span class=""p"">(</span><span class=""n"">contains</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">,</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Selector</span><span class=""p"">,</span> <span class=""n"">etc</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">crawler</span>    <span class=""o"">&lt;</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">Crawler</span> <span class=""nb"">object</span> <span class=""n"">at</span> <span class=""mh"">0x7f07395dd690</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">item</span>       <span class=""p"">{}</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">request</span>    <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">org</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">response</span>   <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">org</span><span class=""o"">/&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">settings</span>   <span class=""o"">&lt;</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">Settings</span> <span class=""nb"">object</span> <span class=""n"">at</span> <span class=""mh"">0x7f07395dd710</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">spider</span>     <span class=""o"">&lt;</span><span class=""n"">DefaultSpider</span> <span class=""s1"">'default'</span> <span class=""n"">at</span> <span class=""mh"">0x7f0735891690</span><span class=""o"">&gt;</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span> <span class=""n"">Useful</span> <span class=""n"">shortcuts</span><span class=""p"">:</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">fetch</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">[,</span> <span class=""n"">redirect</span><span class=""o"">=</span><span class=""kc"">True</span><span class=""p"">])</span> <span class=""n"">Fetch</span> <span class=""n"">URL</span> <span class=""ow"">and</span> <span class=""n"">update</span> <span class=""n"">local</span> <span class=""n"">objects</span> <span class=""p"">(</span><span class=""n"">by</span> <span class=""n"">default</span><span class=""p"">,</span> <span class=""n"">redirects</span> <span class=""n"">are</span> <span class=""n"">followed</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">fetch</span><span class=""p"">(</span><span class=""n"">req</span><span class=""p"">)</span>                  <span class=""n"">Fetch</span> <span class=""n"">a</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span> <span class=""ow"">and</span> <span class=""n"">update</span> <span class=""n"">local</span> <span class=""n"">objects</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">shelp</span><span class=""p"">()</span>           <span class=""n"">Shell</span> <span class=""n"">help</span> <span class=""p"">(</span><span class=""nb"">print</span> <span class=""n"">this</span> <span class=""n"">help</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">view</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">)</span>    <span class=""n"">View</span> <span class=""n"">response</span> <span class=""ow"">in</span> <span class=""n"">a</span> <span class=""n"">browser</span>

<span class=""o"">&gt;&gt;&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'Scrapy | A Fast and Powerful Scraping and Web Crawling Framework'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">fetch</span><span class=""p"">(</span><span class=""s2"">""https://old.reddit.com/""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//title/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'reddit: the front page of the internet'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">replace</span><span class=""p"">(</span><span class=""n"">method</span><span class=""o"">=</span><span class=""s2"">""POST""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">fetch</span><span class=""p"">(</span><span class=""n"">request</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">status</span>
<span class=""go"">404</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">pprint</span> <span class=""kn"">import</span> <span class=""n"">pprint</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">pprint</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">headers</span><span class=""p"">)</span>
<span class=""go"">{'Accept-Ranges': ['bytes'],</span>
<span class=""go""> 'Cache-Control': ['max-age=0, must-revalidate'],</span>
<span class=""go""> 'Content-Type': ['text/html; charset=UTF-8'],</span>
<span class=""go""> 'Date': ['Thu, 08 Dec 2016 16:21:19 GMT'],</span>
<span class=""go""> 'Server': ['snooserv'],</span>
<span class=""go""> 'Set-Cookie': ['loid=KqNLou0V9SKMX4qb4n; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',</span>
<span class=""go"">                'loidcreated=2016-12-08T16%3A21%3A19.445Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',</span>
<span class=""go"">                'loid=vi0ZVe4NkxNWdlH7r7; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',</span>
<span class=""go"">                'loidcreated=2016-12-08T16%3A21%3A19.459Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure'],</span>
<span class=""go""> 'Vary': ['accept-encoding'],</span>
<span class=""go""> 'Via': ['1.1 varnish'],</span>
<span class=""go""> 'X-Cache': ['MISS'],</span>
<span class=""go""> 'X-Cache-Hits': ['0'],</span>
<span class=""go""> 'X-Content-Type-Options': ['nosniff'],</span>
<span class=""go""> 'X-Frame-Options': ['SAMEORIGIN'],</span>
<span class=""go""> 'X-Moose': ['majestic'],</span>
<span class=""go""> 'X-Served-By': ['cache-cdg8730-CDG'],</span>
<span class=""go""> 'X-Timer': ['S1481214079.394283,VS0,VE159'],</span>
<span class=""go""> 'X-Ua-Compatible': ['IE=edge'],</span>
<span class=""go""> 'X-Xss-Protection': ['1; mode=block']}</span>
</pre></div>","scrapy shell 'https://scrapy.org' --nolog
,scrapy shell ""https://scrapy.org"" --nolog
,[s] Available Scrapy objects:
[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)
[s]   crawler    <scrapy.crawler.Crawler object at 0x7f07395dd690>
[s]   item       {}
[s]   request    <GET https://scrapy.org>
[s]   response   <200 https://scrapy.org/>
[s]   settings   <scrapy.settings.Settings object at 0x7f07395dd710>
[s]   spider     <DefaultSpider 'default' at 0x7f0735891690>
[s] Useful shortcuts:
[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)
[s]   fetch(req)                  Fetch a scrapy.Request and update local objects
[s]   shelp()           Shell help (print this help)
[s]   view(response)    View response in a browser

>>>
,>>> response.xpath('//title/text()').get()
'Scrapy | A Fast and Powerful Scraping and Web Crawling Framework'
,>>> fetch(""https://old.reddit.com/"")
,>>> response.xpath('//title/text()').get()
'reddit: the front page of the internet'
,>>> request = request.replace(method=""POST"")
,>>> fetch(request)
,>>> response.status
404
,>>> from pprint import pprint
,>>> pprint(response.headers)
{'Accept-Ranges': ['bytes'],
 'Cache-Control': ['max-age=0, must-revalidate'],
 'Content-Type': ['text/html; charset=UTF-8'],
 'Date': ['Thu, 08 Dec 2016 16:21:19 GMT'],
 'Server': ['snooserv'],
 'Set-Cookie': ['loid=KqNLou0V9SKMX4qb4n; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',
                'loidcreated=2016-12-08T16:21:19.445Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',
                'loid=vi0ZVe4NkxNWdlH7r7; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure',
                'loidcreated=2016-12-08T16:21:19.459Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure'],
 'Vary': ['accept-encoding'],
 'Via': ['1.1 varnish'],
 'X-Cache': ['MISS'],
 'X-Cache-Hits': ['0'],
 'X-Content-Type-Options': ['nosniff'],
 'X-Frame-Options': ['SAMEORIGIN'],
 'X-Moose': ['majestic'],
 'X-Served-By': ['cache-cdg8730-CDG'],
 'X-Timer': ['S1481214079.394283,VS0,VE159'],
 'X-Ua-Compatible': ['IE=edge'],
 'X-Xss-Protection': ['1; mode=block']}
",11
https://docs.scrapy.org/en/latest/topics/shell.html,,##,2,Invoking the shell from spiders to inspect responses,#invoking-the-shell-from-spiders-to-inspect-responses,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""myspider""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s2"">""http://example.com""</span><span class=""p"">,</span>
        <span class=""s2"">""http://example.org""</span><span class=""p"">,</span>
        <span class=""s2"">""http://example.net""</span><span class=""p"">,</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""c1""># We want to inspect one specific response.</span>
        <span class=""k"">if</span> <span class=""s2"">"".org""</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">:</span>
            <span class=""kn"">from</span> <span class=""nn"">scrapy.shell</span> <span class=""kn"">import</span> <span class=""n"">inspect_response</span>
            <span class=""n"">inspect_response</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""p"">)</span>

        <span class=""c1""># Rest of parsing code.</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">2014</span><span class=""o"">-</span><span class=""mi"">01</span><span class=""o"">-</span><span class=""mi"">23</span> <span class=""mi"">17</span><span class=""p"">:</span><span class=""mi"">48</span><span class=""p"">:</span><span class=""mi"">31</span><span class=""o"">-</span><span class=""mi"">0400</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""mi"">2014</span><span class=""o"">-</span><span class=""mi"">01</span><span class=""o"">-</span><span class=""mi"">23</span> <span class=""mi"">17</span><span class=""p"">:</span><span class=""mi"">48</span><span class=""p"">:</span><span class=""mi"">31</span><span class=""o"">-</span><span class=""mi"">0400</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">org</span><span class=""o"">&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span> <span class=""n"">Available</span> <span class=""n"">Scrapy</span> <span class=""n"">objects</span><span class=""p"">:</span>
<span class=""p"">[</span><span class=""n"">s</span><span class=""p"">]</span>   <span class=""n"">crawler</span>    <span class=""o"">&lt;</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">Crawler</span> <span class=""nb"">object</span> <span class=""n"">at</span> <span class=""mh"">0x1e16b50</span><span class=""o"">&gt;</span>
<span class=""o"">...</span>

<span class=""o"">&gt;&gt;&gt;</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span>
<span class=""s1"">'http://example.org'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//h1[@class=""fn""]'</span><span class=""p"">)</span>
<span class=""go"">[]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">view</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">)</span>
<span class=""go"">True</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""o"">^</span><span class=""n"">D</span>
<span class=""go"">2014-01-23 17:50:03-0400 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://example.net&gt; (referer: None)</span>
<span class=""gp"">...</span>
</pre></div>","import scrapy


class MySpider(scrapy.Spider):
    name = ""myspider""
    start_urls = [
        ""http://example.com"",
        ""http://example.org"",
        ""http://example.net"",
    ]

    def parse(self, response):
        # We want to inspect one specific response.
        if "".org"" in response.url:
            from scrapy.shell import inspect_response
            inspect_response(response, self)

        # Rest of parsing code.
,2014-01-23 17:48:31-0400 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://example.com> (referer: None)
2014-01-23 17:48:31-0400 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://example.org> (referer: None)
[s] Available Scrapy objects:
[s]   crawler    <scrapy.crawler.Crawler object at 0x1e16b50>
...

>>> response.url
'http://example.org'
,>>> response.xpath('//h1[@class=""fn""]')
[]
,>>> view(response)
True
,>>> ^D
2014-01-23 17:50:03-0400 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://example.net> (referer: None)
...
",5
https://docs.scrapy.org/en/latest/topics/item-pipeline.html,,#,1,Item Pipeline,#item-pipeline,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exceptions</span> <span class=""kn"">import</span> <span class=""n"">DropItem</span>
<span class=""k"">class</span> <span class=""nc"">PricePipeline</span><span class=""p"">:</span>

    <span class=""n"">vat_factor</span> <span class=""o"">=</span> <span class=""mf"">1.15</span>

    <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""k"">if</span> <span class=""n"">adapter</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'price'</span><span class=""p"">):</span>
            <span class=""k"">if</span> <span class=""n"">adapter</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'price_excludes_vat'</span><span class=""p"">):</span>
                <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'price'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'price'</span><span class=""p"">]</span> <span class=""o"">*</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">vat_factor</span>
            <span class=""k"">return</span> <span class=""n"">item</span>
        <span class=""k"">else</span><span class=""p"">:</span>
            <span class=""k"">raise</span> <span class=""n"">DropItem</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s2"">""Missing price in </span><span class=""si"">{</span><span class=""n"">item</span><span class=""si"">}</span><span class=""s2"">""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">json</span>

<span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>

<span class=""k"">class</span> <span class=""nc"">JsonWriterPipeline</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""nf"">open_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">file</span> <span class=""o"">=</span> <span class=""nb"">open</span><span class=""p"">(</span><span class=""s1"">'items.jsonl'</span><span class=""p"">,</span> <span class=""s1"">'w'</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">close_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">file</span><span class=""o"">.</span><span class=""n"">close</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">line</span> <span class=""o"">=</span> <span class=""n"">json</span><span class=""o"">.</span><span class=""n"">dumps</span><span class=""p"">(</span><span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">asdict</span><span class=""p"">())</span> <span class=""o"">+</span> <span class=""s2"">""</span><span class=""se"">\n</span><span class=""s2"">""</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">file</span><span class=""o"">.</span><span class=""n"">write</span><span class=""p"">(</span><span class=""n"">line</span><span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">pymongo</span>
<span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>

<span class=""k"">class</span> <span class=""nc"">MongoPipeline</span><span class=""p"">:</span>

    <span class=""n"">collection_name</span> <span class=""o"">=</span> <span class=""s1"">'scrapy_items'</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">mongo_uri</span><span class=""p"">,</span> <span class=""n"">mongo_db</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">mongo_uri</span> <span class=""o"">=</span> <span class=""n"">mongo_uri</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">mongo_db</span> <span class=""o"">=</span> <span class=""n"">mongo_db</span>

    <span class=""nd"">@classmethod</span>
    <span class=""k"">def</span> <span class=""nf"">from_crawler</span><span class=""p"">(</span><span class=""bp"">cls</span><span class=""p"">,</span> <span class=""n"">crawler</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""bp"">cls</span><span class=""p"">(</span>
            <span class=""n"">mongo_uri</span><span class=""o"">=</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'MONGO_URI'</span><span class=""p"">),</span>
            <span class=""n"">mongo_db</span><span class=""o"">=</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'MONGO_DATABASE'</span><span class=""p"">,</span> <span class=""s1"">'items'</span><span class=""p"">)</span>
        <span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">open_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">client</span> <span class=""o"">=</span> <span class=""n"">pymongo</span><span class=""o"">.</span><span class=""n"">MongoClient</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">mongo_uri</span><span class=""p"">)</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">db</span> <span class=""o"">=</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">client</span><span class=""p"">[</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">mongo_db</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">close_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">client</span><span class=""o"">.</span><span class=""n"">close</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">db</span><span class=""p"">[</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">collection_name</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">insert_one</span><span class=""p"">(</span><span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">asdict</span><span class=""p"">())</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">hashlib</span>
<span class=""kn"">from</span> <span class=""nn"">urllib.parse</span> <span class=""kn"">import</span> <span class=""n"">quote</span>

<span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.defer</span> <span class=""kn"">import</span> <span class=""n"">maybe_deferred_to_future</span>


<span class=""k"">class</span> <span class=""nc"">ScreenshotPipeline</span><span class=""p"">:</span>
    <span class=""sd"">""""""Pipeline that uses Splash to render screenshot of</span>
<span class=""sd"">    every Scrapy item.""""""</span>

    <span class=""n"">SPLASH_URL</span> <span class=""o"">=</span> <span class=""s2"">""http://localhost:8050/render.png?url=</span><span class=""si"">{}</span><span class=""s2"">""</span>

    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""n"">encoded_item_url</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""p"">(</span><span class=""n"">adapter</span><span class=""p"">[</span><span class=""s2"">""url""</span><span class=""p"">])</span>
        <span class=""n"">screenshot_url</span> <span class=""o"">=</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">SPLASH_URL</span><span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""n"">encoded_item_url</span><span class=""p"">)</span>
        <span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">screenshot_url</span><span class=""p"">)</span>
        <span class=""n"">response</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">maybe_deferred_to_future</span><span class=""p"">(</span><span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""o"">.</span><span class=""n"">download</span><span class=""p"">(</span><span class=""n"">request</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">))</span>

        <span class=""k"">if</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">status</span> <span class=""o"">!=</span> <span class=""mi"">200</span><span class=""p"">:</span>
            <span class=""c1""># Error happened, return item.</span>
            <span class=""k"">return</span> <span class=""n"">item</span>

        <span class=""c1""># Save screenshot to file, filename will be hash of url.</span>
        <span class=""n"">url</span> <span class=""o"">=</span> <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s2"">""url""</span><span class=""p"">]</span>
        <span class=""n"">url_hash</span> <span class=""o"">=</span> <span class=""n"">hashlib</span><span class=""o"">.</span><span class=""n"">md5</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">.</span><span class=""n"">encode</span><span class=""p"">(</span><span class=""s2"">""utf8""</span><span class=""p"">))</span><span class=""o"">.</span><span class=""n"">hexdigest</span><span class=""p"">()</span>
        <span class=""n"">filename</span> <span class=""o"">=</span> <span class=""sa"">f</span><span class=""s2"">""</span><span class=""si"">{</span><span class=""n"">url_hash</span><span class=""si"">}</span><span class=""s2"">.png""</span>
        <span class=""k"">with</span> <span class=""nb"">open</span><span class=""p"">(</span><span class=""n"">filename</span><span class=""p"">,</span> <span class=""s2"">""wb""</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">f</span><span class=""p"">:</span>
            <span class=""n"">f</span><span class=""o"">.</span><span class=""n"">write</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">body</span><span class=""p"">)</span>

        <span class=""c1""># Store filename in item.</span>
        <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s2"">""screenshot_filename""</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">filename</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exceptions</span> <span class=""kn"">import</span> <span class=""n"">DropItem</span>

<span class=""k"">class</span> <span class=""nc"">DuplicatesPipeline</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">ids_seen</span> <span class=""o"">=</span> <span class=""nb"">set</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""k"">if</span> <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">ids_seen</span><span class=""p"">:</span>
            <span class=""k"">raise</span> <span class=""n"">DropItem</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s2"">""Duplicate item found: </span><span class=""si"">{</span><span class=""n"">item</span><span class=""si"">!r}</span><span class=""s2"">""</span><span class=""p"">)</span>
        <span class=""k"">else</span><span class=""p"">:</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">ids_seen</span><span class=""o"">.</span><span class=""n"">add</span><span class=""p"">(</span><span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">])</span>
            <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">ITEM_PIPELINES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'myproject.pipelines.PricePipeline'</span><span class=""p"">:</span> <span class=""mi"">300</span><span class=""p"">,</span>
    <span class=""s1"">'myproject.pipelines.JsonWriterPipeline'</span><span class=""p"">:</span> <span class=""mi"">800</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","from itemadapter import ItemAdapter
from scrapy.exceptions import DropItem
class PricePipeline:

    vat_factor = 1.15

    def process_item(self, item, spider):
        adapter = ItemAdapter(item)
        if adapter.get('price'):
            if adapter.get('price_excludes_vat'):
                adapter['price'] = adapter['price'] * self.vat_factor
            return item
        else:
            raise DropItem(f""Missing price in {item}"")
,import json

from itemadapter import ItemAdapter

class JsonWriterPipeline:

    def open_spider(self, spider):
        self.file = open('items.jsonl', 'w')

    def close_spider(self, spider):
        self.file.close()

    def process_item(self, item, spider):
        line = json.dumps(ItemAdapter(item).asdict()) + ""\n""
        self.file.write(line)
        return item
,import pymongo
from itemadapter import ItemAdapter

class MongoPipeline:

    collection_name = 'scrapy_items'

    def __init__(self, mongo_uri, mongo_db):
        self.mongo_uri = mongo_uri
        self.mongo_db = mongo_db

    @classmethod
    def from_crawler(cls, crawler):
        return cls(
            mongo_uri=crawler.settings.get('MONGO_URI'),
            mongo_db=crawler.settings.get('MONGO_DATABASE', 'items')
        )

    def open_spider(self, spider):
        self.client = pymongo.MongoClient(self.mongo_uri)
        self.db = self.client[self.mongo_db]

    def close_spider(self, spider):
        self.client.close()

    def process_item(self, item, spider):
        self.db[self.collection_name].insert_one(ItemAdapter(item).asdict())
        return item
,import hashlib
from urllib.parse import quote

import scrapy
from itemadapter import ItemAdapter
from scrapy.utils.defer import maybe_deferred_to_future


class ScreenshotPipeline:
    """"""Pipeline that uses Splash to render screenshot of
    every Scrapy item.""""""

    SPLASH_URL = ""http://localhost:8050/render.png?url={}""

    async def process_item(self, item, spider):
        adapter = ItemAdapter(item)
        encoded_item_url = quote(adapter[""url""])
        screenshot_url = self.SPLASH_URL.format(encoded_item_url)
        request = scrapy.Request(screenshot_url)
        response = await maybe_deferred_to_future(spider.crawler.engine.download(request, spider))

        if response.status != 200:
            # Error happened, return item.
            return item

        # Save screenshot to file, filename will be hash of url.
        url = adapter[""url""]
        url_hash = hashlib.md5(url.encode(""utf8"")).hexdigest()
        filename = f""{url_hash}.png""
        with open(filename, ""wb"") as f:
            f.write(response.body)

        # Store filename in item.
        adapter[""screenshot_filename""] = filename
        return item
,from itemadapter import ItemAdapter
from scrapy.exceptions import DropItem

class DuplicatesPipeline:

    def __init__(self):
        self.ids_seen = set()

    def process_item(self, item, spider):
        adapter = ItemAdapter(item)
        if adapter['id'] in self.ids_seen:
            raise DropItem(f""Duplicate item found: {item!r}"")
        else:
            self.ids_seen.add(adapter['id'])
            return item
,ITEM_PIPELINES = {
    'myproject.pipelines.PricePipeline': 300,
    'myproject.pipelines.JsonWriterPipeline': 800,
}
",6
https://docs.scrapy.org/en/latest/topics/item-pipeline.html,,##,2,Writing your own item pipeline,#writing-your-own-item-pipeline,,,2
https://docs.scrapy.org/en/latest/topics/item-pipeline.html,,##,2,Item pipeline example,#item-pipeline-example,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exceptions</span> <span class=""kn"">import</span> <span class=""n"">DropItem</span>
<span class=""k"">class</span> <span class=""nc"">PricePipeline</span><span class=""p"">:</span>

    <span class=""n"">vat_factor</span> <span class=""o"">=</span> <span class=""mf"">1.15</span>

    <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""k"">if</span> <span class=""n"">adapter</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'price'</span><span class=""p"">):</span>
            <span class=""k"">if</span> <span class=""n"">adapter</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'price_excludes_vat'</span><span class=""p"">):</span>
                <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'price'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'price'</span><span class=""p"">]</span> <span class=""o"">*</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">vat_factor</span>
            <span class=""k"">return</span> <span class=""n"">item</span>
        <span class=""k"">else</span><span class=""p"">:</span>
            <span class=""k"">raise</span> <span class=""n"">DropItem</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s2"">""Missing price in </span><span class=""si"">{</span><span class=""n"">item</span><span class=""si"">}</span><span class=""s2"">""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">json</span>

<span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>

<span class=""k"">class</span> <span class=""nc"">JsonWriterPipeline</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""nf"">open_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">file</span> <span class=""o"">=</span> <span class=""nb"">open</span><span class=""p"">(</span><span class=""s1"">'items.jsonl'</span><span class=""p"">,</span> <span class=""s1"">'w'</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">close_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">file</span><span class=""o"">.</span><span class=""n"">close</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">line</span> <span class=""o"">=</span> <span class=""n"">json</span><span class=""o"">.</span><span class=""n"">dumps</span><span class=""p"">(</span><span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">asdict</span><span class=""p"">())</span> <span class=""o"">+</span> <span class=""s2"">""</span><span class=""se"">\n</span><span class=""s2"">""</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">file</span><span class=""o"">.</span><span class=""n"">write</span><span class=""p"">(</span><span class=""n"">line</span><span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">pymongo</span>
<span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>

<span class=""k"">class</span> <span class=""nc"">MongoPipeline</span><span class=""p"">:</span>

    <span class=""n"">collection_name</span> <span class=""o"">=</span> <span class=""s1"">'scrapy_items'</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">mongo_uri</span><span class=""p"">,</span> <span class=""n"">mongo_db</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">mongo_uri</span> <span class=""o"">=</span> <span class=""n"">mongo_uri</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">mongo_db</span> <span class=""o"">=</span> <span class=""n"">mongo_db</span>

    <span class=""nd"">@classmethod</span>
    <span class=""k"">def</span> <span class=""nf"">from_crawler</span><span class=""p"">(</span><span class=""bp"">cls</span><span class=""p"">,</span> <span class=""n"">crawler</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""bp"">cls</span><span class=""p"">(</span>
            <span class=""n"">mongo_uri</span><span class=""o"">=</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'MONGO_URI'</span><span class=""p"">),</span>
            <span class=""n"">mongo_db</span><span class=""o"">=</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'MONGO_DATABASE'</span><span class=""p"">,</span> <span class=""s1"">'items'</span><span class=""p"">)</span>
        <span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">open_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">client</span> <span class=""o"">=</span> <span class=""n"">pymongo</span><span class=""o"">.</span><span class=""n"">MongoClient</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">mongo_uri</span><span class=""p"">)</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">db</span> <span class=""o"">=</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">client</span><span class=""p"">[</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">mongo_db</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">close_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">client</span><span class=""o"">.</span><span class=""n"">close</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">db</span><span class=""p"">[</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">collection_name</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">insert_one</span><span class=""p"">(</span><span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">asdict</span><span class=""p"">())</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">hashlib</span>
<span class=""kn"">from</span> <span class=""nn"">urllib.parse</span> <span class=""kn"">import</span> <span class=""n"">quote</span>

<span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.defer</span> <span class=""kn"">import</span> <span class=""n"">maybe_deferred_to_future</span>


<span class=""k"">class</span> <span class=""nc"">ScreenshotPipeline</span><span class=""p"">:</span>
    <span class=""sd"">""""""Pipeline that uses Splash to render screenshot of</span>
<span class=""sd"">    every Scrapy item.""""""</span>

    <span class=""n"">SPLASH_URL</span> <span class=""o"">=</span> <span class=""s2"">""http://localhost:8050/render.png?url=</span><span class=""si"">{}</span><span class=""s2"">""</span>

    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""n"">encoded_item_url</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""p"">(</span><span class=""n"">adapter</span><span class=""p"">[</span><span class=""s2"">""url""</span><span class=""p"">])</span>
        <span class=""n"">screenshot_url</span> <span class=""o"">=</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">SPLASH_URL</span><span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""n"">encoded_item_url</span><span class=""p"">)</span>
        <span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">screenshot_url</span><span class=""p"">)</span>
        <span class=""n"">response</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">maybe_deferred_to_future</span><span class=""p"">(</span><span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""o"">.</span><span class=""n"">download</span><span class=""p"">(</span><span class=""n"">request</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">))</span>

        <span class=""k"">if</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">status</span> <span class=""o"">!=</span> <span class=""mi"">200</span><span class=""p"">:</span>
            <span class=""c1""># Error happened, return item.</span>
            <span class=""k"">return</span> <span class=""n"">item</span>

        <span class=""c1""># Save screenshot to file, filename will be hash of url.</span>
        <span class=""n"">url</span> <span class=""o"">=</span> <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s2"">""url""</span><span class=""p"">]</span>
        <span class=""n"">url_hash</span> <span class=""o"">=</span> <span class=""n"">hashlib</span><span class=""o"">.</span><span class=""n"">md5</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">.</span><span class=""n"">encode</span><span class=""p"">(</span><span class=""s2"">""utf8""</span><span class=""p"">))</span><span class=""o"">.</span><span class=""n"">hexdigest</span><span class=""p"">()</span>
        <span class=""n"">filename</span> <span class=""o"">=</span> <span class=""sa"">f</span><span class=""s2"">""</span><span class=""si"">{</span><span class=""n"">url_hash</span><span class=""si"">}</span><span class=""s2"">.png""</span>
        <span class=""k"">with</span> <span class=""nb"">open</span><span class=""p"">(</span><span class=""n"">filename</span><span class=""p"">,</span> <span class=""s2"">""wb""</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">f</span><span class=""p"">:</span>
            <span class=""n"">f</span><span class=""o"">.</span><span class=""n"">write</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">body</span><span class=""p"">)</span>

        <span class=""c1""># Store filename in item.</span>
        <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s2"">""screenshot_filename""</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">filename</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exceptions</span> <span class=""kn"">import</span> <span class=""n"">DropItem</span>

<span class=""k"">class</span> <span class=""nc"">DuplicatesPipeline</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">ids_seen</span> <span class=""o"">=</span> <span class=""nb"">set</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""k"">if</span> <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">ids_seen</span><span class=""p"">:</span>
            <span class=""k"">raise</span> <span class=""n"">DropItem</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s2"">""Duplicate item found: </span><span class=""si"">{</span><span class=""n"">item</span><span class=""si"">!r}</span><span class=""s2"">""</span><span class=""p"">)</span>
        <span class=""k"">else</span><span class=""p"">:</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">ids_seen</span><span class=""o"">.</span><span class=""n"">add</span><span class=""p"">(</span><span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">])</span>
            <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>","from itemadapter import ItemAdapter
from scrapy.exceptions import DropItem
class PricePipeline:

    vat_factor = 1.15

    def process_item(self, item, spider):
        adapter = ItemAdapter(item)
        if adapter.get('price'):
            if adapter.get('price_excludes_vat'):
                adapter['price'] = adapter['price'] * self.vat_factor
            return item
        else:
            raise DropItem(f""Missing price in {item}"")
,import json

from itemadapter import ItemAdapter

class JsonWriterPipeline:

    def open_spider(self, spider):
        self.file = open('items.jsonl', 'w')

    def close_spider(self, spider):
        self.file.close()

    def process_item(self, item, spider):
        line = json.dumps(ItemAdapter(item).asdict()) + ""\n""
        self.file.write(line)
        return item
,import pymongo
from itemadapter import ItemAdapter

class MongoPipeline:

    collection_name = 'scrapy_items'

    def __init__(self, mongo_uri, mongo_db):
        self.mongo_uri = mongo_uri
        self.mongo_db = mongo_db

    @classmethod
    def from_crawler(cls, crawler):
        return cls(
            mongo_uri=crawler.settings.get('MONGO_URI'),
            mongo_db=crawler.settings.get('MONGO_DATABASE', 'items')
        )

    def open_spider(self, spider):
        self.client = pymongo.MongoClient(self.mongo_uri)
        self.db = self.client[self.mongo_db]

    def close_spider(self, spider):
        self.client.close()

    def process_item(self, item, spider):
        self.db[self.collection_name].insert_one(ItemAdapter(item).asdict())
        return item
,import hashlib
from urllib.parse import quote

import scrapy
from itemadapter import ItemAdapter
from scrapy.utils.defer import maybe_deferred_to_future


class ScreenshotPipeline:
    """"""Pipeline that uses Splash to render screenshot of
    every Scrapy item.""""""

    SPLASH_URL = ""http://localhost:8050/render.png?url={}""

    async def process_item(self, item, spider):
        adapter = ItemAdapter(item)
        encoded_item_url = quote(adapter[""url""])
        screenshot_url = self.SPLASH_URL.format(encoded_item_url)
        request = scrapy.Request(screenshot_url)
        response = await maybe_deferred_to_future(spider.crawler.engine.download(request, spider))

        if response.status != 200:
            # Error happened, return item.
            return item

        # Save screenshot to file, filename will be hash of url.
        url = adapter[""url""]
        url_hash = hashlib.md5(url.encode(""utf8"")).hexdigest()
        filename = f""{url_hash}.png""
        with open(filename, ""wb"") as f:
            f.write(response.body)

        # Store filename in item.
        adapter[""screenshot_filename""] = filename
        return item
,from itemadapter import ItemAdapter
from scrapy.exceptions import DropItem

class DuplicatesPipeline:

    def __init__(self):
        self.ids_seen = set()

    def process_item(self, item, spider):
        adapter = ItemAdapter(item)
        if adapter['id'] in self.ids_seen:
            raise DropItem(f""Duplicate item found: {item!r}"")
        else:
            self.ids_seen.add(adapter['id'])
            return item
",5
https://docs.scrapy.org/en/latest/topics/item-pipeline.html,,###,3,Price validation and dropping items with no prices,#price-validation-and-dropping-items-with-no-prices,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exceptions</span> <span class=""kn"">import</span> <span class=""n"">DropItem</span>
<span class=""k"">class</span> <span class=""nc"">PricePipeline</span><span class=""p"">:</span>

    <span class=""n"">vat_factor</span> <span class=""o"">=</span> <span class=""mf"">1.15</span>

    <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""k"">if</span> <span class=""n"">adapter</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'price'</span><span class=""p"">):</span>
            <span class=""k"">if</span> <span class=""n"">adapter</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'price_excludes_vat'</span><span class=""p"">):</span>
                <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'price'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'price'</span><span class=""p"">]</span> <span class=""o"">*</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">vat_factor</span>
            <span class=""k"">return</span> <span class=""n"">item</span>
        <span class=""k"">else</span><span class=""p"">:</span>
            <span class=""k"">raise</span> <span class=""n"">DropItem</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s2"">""Missing price in </span><span class=""si"">{</span><span class=""n"">item</span><span class=""si"">}</span><span class=""s2"">""</span><span class=""p"">)</span>
</pre></div>","from itemadapter import ItemAdapter
from scrapy.exceptions import DropItem
class PricePipeline:

    vat_factor = 1.15

    def process_item(self, item, spider):
        adapter = ItemAdapter(item)
        if adapter.get('price'):
            if adapter.get('price_excludes_vat'):
                adapter['price'] = adapter['price'] * self.vat_factor
            return item
        else:
            raise DropItem(f""Missing price in {item}"")
",1
https://docs.scrapy.org/en/latest/topics/item-pipeline.html,,###,3,Write items to a JSON lines file,#write-items-to-a-json-lines-file,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">json</span>

<span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>

<span class=""k"">class</span> <span class=""nc"">JsonWriterPipeline</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""nf"">open_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">file</span> <span class=""o"">=</span> <span class=""nb"">open</span><span class=""p"">(</span><span class=""s1"">'items.jsonl'</span><span class=""p"">,</span> <span class=""s1"">'w'</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">close_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">file</span><span class=""o"">.</span><span class=""n"">close</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">line</span> <span class=""o"">=</span> <span class=""n"">json</span><span class=""o"">.</span><span class=""n"">dumps</span><span class=""p"">(</span><span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">asdict</span><span class=""p"">())</span> <span class=""o"">+</span> <span class=""s2"">""</span><span class=""se"">\n</span><span class=""s2"">""</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">file</span><span class=""o"">.</span><span class=""n"">write</span><span class=""p"">(</span><span class=""n"">line</span><span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>","import json

from itemadapter import ItemAdapter

class JsonWriterPipeline:

    def open_spider(self, spider):
        self.file = open('items.jsonl', 'w')

    def close_spider(self, spider):
        self.file.close()

    def process_item(self, item, spider):
        line = json.dumps(ItemAdapter(item).asdict()) + ""\n""
        self.file.write(line)
        return item
",1
https://docs.scrapy.org/en/latest/topics/item-pipeline.html,,###,3,Write items to MongoDB,#write-items-to-mongodb,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">pymongo</span>
<span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>

<span class=""k"">class</span> <span class=""nc"">MongoPipeline</span><span class=""p"">:</span>

    <span class=""n"">collection_name</span> <span class=""o"">=</span> <span class=""s1"">'scrapy_items'</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">mongo_uri</span><span class=""p"">,</span> <span class=""n"">mongo_db</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">mongo_uri</span> <span class=""o"">=</span> <span class=""n"">mongo_uri</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">mongo_db</span> <span class=""o"">=</span> <span class=""n"">mongo_db</span>

    <span class=""nd"">@classmethod</span>
    <span class=""k"">def</span> <span class=""nf"">from_crawler</span><span class=""p"">(</span><span class=""bp"">cls</span><span class=""p"">,</span> <span class=""n"">crawler</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""bp"">cls</span><span class=""p"">(</span>
            <span class=""n"">mongo_uri</span><span class=""o"">=</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'MONGO_URI'</span><span class=""p"">),</span>
            <span class=""n"">mongo_db</span><span class=""o"">=</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'MONGO_DATABASE'</span><span class=""p"">,</span> <span class=""s1"">'items'</span><span class=""p"">)</span>
        <span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">open_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">client</span> <span class=""o"">=</span> <span class=""n"">pymongo</span><span class=""o"">.</span><span class=""n"">MongoClient</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">mongo_uri</span><span class=""p"">)</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">db</span> <span class=""o"">=</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">client</span><span class=""p"">[</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">mongo_db</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">close_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">client</span><span class=""o"">.</span><span class=""n"">close</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">db</span><span class=""p"">[</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">collection_name</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">insert_one</span><span class=""p"">(</span><span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">asdict</span><span class=""p"">())</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>","import pymongo
from itemadapter import ItemAdapter

class MongoPipeline:

    collection_name = 'scrapy_items'

    def __init__(self, mongo_uri, mongo_db):
        self.mongo_uri = mongo_uri
        self.mongo_db = mongo_db

    @classmethod
    def from_crawler(cls, crawler):
        return cls(
            mongo_uri=crawler.settings.get('MONGO_URI'),
            mongo_db=crawler.settings.get('MONGO_DATABASE', 'items')
        )

    def open_spider(self, spider):
        self.client = pymongo.MongoClient(self.mongo_uri)
        self.db = self.client[self.mongo_db]

    def close_spider(self, spider):
        self.client.close()

    def process_item(self, item, spider):
        self.db[self.collection_name].insert_one(ItemAdapter(item).asdict())
        return item
",1
https://docs.scrapy.org/en/latest/topics/item-pipeline.html,,###,3,Take screenshot of item,#take-screenshot-of-item,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">hashlib</span>
<span class=""kn"">from</span> <span class=""nn"">urllib.parse</span> <span class=""kn"">import</span> <span class=""n"">quote</span>

<span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.defer</span> <span class=""kn"">import</span> <span class=""n"">maybe_deferred_to_future</span>


<span class=""k"">class</span> <span class=""nc"">ScreenshotPipeline</span><span class=""p"">:</span>
    <span class=""sd"">""""""Pipeline that uses Splash to render screenshot of</span>
<span class=""sd"">    every Scrapy item.""""""</span>

    <span class=""n"">SPLASH_URL</span> <span class=""o"">=</span> <span class=""s2"">""http://localhost:8050/render.png?url=</span><span class=""si"">{}</span><span class=""s2"">""</span>

    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""n"">encoded_item_url</span> <span class=""o"">=</span> <span class=""n"">quote</span><span class=""p"">(</span><span class=""n"">adapter</span><span class=""p"">[</span><span class=""s2"">""url""</span><span class=""p"">])</span>
        <span class=""n"">screenshot_url</span> <span class=""o"">=</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">SPLASH_URL</span><span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""n"">encoded_item_url</span><span class=""p"">)</span>
        <span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">screenshot_url</span><span class=""p"">)</span>
        <span class=""n"">response</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">maybe_deferred_to_future</span><span class=""p"">(</span><span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""o"">.</span><span class=""n"">download</span><span class=""p"">(</span><span class=""n"">request</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">))</span>

        <span class=""k"">if</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">status</span> <span class=""o"">!=</span> <span class=""mi"">200</span><span class=""p"">:</span>
            <span class=""c1""># Error happened, return item.</span>
            <span class=""k"">return</span> <span class=""n"">item</span>

        <span class=""c1""># Save screenshot to file, filename will be hash of url.</span>
        <span class=""n"">url</span> <span class=""o"">=</span> <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s2"">""url""</span><span class=""p"">]</span>
        <span class=""n"">url_hash</span> <span class=""o"">=</span> <span class=""n"">hashlib</span><span class=""o"">.</span><span class=""n"">md5</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">.</span><span class=""n"">encode</span><span class=""p"">(</span><span class=""s2"">""utf8""</span><span class=""p"">))</span><span class=""o"">.</span><span class=""n"">hexdigest</span><span class=""p"">()</span>
        <span class=""n"">filename</span> <span class=""o"">=</span> <span class=""sa"">f</span><span class=""s2"">""</span><span class=""si"">{</span><span class=""n"">url_hash</span><span class=""si"">}</span><span class=""s2"">.png""</span>
        <span class=""k"">with</span> <span class=""nb"">open</span><span class=""p"">(</span><span class=""n"">filename</span><span class=""p"">,</span> <span class=""s2"">""wb""</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">f</span><span class=""p"">:</span>
            <span class=""n"">f</span><span class=""o"">.</span><span class=""n"">write</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">body</span><span class=""p"">)</span>

        <span class=""c1""># Store filename in item.</span>
        <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s2"">""screenshot_filename""</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">filename</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>","import hashlib
from urllib.parse import quote

import scrapy
from itemadapter import ItemAdapter
from scrapy.utils.defer import maybe_deferred_to_future


class ScreenshotPipeline:
    """"""Pipeline that uses Splash to render screenshot of
    every Scrapy item.""""""

    SPLASH_URL = ""http://localhost:8050/render.png?url={}""

    async def process_item(self, item, spider):
        adapter = ItemAdapter(item)
        encoded_item_url = quote(adapter[""url""])
        screenshot_url = self.SPLASH_URL.format(encoded_item_url)
        request = scrapy.Request(screenshot_url)
        response = await maybe_deferred_to_future(spider.crawler.engine.download(request, spider))

        if response.status != 200:
            # Error happened, return item.
            return item

        # Save screenshot to file, filename will be hash of url.
        url = adapter[""url""]
        url_hash = hashlib.md5(url.encode(""utf8"")).hexdigest()
        filename = f""{url_hash}.png""
        with open(filename, ""wb"") as f:
            f.write(response.body)

        # Store filename in item.
        adapter[""screenshot_filename""] = filename
        return item
",1
https://docs.scrapy.org/en/latest/topics/item-pipeline.html,,###,3,Duplicates filter,#duplicates-filter,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exceptions</span> <span class=""kn"">import</span> <span class=""n"">DropItem</span>

<span class=""k"">class</span> <span class=""nc"">DuplicatesPipeline</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">ids_seen</span> <span class=""o"">=</span> <span class=""nb"">set</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""k"">if</span> <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">]</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">ids_seen</span><span class=""p"">:</span>
            <span class=""k"">raise</span> <span class=""n"">DropItem</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s2"">""Duplicate item found: </span><span class=""si"">{</span><span class=""n"">item</span><span class=""si"">!r}</span><span class=""s2"">""</span><span class=""p"">)</span>
        <span class=""k"">else</span><span class=""p"">:</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">ids_seen</span><span class=""o"">.</span><span class=""n"">add</span><span class=""p"">(</span><span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">])</span>
            <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>","from itemadapter import ItemAdapter
from scrapy.exceptions import DropItem

class DuplicatesPipeline:

    def __init__(self):
        self.ids_seen = set()

    def process_item(self, item, spider):
        adapter = ItemAdapter(item)
        if adapter['id'] in self.ids_seen:
            raise DropItem(f""Duplicate item found: {item!r}"")
        else:
            self.ids_seen.add(adapter['id'])
            return item
",1
https://docs.scrapy.org/en/latest/topics/item-pipeline.html,,##,2,Activating an Item Pipeline component,#activating-an-item-pipeline-component,"<div class=""highlight""><pre><span></span><span class=""n"">ITEM_PIPELINES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'myproject.pipelines.PricePipeline'</span><span class=""p"">:</span> <span class=""mi"">300</span><span class=""p"">,</span>
    <span class=""s1"">'myproject.pipelines.JsonWriterPipeline'</span><span class=""p"">:</span> <span class=""mi"">800</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","ITEM_PIPELINES = {
    'myproject.pipelines.PricePipeline': 300,
    'myproject.pipelines.JsonWriterPipeline': 800,
}
",1
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,#,1,Feed exports,#feed-exports,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MyCustomFilter</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">feed_options</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">feed_options</span> <span class=""o"">=</span> <span class=""n"">feed_options</span>

    <span class=""k"">def</span> <span class=""nf"">accepts</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""s2"">""field1""</span> <span class=""ow"">in</span> <span class=""n"">item</span> <span class=""ow"">and</span> <span class=""n"">item</span><span class=""p"">[</span><span class=""s2"">""field1""</span><span class=""p"">]</span> <span class=""o"">==</span> <span class=""s2"">""expected_data""</span><span class=""p"">:</span>
            <span class=""k"">return</span> <span class=""kc"">True</span>
        <span class=""k"">return</span> <span class=""kc"">False</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'items.json'</span><span class=""p"">:</span> <span class=""p"">{</span>
        <span class=""s1"">'format'</span><span class=""p"">:</span> <span class=""s1"">'json'</span><span class=""p"">,</span>
        <span class=""s1"">'encoding'</span><span class=""p"">:</span> <span class=""s1"">'utf8'</span><span class=""p"">,</span>
        <span class=""s1"">'store_empty'</span><span class=""p"">:</span> <span class=""kc"">False</span><span class=""p"">,</span>
        <span class=""s1"">'item_classes'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""n"">MyItemClass1</span><span class=""p"">,</span> <span class=""s1"">'myproject.items.MyItemClass2'</span><span class=""p"">],</span>
        <span class=""s1"">'fields'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
        <span class=""s1"">'indent'</span><span class=""p"">:</span> <span class=""mi"">4</span><span class=""p"">,</span>
        <span class=""s1"">'item_export_kwargs'</span><span class=""p"">:</span> <span class=""p"">{</span>
           <span class=""s1"">'export_empty_fields'</span><span class=""p"">:</span> <span class=""kc"">True</span><span class=""p"">,</span>
        <span class=""p"">},</span>
    <span class=""p"">},</span>
    <span class=""s1"">'/home/user/documents/items.xml'</span><span class=""p"">:</span> <span class=""p"">{</span>
        <span class=""s1"">'format'</span><span class=""p"">:</span> <span class=""s1"">'xml'</span><span class=""p"">,</span>
        <span class=""s1"">'fields'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'price'</span><span class=""p"">],</span>
        <span class=""s1"">'item_filter'</span><span class=""p"">:</span> <span class=""n"">MyCustomFilter1</span><span class=""p"">,</span>
        <span class=""s1"">'encoding'</span><span class=""p"">:</span> <span class=""s1"">'latin1'</span><span class=""p"">,</span>
        <span class=""s1"">'indent'</span><span class=""p"">:</span> <span class=""mi"">8</span><span class=""p"">,</span>
    <span class=""p"">},</span>
    <span class=""n"">pathlib</span><span class=""o"">.</span><span class=""n"">Path</span><span class=""p"">(</span><span class=""s1"">'items.csv.gz'</span><span class=""p"">):</span> <span class=""p"">{</span>
        <span class=""s1"">'format'</span><span class=""p"">:</span> <span class=""s1"">'csv'</span><span class=""p"">,</span>
        <span class=""s1"">'fields'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""s1"">'price'</span><span class=""p"">,</span> <span class=""s1"">'name'</span><span class=""p"">],</span>
        <span class=""s1"">'item_filter'</span><span class=""p"">:</span> <span class=""s1"">'myproject.filters.MyCustomFilter2'</span><span class=""p"">,</span>
        <span class=""s1"">'postprocessing'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""n"">MyPlugin1</span><span class=""p"">,</span> <span class=""s1"">'scrapy.extensions.postprocessing.GzipPlugin'</span><span class=""p"">],</span>
        <span class=""s1"">'gzip_compresslevel'</span><span class=""p"">:</span> <span class=""mi"">5</span><span class=""p"">,</span>
    <span class=""p"">},</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">''</span><span class=""p"">:</span> <span class=""s1"">'scrapy.extensions.feedexport.FileFeedStorage'</span><span class=""p"">,</span>
    <span class=""s1"">'file'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.extensions.feedexport.FileFeedStorage'</span><span class=""p"">,</span>
    <span class=""s1"">'stdout'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.extensions.feedexport.StdoutFeedStorage'</span><span class=""p"">,</span>
    <span class=""s1"">'s3'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.extensions.feedexport.S3FeedStorage'</span><span class=""p"">,</span>
    <span class=""s1"">'ftp'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.extensions.feedexport.FTPFeedStorage'</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">FEED_STORAGES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'ftp'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'json'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.JsonItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'jsonlines'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.JsonLinesItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'jsonl'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.JsonLinesItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'jl'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.JsonLinesItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'csv'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.CsvItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'xml'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.XmlItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'marshal'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.MarshalItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'pickle'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.PickleItemExporter'</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">FEED_EXPORTERS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'csv'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">FEED_EXPORT_BATCH_ITEM_COUNT</span> <span class=""o"">=</span> <span class=""mi"">100</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">spidername</span> <span class=""o"">-</span><span class=""n"">o</span> <span class=""s2"">""dirname/</span><span class=""si"">%(batch_id)d</span><span class=""s2"">-filename</span><span class=""si"">%(batch_time)s</span><span class=""s2"">.json""</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">-&gt;</span><span class=""n"">projectname</span>
<span class=""o"">--&gt;</span><span class=""n"">dirname</span>
<span class=""o"">---&gt;</span><span class=""mi"">1</span><span class=""o"">-</span><span class=""n"">filename2020</span><span class=""o"">-</span><span class=""mi"">03</span><span class=""o"">-</span><span class=""mi"">28</span><span class=""n"">T14</span><span class=""o"">-</span><span class=""mi"">45</span><span class=""o"">-</span><span class=""mf"">08.237134</span><span class=""o"">.</span><span class=""n"">json</span>
<span class=""o"">---&gt;</span><span class=""mi"">2</span><span class=""o"">-</span><span class=""n"">filename2020</span><span class=""o"">-</span><span class=""mi"">03</span><span class=""o"">-</span><span class=""mi"">28</span><span class=""n"">T14</span><span class=""o"">-</span><span class=""mi"">45</span><span class=""o"">-</span><span class=""mf"">09.148903</span><span class=""o"">.</span><span class=""n"">json</span>
<span class=""o"">---&gt;</span><span class=""mi"">3</span><span class=""o"">-</span><span class=""n"">filename2020</span><span class=""o"">-</span><span class=""mi"">03</span><span class=""o"">-</span><span class=""mi"">28</span><span class=""n"">T14</span><span class=""o"">-</span><span class=""mi"">45</span><span class=""o"">-</span><span class=""mf"">10.046092</span><span class=""o"">.</span><span class=""n"">json</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># myproject/utils.py</span>
<span class=""k"">def</span> <span class=""nf"">uri_params</span><span class=""p"">(</span><span class=""n"">params</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
    <span class=""k"">return</span> <span class=""p"">{</span><span class=""o"">**</span><span class=""n"">params</span><span class=""p"">,</span> <span class=""s1"">'spider_name'</span><span class=""p"">:</span> <span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">name</span><span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># myproject/settings.py</span>
<span class=""n"">FEED_URI_PARAMS</span> <span class=""o"">=</span> <span class=""s1"">'myproject.utils.uri_params'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""o"">&lt;</span><span class=""n"">spider_name</span><span class=""o"">&gt;</span> <span class=""o"">-</span><span class=""n"">o</span> <span class=""s2"">""</span><span class=""si"">%(spider_name)s</span><span class=""s2"">.jsonl""</span>
</pre></div>","class MyCustomFilter:

    def __init__(self, feed_options):
        self.feed_options = feed_options

    def accepts(self, item):
        if ""field1"" in item and item[""field1""] == ""expected_data"":
            return True
        return False
,{
    'items.json': {
        'format': 'json',
        'encoding': 'utf8',
        'store_empty': False,
        'item_classes': [MyItemClass1, 'myproject.items.MyItemClass2'],
        'fields': None,
        'indent': 4,
        'item_export_kwargs': {
           'export_empty_fields': True,
        },
    },
    '/home/user/documents/items.xml': {
        'format': 'xml',
        'fields': ['name', 'price'],
        'item_filter': MyCustomFilter1,
        'encoding': 'latin1',
        'indent': 8,
    },
    pathlib.Path('items.csv.gz'): {
        'format': 'csv',
        'fields': ['price', 'name'],
        'item_filter': 'myproject.filters.MyCustomFilter2',
        'postprocessing': [MyPlugin1, 'scrapy.extensions.postprocessing.GzipPlugin'],
        'gzip_compresslevel': 5,
    },
}
,{
    '': 'scrapy.extensions.feedexport.FileFeedStorage',
    'file': 'scrapy.extensions.feedexport.FileFeedStorage',
    'stdout': 'scrapy.extensions.feedexport.StdoutFeedStorage',
    's3': 'scrapy.extensions.feedexport.S3FeedStorage',
    'ftp': 'scrapy.extensions.feedexport.FTPFeedStorage',
}
,FEED_STORAGES = {
    'ftp': None,
}
,{
    'json': 'scrapy.exporters.JsonItemExporter',
    'jsonlines': 'scrapy.exporters.JsonLinesItemExporter',
    'jsonl': 'scrapy.exporters.JsonLinesItemExporter',
    'jl': 'scrapy.exporters.JsonLinesItemExporter',
    'csv': 'scrapy.exporters.CsvItemExporter',
    'xml': 'scrapy.exporters.XmlItemExporter',
    'marshal': 'scrapy.exporters.MarshalItemExporter',
    'pickle': 'scrapy.exporters.PickleItemExporter',
}
,FEED_EXPORTERS = {
    'csv': None,
}
,FEED_EXPORT_BATCH_ITEM_COUNT = 100
,scrapy crawl spidername -o ""dirname/%(batch_id)d-filename%(batch_time)s.json""
,->projectname
-->dirname
--->1-filename2020-03-28T14-45-08.237134.json
--->2-filename2020-03-28T14-45-09.148903.json
--->3-filename2020-03-28T14-45-10.046092.json
,# myproject/utils.py
def uri_params(params, spider):
    return {**params, 'spider_name': spider.name}
,# myproject/settings.py
FEED_URI_PARAMS = 'myproject.utils.uri_params'
,scrapy crawl <spider_name> -o ""%(spider_name)s.jsonl""
",12
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,##,2,Serialization formats,#serialization-formats,,,2
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,JSON,#json,,,3
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,JSON lines,#json-lines,,,4
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,CSV,#csv,,,5
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,XML,#xml,,,6
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,Pickle,#pickle,,,7
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,Marshal,#marshal,,,8
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,##,2,Storages,#storages,,,9
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,##,2,Storage URI parameters,#storage-uri-parameters,,,10
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,##,2,Storage backends,#storage-backends,,,11
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,Local filesystem,#local-filesystem,,,12
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,FTP,#ftp,,,13
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,S3,#s3,,,14
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,Google Cloud Storage (GCS),#google-cloud-storage-gcs,,,15
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,Standard output,#standard-output,,,16
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,Delayed file delivery,#delayed-file-delivery,,,17
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,##,2,Item filtering,#item-filtering,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MyCustomFilter</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">feed_options</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">feed_options</span> <span class=""o"">=</span> <span class=""n"">feed_options</span>

    <span class=""k"">def</span> <span class=""nf"">accepts</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""s2"">""field1""</span> <span class=""ow"">in</span> <span class=""n"">item</span> <span class=""ow"">and</span> <span class=""n"">item</span><span class=""p"">[</span><span class=""s2"">""field1""</span><span class=""p"">]</span> <span class=""o"">==</span> <span class=""s2"">""expected_data""</span><span class=""p"">:</span>
            <span class=""k"">return</span> <span class=""kc"">True</span>
        <span class=""k"">return</span> <span class=""kc"">False</span>
</pre></div>","class MyCustomFilter:

    def __init__(self, feed_options):
        self.feed_options = feed_options

    def accepts(self, item):
        if ""field1"" in item and item[""field1""] == ""expected_data"":
            return True
        return False
",1
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,ItemFilter,#itemfilter,,,19
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,##,2,Post-Processing,#post-processing,,,20
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,Built-in Plugins,#built-in-plugins,,,21
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,Custom Plugins,#custom-plugins,,,22
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,##,2,Settings,#settings,"<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'items.json'</span><span class=""p"">:</span> <span class=""p"">{</span>
        <span class=""s1"">'format'</span><span class=""p"">:</span> <span class=""s1"">'json'</span><span class=""p"">,</span>
        <span class=""s1"">'encoding'</span><span class=""p"">:</span> <span class=""s1"">'utf8'</span><span class=""p"">,</span>
        <span class=""s1"">'store_empty'</span><span class=""p"">:</span> <span class=""kc"">False</span><span class=""p"">,</span>
        <span class=""s1"">'item_classes'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""n"">MyItemClass1</span><span class=""p"">,</span> <span class=""s1"">'myproject.items.MyItemClass2'</span><span class=""p"">],</span>
        <span class=""s1"">'fields'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
        <span class=""s1"">'indent'</span><span class=""p"">:</span> <span class=""mi"">4</span><span class=""p"">,</span>
        <span class=""s1"">'item_export_kwargs'</span><span class=""p"">:</span> <span class=""p"">{</span>
           <span class=""s1"">'export_empty_fields'</span><span class=""p"">:</span> <span class=""kc"">True</span><span class=""p"">,</span>
        <span class=""p"">},</span>
    <span class=""p"">},</span>
    <span class=""s1"">'/home/user/documents/items.xml'</span><span class=""p"">:</span> <span class=""p"">{</span>
        <span class=""s1"">'format'</span><span class=""p"">:</span> <span class=""s1"">'xml'</span><span class=""p"">,</span>
        <span class=""s1"">'fields'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'price'</span><span class=""p"">],</span>
        <span class=""s1"">'item_filter'</span><span class=""p"">:</span> <span class=""n"">MyCustomFilter1</span><span class=""p"">,</span>
        <span class=""s1"">'encoding'</span><span class=""p"">:</span> <span class=""s1"">'latin1'</span><span class=""p"">,</span>
        <span class=""s1"">'indent'</span><span class=""p"">:</span> <span class=""mi"">8</span><span class=""p"">,</span>
    <span class=""p"">},</span>
    <span class=""n"">pathlib</span><span class=""o"">.</span><span class=""n"">Path</span><span class=""p"">(</span><span class=""s1"">'items.csv.gz'</span><span class=""p"">):</span> <span class=""p"">{</span>
        <span class=""s1"">'format'</span><span class=""p"">:</span> <span class=""s1"">'csv'</span><span class=""p"">,</span>
        <span class=""s1"">'fields'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""s1"">'price'</span><span class=""p"">,</span> <span class=""s1"">'name'</span><span class=""p"">],</span>
        <span class=""s1"">'item_filter'</span><span class=""p"">:</span> <span class=""s1"">'myproject.filters.MyCustomFilter2'</span><span class=""p"">,</span>
        <span class=""s1"">'postprocessing'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""n"">MyPlugin1</span><span class=""p"">,</span> <span class=""s1"">'scrapy.extensions.postprocessing.GzipPlugin'</span><span class=""p"">],</span>
        <span class=""s1"">'gzip_compresslevel'</span><span class=""p"">:</span> <span class=""mi"">5</span><span class=""p"">,</span>
    <span class=""p"">},</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">''</span><span class=""p"">:</span> <span class=""s1"">'scrapy.extensions.feedexport.FileFeedStorage'</span><span class=""p"">,</span>
    <span class=""s1"">'file'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.extensions.feedexport.FileFeedStorage'</span><span class=""p"">,</span>
    <span class=""s1"">'stdout'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.extensions.feedexport.StdoutFeedStorage'</span><span class=""p"">,</span>
    <span class=""s1"">'s3'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.extensions.feedexport.S3FeedStorage'</span><span class=""p"">,</span>
    <span class=""s1"">'ftp'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.extensions.feedexport.FTPFeedStorage'</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">FEED_STORAGES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'ftp'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'json'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.JsonItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'jsonlines'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.JsonLinesItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'jsonl'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.JsonLinesItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'jl'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.JsonLinesItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'csv'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.CsvItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'xml'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.XmlItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'marshal'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.MarshalItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'pickle'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.PickleItemExporter'</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">FEED_EXPORTERS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'csv'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">FEED_EXPORT_BATCH_ITEM_COUNT</span> <span class=""o"">=</span> <span class=""mi"">100</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">spidername</span> <span class=""o"">-</span><span class=""n"">o</span> <span class=""s2"">""dirname/</span><span class=""si"">%(batch_id)d</span><span class=""s2"">-filename</span><span class=""si"">%(batch_time)s</span><span class=""s2"">.json""</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">-&gt;</span><span class=""n"">projectname</span>
<span class=""o"">--&gt;</span><span class=""n"">dirname</span>
<span class=""o"">---&gt;</span><span class=""mi"">1</span><span class=""o"">-</span><span class=""n"">filename2020</span><span class=""o"">-</span><span class=""mi"">03</span><span class=""o"">-</span><span class=""mi"">28</span><span class=""n"">T14</span><span class=""o"">-</span><span class=""mi"">45</span><span class=""o"">-</span><span class=""mf"">08.237134</span><span class=""o"">.</span><span class=""n"">json</span>
<span class=""o"">---&gt;</span><span class=""mi"">2</span><span class=""o"">-</span><span class=""n"">filename2020</span><span class=""o"">-</span><span class=""mi"">03</span><span class=""o"">-</span><span class=""mi"">28</span><span class=""n"">T14</span><span class=""o"">-</span><span class=""mi"">45</span><span class=""o"">-</span><span class=""mf"">09.148903</span><span class=""o"">.</span><span class=""n"">json</span>
<span class=""o"">---&gt;</span><span class=""mi"">3</span><span class=""o"">-</span><span class=""n"">filename2020</span><span class=""o"">-</span><span class=""mi"">03</span><span class=""o"">-</span><span class=""mi"">28</span><span class=""n"">T14</span><span class=""o"">-</span><span class=""mi"">45</span><span class=""o"">-</span><span class=""mf"">10.046092</span><span class=""o"">.</span><span class=""n"">json</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># myproject/utils.py</span>
<span class=""k"">def</span> <span class=""nf"">uri_params</span><span class=""p"">(</span><span class=""n"">params</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
    <span class=""k"">return</span> <span class=""p"">{</span><span class=""o"">**</span><span class=""n"">params</span><span class=""p"">,</span> <span class=""s1"">'spider_name'</span><span class=""p"">:</span> <span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">name</span><span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># myproject/settings.py</span>
<span class=""n"">FEED_URI_PARAMS</span> <span class=""o"">=</span> <span class=""s1"">'myproject.utils.uri_params'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""o"">&lt;</span><span class=""n"">spider_name</span><span class=""o"">&gt;</span> <span class=""o"">-</span><span class=""n"">o</span> <span class=""s2"">""</span><span class=""si"">%(spider_name)s</span><span class=""s2"">.jsonl""</span>
</pre></div>","{
    'items.json': {
        'format': 'json',
        'encoding': 'utf8',
        'store_empty': False,
        'item_classes': [MyItemClass1, 'myproject.items.MyItemClass2'],
        'fields': None,
        'indent': 4,
        'item_export_kwargs': {
           'export_empty_fields': True,
        },
    },
    '/home/user/documents/items.xml': {
        'format': 'xml',
        'fields': ['name', 'price'],
        'item_filter': MyCustomFilter1,
        'encoding': 'latin1',
        'indent': 8,
    },
    pathlib.Path('items.csv.gz'): {
        'format': 'csv',
        'fields': ['price', 'name'],
        'item_filter': 'myproject.filters.MyCustomFilter2',
        'postprocessing': [MyPlugin1, 'scrapy.extensions.postprocessing.GzipPlugin'],
        'gzip_compresslevel': 5,
    },
}
,{
    '': 'scrapy.extensions.feedexport.FileFeedStorage',
    'file': 'scrapy.extensions.feedexport.FileFeedStorage',
    'stdout': 'scrapy.extensions.feedexport.StdoutFeedStorage',
    's3': 'scrapy.extensions.feedexport.S3FeedStorage',
    'ftp': 'scrapy.extensions.feedexport.FTPFeedStorage',
}
,FEED_STORAGES = {
    'ftp': None,
}
,{
    'json': 'scrapy.exporters.JsonItemExporter',
    'jsonlines': 'scrapy.exporters.JsonLinesItemExporter',
    'jsonl': 'scrapy.exporters.JsonLinesItemExporter',
    'jl': 'scrapy.exporters.JsonLinesItemExporter',
    'csv': 'scrapy.exporters.CsvItemExporter',
    'xml': 'scrapy.exporters.XmlItemExporter',
    'marshal': 'scrapy.exporters.MarshalItemExporter',
    'pickle': 'scrapy.exporters.PickleItemExporter',
}
,FEED_EXPORTERS = {
    'csv': None,
}
,FEED_EXPORT_BATCH_ITEM_COUNT = 100
,scrapy crawl spidername -o ""dirname/%(batch_id)d-filename%(batch_time)s.json""
,->projectname
-->dirname
--->1-filename2020-03-28T14-45-08.237134.json
--->2-filename2020-03-28T14-45-09.148903.json
--->3-filename2020-03-28T14-45-10.046092.json
,# myproject/utils.py
def uri_params(params, spider):
    return {**params, 'spider_name': spider.name}
,# myproject/settings.py
FEED_URI_PARAMS = 'myproject.utils.uri_params'
,scrapy crawl <spider_name> -o ""%(spider_name)s.jsonl""
",11
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,FEEDS,#feeds,"<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'items.json'</span><span class=""p"">:</span> <span class=""p"">{</span>
        <span class=""s1"">'format'</span><span class=""p"">:</span> <span class=""s1"">'json'</span><span class=""p"">,</span>
        <span class=""s1"">'encoding'</span><span class=""p"">:</span> <span class=""s1"">'utf8'</span><span class=""p"">,</span>
        <span class=""s1"">'store_empty'</span><span class=""p"">:</span> <span class=""kc"">False</span><span class=""p"">,</span>
        <span class=""s1"">'item_classes'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""n"">MyItemClass1</span><span class=""p"">,</span> <span class=""s1"">'myproject.items.MyItemClass2'</span><span class=""p"">],</span>
        <span class=""s1"">'fields'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
        <span class=""s1"">'indent'</span><span class=""p"">:</span> <span class=""mi"">4</span><span class=""p"">,</span>
        <span class=""s1"">'item_export_kwargs'</span><span class=""p"">:</span> <span class=""p"">{</span>
           <span class=""s1"">'export_empty_fields'</span><span class=""p"">:</span> <span class=""kc"">True</span><span class=""p"">,</span>
        <span class=""p"">},</span>
    <span class=""p"">},</span>
    <span class=""s1"">'/home/user/documents/items.xml'</span><span class=""p"">:</span> <span class=""p"">{</span>
        <span class=""s1"">'format'</span><span class=""p"">:</span> <span class=""s1"">'xml'</span><span class=""p"">,</span>
        <span class=""s1"">'fields'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""s1"">'name'</span><span class=""p"">,</span> <span class=""s1"">'price'</span><span class=""p"">],</span>
        <span class=""s1"">'item_filter'</span><span class=""p"">:</span> <span class=""n"">MyCustomFilter1</span><span class=""p"">,</span>
        <span class=""s1"">'encoding'</span><span class=""p"">:</span> <span class=""s1"">'latin1'</span><span class=""p"">,</span>
        <span class=""s1"">'indent'</span><span class=""p"">:</span> <span class=""mi"">8</span><span class=""p"">,</span>
    <span class=""p"">},</span>
    <span class=""n"">pathlib</span><span class=""o"">.</span><span class=""n"">Path</span><span class=""p"">(</span><span class=""s1"">'items.csv.gz'</span><span class=""p"">):</span> <span class=""p"">{</span>
        <span class=""s1"">'format'</span><span class=""p"">:</span> <span class=""s1"">'csv'</span><span class=""p"">,</span>
        <span class=""s1"">'fields'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""s1"">'price'</span><span class=""p"">,</span> <span class=""s1"">'name'</span><span class=""p"">],</span>
        <span class=""s1"">'item_filter'</span><span class=""p"">:</span> <span class=""s1"">'myproject.filters.MyCustomFilter2'</span><span class=""p"">,</span>
        <span class=""s1"">'postprocessing'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""n"">MyPlugin1</span><span class=""p"">,</span> <span class=""s1"">'scrapy.extensions.postprocessing.GzipPlugin'</span><span class=""p"">],</span>
        <span class=""s1"">'gzip_compresslevel'</span><span class=""p"">:</span> <span class=""mi"">5</span><span class=""p"">,</span>
    <span class=""p"">},</span>
<span class=""p"">}</span>
</pre></div>","{
    'items.json': {
        'format': 'json',
        'encoding': 'utf8',
        'store_empty': False,
        'item_classes': [MyItemClass1, 'myproject.items.MyItemClass2'],
        'fields': None,
        'indent': 4,
        'item_export_kwargs': {
           'export_empty_fields': True,
        },
    },
    '/home/user/documents/items.xml': {
        'format': 'xml',
        'fields': ['name', 'price'],
        'item_filter': MyCustomFilter1,
        'encoding': 'latin1',
        'indent': 8,
    },
    pathlib.Path('items.csv.gz'): {
        'format': 'csv',
        'fields': ['price', 'name'],
        'item_filter': 'myproject.filters.MyCustomFilter2',
        'postprocessing': [MyPlugin1, 'scrapy.extensions.postprocessing.GzipPlugin'],
        'gzip_compresslevel': 5,
    },
}
",1
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,FEED_EXPORT_ENCODING,#feed-export-encoding,,,25
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,FEED_EXPORT_FIELDS,#feed-export-fields,,,26
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,FEED_EXPORT_INDENT,#feed-export-indent,,,27
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,FEED_STORE_EMPTY,#feed-store-empty,,,28
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,FEED_STORAGES,#feed-storages,,,29
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,FEED_STORAGE_FTP_ACTIVE,#feed-storage-ftp-active,,,30
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,FEED_STORAGE_S3_ACL,#feed-storage-s3-acl,,,31
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,FEED_STORAGES_BASE,#feed-storages-base,"<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">''</span><span class=""p"">:</span> <span class=""s1"">'scrapy.extensions.feedexport.FileFeedStorage'</span><span class=""p"">,</span>
    <span class=""s1"">'file'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.extensions.feedexport.FileFeedStorage'</span><span class=""p"">,</span>
    <span class=""s1"">'stdout'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.extensions.feedexport.StdoutFeedStorage'</span><span class=""p"">,</span>
    <span class=""s1"">'s3'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.extensions.feedexport.S3FeedStorage'</span><span class=""p"">,</span>
    <span class=""s1"">'ftp'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.extensions.feedexport.FTPFeedStorage'</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">FEED_STORAGES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'ftp'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","{
    '': 'scrapy.extensions.feedexport.FileFeedStorage',
    'file': 'scrapy.extensions.feedexport.FileFeedStorage',
    'stdout': 'scrapy.extensions.feedexport.StdoutFeedStorage',
    's3': 'scrapy.extensions.feedexport.S3FeedStorage',
    'ftp': 'scrapy.extensions.feedexport.FTPFeedStorage',
}
,FEED_STORAGES = {
    'ftp': None,
}
",2
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,FEED_EXPORTERS,#feed-exporters,,,33
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,FEED_EXPORTERS_BASE,#feed-exporters-base,"<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'json'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.JsonItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'jsonlines'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.JsonLinesItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'jsonl'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.JsonLinesItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'jl'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.JsonLinesItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'csv'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.CsvItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'xml'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.XmlItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'marshal'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.MarshalItemExporter'</span><span class=""p"">,</span>
    <span class=""s1"">'pickle'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.exporters.PickleItemExporter'</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">FEED_EXPORTERS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'csv'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","{
    'json': 'scrapy.exporters.JsonItemExporter',
    'jsonlines': 'scrapy.exporters.JsonLinesItemExporter',
    'jsonl': 'scrapy.exporters.JsonLinesItemExporter',
    'jl': 'scrapy.exporters.JsonLinesItemExporter',
    'csv': 'scrapy.exporters.CsvItemExporter',
    'xml': 'scrapy.exporters.XmlItemExporter',
    'marshal': 'scrapy.exporters.MarshalItemExporter',
    'pickle': 'scrapy.exporters.PickleItemExporter',
}
,FEED_EXPORTERS = {
    'csv': None,
}
",2
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,FEED_EXPORT_BATCH_ITEM_COUNT,#feed-export-batch-item-count,"<div class=""highlight""><pre><span></span><span class=""n"">FEED_EXPORT_BATCH_ITEM_COUNT</span> <span class=""o"">=</span> <span class=""mi"">100</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">spidername</span> <span class=""o"">-</span><span class=""n"">o</span> <span class=""s2"">""dirname/</span><span class=""si"">%(batch_id)d</span><span class=""s2"">-filename</span><span class=""si"">%(batch_time)s</span><span class=""s2"">.json""</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">-&gt;</span><span class=""n"">projectname</span>
<span class=""o"">--&gt;</span><span class=""n"">dirname</span>
<span class=""o"">---&gt;</span><span class=""mi"">1</span><span class=""o"">-</span><span class=""n"">filename2020</span><span class=""o"">-</span><span class=""mi"">03</span><span class=""o"">-</span><span class=""mi"">28</span><span class=""n"">T14</span><span class=""o"">-</span><span class=""mi"">45</span><span class=""o"">-</span><span class=""mf"">08.237134</span><span class=""o"">.</span><span class=""n"">json</span>
<span class=""o"">---&gt;</span><span class=""mi"">2</span><span class=""o"">-</span><span class=""n"">filename2020</span><span class=""o"">-</span><span class=""mi"">03</span><span class=""o"">-</span><span class=""mi"">28</span><span class=""n"">T14</span><span class=""o"">-</span><span class=""mi"">45</span><span class=""o"">-</span><span class=""mf"">09.148903</span><span class=""o"">.</span><span class=""n"">json</span>
<span class=""o"">---&gt;</span><span class=""mi"">3</span><span class=""o"">-</span><span class=""n"">filename2020</span><span class=""o"">-</span><span class=""mi"">03</span><span class=""o"">-</span><span class=""mi"">28</span><span class=""n"">T14</span><span class=""o"">-</span><span class=""mi"">45</span><span class=""o"">-</span><span class=""mf"">10.046092</span><span class=""o"">.</span><span class=""n"">json</span>
</pre></div>","FEED_EXPORT_BATCH_ITEM_COUNT = 100
,scrapy crawl spidername -o ""dirname/%(batch_id)d-filename%(batch_time)s.json""
,->projectname
-->dirname
--->1-filename2020-03-28T14-45-08.237134.json
--->2-filename2020-03-28T14-45-09.148903.json
--->3-filename2020-03-28T14-45-10.046092.json
",3
https://docs.scrapy.org/en/latest/topics/feed-exports.html,,###,3,FEED_URI_PARAMS,#feed-uri-params,"<div class=""highlight""><pre><span></span><span class=""c1""># myproject/utils.py</span>
<span class=""k"">def</span> <span class=""nf"">uri_params</span><span class=""p"">(</span><span class=""n"">params</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
    <span class=""k"">return</span> <span class=""p"">{</span><span class=""o"">**</span><span class=""n"">params</span><span class=""p"">,</span> <span class=""s1"">'spider_name'</span><span class=""p"">:</span> <span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">name</span><span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># myproject/settings.py</span>
<span class=""n"">FEED_URI_PARAMS</span> <span class=""o"">=</span> <span class=""s1"">'myproject.utils.uri_params'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""o"">&lt;</span><span class=""n"">spider_name</span><span class=""o"">&gt;</span> <span class=""o"">-</span><span class=""n"">o</span> <span class=""s2"">""</span><span class=""si"">%(spider_name)s</span><span class=""s2"">.jsonl""</span>
</pre></div>","# myproject/utils.py
def uri_params(params, spider):
    return {**params, 'spider_name': spider.name}
,# myproject/settings.py
FEED_URI_PARAMS = 'myproject.utils.uri_params'
,scrapy crawl <spider_name> -o ""%(spider_name)s.jsonl""
",3
https://docs.scrapy.org/en/latest/topics/request-response.html,,#,1,Requests and Responses,#module-scrapy.http,"<div class=""highlight""><pre><span></span><span class=""n"">request_with_cookies</span> <span class=""o"">=</span> <span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""s2"">""http://www.example.com""</span><span class=""p"">,</span>
                               <span class=""n"">cookies</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'currency'</span><span class=""p"">:</span> <span class=""s1"">'USD'</span><span class=""p"">,</span> <span class=""s1"">'country'</span><span class=""p"">:</span> <span class=""s1"">'UY'</span><span class=""p"">})</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">request_with_cookies</span> <span class=""o"">=</span> <span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""s2"">""http://www.example.com""</span><span class=""p"">,</span>
                               <span class=""n"">cookies</span><span class=""o"">=</span><span class=""p"">[{</span><span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""s1"">'currency'</span><span class=""p"">,</span>
                                        <span class=""s1"">'value'</span><span class=""p"">:</span> <span class=""s1"">'USD'</span><span class=""p"">,</span>
                                        <span class=""s1"">'domain'</span><span class=""p"">:</span> <span class=""s1"">'example.com'</span><span class=""p"">,</span>
                                        <span class=""s1"">'path'</span><span class=""p"">:</span> <span class=""s1"">'/currency'</span><span class=""p"">}])</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">Request</span><span class=""p"">(</span>
    <span class=""n"">url</span><span class=""o"">=</span><span class=""s2"">""http://www.example.com""</span><span class=""p"">,</span>
    <span class=""n"">cookies</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'currency'</span><span class=""p"">:</span> <span class=""s1"">'USD'</span><span class=""p"">,</span> <span class=""s1"">'country'</span><span class=""p"">:</span> <span class=""s1"">'UY'</span><span class=""p"">},</span>
    <span class=""n"">meta</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'dont_merge_cookies'</span><span class=""p"">:</span> <span class=""kc"">True</span><span class=""p"">},</span>
<span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse_page1</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""k"">return</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s2"">""http://www.example.com/some_page.html""</span><span class=""p"">,</span>
                          <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_page2</span><span class=""p"">)</span>

<span class=""k"">def</span> <span class=""nf"">parse_page2</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""c1""># this would log http://www.example.com/some_page.html</span>
    <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s2"">""Visited </span><span class=""si"">%s</span><span class=""s2"">""</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s1"">'http://www.example.com/index.html'</span><span class=""p"">,</span>
                             <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_page2</span><span class=""p"">,</span>
                             <span class=""n"">cb_kwargs</span><span class=""o"">=</span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">main_url</span><span class=""o"">=</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">))</span>
    <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">cb_kwargs</span><span class=""p"">[</span><span class=""s1"">'foo'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""s1"">'bar'</span>  <span class=""c1""># add more arguments for the callback</span>
    <span class=""k"">yield</span> <span class=""n"">request</span>

<span class=""k"">def</span> <span class=""nf"">parse_page2</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">main_url</span><span class=""p"">,</span> <span class=""n"">foo</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""nb"">dict</span><span class=""p"">(</span>
        <span class=""n"">main_url</span><span class=""o"">=</span><span class=""n"">main_url</span><span class=""p"">,</span>
        <span class=""n"">other_url</span><span class=""o"">=</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">,</span>
        <span class=""n"">foo</span><span class=""o"">=</span><span class=""n"">foo</span><span class=""p"">,</span>
    <span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""kn"">from</span> <span class=""nn"">scrapy.spidermiddlewares.httperror</span> <span class=""kn"">import</span> <span class=""n"">HttpError</span>
<span class=""kn"">from</span> <span class=""nn"">twisted.internet.error</span> <span class=""kn"">import</span> <span class=""n"">DNSLookupError</span>
<span class=""kn"">from</span> <span class=""nn"">twisted.internet.error</span> <span class=""kn"">import</span> <span class=""ne"">TimeoutError</span><span class=""p"">,</span> <span class=""n"">TCPTimedOutError</span>

<span class=""k"">class</span> <span class=""nc"">ErrbackSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""errback_example""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s2"">""http://www.httpbin.org/""</span><span class=""p"">,</span>              <span class=""c1""># HTTP 200 expected</span>
        <span class=""s2"">""http://www.httpbin.org/status/404""</span><span class=""p"">,</span>    <span class=""c1""># Not found error</span>
        <span class=""s2"">""http://www.httpbin.org/status/500""</span><span class=""p"">,</span>    <span class=""c1""># server issue</span>
        <span class=""s2"">""http://www.httpbin.org:12345/""</span><span class=""p"">,</span>        <span class=""c1""># non-responding host, timeout expected</span>
        <span class=""s2"">""https://example.invalid/""</span><span class=""p"">,</span>             <span class=""c1""># DNS error expected</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">u</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">start_urls</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">u</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_httpbin</span><span class=""p"">,</span>
                                    <span class=""n"">errback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">errback_httpbin</span><span class=""p"">,</span>
                                    <span class=""n"">dont_filter</span><span class=""o"">=</span><span class=""kc"">True</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse_httpbin</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Got successful response from </span><span class=""si"">{}</span><span class=""s1"">'</span><span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">))</span>
        <span class=""c1""># do something useful here...</span>

    <span class=""k"">def</span> <span class=""nf"">errback_httpbin</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">failure</span><span class=""p"">):</span>
        <span class=""c1""># log all failures</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">error</span><span class=""p"">(</span><span class=""nb"">repr</span><span class=""p"">(</span><span class=""n"">failure</span><span class=""p"">))</span>

        <span class=""c1""># in case you want to do something special for some errors,</span>
        <span class=""c1""># you may need the failure's type:</span>

        <span class=""k"">if</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">check</span><span class=""p"">(</span><span class=""n"">HttpError</span><span class=""p"">):</span>
            <span class=""c1""># these exceptions come from HttpError spider middleware</span>
            <span class=""c1""># you can get the non-200 response</span>
            <span class=""n"">response</span> <span class=""o"">=</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">value</span><span class=""o"">.</span><span class=""n"">response</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">error</span><span class=""p"">(</span><span class=""s1"">'HttpError on </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>

        <span class=""k"">elif</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">check</span><span class=""p"">(</span><span class=""n"">DNSLookupError</span><span class=""p"">):</span>
            <span class=""c1""># this is the original request</span>
            <span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">request</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">error</span><span class=""p"">(</span><span class=""s1"">'DNSLookupError on </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>

        <span class=""k"">elif</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">check</span><span class=""p"">(</span><span class=""ne"">TimeoutError</span><span class=""p"">,</span> <span class=""n"">TCPTimedOutError</span><span class=""p"">):</span>
            <span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">request</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">error</span><span class=""p"">(</span><span class=""s1"">'TimeoutError on </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s1"">'http://www.example.com/index.html'</span><span class=""p"">,</span>
                             <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_page2</span><span class=""p"">,</span>
                             <span class=""n"">errback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">errback_page2</span><span class=""p"">,</span>
                             <span class=""n"">cb_kwargs</span><span class=""o"">=</span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">main_url</span><span class=""o"">=</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">))</span>
    <span class=""k"">yield</span> <span class=""n"">request</span>

<span class=""k"">def</span> <span class=""nf"">parse_page2</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">main_url</span><span class=""p"">):</span>
    <span class=""k"">pass</span>

<span class=""k"">def</span> <span class=""nf"">errback_page2</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">failure</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""nb"">dict</span><span class=""p"">(</span>
        <span class=""n"">main_url</span><span class=""o"">=</span><span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">cb_kwargs</span><span class=""p"">[</span><span class=""s1"">'main_url'</span><span class=""p"">],</span>
    <span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># my_project/settings.py</span>
<span class=""n"">REQUEST_FINGERPRINTER_CLASS</span> <span class=""o"">=</span> <span class=""s1"">'my_project.utils.RequestFingerprinter'</span>

<span class=""c1""># my_project/utils.py</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.request</span> <span class=""kn"">import</span> <span class=""n"">fingerprint</span>

<span class=""k"">class</span> <span class=""nc"">RequestFingerprinter</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""nf"">fingerprint</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""n"">fingerprint</span><span class=""p"">(</span><span class=""n"">request</span><span class=""p"">,</span> <span class=""n"">include_headers</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s1"">'X-ID'</span><span class=""p"">])</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">hashlib</span> <span class=""kn"">import</span> <span class=""n"">sha1</span>
<span class=""kn"">from</span> <span class=""nn"">weakref</span> <span class=""kn"">import</span> <span class=""n"">WeakKeyDictionary</span>

<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.python</span> <span class=""kn"">import</span> <span class=""n"">to_bytes</span>

<span class=""k"">class</span> <span class=""nc"">RequestFingerprinter</span><span class=""p"">:</span>

    <span class=""n"">cache</span> <span class=""o"">=</span> <span class=""n"">WeakKeyDictionary</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">fingerprint</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">request</span> <span class=""ow"">not</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">:</span>
            <span class=""n"">fp</span> <span class=""o"">=</span> <span class=""n"">sha1</span><span class=""p"">()</span>
            <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">update</span><span class=""p"">(</span><span class=""n"">to_bytes</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">))</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">[</span><span class=""n"">request</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">digest</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">[</span><span class=""n"">request</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.utils.request</span> <span class=""kn"">import</span> <span class=""n"">fingerprint</span>

<span class=""k"">class</span> <span class=""nc"">RequestFingerprinter</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""nf"">fingerprint</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""s1"">'fingerprint'</span> <span class=""ow"">in</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">meta</span><span class=""p"">:</span>
            <span class=""k"">return</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">meta</span><span class=""p"">[</span><span class=""s1"">'fingerprint'</span><span class=""p"">]</span>
        <span class=""k"">return</span> <span class=""n"">fingerprint</span><span class=""p"">(</span><span class=""n"">request</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">hashlib</span> <span class=""kn"">import</span> <span class=""n"">sha1</span>
<span class=""kn"">from</span> <span class=""nn"">weakref</span> <span class=""kn"">import</span> <span class=""n"">WeakKeyDictionary</span>

<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.python</span> <span class=""kn"">import</span> <span class=""n"">to_bytes</span>
<span class=""kn"">from</span> <span class=""nn"">w3lib.url</span> <span class=""kn"">import</span> <span class=""n"">canonicalize_url</span>

<span class=""k"">class</span> <span class=""nc"">RequestFingerprinter</span><span class=""p"">:</span>

    <span class=""n"">cache</span> <span class=""o"">=</span> <span class=""n"">WeakKeyDictionary</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">fingerprint</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">request</span> <span class=""ow"">not</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">:</span>
            <span class=""n"">fp</span> <span class=""o"">=</span> <span class=""n"">sha1</span><span class=""p"">()</span>
            <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">update</span><span class=""p"">(</span><span class=""n"">to_bytes</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">method</span><span class=""p"">))</span>
            <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">update</span><span class=""p"">(</span><span class=""n"">to_bytes</span><span class=""p"">(</span><span class=""n"">canonicalize_url</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)))</span>
            <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">update</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">body</span> <span class=""ow"">or</span> <span class=""sa"">b</span><span class=""s1"">''</span><span class=""p"">)</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">[</span><span class=""n"">request</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">digest</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">[</span><span class=""n"">request</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">/</span><span class=""n"">home</span><span class=""o"">/</span><span class=""n"">user</span><span class=""o"">/</span><span class=""n"">project</span><span class=""o"">/.</span><span class=""n"">scrapy</span><span class=""o"">/</span><span class=""n"">httpcache</span><span class=""o"">/</span><span class=""n"">my_spider</span><span class=""o"">/</span><span class=""mi"">01</span><span class=""o"">/</span><span class=""mi"">0123456789</span><span class=""n"">abcdef0123456789abcdef01234567</span><span class=""o"">/</span><span class=""n"">response_headers</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">StopSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""stop""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s2"">""https://docs.scrapy.org/en/latest/""</span><span class=""p"">]</span>

    <span class=""nd"">@classmethod</span>
    <span class=""k"">def</span> <span class=""nf"">from_crawler</span><span class=""p"">(</span><span class=""bp"">cls</span><span class=""p"">,</span> <span class=""n"">crawler</span><span class=""p"">):</span>
        <span class=""n"">spider</span> <span class=""o"">=</span> <span class=""nb"">super</span><span class=""p"">()</span><span class=""o"">.</span><span class=""n"">from_crawler</span><span class=""p"">(</span><span class=""n"">crawler</span><span class=""p"">)</span>
        <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">on_bytes_received</span><span class=""p"">,</span> <span class=""n"">signal</span><span class=""o"">=</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">bytes_received</span><span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""n"">spider</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""c1""># 'last_chars' show that the full response was not downloaded</span>
        <span class=""k"">yield</span> <span class=""p"">{</span><span class=""s2"">""len""</span><span class=""p"">:</span> <span class=""nb"">len</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">text</span><span class=""p"">),</span> <span class=""s2"">""last_chars""</span><span class=""p"">:</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">text</span><span class=""p"">[</span><span class=""o"">-</span><span class=""mi"">40</span><span class=""p"">:]}</span>

    <span class=""k"">def</span> <span class=""nf"">on_bytes_received</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">data</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""k"">raise</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">exceptions</span><span class=""o"">.</span><span class=""n"">StopDownload</span><span class=""p"">(</span><span class=""n"">fail</span><span class=""o"">=</span><span class=""kc"">False</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">2020</span><span class=""o"">-</span><span class=""mi"">05</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">17</span><span class=""p"">:</span><span class=""mi"">26</span><span class=""p"">:</span><span class=""mi"">12</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Spider</span> <span class=""n"">opened</span>
<span class=""mi"">2020</span><span class=""o"">-</span><span class=""mi"">05</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">17</span><span class=""p"">:</span><span class=""mi"">26</span><span class=""p"">:</span><span class=""mi"">12</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">logstats</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""mi"">0</span> <span class=""n"">pages</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">pages</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">),</span> <span class=""n"">scraped</span> <span class=""mi"">0</span> <span class=""n"">items</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">items</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">)</span>
<span class=""mi"">2020</span><span class=""o"">-</span><span class=""mi"">05</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">17</span><span class=""p"">:</span><span class=""mi"">26</span><span class=""p"">:</span><span class=""mi"">13</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">downloader</span><span class=""o"">.</span><span class=""n"">handlers</span><span class=""o"">.</span><span class=""n"">http11</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Download</span> <span class=""n"">stopped</span> <span class=""k"">for</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">docs</span><span class=""o"">.</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">org</span><span class=""o"">/</span><span class=""n"">en</span><span class=""o"">/</span><span class=""n"">latest</span><span class=""o"">/&gt;</span> <span class=""kn"">from</span> <span class=""nn"">signal</span> <span class=""n"">handler</span> <span class=""n"">StopSpider</span><span class=""o"">.</span><span class=""n"">on_bytes_received</span>
<span class=""mi"">2020</span><span class=""o"">-</span><span class=""mi"">05</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">17</span><span class=""p"">:</span><span class=""mi"">26</span><span class=""p"">:</span><span class=""mi"">13</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">docs</span><span class=""o"">.</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">org</span><span class=""o"">/</span><span class=""n"">en</span><span class=""o"">/</span><span class=""n"">latest</span><span class=""o"">/&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span> <span class=""p"">[</span><span class=""s1"">'download_stopped'</span><span class=""p"">]</span>
<span class=""mi"">2020</span><span class=""o"">-</span><span class=""mi"">05</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">17</span><span class=""p"">:</span><span class=""mi"">26</span><span class=""p"">:</span><span class=""mi"">13</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">scraper</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Scraped</span> <span class=""kn"">from</span> <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">docs</span><span class=""o"">.</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">org</span><span class=""o"">/</span><span class=""n"">en</span><span class=""o"">/</span><span class=""n"">latest</span><span class=""o"">/&gt;</span>
<span class=""p"">{</span><span class=""s1"">'len'</span><span class=""p"">:</span> <span class=""mi"">279</span><span class=""p"">,</span> <span class=""s1"">'last_chars'</span><span class=""p"">:</span> <span class=""s1"">'dth, initial-scale=1.0""&gt;</span><span class=""se"">\n</span><span class=""s1"">  </span><span class=""se"">\n</span><span class=""s1"">  &lt;title&gt;Scr'</span><span class=""p"">}</span>
<span class=""mi"">2020</span><span class=""o"">-</span><span class=""mi"">05</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">17</span><span class=""p"">:</span><span class=""mi"">26</span><span class=""p"">:</span><span class=""mi"">13</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Closing</span> <span class=""n"">spider</span> <span class=""p"">(</span><span class=""n"">finished</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">return</span> <span class=""p"">[</span><span class=""n"">FormRequest</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""s2"">""http://www.example.com/post/action""</span><span class=""p"">,</span>
                    <span class=""n"">formdata</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""s1"">'John Doe'</span><span class=""p"">,</span> <span class=""s1"">'age'</span><span class=""p"">:</span> <span class=""s1"">'27'</span><span class=""p"">},</span>
                    <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">after_post</span><span class=""p"">)]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">def</span> <span class=""nf"">authentication_failed</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">):</span>
    <span class=""c1""># TODO: Check the contents of the response and return True if it failed</span>
    <span class=""c1""># or False if it succeeded.</span>
    <span class=""k"">pass</span>

<span class=""k"">class</span> <span class=""nc"">LoginSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/users/login.php'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">FormRequest</span><span class=""o"">.</span><span class=""n"">from_response</span><span class=""p"">(</span>
            <span class=""n"">response</span><span class=""p"">,</span>
            <span class=""n"">formdata</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'username'</span><span class=""p"">:</span> <span class=""s1"">'john'</span><span class=""p"">,</span> <span class=""s1"">'password'</span><span class=""p"">:</span> <span class=""s1"">'secret'</span><span class=""p"">},</span>
            <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">after_login</span>
        <span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">after_login</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">authentication_failed</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">):</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">error</span><span class=""p"">(</span><span class=""s2"">""Login failed""</span><span class=""p"">)</span>
            <span class=""k"">return</span>

        <span class=""c1""># continue scraping with authenticated session...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">data</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'name1'</span><span class=""p"">:</span> <span class=""s1"">'value1'</span><span class=""p"">,</span>
    <span class=""s1"">'name2'</span><span class=""p"">:</span> <span class=""s1"">'value2'</span><span class=""p"">,</span>
<span class=""p"">}</span>
<span class=""k"">yield</span> <span class=""n"">JsonRequest</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""s1"">'http://www.example.com/post/action'</span><span class=""p"">,</span> <span class=""n"">data</span><span class=""o"">=</span><span class=""n"">data</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">headers</span><span class=""o"">.</span><span class=""n"">getlist</span><span class=""p"">(</span><span class=""s1"">'Set-Cookie'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">urllib</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""o"">.</span><span class=""n"">urljoin</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">url</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""nb"">str</span><span class=""p"">(</span><span class=""sa"">b</span><span class=""s1"">'body'</span><span class=""p"">)</span>
<span class=""go"">""b'body'""</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'p'</span><span class=""p"">)</span>
</pre></div>","request_with_cookies = Request(url=""http://www.example.com"",
                               cookies={'currency': 'USD', 'country': 'UY'})
,request_with_cookies = Request(url=""http://www.example.com"",
                               cookies=[{'name': 'currency',
                                        'value': 'USD',
                                        'domain': 'example.com',
                                        'path': '/currency'}])
,Request(
    url=""http://www.example.com"",
    cookies={'currency': 'USD', 'country': 'UY'},
    meta={'dont_merge_cookies': True},
)
,def parse_page1(self, response):
    return scrapy.Request(""http://www.example.com/some_page.html"",
                          callback=self.parse_page2)

def parse_page2(self, response):
    # this would log http://www.example.com/some_page.html
    self.logger.info(""Visited %s"", response.url)
,def parse(self, response):
    request = scrapy.Request('http://www.example.com/index.html',
                             callback=self.parse_page2,
                             cb_kwargs=dict(main_url=response.url))
    request.cb_kwargs['foo'] = 'bar'  # add more arguments for the callback
    yield request

def parse_page2(self, response, main_url, foo):
    yield dict(
        main_url=main_url,
        other_url=response.url,
        foo=foo,
    )
,import scrapy

from scrapy.spidermiddlewares.httperror import HttpError
from twisted.internet.error import DNSLookupError
from twisted.internet.error import TimeoutError, TCPTimedOutError

class ErrbackSpider(scrapy.Spider):
    name = ""errback_example""
    start_urls = [
        ""http://www.httpbin.org/"",              # HTTP 200 expected
        ""http://www.httpbin.org/status/404"",    # Not found error
        ""http://www.httpbin.org/status/500"",    # server issue
        ""http://www.httpbin.org:12345/"",        # non-responding host, timeout expected
        ""https://example.invalid/"",             # DNS error expected
    ]

    def start_requests(self):
        for u in self.start_urls:
            yield scrapy.Request(u, callback=self.parse_httpbin,
                                    errback=self.errback_httpbin,
                                    dont_filter=True)

    def parse_httpbin(self, response):
        self.logger.info('Got successful response from {}'.format(response.url))
        # do something useful here...

    def errback_httpbin(self, failure):
        # log all failures
        self.logger.error(repr(failure))

        # in case you want to do something special for some errors,
        # you may need the failure's type:

        if failure.check(HttpError):
            # these exceptions come from HttpError spider middleware
            # you can get the non-200 response
            response = failure.value.response
            self.logger.error('HttpError on %s', response.url)

        elif failure.check(DNSLookupError):
            # this is the original request
            request = failure.request
            self.logger.error('DNSLookupError on %s', request.url)

        elif failure.check(TimeoutError, TCPTimedOutError):
            request = failure.request
            self.logger.error('TimeoutError on %s', request.url)
,def parse(self, response):
    request = scrapy.Request('http://www.example.com/index.html',
                             callback=self.parse_page2,
                             errback=self.errback_page2,
                             cb_kwargs=dict(main_url=response.url))
    yield request

def parse_page2(self, response, main_url):
    pass

def errback_page2(self, failure):
    yield dict(
        main_url=failure.request.cb_kwargs['main_url'],
    )
,# my_project/settings.py
REQUEST_FINGERPRINTER_CLASS = 'my_project.utils.RequestFingerprinter'

# my_project/utils.py
from scrapy.utils.request import fingerprint

class RequestFingerprinter:

    def fingerprint(self, request):
        return fingerprint(request, include_headers=['X-ID'])
,from hashlib import sha1
from weakref import WeakKeyDictionary

from scrapy.utils.python import to_bytes

class RequestFingerprinter:

    cache = WeakKeyDictionary()

    def fingerprint(self, request):
        if request not in self.cache:
            fp = sha1()
            fp.update(to_bytes(request.url))
            self.cache[request] = fp.digest()
        return self.cache[request]
,from scrapy.utils.request import fingerprint

class RequestFingerprinter:

    def fingerprint(self, request):
        if 'fingerprint' in request.meta:
            return request.meta['fingerprint']
        return fingerprint(request)
,from hashlib import sha1
from weakref import WeakKeyDictionary

from scrapy.utils.python import to_bytes
from w3lib.url import canonicalize_url

class RequestFingerprinter:

    cache = WeakKeyDictionary()

    def fingerprint(self, request):
        if request not in self.cache:
            fp = sha1()
            fp.update(to_bytes(request.method))
            fp.update(to_bytes(canonicalize_url(request.url)))
            fp.update(request.body or b'')
            self.cache[request] = fp.digest()
        return self.cache[request]
,/home/user/project/.scrapy/httpcache/my_spider/01/0123456789abcdef0123456789abcdef01234567/response_headers
,import scrapy


class StopSpider(scrapy.Spider):
    name = ""stop""
    start_urls = [""https://docs.scrapy.org/en/latest/""]

    @classmethod
    def from_crawler(cls, crawler):
        spider = super().from_crawler(crawler)
        crawler.signals.connect(spider.on_bytes_received, signal=scrapy.signals.bytes_received)
        return spider

    def parse(self, response):
        # 'last_chars' show that the full response was not downloaded
        yield {""len"": len(response.text), ""last_chars"": response.text[-40:]}

    def on_bytes_received(self, data, request, spider):
        raise scrapy.exceptions.StopDownload(fail=False)
,2020-05-19 17:26:12 [scrapy.core.engine] INFO: Spider opened
2020-05-19 17:26:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-19 17:26:13 [scrapy.core.downloader.handlers.http11] DEBUG: Download stopped for <GET https://docs.scrapy.org/en/latest/> from signal handler StopSpider.on_bytes_received
2020-05-19 17:26:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://docs.scrapy.org/en/latest/> (referer: None) ['download_stopped']
2020-05-19 17:26:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://docs.scrapy.org/en/latest/>
{'len': 279, 'last_chars': 'dth, initial-scale=1.0"">\n  \n  <title>Scr'}
2020-05-19 17:26:13 [scrapy.core.engine] INFO: Closing spider (finished)
,return [FormRequest(url=""http://www.example.com/post/action"",
                    formdata={'name': 'John Doe', 'age': '27'},
                    callback=self.after_post)]
,import scrapy

def authentication_failed(response):
    # TODO: Check the contents of the response and return True if it failed
    # or False if it succeeded.
    pass

class LoginSpider(scrapy.Spider):
    name = 'example.com'
    start_urls = ['http://www.example.com/users/login.php']

    def parse(self, response):
        return scrapy.FormRequest.from_response(
            response,
            formdata={'username': 'john', 'password': 'secret'},
            callback=self.after_login
        )

    def after_login(self, response):
        if authentication_failed(response):
            self.logger.error(""Login failed"")
            return

        # continue scraping with authenticated session...
,data = {
    'name1': 'value1',
    'name2': 'value2',
}
yield JsonRequest(url='http://www.example.com/post/action', data=data)
,response.headers.getlist('Set-Cookie')
,urllib.parse.urljoin(response.url, url)
,>>> str(b'body')
""b'body'""
,response.xpath('//p')
,response.css('p')
",22
https://docs.scrapy.org/en/latest/topics/request-response.html,,##,2,Request objects,#request-objects,"<div class=""highlight""><pre><span></span><span class=""n"">request_with_cookies</span> <span class=""o"">=</span> <span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""s2"">""http://www.example.com""</span><span class=""p"">,</span>
                               <span class=""n"">cookies</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'currency'</span><span class=""p"">:</span> <span class=""s1"">'USD'</span><span class=""p"">,</span> <span class=""s1"">'country'</span><span class=""p"">:</span> <span class=""s1"">'UY'</span><span class=""p"">})</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">request_with_cookies</span> <span class=""o"">=</span> <span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""s2"">""http://www.example.com""</span><span class=""p"">,</span>
                               <span class=""n"">cookies</span><span class=""o"">=</span><span class=""p"">[{</span><span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""s1"">'currency'</span><span class=""p"">,</span>
                                        <span class=""s1"">'value'</span><span class=""p"">:</span> <span class=""s1"">'USD'</span><span class=""p"">,</span>
                                        <span class=""s1"">'domain'</span><span class=""p"">:</span> <span class=""s1"">'example.com'</span><span class=""p"">,</span>
                                        <span class=""s1"">'path'</span><span class=""p"">:</span> <span class=""s1"">'/currency'</span><span class=""p"">}])</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">Request</span><span class=""p"">(</span>
    <span class=""n"">url</span><span class=""o"">=</span><span class=""s2"">""http://www.example.com""</span><span class=""p"">,</span>
    <span class=""n"">cookies</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'currency'</span><span class=""p"">:</span> <span class=""s1"">'USD'</span><span class=""p"">,</span> <span class=""s1"">'country'</span><span class=""p"">:</span> <span class=""s1"">'UY'</span><span class=""p"">},</span>
    <span class=""n"">meta</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'dont_merge_cookies'</span><span class=""p"">:</span> <span class=""kc"">True</span><span class=""p"">},</span>
<span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse_page1</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""k"">return</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s2"">""http://www.example.com/some_page.html""</span><span class=""p"">,</span>
                          <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_page2</span><span class=""p"">)</span>

<span class=""k"">def</span> <span class=""nf"">parse_page2</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""c1""># this would log http://www.example.com/some_page.html</span>
    <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s2"">""Visited </span><span class=""si"">%s</span><span class=""s2"">""</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s1"">'http://www.example.com/index.html'</span><span class=""p"">,</span>
                             <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_page2</span><span class=""p"">,</span>
                             <span class=""n"">cb_kwargs</span><span class=""o"">=</span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">main_url</span><span class=""o"">=</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">))</span>
    <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">cb_kwargs</span><span class=""p"">[</span><span class=""s1"">'foo'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""s1"">'bar'</span>  <span class=""c1""># add more arguments for the callback</span>
    <span class=""k"">yield</span> <span class=""n"">request</span>

<span class=""k"">def</span> <span class=""nf"">parse_page2</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">main_url</span><span class=""p"">,</span> <span class=""n"">foo</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""nb"">dict</span><span class=""p"">(</span>
        <span class=""n"">main_url</span><span class=""o"">=</span><span class=""n"">main_url</span><span class=""p"">,</span>
        <span class=""n"">other_url</span><span class=""o"">=</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">,</span>
        <span class=""n"">foo</span><span class=""o"">=</span><span class=""n"">foo</span><span class=""p"">,</span>
    <span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""kn"">from</span> <span class=""nn"">scrapy.spidermiddlewares.httperror</span> <span class=""kn"">import</span> <span class=""n"">HttpError</span>
<span class=""kn"">from</span> <span class=""nn"">twisted.internet.error</span> <span class=""kn"">import</span> <span class=""n"">DNSLookupError</span>
<span class=""kn"">from</span> <span class=""nn"">twisted.internet.error</span> <span class=""kn"">import</span> <span class=""ne"">TimeoutError</span><span class=""p"">,</span> <span class=""n"">TCPTimedOutError</span>

<span class=""k"">class</span> <span class=""nc"">ErrbackSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""errback_example""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s2"">""http://www.httpbin.org/""</span><span class=""p"">,</span>              <span class=""c1""># HTTP 200 expected</span>
        <span class=""s2"">""http://www.httpbin.org/status/404""</span><span class=""p"">,</span>    <span class=""c1""># Not found error</span>
        <span class=""s2"">""http://www.httpbin.org/status/500""</span><span class=""p"">,</span>    <span class=""c1""># server issue</span>
        <span class=""s2"">""http://www.httpbin.org:12345/""</span><span class=""p"">,</span>        <span class=""c1""># non-responding host, timeout expected</span>
        <span class=""s2"">""https://example.invalid/""</span><span class=""p"">,</span>             <span class=""c1""># DNS error expected</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">u</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">start_urls</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">u</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_httpbin</span><span class=""p"">,</span>
                                    <span class=""n"">errback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">errback_httpbin</span><span class=""p"">,</span>
                                    <span class=""n"">dont_filter</span><span class=""o"">=</span><span class=""kc"">True</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse_httpbin</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Got successful response from </span><span class=""si"">{}</span><span class=""s1"">'</span><span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">))</span>
        <span class=""c1""># do something useful here...</span>

    <span class=""k"">def</span> <span class=""nf"">errback_httpbin</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">failure</span><span class=""p"">):</span>
        <span class=""c1""># log all failures</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">error</span><span class=""p"">(</span><span class=""nb"">repr</span><span class=""p"">(</span><span class=""n"">failure</span><span class=""p"">))</span>

        <span class=""c1""># in case you want to do something special for some errors,</span>
        <span class=""c1""># you may need the failure's type:</span>

        <span class=""k"">if</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">check</span><span class=""p"">(</span><span class=""n"">HttpError</span><span class=""p"">):</span>
            <span class=""c1""># these exceptions come from HttpError spider middleware</span>
            <span class=""c1""># you can get the non-200 response</span>
            <span class=""n"">response</span> <span class=""o"">=</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">value</span><span class=""o"">.</span><span class=""n"">response</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">error</span><span class=""p"">(</span><span class=""s1"">'HttpError on </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>

        <span class=""k"">elif</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">check</span><span class=""p"">(</span><span class=""n"">DNSLookupError</span><span class=""p"">):</span>
            <span class=""c1""># this is the original request</span>
            <span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">request</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">error</span><span class=""p"">(</span><span class=""s1"">'DNSLookupError on </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>

        <span class=""k"">elif</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">check</span><span class=""p"">(</span><span class=""ne"">TimeoutError</span><span class=""p"">,</span> <span class=""n"">TCPTimedOutError</span><span class=""p"">):</span>
            <span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">request</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">error</span><span class=""p"">(</span><span class=""s1"">'TimeoutError on </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s1"">'http://www.example.com/index.html'</span><span class=""p"">,</span>
                             <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_page2</span><span class=""p"">,</span>
                             <span class=""n"">errback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">errback_page2</span><span class=""p"">,</span>
                             <span class=""n"">cb_kwargs</span><span class=""o"">=</span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">main_url</span><span class=""o"">=</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">))</span>
    <span class=""k"">yield</span> <span class=""n"">request</span>

<span class=""k"">def</span> <span class=""nf"">parse_page2</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">main_url</span><span class=""p"">):</span>
    <span class=""k"">pass</span>

<span class=""k"">def</span> <span class=""nf"">errback_page2</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">failure</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""nb"">dict</span><span class=""p"">(</span>
        <span class=""n"">main_url</span><span class=""o"">=</span><span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">cb_kwargs</span><span class=""p"">[</span><span class=""s1"">'main_url'</span><span class=""p"">],</span>
    <span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># my_project/settings.py</span>
<span class=""n"">REQUEST_FINGERPRINTER_CLASS</span> <span class=""o"">=</span> <span class=""s1"">'my_project.utils.RequestFingerprinter'</span>

<span class=""c1""># my_project/utils.py</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.request</span> <span class=""kn"">import</span> <span class=""n"">fingerprint</span>

<span class=""k"">class</span> <span class=""nc"">RequestFingerprinter</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""nf"">fingerprint</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""n"">fingerprint</span><span class=""p"">(</span><span class=""n"">request</span><span class=""p"">,</span> <span class=""n"">include_headers</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s1"">'X-ID'</span><span class=""p"">])</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">hashlib</span> <span class=""kn"">import</span> <span class=""n"">sha1</span>
<span class=""kn"">from</span> <span class=""nn"">weakref</span> <span class=""kn"">import</span> <span class=""n"">WeakKeyDictionary</span>

<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.python</span> <span class=""kn"">import</span> <span class=""n"">to_bytes</span>

<span class=""k"">class</span> <span class=""nc"">RequestFingerprinter</span><span class=""p"">:</span>

    <span class=""n"">cache</span> <span class=""o"">=</span> <span class=""n"">WeakKeyDictionary</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">fingerprint</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">request</span> <span class=""ow"">not</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">:</span>
            <span class=""n"">fp</span> <span class=""o"">=</span> <span class=""n"">sha1</span><span class=""p"">()</span>
            <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">update</span><span class=""p"">(</span><span class=""n"">to_bytes</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">))</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">[</span><span class=""n"">request</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">digest</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">[</span><span class=""n"">request</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.utils.request</span> <span class=""kn"">import</span> <span class=""n"">fingerprint</span>

<span class=""k"">class</span> <span class=""nc"">RequestFingerprinter</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""nf"">fingerprint</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""s1"">'fingerprint'</span> <span class=""ow"">in</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">meta</span><span class=""p"">:</span>
            <span class=""k"">return</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">meta</span><span class=""p"">[</span><span class=""s1"">'fingerprint'</span><span class=""p"">]</span>
        <span class=""k"">return</span> <span class=""n"">fingerprint</span><span class=""p"">(</span><span class=""n"">request</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">hashlib</span> <span class=""kn"">import</span> <span class=""n"">sha1</span>
<span class=""kn"">from</span> <span class=""nn"">weakref</span> <span class=""kn"">import</span> <span class=""n"">WeakKeyDictionary</span>

<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.python</span> <span class=""kn"">import</span> <span class=""n"">to_bytes</span>
<span class=""kn"">from</span> <span class=""nn"">w3lib.url</span> <span class=""kn"">import</span> <span class=""n"">canonicalize_url</span>

<span class=""k"">class</span> <span class=""nc"">RequestFingerprinter</span><span class=""p"">:</span>

    <span class=""n"">cache</span> <span class=""o"">=</span> <span class=""n"">WeakKeyDictionary</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">fingerprint</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">request</span> <span class=""ow"">not</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">:</span>
            <span class=""n"">fp</span> <span class=""o"">=</span> <span class=""n"">sha1</span><span class=""p"">()</span>
            <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">update</span><span class=""p"">(</span><span class=""n"">to_bytes</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">method</span><span class=""p"">))</span>
            <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">update</span><span class=""p"">(</span><span class=""n"">to_bytes</span><span class=""p"">(</span><span class=""n"">canonicalize_url</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)))</span>
            <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">update</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">body</span> <span class=""ow"">or</span> <span class=""sa"">b</span><span class=""s1"">''</span><span class=""p"">)</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">[</span><span class=""n"">request</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">digest</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">[</span><span class=""n"">request</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">/</span><span class=""n"">home</span><span class=""o"">/</span><span class=""n"">user</span><span class=""o"">/</span><span class=""n"">project</span><span class=""o"">/.</span><span class=""n"">scrapy</span><span class=""o"">/</span><span class=""n"">httpcache</span><span class=""o"">/</span><span class=""n"">my_spider</span><span class=""o"">/</span><span class=""mi"">01</span><span class=""o"">/</span><span class=""mi"">0123456789</span><span class=""n"">abcdef0123456789abcdef01234567</span><span class=""o"">/</span><span class=""n"">response_headers</span>
</pre></div>","request_with_cookies = Request(url=""http://www.example.com"",
                               cookies={'currency': 'USD', 'country': 'UY'})
,request_with_cookies = Request(url=""http://www.example.com"",
                               cookies=[{'name': 'currency',
                                        'value': 'USD',
                                        'domain': 'example.com',
                                        'path': '/currency'}])
,Request(
    url=""http://www.example.com"",
    cookies={'currency': 'USD', 'country': 'UY'},
    meta={'dont_merge_cookies': True},
)
,def parse_page1(self, response):
    return scrapy.Request(""http://www.example.com/some_page.html"",
                          callback=self.parse_page2)

def parse_page2(self, response):
    # this would log http://www.example.com/some_page.html
    self.logger.info(""Visited %s"", response.url)
,def parse(self, response):
    request = scrapy.Request('http://www.example.com/index.html',
                             callback=self.parse_page2,
                             cb_kwargs=dict(main_url=response.url))
    request.cb_kwargs['foo'] = 'bar'  # add more arguments for the callback
    yield request

def parse_page2(self, response, main_url, foo):
    yield dict(
        main_url=main_url,
        other_url=response.url,
        foo=foo,
    )
,import scrapy

from scrapy.spidermiddlewares.httperror import HttpError
from twisted.internet.error import DNSLookupError
from twisted.internet.error import TimeoutError, TCPTimedOutError

class ErrbackSpider(scrapy.Spider):
    name = ""errback_example""
    start_urls = [
        ""http://www.httpbin.org/"",              # HTTP 200 expected
        ""http://www.httpbin.org/status/404"",    # Not found error
        ""http://www.httpbin.org/status/500"",    # server issue
        ""http://www.httpbin.org:12345/"",        # non-responding host, timeout expected
        ""https://example.invalid/"",             # DNS error expected
    ]

    def start_requests(self):
        for u in self.start_urls:
            yield scrapy.Request(u, callback=self.parse_httpbin,
                                    errback=self.errback_httpbin,
                                    dont_filter=True)

    def parse_httpbin(self, response):
        self.logger.info('Got successful response from {}'.format(response.url))
        # do something useful here...

    def errback_httpbin(self, failure):
        # log all failures
        self.logger.error(repr(failure))

        # in case you want to do something special for some errors,
        # you may need the failure's type:

        if failure.check(HttpError):
            # these exceptions come from HttpError spider middleware
            # you can get the non-200 response
            response = failure.value.response
            self.logger.error('HttpError on %s', response.url)

        elif failure.check(DNSLookupError):
            # this is the original request
            request = failure.request
            self.logger.error('DNSLookupError on %s', request.url)

        elif failure.check(TimeoutError, TCPTimedOutError):
            request = failure.request
            self.logger.error('TimeoutError on %s', request.url)
,def parse(self, response):
    request = scrapy.Request('http://www.example.com/index.html',
                             callback=self.parse_page2,
                             errback=self.errback_page2,
                             cb_kwargs=dict(main_url=response.url))
    yield request

def parse_page2(self, response, main_url):
    pass

def errback_page2(self, failure):
    yield dict(
        main_url=failure.request.cb_kwargs['main_url'],
    )
,# my_project/settings.py
REQUEST_FINGERPRINTER_CLASS = 'my_project.utils.RequestFingerprinter'

# my_project/utils.py
from scrapy.utils.request import fingerprint

class RequestFingerprinter:

    def fingerprint(self, request):
        return fingerprint(request, include_headers=['X-ID'])
,from hashlib import sha1
from weakref import WeakKeyDictionary

from scrapy.utils.python import to_bytes

class RequestFingerprinter:

    cache = WeakKeyDictionary()

    def fingerprint(self, request):
        if request not in self.cache:
            fp = sha1()
            fp.update(to_bytes(request.url))
            self.cache[request] = fp.digest()
        return self.cache[request]
,from scrapy.utils.request import fingerprint

class RequestFingerprinter:

    def fingerprint(self, request):
        if 'fingerprint' in request.meta:
            return request.meta['fingerprint']
        return fingerprint(request)
,from hashlib import sha1
from weakref import WeakKeyDictionary

from scrapy.utils.python import to_bytes
from w3lib.url import canonicalize_url

class RequestFingerprinter:

    cache = WeakKeyDictionary()

    def fingerprint(self, request):
        if request not in self.cache:
            fp = sha1()
            fp.update(to_bytes(request.method))
            fp.update(to_bytes(canonicalize_url(request.url)))
            fp.update(request.body or b'')
            self.cache[request] = fp.digest()
        return self.cache[request]
,/home/user/project/.scrapy/httpcache/my_spider/01/0123456789abcdef0123456789abcdef01234567/response_headers
",12
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,Other functions related to requests,#other-functions-related-to-requests,,,3
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,Passing additional data to callback functions,#passing-additional-data-to-callback-functions,"<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse_page1</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""k"">return</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s2"">""http://www.example.com/some_page.html""</span><span class=""p"">,</span>
                          <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_page2</span><span class=""p"">)</span>

<span class=""k"">def</span> <span class=""nf"">parse_page2</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""c1""># this would log http://www.example.com/some_page.html</span>
    <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s2"">""Visited </span><span class=""si"">%s</span><span class=""s2"">""</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s1"">'http://www.example.com/index.html'</span><span class=""p"">,</span>
                             <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_page2</span><span class=""p"">,</span>
                             <span class=""n"">cb_kwargs</span><span class=""o"">=</span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">main_url</span><span class=""o"">=</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">))</span>
    <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">cb_kwargs</span><span class=""p"">[</span><span class=""s1"">'foo'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""s1"">'bar'</span>  <span class=""c1""># add more arguments for the callback</span>
    <span class=""k"">yield</span> <span class=""n"">request</span>

<span class=""k"">def</span> <span class=""nf"">parse_page2</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">main_url</span><span class=""p"">,</span> <span class=""n"">foo</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""nb"">dict</span><span class=""p"">(</span>
        <span class=""n"">main_url</span><span class=""o"">=</span><span class=""n"">main_url</span><span class=""p"">,</span>
        <span class=""n"">other_url</span><span class=""o"">=</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">,</span>
        <span class=""n"">foo</span><span class=""o"">=</span><span class=""n"">foo</span><span class=""p"">,</span>
    <span class=""p"">)</span>
</pre></div>","def parse_page1(self, response):
    return scrapy.Request(""http://www.example.com/some_page.html"",
                          callback=self.parse_page2)

def parse_page2(self, response):
    # this would log http://www.example.com/some_page.html
    self.logger.info(""Visited %s"", response.url)
,def parse(self, response):
    request = scrapy.Request('http://www.example.com/index.html',
                             callback=self.parse_page2,
                             cb_kwargs=dict(main_url=response.url))
    request.cb_kwargs['foo'] = 'bar'  # add more arguments for the callback
    yield request

def parse_page2(self, response, main_url, foo):
    yield dict(
        main_url=main_url,
        other_url=response.url,
        foo=foo,
    )
",2
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,Using errbacks to catch exceptions in request processing,#using-errbacks-to-catch-exceptions-in-request-processing,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""kn"">from</span> <span class=""nn"">scrapy.spidermiddlewares.httperror</span> <span class=""kn"">import</span> <span class=""n"">HttpError</span>
<span class=""kn"">from</span> <span class=""nn"">twisted.internet.error</span> <span class=""kn"">import</span> <span class=""n"">DNSLookupError</span>
<span class=""kn"">from</span> <span class=""nn"">twisted.internet.error</span> <span class=""kn"">import</span> <span class=""ne"">TimeoutError</span><span class=""p"">,</span> <span class=""n"">TCPTimedOutError</span>

<span class=""k"">class</span> <span class=""nc"">ErrbackSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""errback_example""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s2"">""http://www.httpbin.org/""</span><span class=""p"">,</span>              <span class=""c1""># HTTP 200 expected</span>
        <span class=""s2"">""http://www.httpbin.org/status/404""</span><span class=""p"">,</span>    <span class=""c1""># Not found error</span>
        <span class=""s2"">""http://www.httpbin.org/status/500""</span><span class=""p"">,</span>    <span class=""c1""># server issue</span>
        <span class=""s2"">""http://www.httpbin.org:12345/""</span><span class=""p"">,</span>        <span class=""c1""># non-responding host, timeout expected</span>
        <span class=""s2"">""https://example.invalid/""</span><span class=""p"">,</span>             <span class=""c1""># DNS error expected</span>
    <span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">u</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">start_urls</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">u</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_httpbin</span><span class=""p"">,</span>
                                    <span class=""n"">errback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">errback_httpbin</span><span class=""p"">,</span>
                                    <span class=""n"">dont_filter</span><span class=""o"">=</span><span class=""kc"">True</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse_httpbin</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Got successful response from </span><span class=""si"">{}</span><span class=""s1"">'</span><span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">))</span>
        <span class=""c1""># do something useful here...</span>

    <span class=""k"">def</span> <span class=""nf"">errback_httpbin</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">failure</span><span class=""p"">):</span>
        <span class=""c1""># log all failures</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">error</span><span class=""p"">(</span><span class=""nb"">repr</span><span class=""p"">(</span><span class=""n"">failure</span><span class=""p"">))</span>

        <span class=""c1""># in case you want to do something special for some errors,</span>
        <span class=""c1""># you may need the failure's type:</span>

        <span class=""k"">if</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">check</span><span class=""p"">(</span><span class=""n"">HttpError</span><span class=""p"">):</span>
            <span class=""c1""># these exceptions come from HttpError spider middleware</span>
            <span class=""c1""># you can get the non-200 response</span>
            <span class=""n"">response</span> <span class=""o"">=</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">value</span><span class=""o"">.</span><span class=""n"">response</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">error</span><span class=""p"">(</span><span class=""s1"">'HttpError on </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>

        <span class=""k"">elif</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">check</span><span class=""p"">(</span><span class=""n"">DNSLookupError</span><span class=""p"">):</span>
            <span class=""c1""># this is the original request</span>
            <span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">request</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">error</span><span class=""p"">(</span><span class=""s1"">'DNSLookupError on </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>

        <span class=""k"">elif</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">check</span><span class=""p"">(</span><span class=""ne"">TimeoutError</span><span class=""p"">,</span> <span class=""n"">TCPTimedOutError</span><span class=""p"">):</span>
            <span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">request</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">error</span><span class=""p"">(</span><span class=""s1"">'TimeoutError on </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>","import scrapy

from scrapy.spidermiddlewares.httperror import HttpError
from twisted.internet.error import DNSLookupError
from twisted.internet.error import TimeoutError, TCPTimedOutError

class ErrbackSpider(scrapy.Spider):
    name = ""errback_example""
    start_urls = [
        ""http://www.httpbin.org/"",              # HTTP 200 expected
        ""http://www.httpbin.org/status/404"",    # Not found error
        ""http://www.httpbin.org/status/500"",    # server issue
        ""http://www.httpbin.org:12345/"",        # non-responding host, timeout expected
        ""https://example.invalid/"",             # DNS error expected
    ]

    def start_requests(self):
        for u in self.start_urls:
            yield scrapy.Request(u, callback=self.parse_httpbin,
                                    errback=self.errback_httpbin,
                                    dont_filter=True)

    def parse_httpbin(self, response):
        self.logger.info('Got successful response from {}'.format(response.url))
        # do something useful here...

    def errback_httpbin(self, failure):
        # log all failures
        self.logger.error(repr(failure))

        # in case you want to do something special for some errors,
        # you may need the failure's type:

        if failure.check(HttpError):
            # these exceptions come from HttpError spider middleware
            # you can get the non-200 response
            response = failure.value.response
            self.logger.error('HttpError on %s', response.url)

        elif failure.check(DNSLookupError):
            # this is the original request
            request = failure.request
            self.logger.error('DNSLookupError on %s', request.url)

        elif failure.check(TimeoutError, TCPTimedOutError):
            request = failure.request
            self.logger.error('TimeoutError on %s', request.url)
",1
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,Accessing additional data in errback functions,#accessing-additional-data-in-errback-functions,"<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s1"">'http://www.example.com/index.html'</span><span class=""p"">,</span>
                             <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_page2</span><span class=""p"">,</span>
                             <span class=""n"">errback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">errback_page2</span><span class=""p"">,</span>
                             <span class=""n"">cb_kwargs</span><span class=""o"">=</span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">main_url</span><span class=""o"">=</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">))</span>
    <span class=""k"">yield</span> <span class=""n"">request</span>

<span class=""k"">def</span> <span class=""nf"">parse_page2</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">main_url</span><span class=""p"">):</span>
    <span class=""k"">pass</span>

<span class=""k"">def</span> <span class=""nf"">errback_page2</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">failure</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""nb"">dict</span><span class=""p"">(</span>
        <span class=""n"">main_url</span><span class=""o"">=</span><span class=""n"">failure</span><span class=""o"">.</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">cb_kwargs</span><span class=""p"">[</span><span class=""s1"">'main_url'</span><span class=""p"">],</span>
    <span class=""p"">)</span>
</pre></div>","def parse(self, response):
    request = scrapy.Request('http://www.example.com/index.html',
                             callback=self.parse_page2,
                             errback=self.errback_page2,
                             cb_kwargs=dict(main_url=response.url))
    yield request

def parse_page2(self, response, main_url):
    pass

def errback_page2(self, failure):
    yield dict(
        main_url=failure.request.cb_kwargs['main_url'],
    )
",1
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,Request fingerprints,#request-fingerprints,"<div class=""highlight""><pre><span></span><span class=""c1""># my_project/settings.py</span>
<span class=""n"">REQUEST_FINGERPRINTER_CLASS</span> <span class=""o"">=</span> <span class=""s1"">'my_project.utils.RequestFingerprinter'</span>

<span class=""c1""># my_project/utils.py</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.request</span> <span class=""kn"">import</span> <span class=""n"">fingerprint</span>

<span class=""k"">class</span> <span class=""nc"">RequestFingerprinter</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""nf"">fingerprint</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""n"">fingerprint</span><span class=""p"">(</span><span class=""n"">request</span><span class=""p"">,</span> <span class=""n"">include_headers</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s1"">'X-ID'</span><span class=""p"">])</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">hashlib</span> <span class=""kn"">import</span> <span class=""n"">sha1</span>
<span class=""kn"">from</span> <span class=""nn"">weakref</span> <span class=""kn"">import</span> <span class=""n"">WeakKeyDictionary</span>

<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.python</span> <span class=""kn"">import</span> <span class=""n"">to_bytes</span>

<span class=""k"">class</span> <span class=""nc"">RequestFingerprinter</span><span class=""p"">:</span>

    <span class=""n"">cache</span> <span class=""o"">=</span> <span class=""n"">WeakKeyDictionary</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">fingerprint</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">request</span> <span class=""ow"">not</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">:</span>
            <span class=""n"">fp</span> <span class=""o"">=</span> <span class=""n"">sha1</span><span class=""p"">()</span>
            <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">update</span><span class=""p"">(</span><span class=""n"">to_bytes</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">))</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">[</span><span class=""n"">request</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">digest</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">[</span><span class=""n"">request</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.utils.request</span> <span class=""kn"">import</span> <span class=""n"">fingerprint</span>

<span class=""k"">class</span> <span class=""nc"">RequestFingerprinter</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""nf"">fingerprint</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""s1"">'fingerprint'</span> <span class=""ow"">in</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">meta</span><span class=""p"">:</span>
            <span class=""k"">return</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">meta</span><span class=""p"">[</span><span class=""s1"">'fingerprint'</span><span class=""p"">]</span>
        <span class=""k"">return</span> <span class=""n"">fingerprint</span><span class=""p"">(</span><span class=""n"">request</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">hashlib</span> <span class=""kn"">import</span> <span class=""n"">sha1</span>
<span class=""kn"">from</span> <span class=""nn"">weakref</span> <span class=""kn"">import</span> <span class=""n"">WeakKeyDictionary</span>

<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.python</span> <span class=""kn"">import</span> <span class=""n"">to_bytes</span>
<span class=""kn"">from</span> <span class=""nn"">w3lib.url</span> <span class=""kn"">import</span> <span class=""n"">canonicalize_url</span>

<span class=""k"">class</span> <span class=""nc"">RequestFingerprinter</span><span class=""p"">:</span>

    <span class=""n"">cache</span> <span class=""o"">=</span> <span class=""n"">WeakKeyDictionary</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">fingerprint</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">request</span> <span class=""ow"">not</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">:</span>
            <span class=""n"">fp</span> <span class=""o"">=</span> <span class=""n"">sha1</span><span class=""p"">()</span>
            <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">update</span><span class=""p"">(</span><span class=""n"">to_bytes</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">method</span><span class=""p"">))</span>
            <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">update</span><span class=""p"">(</span><span class=""n"">to_bytes</span><span class=""p"">(</span><span class=""n"">canonicalize_url</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)))</span>
            <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">update</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">body</span> <span class=""ow"">or</span> <span class=""sa"">b</span><span class=""s1"">''</span><span class=""p"">)</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">[</span><span class=""n"">request</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">digest</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">[</span><span class=""n"">request</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">/</span><span class=""n"">home</span><span class=""o"">/</span><span class=""n"">user</span><span class=""o"">/</span><span class=""n"">project</span><span class=""o"">/.</span><span class=""n"">scrapy</span><span class=""o"">/</span><span class=""n"">httpcache</span><span class=""o"">/</span><span class=""n"">my_spider</span><span class=""o"">/</span><span class=""mi"">01</span><span class=""o"">/</span><span class=""mi"">0123456789</span><span class=""n"">abcdef0123456789abcdef01234567</span><span class=""o"">/</span><span class=""n"">response_headers</span>
</pre></div>","# my_project/settings.py
REQUEST_FINGERPRINTER_CLASS = 'my_project.utils.RequestFingerprinter'

# my_project/utils.py
from scrapy.utils.request import fingerprint

class RequestFingerprinter:

    def fingerprint(self, request):
        return fingerprint(request, include_headers=['X-ID'])
,from hashlib import sha1
from weakref import WeakKeyDictionary

from scrapy.utils.python import to_bytes

class RequestFingerprinter:

    cache = WeakKeyDictionary()

    def fingerprint(self, request):
        if request not in self.cache:
            fp = sha1()
            fp.update(to_bytes(request.url))
            self.cache[request] = fp.digest()
        return self.cache[request]
,from scrapy.utils.request import fingerprint

class RequestFingerprinter:

    def fingerprint(self, request):
        if 'fingerprint' in request.meta:
            return request.meta['fingerprint']
        return fingerprint(request)
,from hashlib import sha1
from weakref import WeakKeyDictionary

from scrapy.utils.python import to_bytes
from w3lib.url import canonicalize_url

class RequestFingerprinter:

    cache = WeakKeyDictionary()

    def fingerprint(self, request):
        if request not in self.cache:
            fp = sha1()
            fp.update(to_bytes(request.method))
            fp.update(to_bytes(canonicalize_url(request.url)))
            fp.update(request.body or b'')
            self.cache[request] = fp.digest()
        return self.cache[request]
,/home/user/project/.scrapy/httpcache/my_spider/01/0123456789abcdef0123456789abcdef01234567/response_headers
",5
https://docs.scrapy.org/en/latest/topics/request-response.html,,####,4,REQUEST_FINGERPRINTER_CLASS,#request-fingerprinter-class,,,8
https://docs.scrapy.org/en/latest/topics/request-response.html,,####,4,REQUEST_FINGERPRINTER_IMPLEMENTATION,#request-fingerprinter-implementation,,,9
https://docs.scrapy.org/en/latest/topics/request-response.html,,####,4,Writing your own request fingerprinter,#writing-your-own-request-fingerprinter,"<div class=""highlight""><pre><span></span><span class=""c1""># my_project/settings.py</span>
<span class=""n"">REQUEST_FINGERPRINTER_CLASS</span> <span class=""o"">=</span> <span class=""s1"">'my_project.utils.RequestFingerprinter'</span>

<span class=""c1""># my_project/utils.py</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.request</span> <span class=""kn"">import</span> <span class=""n"">fingerprint</span>

<span class=""k"">class</span> <span class=""nc"">RequestFingerprinter</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""nf"">fingerprint</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""n"">fingerprint</span><span class=""p"">(</span><span class=""n"">request</span><span class=""p"">,</span> <span class=""n"">include_headers</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s1"">'X-ID'</span><span class=""p"">])</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">hashlib</span> <span class=""kn"">import</span> <span class=""n"">sha1</span>
<span class=""kn"">from</span> <span class=""nn"">weakref</span> <span class=""kn"">import</span> <span class=""n"">WeakKeyDictionary</span>

<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.python</span> <span class=""kn"">import</span> <span class=""n"">to_bytes</span>

<span class=""k"">class</span> <span class=""nc"">RequestFingerprinter</span><span class=""p"">:</span>

    <span class=""n"">cache</span> <span class=""o"">=</span> <span class=""n"">WeakKeyDictionary</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">fingerprint</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">request</span> <span class=""ow"">not</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">:</span>
            <span class=""n"">fp</span> <span class=""o"">=</span> <span class=""n"">sha1</span><span class=""p"">()</span>
            <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">update</span><span class=""p"">(</span><span class=""n"">to_bytes</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">))</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">[</span><span class=""n"">request</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">digest</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">[</span><span class=""n"">request</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.utils.request</span> <span class=""kn"">import</span> <span class=""n"">fingerprint</span>

<span class=""k"">class</span> <span class=""nc"">RequestFingerprinter</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""nf"">fingerprint</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""s1"">'fingerprint'</span> <span class=""ow"">in</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">meta</span><span class=""p"">:</span>
            <span class=""k"">return</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">meta</span><span class=""p"">[</span><span class=""s1"">'fingerprint'</span><span class=""p"">]</span>
        <span class=""k"">return</span> <span class=""n"">fingerprint</span><span class=""p"">(</span><span class=""n"">request</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">hashlib</span> <span class=""kn"">import</span> <span class=""n"">sha1</span>
<span class=""kn"">from</span> <span class=""nn"">weakref</span> <span class=""kn"">import</span> <span class=""n"">WeakKeyDictionary</span>

<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.python</span> <span class=""kn"">import</span> <span class=""n"">to_bytes</span>
<span class=""kn"">from</span> <span class=""nn"">w3lib.url</span> <span class=""kn"">import</span> <span class=""n"">canonicalize_url</span>

<span class=""k"">class</span> <span class=""nc"">RequestFingerprinter</span><span class=""p"">:</span>

    <span class=""n"">cache</span> <span class=""o"">=</span> <span class=""n"">WeakKeyDictionary</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">fingerprint</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">request</span> <span class=""ow"">not</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">:</span>
            <span class=""n"">fp</span> <span class=""o"">=</span> <span class=""n"">sha1</span><span class=""p"">()</span>
            <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">update</span><span class=""p"">(</span><span class=""n"">to_bytes</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">method</span><span class=""p"">))</span>
            <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">update</span><span class=""p"">(</span><span class=""n"">to_bytes</span><span class=""p"">(</span><span class=""n"">canonicalize_url</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)))</span>
            <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">update</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">body</span> <span class=""ow"">or</span> <span class=""sa"">b</span><span class=""s1"">''</span><span class=""p"">)</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">[</span><span class=""n"">request</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">fp</span><span class=""o"">.</span><span class=""n"">digest</span><span class=""p"">()</span>
        <span class=""k"">return</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">cache</span><span class=""p"">[</span><span class=""n"">request</span><span class=""p"">]</span>
</pre></div>","# my_project/settings.py
REQUEST_FINGERPRINTER_CLASS = 'my_project.utils.RequestFingerprinter'

# my_project/utils.py
from scrapy.utils.request import fingerprint

class RequestFingerprinter:

    def fingerprint(self, request):
        return fingerprint(request, include_headers=['X-ID'])
,from hashlib import sha1
from weakref import WeakKeyDictionary

from scrapy.utils.python import to_bytes

class RequestFingerprinter:

    cache = WeakKeyDictionary()

    def fingerprint(self, request):
        if request not in self.cache:
            fp = sha1()
            fp.update(to_bytes(request.url))
            self.cache[request] = fp.digest()
        return self.cache[request]
,from scrapy.utils.request import fingerprint

class RequestFingerprinter:

    def fingerprint(self, request):
        if 'fingerprint' in request.meta:
            return request.meta['fingerprint']
        return fingerprint(request)
,from hashlib import sha1
from weakref import WeakKeyDictionary

from scrapy.utils.python import to_bytes
from w3lib.url import canonicalize_url

class RequestFingerprinter:

    cache = WeakKeyDictionary()

    def fingerprint(self, request):
        if request not in self.cache:
            fp = sha1()
            fp.update(to_bytes(request.method))
            fp.update(to_bytes(canonicalize_url(request.url)))
            fp.update(request.body or b'')
            self.cache[request] = fp.digest()
        return self.cache[request]
",4
https://docs.scrapy.org/en/latest/topics/request-response.html,,####,4,Request fingerprint restrictions,#request-fingerprint-restrictions,"<div class=""highlight""><pre><span></span><span class=""o"">/</span><span class=""n"">home</span><span class=""o"">/</span><span class=""n"">user</span><span class=""o"">/</span><span class=""n"">project</span><span class=""o"">/.</span><span class=""n"">scrapy</span><span class=""o"">/</span><span class=""n"">httpcache</span><span class=""o"">/</span><span class=""n"">my_spider</span><span class=""o"">/</span><span class=""mi"">01</span><span class=""o"">/</span><span class=""mi"">0123456789</span><span class=""n"">abcdef0123456789abcdef01234567</span><span class=""o"">/</span><span class=""n"">response_headers</span>
</pre></div>","/home/user/project/.scrapy/httpcache/my_spider/01/0123456789abcdef0123456789abcdef01234567/response_headers
",1
https://docs.scrapy.org/en/latest/topics/request-response.html,,##,2,Request.meta special keys,#request-meta-special-keys,,,12
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,bindaddress,#bindaddress,,,13
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,download_timeout,#download-timeout,,,14
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,download_latency,#download-latency,,,15
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,download_fail_on_dataloss,#download-fail-on-dataloss,,,16
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,max_retry_times,#max-retry-times,,,17
https://docs.scrapy.org/en/latest/topics/request-response.html,,##,2,Stopping the download of a Response,#stopping-the-download-of-a-response,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">StopSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""stop""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s2"">""https://docs.scrapy.org/en/latest/""</span><span class=""p"">]</span>

    <span class=""nd"">@classmethod</span>
    <span class=""k"">def</span> <span class=""nf"">from_crawler</span><span class=""p"">(</span><span class=""bp"">cls</span><span class=""p"">,</span> <span class=""n"">crawler</span><span class=""p"">):</span>
        <span class=""n"">spider</span> <span class=""o"">=</span> <span class=""nb"">super</span><span class=""p"">()</span><span class=""o"">.</span><span class=""n"">from_crawler</span><span class=""p"">(</span><span class=""n"">crawler</span><span class=""p"">)</span>
        <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">on_bytes_received</span><span class=""p"">,</span> <span class=""n"">signal</span><span class=""o"">=</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">bytes_received</span><span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""n"">spider</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""c1""># 'last_chars' show that the full response was not downloaded</span>
        <span class=""k"">yield</span> <span class=""p"">{</span><span class=""s2"">""len""</span><span class=""p"">:</span> <span class=""nb"">len</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">text</span><span class=""p"">),</span> <span class=""s2"">""last_chars""</span><span class=""p"">:</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">text</span><span class=""p"">[</span><span class=""o"">-</span><span class=""mi"">40</span><span class=""p"">:]}</span>

    <span class=""k"">def</span> <span class=""nf"">on_bytes_received</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">data</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""k"">raise</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">exceptions</span><span class=""o"">.</span><span class=""n"">StopDownload</span><span class=""p"">(</span><span class=""n"">fail</span><span class=""o"">=</span><span class=""kc"">False</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">2020</span><span class=""o"">-</span><span class=""mi"">05</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">17</span><span class=""p"">:</span><span class=""mi"">26</span><span class=""p"">:</span><span class=""mi"">12</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Spider</span> <span class=""n"">opened</span>
<span class=""mi"">2020</span><span class=""o"">-</span><span class=""mi"">05</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">17</span><span class=""p"">:</span><span class=""mi"">26</span><span class=""p"">:</span><span class=""mi"">12</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">logstats</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""mi"">0</span> <span class=""n"">pages</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">pages</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">),</span> <span class=""n"">scraped</span> <span class=""mi"">0</span> <span class=""n"">items</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">items</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">)</span>
<span class=""mi"">2020</span><span class=""o"">-</span><span class=""mi"">05</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">17</span><span class=""p"">:</span><span class=""mi"">26</span><span class=""p"">:</span><span class=""mi"">13</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">downloader</span><span class=""o"">.</span><span class=""n"">handlers</span><span class=""o"">.</span><span class=""n"">http11</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Download</span> <span class=""n"">stopped</span> <span class=""k"">for</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">docs</span><span class=""o"">.</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">org</span><span class=""o"">/</span><span class=""n"">en</span><span class=""o"">/</span><span class=""n"">latest</span><span class=""o"">/&gt;</span> <span class=""kn"">from</span> <span class=""nn"">signal</span> <span class=""n"">handler</span> <span class=""n"">StopSpider</span><span class=""o"">.</span><span class=""n"">on_bytes_received</span>
<span class=""mi"">2020</span><span class=""o"">-</span><span class=""mi"">05</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">17</span><span class=""p"">:</span><span class=""mi"">26</span><span class=""p"">:</span><span class=""mi"">13</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">docs</span><span class=""o"">.</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">org</span><span class=""o"">/</span><span class=""n"">en</span><span class=""o"">/</span><span class=""n"">latest</span><span class=""o"">/&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span> <span class=""p"">[</span><span class=""s1"">'download_stopped'</span><span class=""p"">]</span>
<span class=""mi"">2020</span><span class=""o"">-</span><span class=""mi"">05</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">17</span><span class=""p"">:</span><span class=""mi"">26</span><span class=""p"">:</span><span class=""mi"">13</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">scraper</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Scraped</span> <span class=""kn"">from</span> <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">docs</span><span class=""o"">.</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">org</span><span class=""o"">/</span><span class=""n"">en</span><span class=""o"">/</span><span class=""n"">latest</span><span class=""o"">/&gt;</span>
<span class=""p"">{</span><span class=""s1"">'len'</span><span class=""p"">:</span> <span class=""mi"">279</span><span class=""p"">,</span> <span class=""s1"">'last_chars'</span><span class=""p"">:</span> <span class=""s1"">'dth, initial-scale=1.0""&gt;</span><span class=""se"">\n</span><span class=""s1"">  </span><span class=""se"">\n</span><span class=""s1"">  &lt;title&gt;Scr'</span><span class=""p"">}</span>
<span class=""mi"">2020</span><span class=""o"">-</span><span class=""mi"">05</span><span class=""o"">-</span><span class=""mi"">19</span> <span class=""mi"">17</span><span class=""p"">:</span><span class=""mi"">26</span><span class=""p"">:</span><span class=""mi"">13</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Closing</span> <span class=""n"">spider</span> <span class=""p"">(</span><span class=""n"">finished</span><span class=""p"">)</span>
</pre></div>","import scrapy


class StopSpider(scrapy.Spider):
    name = ""stop""
    start_urls = [""https://docs.scrapy.org/en/latest/""]

    @classmethod
    def from_crawler(cls, crawler):
        spider = super().from_crawler(crawler)
        crawler.signals.connect(spider.on_bytes_received, signal=scrapy.signals.bytes_received)
        return spider

    def parse(self, response):
        # 'last_chars' show that the full response was not downloaded
        yield {""len"": len(response.text), ""last_chars"": response.text[-40:]}

    def on_bytes_received(self, data, request, spider):
        raise scrapy.exceptions.StopDownload(fail=False)
,2020-05-19 17:26:12 [scrapy.core.engine] INFO: Spider opened
2020-05-19 17:26:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-19 17:26:13 [scrapy.core.downloader.handlers.http11] DEBUG: Download stopped for <GET https://docs.scrapy.org/en/latest/> from signal handler StopSpider.on_bytes_received
2020-05-19 17:26:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://docs.scrapy.org/en/latest/> (referer: None) ['download_stopped']
2020-05-19 17:26:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://docs.scrapy.org/en/latest/>
{'len': 279, 'last_chars': 'dth, initial-scale=1.0"">\n  \n  <title>Scr'}
2020-05-19 17:26:13 [scrapy.core.engine] INFO: Closing spider (finished)
",2
https://docs.scrapy.org/en/latest/topics/request-response.html,,##,2,Request subclasses,#request-subclasses,"<div class=""highlight""><pre><span></span><span class=""k"">return</span> <span class=""p"">[</span><span class=""n"">FormRequest</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""s2"">""http://www.example.com/post/action""</span><span class=""p"">,</span>
                    <span class=""n"">formdata</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""s1"">'John Doe'</span><span class=""p"">,</span> <span class=""s1"">'age'</span><span class=""p"">:</span> <span class=""s1"">'27'</span><span class=""p"">},</span>
                    <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">after_post</span><span class=""p"">)]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">def</span> <span class=""nf"">authentication_failed</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">):</span>
    <span class=""c1""># TODO: Check the contents of the response and return True if it failed</span>
    <span class=""c1""># or False if it succeeded.</span>
    <span class=""k"">pass</span>

<span class=""k"">class</span> <span class=""nc"">LoginSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/users/login.php'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">FormRequest</span><span class=""o"">.</span><span class=""n"">from_response</span><span class=""p"">(</span>
            <span class=""n"">response</span><span class=""p"">,</span>
            <span class=""n"">formdata</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'username'</span><span class=""p"">:</span> <span class=""s1"">'john'</span><span class=""p"">,</span> <span class=""s1"">'password'</span><span class=""p"">:</span> <span class=""s1"">'secret'</span><span class=""p"">},</span>
            <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">after_login</span>
        <span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">after_login</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">authentication_failed</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">):</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">error</span><span class=""p"">(</span><span class=""s2"">""Login failed""</span><span class=""p"">)</span>
            <span class=""k"">return</span>

        <span class=""c1""># continue scraping with authenticated session...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">data</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'name1'</span><span class=""p"">:</span> <span class=""s1"">'value1'</span><span class=""p"">,</span>
    <span class=""s1"">'name2'</span><span class=""p"">:</span> <span class=""s1"">'value2'</span><span class=""p"">,</span>
<span class=""p"">}</span>
<span class=""k"">yield</span> <span class=""n"">JsonRequest</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""s1"">'http://www.example.com/post/action'</span><span class=""p"">,</span> <span class=""n"">data</span><span class=""o"">=</span><span class=""n"">data</span><span class=""p"">)</span>
</pre></div>","return [FormRequest(url=""http://www.example.com/post/action"",
                    formdata={'name': 'John Doe', 'age': '27'},
                    callback=self.after_post)]
,import scrapy

def authentication_failed(response):
    # TODO: Check the contents of the response and return True if it failed
    # or False if it succeeded.
    pass

class LoginSpider(scrapy.Spider):
    name = 'example.com'
    start_urls = ['http://www.example.com/users/login.php']

    def parse(self, response):
        return scrapy.FormRequest.from_response(
            response,
            formdata={'username': 'john', 'password': 'secret'},
            callback=self.after_login
        )

    def after_login(self, response):
        if authentication_failed(response):
            self.logger.error(""Login failed"")
            return

        # continue scraping with authenticated session...
,data = {
    'name1': 'value1',
    'name2': 'value2',
}
yield JsonRequest(url='http://www.example.com/post/action', data=data)
",3
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,FormRequest objects,#formrequest-objects,,,20
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,Request usage examples,#request-usage-examples,"<div class=""highlight""><pre><span></span><span class=""k"">return</span> <span class=""p"">[</span><span class=""n"">FormRequest</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""s2"">""http://www.example.com/post/action""</span><span class=""p"">,</span>
                    <span class=""n"">formdata</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""s1"">'John Doe'</span><span class=""p"">,</span> <span class=""s1"">'age'</span><span class=""p"">:</span> <span class=""s1"">'27'</span><span class=""p"">},</span>
                    <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">after_post</span><span class=""p"">)]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">def</span> <span class=""nf"">authentication_failed</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">):</span>
    <span class=""c1""># TODO: Check the contents of the response and return True if it failed</span>
    <span class=""c1""># or False if it succeeded.</span>
    <span class=""k"">pass</span>

<span class=""k"">class</span> <span class=""nc"">LoginSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/users/login.php'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">FormRequest</span><span class=""o"">.</span><span class=""n"">from_response</span><span class=""p"">(</span>
            <span class=""n"">response</span><span class=""p"">,</span>
            <span class=""n"">formdata</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'username'</span><span class=""p"">:</span> <span class=""s1"">'john'</span><span class=""p"">,</span> <span class=""s1"">'password'</span><span class=""p"">:</span> <span class=""s1"">'secret'</span><span class=""p"">},</span>
            <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">after_login</span>
        <span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">after_login</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">authentication_failed</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">):</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">error</span><span class=""p"">(</span><span class=""s2"">""Login failed""</span><span class=""p"">)</span>
            <span class=""k"">return</span>

        <span class=""c1""># continue scraping with authenticated session...</span>
</pre></div>","return [FormRequest(url=""http://www.example.com/post/action"",
                    formdata={'name': 'John Doe', 'age': '27'},
                    callback=self.after_post)]
,import scrapy

def authentication_failed(response):
    # TODO: Check the contents of the response and return True if it failed
    # or False if it succeeded.
    pass

class LoginSpider(scrapy.Spider):
    name = 'example.com'
    start_urls = ['http://www.example.com/users/login.php']

    def parse(self, response):
        return scrapy.FormRequest.from_response(
            response,
            formdata={'username': 'john', 'password': 'secret'},
            callback=self.after_login
        )

    def after_login(self, response):
        if authentication_failed(response):
            self.logger.error(""Login failed"")
            return

        # continue scraping with authenticated session...
",2
https://docs.scrapy.org/en/latest/topics/request-response.html,,####,4,Using FormRequest to send data via HTTP POST,#using-formrequest-to-send-data-via-http-post,"<div class=""highlight""><pre><span></span><span class=""k"">return</span> <span class=""p"">[</span><span class=""n"">FormRequest</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""s2"">""http://www.example.com/post/action""</span><span class=""p"">,</span>
                    <span class=""n"">formdata</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'name'</span><span class=""p"">:</span> <span class=""s1"">'John Doe'</span><span class=""p"">,</span> <span class=""s1"">'age'</span><span class=""p"">:</span> <span class=""s1"">'27'</span><span class=""p"">},</span>
                    <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">after_post</span><span class=""p"">)]</span>
</pre></div>","return [FormRequest(url=""http://www.example.com/post/action"",
                    formdata={'name': 'John Doe', 'age': '27'},
                    callback=self.after_post)]
",1
https://docs.scrapy.org/en/latest/topics/request-response.html,,####,4,Using FormRequest.from_response() to simulate a user login,#using-formrequest-from-response-to-simulate-a-user-login,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">def</span> <span class=""nf"">authentication_failed</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">):</span>
    <span class=""c1""># TODO: Check the contents of the response and return True if it failed</span>
    <span class=""c1""># or False if it succeeded.</span>
    <span class=""k"">pass</span>

<span class=""k"">class</span> <span class=""nc"">LoginSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example.com'</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://www.example.com/users/login.php'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">FormRequest</span><span class=""o"">.</span><span class=""n"">from_response</span><span class=""p"">(</span>
            <span class=""n"">response</span><span class=""p"">,</span>
            <span class=""n"">formdata</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'username'</span><span class=""p"">:</span> <span class=""s1"">'john'</span><span class=""p"">,</span> <span class=""s1"">'password'</span><span class=""p"">:</span> <span class=""s1"">'secret'</span><span class=""p"">},</span>
            <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">after_login</span>
        <span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">after_login</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">authentication_failed</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">):</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">error</span><span class=""p"">(</span><span class=""s2"">""Login failed""</span><span class=""p"">)</span>
            <span class=""k"">return</span>

        <span class=""c1""># continue scraping with authenticated session...</span>
</pre></div>","import scrapy

def authentication_failed(response):
    # TODO: Check the contents of the response and return True if it failed
    # or False if it succeeded.
    pass

class LoginSpider(scrapy.Spider):
    name = 'example.com'
    start_urls = ['http://www.example.com/users/login.php']

    def parse(self, response):
        return scrapy.FormRequest.from_response(
            response,
            formdata={'username': 'john', 'password': 'secret'},
            callback=self.after_login
        )

    def after_login(self, response):
        if authentication_failed(response):
            self.logger.error(""Login failed"")
            return

        # continue scraping with authenticated session...
",1
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,JsonRequest,#jsonrequest,,,24
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,JsonRequest usage example,#jsonrequest-usage-example,"<div class=""highlight""><pre><span></span><span class=""n"">data</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'name1'</span><span class=""p"">:</span> <span class=""s1"">'value1'</span><span class=""p"">,</span>
    <span class=""s1"">'name2'</span><span class=""p"">:</span> <span class=""s1"">'value2'</span><span class=""p"">,</span>
<span class=""p"">}</span>
<span class=""k"">yield</span> <span class=""n"">JsonRequest</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""s1"">'http://www.example.com/post/action'</span><span class=""p"">,</span> <span class=""n"">data</span><span class=""o"">=</span><span class=""n"">data</span><span class=""p"">)</span>
</pre></div>","data = {
    'name1': 'value1',
    'name2': 'value2',
}
yield JsonRequest(url='http://www.example.com/post/action', data=data)
",1
https://docs.scrapy.org/en/latest/topics/request-response.html,,##,2,Response objects,#response-objects,"<div class=""highlight""><pre><span></span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">headers</span><span class=""o"">.</span><span class=""n"">getlist</span><span class=""p"">(</span><span class=""s1"">'Set-Cookie'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">urllib</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""o"">.</span><span class=""n"">urljoin</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">url</span><span class=""p"">)</span>
</pre></div>","response.headers.getlist('Set-Cookie')
,urllib.parse.urljoin(response.url, url)
",2
https://docs.scrapy.org/en/latest/topics/request-response.html,,##,2,Response subclasses,#response-subclasses,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""nb"">str</span><span class=""p"">(</span><span class=""sa"">b</span><span class=""s1"">'body'</span><span class=""p"">)</span>
<span class=""go"">""b'body'""</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'p'</span><span class=""p"">)</span>
</pre></div>",">>> str(b'body')
""b'body'""
,response.xpath('//p')
,response.css('p')
",3
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,TextResponse objects,#textresponse-objects,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""nb"">str</span><span class=""p"">(</span><span class=""sa"">b</span><span class=""s1"">'body'</span><span class=""p"">)</span>
<span class=""go"">""b'body'""</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//p'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'p'</span><span class=""p"">)</span>
</pre></div>",">>> str(b'body')
""b'body'""
,response.xpath('//p')
,response.css('p')
",3
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,HtmlResponse objects,#htmlresponse-objects,,,29
https://docs.scrapy.org/en/latest/topics/request-response.html,,###,3,XmlResponse objects,#xmlresponse-objects,,,30
https://docs.scrapy.org/en/latest/topics/link-extractors.html,,#,1,Link Extractors,#link-extractors,"<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""k"">for</span> <span class=""n"">link</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">link_extractor</span><span class=""o"">.</span><span class=""n"">extract_links</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">yield</span> <span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">link</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.linkextractors</span> <span class=""kn"">import</span> <span class=""n"">LinkExtractor</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""javascript:goToPage('../other/page.html'); return false""</span><span class=""p"">&gt;</span>Link text<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">process_value</span><span class=""p"">(</span><span class=""n"">value</span><span class=""p"">):</span>
    <span class=""n"">m</span> <span class=""o"">=</span> <span class=""n"">re</span><span class=""o"">.</span><span class=""n"">search</span><span class=""p"">(</span><span class=""s2"">""javascript:goToPage\('(.*?)'""</span><span class=""p"">,</span> <span class=""n"">value</span><span class=""p"">)</span>
    <span class=""k"">if</span> <span class=""n"">m</span><span class=""p"">:</span>
        <span class=""k"">return</span> <span class=""n"">m</span><span class=""o"">.</span><span class=""n"">group</span><span class=""p"">(</span><span class=""mi"">1</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">a</span> <span class=""n"">href</span><span class=""o"">=</span><span class=""s2"">""https://example.com/nofollow.html#foo""</span> <span class=""n"">rel</span><span class=""o"">=</span><span class=""s2"">""nofollow""</span><span class=""o"">&gt;</span><span class=""n"">Dont</span> <span class=""n"">follow</span> <span class=""n"">this</span> <span class=""n"">one</span><span class=""o"">&lt;/</span><span class=""n"">a</span><span class=""o"">&gt;</span>
</pre></div>","def parse(self, response):
    for link in self.link_extractor.extract_links(response):
        yield Request(link.url, callback=self.parse)
,from scrapy.linkextractors import LinkExtractor
,<a href=""javascript:goToPage('../other/page.html'); return false"">Link text</a>
,def process_value(value):
    m = re.search(""javascript:goToPage\('(.*?)'"", value)
    if m:
        return m.group(1)
,<a href=""https://example.com/nofollow.html#foo"" rel=""nofollow"">Dont follow this one</a>
",5
https://docs.scrapy.org/en/latest/topics/link-extractors.html,,##,2,Link extractor reference,#module-scrapy.linkextractors,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.linkextractors</span> <span class=""kn"">import</span> <span class=""n"">LinkExtractor</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""javascript:goToPage('../other/page.html'); return false""</span><span class=""p"">&gt;</span>Link text<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">process_value</span><span class=""p"">(</span><span class=""n"">value</span><span class=""p"">):</span>
    <span class=""n"">m</span> <span class=""o"">=</span> <span class=""n"">re</span><span class=""o"">.</span><span class=""n"">search</span><span class=""p"">(</span><span class=""s2"">""javascript:goToPage\('(.*?)'""</span><span class=""p"">,</span> <span class=""n"">value</span><span class=""p"">)</span>
    <span class=""k"">if</span> <span class=""n"">m</span><span class=""p"">:</span>
        <span class=""k"">return</span> <span class=""n"">m</span><span class=""o"">.</span><span class=""n"">group</span><span class=""p"">(</span><span class=""mi"">1</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">a</span> <span class=""n"">href</span><span class=""o"">=</span><span class=""s2"">""https://example.com/nofollow.html#foo""</span> <span class=""n"">rel</span><span class=""o"">=</span><span class=""s2"">""nofollow""</span><span class=""o"">&gt;</span><span class=""n"">Dont</span> <span class=""n"">follow</span> <span class=""n"">this</span> <span class=""n"">one</span><span class=""o"">&lt;/</span><span class=""n"">a</span><span class=""o"">&gt;</span>
</pre></div>","from scrapy.linkextractors import LinkExtractor
,<a href=""javascript:goToPage('../other/page.html'); return false"">Link text</a>
,def process_value(value):
    m = re.search(""javascript:goToPage\('(.*?)'"", value)
    if m:
        return m.group(1)
,<a href=""https://example.com/nofollow.html#foo"" rel=""nofollow"">Dont follow this one</a>
",4
https://docs.scrapy.org/en/latest/topics/link-extractors.html,,###,3,LxmlLinkExtractor,#module-scrapy.linkextractors.lxmlhtml,"<div class=""highlight""><pre><span></span><span class=""p"">&lt;</span><span class=""nt"">a</span> <span class=""na"">href</span><span class=""o"">=</span><span class=""s"">""javascript:goToPage('../other/page.html'); return false""</span><span class=""p"">&gt;</span>Link text<span class=""p"">&lt;/</span><span class=""nt"">a</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">process_value</span><span class=""p"">(</span><span class=""n"">value</span><span class=""p"">):</span>
    <span class=""n"">m</span> <span class=""o"">=</span> <span class=""n"">re</span><span class=""o"">.</span><span class=""n"">search</span><span class=""p"">(</span><span class=""s2"">""javascript:goToPage\('(.*?)'""</span><span class=""p"">,</span> <span class=""n"">value</span><span class=""p"">)</span>
    <span class=""k"">if</span> <span class=""n"">m</span><span class=""p"">:</span>
        <span class=""k"">return</span> <span class=""n"">m</span><span class=""o"">.</span><span class=""n"">group</span><span class=""p"">(</span><span class=""mi"">1</span><span class=""p"">)</span>
</pre></div>","<a href=""javascript:goToPage('../other/page.html'); return false"">Link text</a>
,def process_value(value):
    m = re.search(""javascript:goToPage\('(.*?)'"", value)
    if m:
        return m.group(1)
",2
https://docs.scrapy.org/en/latest/topics/link-extractors.html,,###,3,Link,#module-scrapy.link,"<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">a</span> <span class=""n"">href</span><span class=""o"">=</span><span class=""s2"">""https://example.com/nofollow.html#foo""</span> <span class=""n"">rel</span><span class=""o"">=</span><span class=""s2"">""nofollow""</span><span class=""o"">&gt;</span><span class=""n"">Dont</span> <span class=""n"">follow</span> <span class=""n"">this</span> <span class=""n"">one</span><span class=""o"">&lt;/</span><span class=""n"">a</span><span class=""o"">&gt;</span>
</pre></div>","<a href=""https://example.com/nofollow.html#foo"" rel=""nofollow"">Dont follow this one</a>
",1
https://docs.scrapy.org/en/latest/topics/settings.html,,#,1,Settings,#settings,"<div class=""highlight""><pre><span></span>scrapy crawl myspider -s <span class=""nv"">LOG_FILE</span><span class=""o"">=</span>scrapy.log
</pre></div>,<div class=""highlight""><pre><span></span>class MySpider<span class=""o"">(</span>scrapy.Spider<span class=""o"">)</span>:
    <span class=""nv"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>

    <span class=""nv"">custom_settings</span> <span class=""o"">=</span> <span class=""o"">{</span>
        <span class=""s1"">'SOME_SETTING'</span>: <span class=""s1"">'some value'</span>,
    <span class=""o"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span>from mybot.pipelines.validate import ValidateMyItem
<span class=""nv"">ITEM_PIPELINES</span> <span class=""o"">=</span> <span class=""o"">{</span>
    <span class=""c1""># passing the classname...</span>
    ValidateMyItem: <span class=""m"">300</span>,
    <span class=""c1""># ...equals passing the class path</span>
    <span class=""s1"">'mybot.pipelines.validate.ValidateMyItem'</span>: <span class=""m"">300</span>,
<span class=""o"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://example.com'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""nb"">print</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s2"">""Existing settings: </span><span class=""si"">{</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">attributes</span><span class=""o"">.</span><span class=""n"">keys</span><span class=""p"">()</span><span class=""si"">}</span><span class=""s2"">""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MyExtension</span><span class=""p"">:</span>
    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">log_is_enabled</span><span class=""o"">=</span><span class=""kc"">False</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">log_is_enabled</span><span class=""p"">:</span>
            <span class=""nb"">print</span><span class=""p"">(</span><span class=""s2"">""log is enabled!""</span><span class=""p"">)</span>

    <span class=""nd"">@classmethod</span>
    <span class=""k"">def</span> <span class=""nf"">from_crawler</span><span class=""p"">(</span><span class=""bp"">cls</span><span class=""p"">,</span> <span class=""n"">crawler</span><span class=""p"">):</span>
        <span class=""n"">settings</span> <span class=""o"">=</span> <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">settings</span>
        <span class=""k"">return</span> <span class=""bp"">cls</span><span class=""p"">(</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">getbool</span><span class=""p"">(</span><span class=""s1"">'LOG_ENABLED'</span><span class=""p"">))</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'Accept'</span><span class=""p"">:</span> <span class=""s1"">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span><span class=""p"">,</span>
    <span class=""s1"">'Accept-Language'</span><span class=""p"">:</span> <span class=""s1"">'en'</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">priority</span> <span class=""o"">=</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">priority</span> <span class=""o"">-</span> <span class=""p"">(</span> <span class=""n"">depth</span> <span class=""o"">*</span> <span class=""n"">DEPTH_PRIORITY</span> <span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware'</span><span class=""p"">:</span> <span class=""mi"">100</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware'</span><span class=""p"">:</span> <span class=""mi"">300</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware'</span><span class=""p"">:</span> <span class=""mi"">350</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware'</span><span class=""p"">:</span> <span class=""mi"">400</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span><span class=""p"">:</span> <span class=""mi"">500</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.retry.RetryMiddleware'</span><span class=""p"">:</span> <span class=""mi"">550</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware'</span><span class=""p"">:</span> <span class=""mi"">560</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware'</span><span class=""p"">:</span> <span class=""mi"">580</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span><span class=""p"">:</span> <span class=""mi"">590</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'</span><span class=""p"">:</span> <span class=""mi"">600</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.cookies.CookiesMiddleware'</span><span class=""p"">:</span> <span class=""mi"">700</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware'</span><span class=""p"">:</span> <span class=""mi"">750</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.stats.DownloaderStats'</span><span class=""p"">:</span> <span class=""mi"">850</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware'</span><span class=""p"">:</span> <span class=""mi"">900</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">DOWNLOAD_DELAY</span> <span class=""o"">=</span> <span class=""mf"">0.25</span>    <span class=""c1""># 250 ms of delay</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'data'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.datauri.DataURIDownloadHandler'</span><span class=""p"">,</span>
    <span class=""s1"">'file'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.file.FileDownloadHandler'</span><span class=""p"">,</span>
    <span class=""s1"">'http'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.http.HTTPDownloadHandler'</span><span class=""p"">,</span>
    <span class=""s1"">'https'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.http.HTTPDownloadHandler'</span><span class=""p"">,</span>
    <span class=""s1"">'s3'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.s3.S3DownloadHandler'</span><span class=""p"">,</span>
    <span class=""s1"">'ftp'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.ftp.FTPDownloadHandler'</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">DOWNLOAD_HANDLERS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'ftp'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">DOWNLOAD_HANDLERS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'https'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.http2.H2DownloadHandler'</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'scrapy.extensions.corestats.CoreStats'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.telnet.TelnetConsole'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.memusage.MemoryUsage'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.memdebug.MemoryDebugger'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.closespider.CloseSpider'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.feedexport.FeedExporter'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.logstats.LogStats'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.spiderstate.SpiderState'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.throttle.AutoThrottle'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">ITEM_PIPELINES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'mybot.pipelines.validate.ValidateMyItem'</span><span class=""p"">:</span> <span class=""mi"">300</span><span class=""p"">,</span>
    <span class=""s1"">'mybot.pipelines.validate.StoreMyItem'</span><span class=""p"">:</span> <span class=""mi"">800</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">MEMDEBUG_NOTIFY</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'user@example.com'</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">MEMUSAGE_NOTIFY_MAIL</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'user@example.com'</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">NEWSPIDER_MODULE</span> <span class=""o"">=</span> <span class=""s1"">'mybot.spiders_dev'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">1956</span><span class=""o"">-</span><span class=""mi"">01</span><span class=""o"">-</span><span class=""mi"">31</span> <span class=""mi"">00</span><span class=""p"">:</span><span class=""mi"">00</span><span class=""p"">:</span><span class=""mi"">00</span><span class=""o"">+</span><span class=""mi"">0800</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">scheduler</span><span class=""p"">]</span> <span class=""n"">ERROR</span><span class=""p"">:</span> <span class=""n"">Unable</span> <span class=""n"">to</span> <span class=""n"">serialize</span> <span class=""n"">request</span><span class=""p"">:</span>
<span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">&gt;</span> <span class=""o"">-</span> <span class=""n"">reason</span><span class=""p"">:</span> <span class=""n"">cannot</span> <span class=""n"">serialize</span> <span class=""o"">&lt;</span><span class=""n"">Request</span> <span class=""n"">at</span> <span class=""mh"">0x9a7c7ec</span><span class=""o"">&gt;</span>
<span class=""p"">(</span><span class=""nb"">type</span> <span class=""n"">Request</span><span class=""p"">)</span><span class=""o"">&gt;</span> <span class=""o"">-</span> <span class=""n"">no</span> <span class=""n"">more</span> <span class=""n"">unserializable</span> <span class=""n"">requests</span> <span class=""n"">will</span> <span class=""n"">be</span> <span class=""n"">logged</span>
<span class=""p"">(</span><span class=""n"">see</span> <span class=""s1"">'scheduler/unserializable'</span> <span class=""n"">stats</span> <span class=""n"">counter</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'scrapy.contracts.default.UrlContract'</span> <span class=""p"">:</span> <span class=""mi"">1</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.contracts.default.ReturnsContract'</span><span class=""p"">:</span> <span class=""mi"">2</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.contracts.default.ScrapesContract'</span><span class=""p"">:</span> <span class=""mi"">3</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">SPIDER_CONTRACTS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'scrapy.contracts.default.ScrapesContract'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware'</span><span class=""p"">:</span> <span class=""mi"">50</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class=""p"">:</span> <span class=""mi"">500</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.spidermiddlewares.referer.RefererMiddleware'</span><span class=""p"">:</span> <span class=""mi"">700</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware'</span><span class=""p"">:</span> <span class=""mi"">800</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.spidermiddlewares.depth.DepthMiddleware'</span><span class=""p"">:</span> <span class=""mi"">900</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">SPIDER_MODULES</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'mybot.spiders_prod'</span><span class=""p"">,</span> <span class=""s1"">'mybot.spiders_dev'</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">twisted.internet</span> <span class=""kn"">import</span> <span class=""n"">reactor</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'quotes'</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">timeout</span> <span class=""o"">=</span> <span class=""nb"">int</span><span class=""p"">(</span><span class=""n"">kwargs</span><span class=""o"">.</span><span class=""n"">pop</span><span class=""p"">(</span><span class=""s1"">'timeout'</span><span class=""p"">,</span> <span class=""s1"">'60'</span><span class=""p"">))</span>
        <span class=""nb"">super</span><span class=""p"">(</span><span class=""n"">QuotesSpider</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""p"">)</span><span class=""o"">.</span><span class=""fm"">__init__</span><span class=""p"">(</span><span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">callLater</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">timeout</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">stop</span><span class=""p"">)</span>

        <span class=""n"">urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://quotes.toscrape.com/page/1'</span><span class=""p"">]</span>
        <span class=""k"">for</span> <span class=""n"">url</span> <span class=""ow"">in</span> <span class=""n"">urls</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span><span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()}</span>

    <span class=""k"">def</span> <span class=""nf"">stop</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""o"">.</span><span class=""n"">close_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""s1"">'timeout'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'quotes'</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">timeout</span> <span class=""o"">=</span> <span class=""nb"">int</span><span class=""p"">(</span><span class=""n"">kwargs</span><span class=""o"">.</span><span class=""n"">pop</span><span class=""p"">(</span><span class=""s1"">'timeout'</span><span class=""p"">,</span> <span class=""s1"">'60'</span><span class=""p"">))</span>
        <span class=""nb"">super</span><span class=""p"">(</span><span class=""n"">QuotesSpider</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""p"">)</span><span class=""o"">.</span><span class=""fm"">__init__</span><span class=""p"">(</span><span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""kn"">from</span> <span class=""nn"">twisted.internet</span> <span class=""kn"">import</span> <span class=""n"">reactor</span>
        <span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">callLater</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">timeout</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">stop</span><span class=""p"">)</span>

        <span class=""n"">urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://quotes.toscrape.com/page/1'</span><span class=""p"">]</span>
        <span class=""k"">for</span> <span class=""n"">url</span> <span class=""ow"">in</span> <span class=""n"">urls</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span><span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()}</span>

    <span class=""k"">def</span> <span class=""nf"">stop</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""o"">.</span><span class=""n"">close_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""s1"">'timeout'</span><span class=""p"">)</span>
</pre></div>","scrapy crawl myspider -s LOG_FILE=scrapy.log
,class MySpider(scrapy.Spider):
    name = 'myspider'

    custom_settings = {
        'SOME_SETTING': 'some value',
    }
,from mybot.pipelines.validate import ValidateMyItem
ITEM_PIPELINES = {
    # passing the classname...
    ValidateMyItem: 300,
    # ...equals passing the class path
    'mybot.pipelines.validate.ValidateMyItem': 300,
}
,class MySpider(scrapy.Spider):
    name = 'myspider'
    start_urls = ['http://example.com']

    def parse(self, response):
        print(f""Existing settings: {self.settings.attributes.keys()}"")
,class MyExtension:
    def __init__(self, log_is_enabled=False):
        if log_is_enabled:
            print(""log is enabled!"")

    @classmethod
    def from_crawler(cls, crawler):
        settings = crawler.settings
        return cls(settings.getbool('LOG_ENABLED'))
,{
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'en',
}
,request.priority = request.priority - ( depth * DEPTH_PRIORITY )
,{
    'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware': 100,
    'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware': 300,
    'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware': 350,
    'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware': 400,
    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': 500,
    'scrapy.downloadermiddlewares.retry.RetryMiddleware': 550,
    'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware': 560,
    'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware': 580,
    'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware': 590,
    'scrapy.downloadermiddlewares.redirect.RedirectMiddleware': 600,
    'scrapy.downloadermiddlewares.cookies.CookiesMiddleware': 700,
    'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware': 750,
    'scrapy.downloadermiddlewares.stats.DownloaderStats': 850,
    'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware': 900,
}
,DOWNLOAD_DELAY = 0.25    # 250 ms of delay
,{
    'data': 'scrapy.core.downloader.handlers.datauri.DataURIDownloadHandler',
    'file': 'scrapy.core.downloader.handlers.file.FileDownloadHandler',
    'http': 'scrapy.core.downloader.handlers.http.HTTPDownloadHandler',
    'https': 'scrapy.core.downloader.handlers.http.HTTPDownloadHandler',
    's3': 'scrapy.core.downloader.handlers.s3.S3DownloadHandler',
    'ftp': 'scrapy.core.downloader.handlers.ftp.FTPDownloadHandler',
}
,DOWNLOAD_HANDLERS = {
    'ftp': None,
}
,DOWNLOAD_HANDLERS = {
    'https': 'scrapy.core.downloader.handlers.http2.H2DownloadHandler',
}
,{
    'scrapy.extensions.corestats.CoreStats': 0,
    'scrapy.extensions.telnet.TelnetConsole': 0,
    'scrapy.extensions.memusage.MemoryUsage': 0,
    'scrapy.extensions.memdebug.MemoryDebugger': 0,
    'scrapy.extensions.closespider.CloseSpider': 0,
    'scrapy.extensions.feedexport.FeedExporter': 0,
    'scrapy.extensions.logstats.LogStats': 0,
    'scrapy.extensions.spiderstate.SpiderState': 0,
    'scrapy.extensions.throttle.AutoThrottle': 0,
}
,ITEM_PIPELINES = {
    'mybot.pipelines.validate.ValidateMyItem': 300,
    'mybot.pipelines.validate.StoreMyItem': 800,
}
,MEMDEBUG_NOTIFY = ['user@example.com']
,MEMUSAGE_NOTIFY_MAIL = ['user@example.com']
,NEWSPIDER_MODULE = 'mybot.spiders_dev'
,1956-01-31 00:00:00+0800 [scrapy.core.scheduler] ERROR: Unable to serialize request:
<GET http://example.com> - reason: cannot serialize <Request at 0x9a7c7ec>
(type Request)> - no more unserializable requests will be logged
(see 'scheduler/unserializable' stats counter)
,{
    'scrapy.contracts.default.UrlContract' : 1,
    'scrapy.contracts.default.ReturnsContract': 2,
    'scrapy.contracts.default.ScrapesContract': 3,
}
,SPIDER_CONTRACTS = {
    'scrapy.contracts.default.ScrapesContract': None,
}
,{
    'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware': 50,
    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': 500,
    'scrapy.spidermiddlewares.referer.RefererMiddleware': 700,
    'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware': 800,
    'scrapy.spidermiddlewares.depth.DepthMiddleware': 900,
}
,SPIDER_MODULES = ['mybot.spiders_prod', 'mybot.spiders_dev']
,import scrapy
from twisted.internet import reactor


class QuotesSpider(scrapy.Spider):
    name = 'quotes'

    def __init__(self, *args, **kwargs):
        self.timeout = int(kwargs.pop('timeout', '60'))
        super(QuotesSpider, self).__init__(*args, **kwargs)

    def start_requests(self):
        reactor.callLater(self.timeout, self.stop)

        urls = ['https://quotes.toscrape.com/page/1']
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {'text': quote.css('span.text::text').get()}

    def stop(self):
        self.crawler.engine.close_spider(self, 'timeout')
,import scrapy


class QuotesSpider(scrapy.Spider):
    name = 'quotes'

    def __init__(self, *args, **kwargs):
        self.timeout = int(kwargs.pop('timeout', '60'))
        super(QuotesSpider, self).__init__(*args, **kwargs)

    def start_requests(self):
        from twisted.internet import reactor
        reactor.callLater(self.timeout, self.stop)

        urls = ['https://quotes.toscrape.com/page/1']
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {'text': quote.css('span.text::text').get()}

    def stop(self):
        self.crawler.engine.close_spider(self, 'timeout')
",24
https://docs.scrapy.org/en/latest/topics/settings.html,,##,2,Designating the settings,#designating-the-settings,,,2
https://docs.scrapy.org/en/latest/topics/settings.html,,##,2,Populating the settings,#populating-the-settings,"<div class=""highlight""><pre><span></span>scrapy crawl myspider -s <span class=""nv"">LOG_FILE</span><span class=""o"">=</span>scrapy.log
</pre></div>,<div class=""highlight""><pre><span></span>class MySpider<span class=""o"">(</span>scrapy.Spider<span class=""o"">)</span>:
    <span class=""nv"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>

    <span class=""nv"">custom_settings</span> <span class=""o"">=</span> <span class=""o"">{</span>
        <span class=""s1"">'SOME_SETTING'</span>: <span class=""s1"">'some value'</span>,
    <span class=""o"">}</span>
</pre></div>","scrapy crawl myspider -s LOG_FILE=scrapy.log
,class MySpider(scrapy.Spider):
    name = 'myspider'

    custom_settings = {
        'SOME_SETTING': 'some value',
    }
",2
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,1. Command line options,#command-line-options,"<div class=""highlight""><pre><span></span>scrapy crawl myspider -s <span class=""nv"">LOG_FILE</span><span class=""o"">=</span>scrapy.log
</pre></div>","scrapy crawl myspider -s LOG_FILE=scrapy.log
",1
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,2. Settings per-spider,#settings-per-spider,"<div class=""highlight""><pre><span></span>class MySpider<span class=""o"">(</span>scrapy.Spider<span class=""o"">)</span>:
    <span class=""nv"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>

    <span class=""nv"">custom_settings</span> <span class=""o"">=</span> <span class=""o"">{</span>
        <span class=""s1"">'SOME_SETTING'</span>: <span class=""s1"">'some value'</span>,
    <span class=""o"">}</span>
</pre></div>","class MySpider(scrapy.Spider):
    name = 'myspider'

    custom_settings = {
        'SOME_SETTING': 'some value',
    }
",1
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,3. Project settings module,#project-settings-module,,,6
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,4. Default settings per-command,#default-settings-per-command,,,7
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,5. Default global settings,#default-global-settings,,,8
https://docs.scrapy.org/en/latest/topics/settings.html,,##,2,Compatibility with pickle,#compatibility-with-pickle,,,9
https://docs.scrapy.org/en/latest/topics/settings.html,,##,2,Import paths and classes,#import-paths-and-classes,"<div class=""highlight""><pre><span></span>from mybot.pipelines.validate import ValidateMyItem
<span class=""nv"">ITEM_PIPELINES</span> <span class=""o"">=</span> <span class=""o"">{</span>
    <span class=""c1""># passing the classname...</span>
    ValidateMyItem: <span class=""m"">300</span>,
    <span class=""c1""># ...equals passing the class path</span>
    <span class=""s1"">'mybot.pipelines.validate.ValidateMyItem'</span>: <span class=""m"">300</span>,
<span class=""o"">}</span>
</pre></div>","from mybot.pipelines.validate import ValidateMyItem
ITEM_PIPELINES = {
    # passing the classname...
    ValidateMyItem: 300,
    # ...equals passing the class path
    'mybot.pipelines.validate.ValidateMyItem': 300,
}
",1
https://docs.scrapy.org/en/latest/topics/settings.html,,##,2,How to access settings,#how-to-access-settings,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'http://example.com'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""nb"">print</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s2"">""Existing settings: </span><span class=""si"">{</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">attributes</span><span class=""o"">.</span><span class=""n"">keys</span><span class=""p"">()</span><span class=""si"">}</span><span class=""s2"">""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MyExtension</span><span class=""p"">:</span>
    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">log_is_enabled</span><span class=""o"">=</span><span class=""kc"">False</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">log_is_enabled</span><span class=""p"">:</span>
            <span class=""nb"">print</span><span class=""p"">(</span><span class=""s2"">""log is enabled!""</span><span class=""p"">)</span>

    <span class=""nd"">@classmethod</span>
    <span class=""k"">def</span> <span class=""nf"">from_crawler</span><span class=""p"">(</span><span class=""bp"">cls</span><span class=""p"">,</span> <span class=""n"">crawler</span><span class=""p"">):</span>
        <span class=""n"">settings</span> <span class=""o"">=</span> <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">settings</span>
        <span class=""k"">return</span> <span class=""bp"">cls</span><span class=""p"">(</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">getbool</span><span class=""p"">(</span><span class=""s1"">'LOG_ENABLED'</span><span class=""p"">))</span>
</pre></div>","class MySpider(scrapy.Spider):
    name = 'myspider'
    start_urls = ['http://example.com']

    def parse(self, response):
        print(f""Existing settings: {self.settings.attributes.keys()}"")
,class MyExtension:
    def __init__(self, log_is_enabled=False):
        if log_is_enabled:
            print(""log is enabled!"")

    @classmethod
    def from_crawler(cls, crawler):
        settings = crawler.settings
        return cls(settings.getbool('LOG_ENABLED'))
",2
https://docs.scrapy.org/en/latest/topics/settings.html,,##,2,Rationale for setting names,#rationale-for-setting-names,,,12
https://docs.scrapy.org/en/latest/topics/settings.html,,##,2,Built-in settings reference,#built-in-settings-reference,"<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'Accept'</span><span class=""p"">:</span> <span class=""s1"">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span><span class=""p"">,</span>
    <span class=""s1"">'Accept-Language'</span><span class=""p"">:</span> <span class=""s1"">'en'</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">priority</span> <span class=""o"">=</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">priority</span> <span class=""o"">-</span> <span class=""p"">(</span> <span class=""n"">depth</span> <span class=""o"">*</span> <span class=""n"">DEPTH_PRIORITY</span> <span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware'</span><span class=""p"">:</span> <span class=""mi"">100</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware'</span><span class=""p"">:</span> <span class=""mi"">300</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware'</span><span class=""p"">:</span> <span class=""mi"">350</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware'</span><span class=""p"">:</span> <span class=""mi"">400</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span><span class=""p"">:</span> <span class=""mi"">500</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.retry.RetryMiddleware'</span><span class=""p"">:</span> <span class=""mi"">550</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware'</span><span class=""p"">:</span> <span class=""mi"">560</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware'</span><span class=""p"">:</span> <span class=""mi"">580</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span><span class=""p"">:</span> <span class=""mi"">590</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'</span><span class=""p"">:</span> <span class=""mi"">600</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.cookies.CookiesMiddleware'</span><span class=""p"">:</span> <span class=""mi"">700</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware'</span><span class=""p"">:</span> <span class=""mi"">750</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.stats.DownloaderStats'</span><span class=""p"">:</span> <span class=""mi"">850</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware'</span><span class=""p"">:</span> <span class=""mi"">900</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">DOWNLOAD_DELAY</span> <span class=""o"">=</span> <span class=""mf"">0.25</span>    <span class=""c1""># 250 ms of delay</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'data'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.datauri.DataURIDownloadHandler'</span><span class=""p"">,</span>
    <span class=""s1"">'file'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.file.FileDownloadHandler'</span><span class=""p"">,</span>
    <span class=""s1"">'http'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.http.HTTPDownloadHandler'</span><span class=""p"">,</span>
    <span class=""s1"">'https'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.http.HTTPDownloadHandler'</span><span class=""p"">,</span>
    <span class=""s1"">'s3'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.s3.S3DownloadHandler'</span><span class=""p"">,</span>
    <span class=""s1"">'ftp'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.ftp.FTPDownloadHandler'</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">DOWNLOAD_HANDLERS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'ftp'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">DOWNLOAD_HANDLERS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'https'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.http2.H2DownloadHandler'</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'scrapy.extensions.corestats.CoreStats'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.telnet.TelnetConsole'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.memusage.MemoryUsage'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.memdebug.MemoryDebugger'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.closespider.CloseSpider'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.feedexport.FeedExporter'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.logstats.LogStats'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.spiderstate.SpiderState'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.throttle.AutoThrottle'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">ITEM_PIPELINES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'mybot.pipelines.validate.ValidateMyItem'</span><span class=""p"">:</span> <span class=""mi"">300</span><span class=""p"">,</span>
    <span class=""s1"">'mybot.pipelines.validate.StoreMyItem'</span><span class=""p"">:</span> <span class=""mi"">800</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">MEMDEBUG_NOTIFY</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'user@example.com'</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">MEMUSAGE_NOTIFY_MAIL</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'user@example.com'</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">NEWSPIDER_MODULE</span> <span class=""o"">=</span> <span class=""s1"">'mybot.spiders_dev'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">1956</span><span class=""o"">-</span><span class=""mi"">01</span><span class=""o"">-</span><span class=""mi"">31</span> <span class=""mi"">00</span><span class=""p"">:</span><span class=""mi"">00</span><span class=""p"">:</span><span class=""mi"">00</span><span class=""o"">+</span><span class=""mi"">0800</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">scheduler</span><span class=""p"">]</span> <span class=""n"">ERROR</span><span class=""p"">:</span> <span class=""n"">Unable</span> <span class=""n"">to</span> <span class=""n"">serialize</span> <span class=""n"">request</span><span class=""p"">:</span>
<span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">&gt;</span> <span class=""o"">-</span> <span class=""n"">reason</span><span class=""p"">:</span> <span class=""n"">cannot</span> <span class=""n"">serialize</span> <span class=""o"">&lt;</span><span class=""n"">Request</span> <span class=""n"">at</span> <span class=""mh"">0x9a7c7ec</span><span class=""o"">&gt;</span>
<span class=""p"">(</span><span class=""nb"">type</span> <span class=""n"">Request</span><span class=""p"">)</span><span class=""o"">&gt;</span> <span class=""o"">-</span> <span class=""n"">no</span> <span class=""n"">more</span> <span class=""n"">unserializable</span> <span class=""n"">requests</span> <span class=""n"">will</span> <span class=""n"">be</span> <span class=""n"">logged</span>
<span class=""p"">(</span><span class=""n"">see</span> <span class=""s1"">'scheduler/unserializable'</span> <span class=""n"">stats</span> <span class=""n"">counter</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'scrapy.contracts.default.UrlContract'</span> <span class=""p"">:</span> <span class=""mi"">1</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.contracts.default.ReturnsContract'</span><span class=""p"">:</span> <span class=""mi"">2</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.contracts.default.ScrapesContract'</span><span class=""p"">:</span> <span class=""mi"">3</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">SPIDER_CONTRACTS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'scrapy.contracts.default.ScrapesContract'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware'</span><span class=""p"">:</span> <span class=""mi"">50</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class=""p"">:</span> <span class=""mi"">500</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.spidermiddlewares.referer.RefererMiddleware'</span><span class=""p"">:</span> <span class=""mi"">700</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware'</span><span class=""p"">:</span> <span class=""mi"">800</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.spidermiddlewares.depth.DepthMiddleware'</span><span class=""p"">:</span> <span class=""mi"">900</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">SPIDER_MODULES</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'mybot.spiders_prod'</span><span class=""p"">,</span> <span class=""s1"">'mybot.spiders_dev'</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">twisted.internet</span> <span class=""kn"">import</span> <span class=""n"">reactor</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'quotes'</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">timeout</span> <span class=""o"">=</span> <span class=""nb"">int</span><span class=""p"">(</span><span class=""n"">kwargs</span><span class=""o"">.</span><span class=""n"">pop</span><span class=""p"">(</span><span class=""s1"">'timeout'</span><span class=""p"">,</span> <span class=""s1"">'60'</span><span class=""p"">))</span>
        <span class=""nb"">super</span><span class=""p"">(</span><span class=""n"">QuotesSpider</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""p"">)</span><span class=""o"">.</span><span class=""fm"">__init__</span><span class=""p"">(</span><span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">callLater</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">timeout</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">stop</span><span class=""p"">)</span>

        <span class=""n"">urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://quotes.toscrape.com/page/1'</span><span class=""p"">]</span>
        <span class=""k"">for</span> <span class=""n"">url</span> <span class=""ow"">in</span> <span class=""n"">urls</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span><span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()}</span>

    <span class=""k"">def</span> <span class=""nf"">stop</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""o"">.</span><span class=""n"">close_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""s1"">'timeout'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'quotes'</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">timeout</span> <span class=""o"">=</span> <span class=""nb"">int</span><span class=""p"">(</span><span class=""n"">kwargs</span><span class=""o"">.</span><span class=""n"">pop</span><span class=""p"">(</span><span class=""s1"">'timeout'</span><span class=""p"">,</span> <span class=""s1"">'60'</span><span class=""p"">))</span>
        <span class=""nb"">super</span><span class=""p"">(</span><span class=""n"">QuotesSpider</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""p"">)</span><span class=""o"">.</span><span class=""fm"">__init__</span><span class=""p"">(</span><span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""kn"">from</span> <span class=""nn"">twisted.internet</span> <span class=""kn"">import</span> <span class=""n"">reactor</span>
        <span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">callLater</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">timeout</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">stop</span><span class=""p"">)</span>

        <span class=""n"">urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://quotes.toscrape.com/page/1'</span><span class=""p"">]</span>
        <span class=""k"">for</span> <span class=""n"">url</span> <span class=""ow"">in</span> <span class=""n"">urls</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span><span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()}</span>

    <span class=""k"">def</span> <span class=""nf"">stop</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""o"">.</span><span class=""n"">close_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""s1"">'timeout'</span><span class=""p"">)</span>
</pre></div>","{
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'en',
}
,request.priority = request.priority - ( depth * DEPTH_PRIORITY )
,{
    'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware': 100,
    'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware': 300,
    'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware': 350,
    'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware': 400,
    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': 500,
    'scrapy.downloadermiddlewares.retry.RetryMiddleware': 550,
    'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware': 560,
    'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware': 580,
    'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware': 590,
    'scrapy.downloadermiddlewares.redirect.RedirectMiddleware': 600,
    'scrapy.downloadermiddlewares.cookies.CookiesMiddleware': 700,
    'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware': 750,
    'scrapy.downloadermiddlewares.stats.DownloaderStats': 850,
    'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware': 900,
}
,DOWNLOAD_DELAY = 0.25    # 250 ms of delay
,{
    'data': 'scrapy.core.downloader.handlers.datauri.DataURIDownloadHandler',
    'file': 'scrapy.core.downloader.handlers.file.FileDownloadHandler',
    'http': 'scrapy.core.downloader.handlers.http.HTTPDownloadHandler',
    'https': 'scrapy.core.downloader.handlers.http.HTTPDownloadHandler',
    's3': 'scrapy.core.downloader.handlers.s3.S3DownloadHandler',
    'ftp': 'scrapy.core.downloader.handlers.ftp.FTPDownloadHandler',
}
,DOWNLOAD_HANDLERS = {
    'ftp': None,
}
,DOWNLOAD_HANDLERS = {
    'https': 'scrapy.core.downloader.handlers.http2.H2DownloadHandler',
}
,{
    'scrapy.extensions.corestats.CoreStats': 0,
    'scrapy.extensions.telnet.TelnetConsole': 0,
    'scrapy.extensions.memusage.MemoryUsage': 0,
    'scrapy.extensions.memdebug.MemoryDebugger': 0,
    'scrapy.extensions.closespider.CloseSpider': 0,
    'scrapy.extensions.feedexport.FeedExporter': 0,
    'scrapy.extensions.logstats.LogStats': 0,
    'scrapy.extensions.spiderstate.SpiderState': 0,
    'scrapy.extensions.throttle.AutoThrottle': 0,
}
,ITEM_PIPELINES = {
    'mybot.pipelines.validate.ValidateMyItem': 300,
    'mybot.pipelines.validate.StoreMyItem': 800,
}
,MEMDEBUG_NOTIFY = ['user@example.com']
,MEMUSAGE_NOTIFY_MAIL = ['user@example.com']
,NEWSPIDER_MODULE = 'mybot.spiders_dev'
,1956-01-31 00:00:00+0800 [scrapy.core.scheduler] ERROR: Unable to serialize request:
<GET http://example.com> - reason: cannot serialize <Request at 0x9a7c7ec>
(type Request)> - no more unserializable requests will be logged
(see 'scheduler/unserializable' stats counter)
,{
    'scrapy.contracts.default.UrlContract' : 1,
    'scrapy.contracts.default.ReturnsContract': 2,
    'scrapy.contracts.default.ScrapesContract': 3,
}
,SPIDER_CONTRACTS = {
    'scrapy.contracts.default.ScrapesContract': None,
}
,{
    'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware': 50,
    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': 500,
    'scrapy.spidermiddlewares.referer.RefererMiddleware': 700,
    'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware': 800,
    'scrapy.spidermiddlewares.depth.DepthMiddleware': 900,
}
,SPIDER_MODULES = ['mybot.spiders_prod', 'mybot.spiders_dev']
,import scrapy
from twisted.internet import reactor


class QuotesSpider(scrapy.Spider):
    name = 'quotes'

    def __init__(self, *args, **kwargs):
        self.timeout = int(kwargs.pop('timeout', '60'))
        super(QuotesSpider, self).__init__(*args, **kwargs)

    def start_requests(self):
        reactor.callLater(self.timeout, self.stop)

        urls = ['https://quotes.toscrape.com/page/1']
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {'text': quote.css('span.text::text').get()}

    def stop(self):
        self.crawler.engine.close_spider(self, 'timeout')
,import scrapy


class QuotesSpider(scrapy.Spider):
    name = 'quotes'

    def __init__(self, *args, **kwargs):
        self.timeout = int(kwargs.pop('timeout', '60'))
        super(QuotesSpider, self).__init__(*args, **kwargs)

    def start_requests(self):
        from twisted.internet import reactor
        reactor.callLater(self.timeout, self.stop)

        urls = ['https://quotes.toscrape.com/page/1']
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {'text': quote.css('span.text::text').get()}

    def stop(self):
        self.crawler.engine.close_spider(self, 'timeout')
",19
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,AWS_ACCESS_KEY_ID,#aws-access-key-id,,,14
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,AWS_SECRET_ACCESS_KEY,#aws-secret-access-key,,,15
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,AWS_SESSION_TOKEN,#aws-session-token,,,16
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,AWS_ENDPOINT_URL,#aws-endpoint-url,,,17
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,AWS_USE_SSL,#aws-use-ssl,,,18
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,AWS_VERIFY,#aws-verify,,,19
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,AWS_REGION_NAME,#aws-region-name,,,20
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,ASYNCIO_EVENT_LOOP,#asyncio-event-loop,,,21
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,BOT_NAME,#bot-name,,,22
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,CONCURRENT_ITEMS,#concurrent-items,,,23
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,CONCURRENT_REQUESTS,#concurrent-requests,,,24
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,CONCURRENT_REQUESTS_PER_DOMAIN,#concurrent-requests-per-domain,,,25
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,CONCURRENT_REQUESTS_PER_IP,#concurrent-requests-per-ip,,,26
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DEFAULT_ITEM_CLASS,#default-item-class,,,27
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DEFAULT_REQUEST_HEADERS,#default-request-headers,"<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'Accept'</span><span class=""p"">:</span> <span class=""s1"">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span><span class=""p"">,</span>
    <span class=""s1"">'Accept-Language'</span><span class=""p"">:</span> <span class=""s1"">'en'</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","{
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'en',
}
",1
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DEPTH_LIMIT,#depth-limit,,,29
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DEPTH_PRIORITY,#depth-priority,"<div class=""highlight""><pre><span></span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">priority</span> <span class=""o"">=</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">priority</span> <span class=""o"">-</span> <span class=""p"">(</span> <span class=""n"">depth</span> <span class=""o"">*</span> <span class=""n"">DEPTH_PRIORITY</span> <span class=""p"">)</span>
</pre></div>","request.priority = request.priority - ( depth * DEPTH_PRIORITY )
",1
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DEPTH_STATS_VERBOSE,#depth-stats-verbose,,,31
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DNSCACHE_ENABLED,#dnscache-enabled,,,32
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DNSCACHE_SIZE,#dnscache-size,,,33
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DNS_RESOLVER,#dns-resolver,,,34
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DNS_TIMEOUT,#dns-timeout,,,35
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DOWNLOADER,#downloader,,,36
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DOWNLOADER_HTTPCLIENTFACTORY,#downloader-httpclientfactory,,,37
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DOWNLOADER_CLIENTCONTEXTFACTORY,#downloader-clientcontextfactory,,,38
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DOWNLOADER_CLIENT_TLS_CIPHERS,#downloader-client-tls-ciphers,,,39
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DOWNLOADER_CLIENT_TLS_METHOD,#downloader-client-tls-method,,,40
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DOWNLOADER_CLIENT_TLS_VERBOSE_LOGGING,#downloader-client-tls-verbose-logging,,,41
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DOWNLOADER_MIDDLEWARES,#downloader-middlewares,,,42
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DOWNLOADER_MIDDLEWARES_BASE,#downloader-middlewares-base,"<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware'</span><span class=""p"">:</span> <span class=""mi"">100</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware'</span><span class=""p"">:</span> <span class=""mi"">300</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware'</span><span class=""p"">:</span> <span class=""mi"">350</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware'</span><span class=""p"">:</span> <span class=""mi"">400</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span><span class=""p"">:</span> <span class=""mi"">500</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.retry.RetryMiddleware'</span><span class=""p"">:</span> <span class=""mi"">550</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware'</span><span class=""p"">:</span> <span class=""mi"">560</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware'</span><span class=""p"">:</span> <span class=""mi"">580</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span><span class=""p"">:</span> <span class=""mi"">590</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'</span><span class=""p"">:</span> <span class=""mi"">600</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.cookies.CookiesMiddleware'</span><span class=""p"">:</span> <span class=""mi"">700</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware'</span><span class=""p"">:</span> <span class=""mi"">750</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.stats.DownloaderStats'</span><span class=""p"">:</span> <span class=""mi"">850</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware'</span><span class=""p"">:</span> <span class=""mi"">900</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","{
    'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware': 100,
    'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware': 300,
    'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware': 350,
    'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware': 400,
    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': 500,
    'scrapy.downloadermiddlewares.retry.RetryMiddleware': 550,
    'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware': 560,
    'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware': 580,
    'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware': 590,
    'scrapy.downloadermiddlewares.redirect.RedirectMiddleware': 600,
    'scrapy.downloadermiddlewares.cookies.CookiesMiddleware': 700,
    'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware': 750,
    'scrapy.downloadermiddlewares.stats.DownloaderStats': 850,
    'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware': 900,
}
",1
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DOWNLOADER_STATS,#downloader-stats,,,44
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DOWNLOAD_DELAY,#download-delay,"<div class=""highlight""><pre><span></span><span class=""n"">DOWNLOAD_DELAY</span> <span class=""o"">=</span> <span class=""mf"">0.25</span>    <span class=""c1""># 250 ms of delay</span>
</pre></div>","DOWNLOAD_DELAY = 0.25    # 250 ms of delay
",1
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DOWNLOAD_HANDLERS,#download-handlers,,,46
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DOWNLOAD_HANDLERS_BASE,#download-handlers-base,"<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'data'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.datauri.DataURIDownloadHandler'</span><span class=""p"">,</span>
    <span class=""s1"">'file'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.file.FileDownloadHandler'</span><span class=""p"">,</span>
    <span class=""s1"">'http'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.http.HTTPDownloadHandler'</span><span class=""p"">,</span>
    <span class=""s1"">'https'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.http.HTTPDownloadHandler'</span><span class=""p"">,</span>
    <span class=""s1"">'s3'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.s3.S3DownloadHandler'</span><span class=""p"">,</span>
    <span class=""s1"">'ftp'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.ftp.FTPDownloadHandler'</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">DOWNLOAD_HANDLERS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'ftp'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">DOWNLOAD_HANDLERS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'https'</span><span class=""p"">:</span> <span class=""s1"">'scrapy.core.downloader.handlers.http2.H2DownloadHandler'</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","{
    'data': 'scrapy.core.downloader.handlers.datauri.DataURIDownloadHandler',
    'file': 'scrapy.core.downloader.handlers.file.FileDownloadHandler',
    'http': 'scrapy.core.downloader.handlers.http.HTTPDownloadHandler',
    'https': 'scrapy.core.downloader.handlers.http.HTTPDownloadHandler',
    's3': 'scrapy.core.downloader.handlers.s3.S3DownloadHandler',
    'ftp': 'scrapy.core.downloader.handlers.ftp.FTPDownloadHandler',
}
,DOWNLOAD_HANDLERS = {
    'ftp': None,
}
,DOWNLOAD_HANDLERS = {
    'https': 'scrapy.core.downloader.handlers.http2.H2DownloadHandler',
}
",3
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DOWNLOAD_TIMEOUT,#download-timeout,,,48
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DOWNLOAD_MAXSIZE,#download-maxsize,,,49
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DOWNLOAD_WARNSIZE,#download-warnsize,,,50
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DOWNLOAD_FAIL_ON_DATALOSS,#download-fail-on-dataloss,,,51
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DUPEFILTER_CLASS,#dupefilter-class,,,52
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,DUPEFILTER_DEBUG,#dupefilter-debug,,,53
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,EDITOR,#editor,,,54
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,EXTENSIONS,#extensions,,,55
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,EXTENSIONS_BASE,#extensions-base,"<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'scrapy.extensions.corestats.CoreStats'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.telnet.TelnetConsole'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.memusage.MemoryUsage'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.memdebug.MemoryDebugger'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.closespider.CloseSpider'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.feedexport.FeedExporter'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.logstats.LogStats'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.spiderstate.SpiderState'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.throttle.AutoThrottle'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","{
    'scrapy.extensions.corestats.CoreStats': 0,
    'scrapy.extensions.telnet.TelnetConsole': 0,
    'scrapy.extensions.memusage.MemoryUsage': 0,
    'scrapy.extensions.memdebug.MemoryDebugger': 0,
    'scrapy.extensions.closespider.CloseSpider': 0,
    'scrapy.extensions.feedexport.FeedExporter': 0,
    'scrapy.extensions.logstats.LogStats': 0,
    'scrapy.extensions.spiderstate.SpiderState': 0,
    'scrapy.extensions.throttle.AutoThrottle': 0,
}
",1
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,FEED_TEMPDIR,#feed-tempdir,,,57
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,FEED_STORAGE_GCS_ACL,#feed-storage-gcs-acl,,,58
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,FTP_PASSIVE_MODE,#ftp-passive-mode,,,59
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,FTP_PASSWORD,#ftp-password,,,60
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,FTP_USER,#ftp-user,,,61
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,GCS_PROJECT_ID,#gcs-project-id,,,62
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,ITEM_PIPELINES,#item-pipelines,"<div class=""highlight""><pre><span></span><span class=""n"">ITEM_PIPELINES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'mybot.pipelines.validate.ValidateMyItem'</span><span class=""p"">:</span> <span class=""mi"">300</span><span class=""p"">,</span>
    <span class=""s1"">'mybot.pipelines.validate.StoreMyItem'</span><span class=""p"">:</span> <span class=""mi"">800</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","ITEM_PIPELINES = {
    'mybot.pipelines.validate.ValidateMyItem': 300,
    'mybot.pipelines.validate.StoreMyItem': 800,
}
",1
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,ITEM_PIPELINES_BASE,#item-pipelines-base,,,64
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,JOBDIR,#jobdir,,,65
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,LOG_ENABLED,#log-enabled,,,66
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,LOG_ENCODING,#log-encoding,,,67
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,LOG_FILE,#log-file,,,68
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,LOG_FILE_APPEND,#log-file-append,,,69
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,LOG_FORMAT,#log-format,,,70
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,LOG_DATEFORMAT,#log-dateformat,,,71
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,LOG_FORMATTER,#log-formatter,,,72
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,LOG_LEVEL,#log-level,,,73
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,LOG_STDOUT,#log-stdout,,,74
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,LOG_SHORT_NAMES,#log-short-names,,,75
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,LOGSTATS_INTERVAL,#logstats-interval,,,76
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,MEMDEBUG_ENABLED,#memdebug-enabled,,,77
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,MEMDEBUG_NOTIFY,#memdebug-notify,"<div class=""highlight""><pre><span></span><span class=""n"">MEMDEBUG_NOTIFY</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'user@example.com'</span><span class=""p"">]</span>
</pre></div>","MEMDEBUG_NOTIFY = ['user@example.com']
",1
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,MEMUSAGE_ENABLED,#memusage-enabled,,,79
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,MEMUSAGE_LIMIT_MB,#memusage-limit-mb,,,80
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,MEMUSAGE_CHECK_INTERVAL_SECONDS,#memusage-check-interval-seconds,,,81
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,MEMUSAGE_NOTIFY_MAIL,#memusage-notify-mail,"<div class=""highlight""><pre><span></span><span class=""n"">MEMUSAGE_NOTIFY_MAIL</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'user@example.com'</span><span class=""p"">]</span>
</pre></div>","MEMUSAGE_NOTIFY_MAIL = ['user@example.com']
",1
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,MEMUSAGE_WARNING_MB,#memusage-warning-mb,,,83
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,NEWSPIDER_MODULE,#newspider-module,"<div class=""highlight""><pre><span></span><span class=""n"">NEWSPIDER_MODULE</span> <span class=""o"">=</span> <span class=""s1"">'mybot.spiders_dev'</span>
</pre></div>","NEWSPIDER_MODULE = 'mybot.spiders_dev'
",1
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,RANDOMIZE_DOWNLOAD_DELAY,#randomize-download-delay,,,85
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,REACTOR_THREADPOOL_MAXSIZE,#reactor-threadpool-maxsize,,,86
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,REDIRECT_PRIORITY_ADJUST,#redirect-priority-adjust,,,87
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,ROBOTSTXT_OBEY,#robotstxt-obey,,,88
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,ROBOTSTXT_PARSER,#robotstxt-parser,,,89
https://docs.scrapy.org/en/latest/topics/settings.html,,####,4,ROBOTSTXT_USER_AGENT,#robotstxt-user-agent,,,90
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,SCHEDULER,#scheduler,,,91
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,SCHEDULER_DEBUG,#scheduler-debug,"<div class=""highlight""><pre><span></span><span class=""mi"">1956</span><span class=""o"">-</span><span class=""mi"">01</span><span class=""o"">-</span><span class=""mi"">31</span> <span class=""mi"">00</span><span class=""p"">:</span><span class=""mi"">00</span><span class=""p"">:</span><span class=""mi"">00</span><span class=""o"">+</span><span class=""mi"">0800</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">scheduler</span><span class=""p"">]</span> <span class=""n"">ERROR</span><span class=""p"">:</span> <span class=""n"">Unable</span> <span class=""n"">to</span> <span class=""n"">serialize</span> <span class=""n"">request</span><span class=""p"">:</span>
<span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">&gt;</span> <span class=""o"">-</span> <span class=""n"">reason</span><span class=""p"">:</span> <span class=""n"">cannot</span> <span class=""n"">serialize</span> <span class=""o"">&lt;</span><span class=""n"">Request</span> <span class=""n"">at</span> <span class=""mh"">0x9a7c7ec</span><span class=""o"">&gt;</span>
<span class=""p"">(</span><span class=""nb"">type</span> <span class=""n"">Request</span><span class=""p"">)</span><span class=""o"">&gt;</span> <span class=""o"">-</span> <span class=""n"">no</span> <span class=""n"">more</span> <span class=""n"">unserializable</span> <span class=""n"">requests</span> <span class=""n"">will</span> <span class=""n"">be</span> <span class=""n"">logged</span>
<span class=""p"">(</span><span class=""n"">see</span> <span class=""s1"">'scheduler/unserializable'</span> <span class=""n"">stats</span> <span class=""n"">counter</span><span class=""p"">)</span>
</pre></div>","1956-01-31 00:00:00+0800 [scrapy.core.scheduler] ERROR: Unable to serialize request:
<GET http://example.com> - reason: cannot serialize <Request at 0x9a7c7ec>
(type Request)> - no more unserializable requests will be logged
(see 'scheduler/unserializable' stats counter)
",1
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,SCHEDULER_DISK_QUEUE,#scheduler-disk-queue,,,93
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,SCHEDULER_MEMORY_QUEUE,#scheduler-memory-queue,,,94
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,SCHEDULER_PRIORITY_QUEUE,#scheduler-priority-queue,,,95
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,SCRAPER_SLOT_MAX_ACTIVE_SIZE,#scraper-slot-max-active-size,,,96
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,SPIDER_CONTRACTS,#spider-contracts,,,97
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,SPIDER_CONTRACTS_BASE,#spider-contracts-base,"<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'scrapy.contracts.default.UrlContract'</span> <span class=""p"">:</span> <span class=""mi"">1</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.contracts.default.ReturnsContract'</span><span class=""p"">:</span> <span class=""mi"">2</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.contracts.default.ScrapesContract'</span><span class=""p"">:</span> <span class=""mi"">3</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">SPIDER_CONTRACTS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'scrapy.contracts.default.ScrapesContract'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","{
    'scrapy.contracts.default.UrlContract' : 1,
    'scrapy.contracts.default.ReturnsContract': 2,
    'scrapy.contracts.default.ScrapesContract': 3,
}
,SPIDER_CONTRACTS = {
    'scrapy.contracts.default.ScrapesContract': None,
}
",2
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,SPIDER_LOADER_CLASS,#spider-loader-class,,,99
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,SPIDER_LOADER_WARN_ONLY,#spider-loader-warn-only,,,100
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,SPIDER_MIDDLEWARES,#spider-middlewares,,,101
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,SPIDER_MIDDLEWARES_BASE,#spider-middlewares-base,"<div class=""highlight""><pre><span></span><span class=""p"">{</span>
    <span class=""s1"">'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware'</span><span class=""p"">:</span> <span class=""mi"">50</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class=""p"">:</span> <span class=""mi"">500</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.spidermiddlewares.referer.RefererMiddleware'</span><span class=""p"">:</span> <span class=""mi"">700</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware'</span><span class=""p"">:</span> <span class=""mi"">800</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.spidermiddlewares.depth.DepthMiddleware'</span><span class=""p"">:</span> <span class=""mi"">900</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","{
    'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware': 50,
    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': 500,
    'scrapy.spidermiddlewares.referer.RefererMiddleware': 700,
    'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware': 800,
    'scrapy.spidermiddlewares.depth.DepthMiddleware': 900,
}
",1
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,SPIDER_MODULES,#spider-modules,"<div class=""highlight""><pre><span></span><span class=""n"">SPIDER_MODULES</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'mybot.spiders_prod'</span><span class=""p"">,</span> <span class=""s1"">'mybot.spiders_dev'</span><span class=""p"">]</span>
</pre></div>","SPIDER_MODULES = ['mybot.spiders_prod', 'mybot.spiders_dev']
",1
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,STATS_CLASS,#stats-class,,,104
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,STATS_DUMP,#stats-dump,,,105
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,STATSMAILER_RCPTS,#statsmailer-rcpts,,,106
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,TELNETCONSOLE_ENABLED,#telnetconsole-enabled,,,107
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,TEMPLATES_DIR,#templates-dir,,,108
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,TWISTED_REACTOR,#twisted-reactor,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">twisted.internet</span> <span class=""kn"">import</span> <span class=""n"">reactor</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'quotes'</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">timeout</span> <span class=""o"">=</span> <span class=""nb"">int</span><span class=""p"">(</span><span class=""n"">kwargs</span><span class=""o"">.</span><span class=""n"">pop</span><span class=""p"">(</span><span class=""s1"">'timeout'</span><span class=""p"">,</span> <span class=""s1"">'60'</span><span class=""p"">))</span>
        <span class=""nb"">super</span><span class=""p"">(</span><span class=""n"">QuotesSpider</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""p"">)</span><span class=""o"">.</span><span class=""fm"">__init__</span><span class=""p"">(</span><span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">callLater</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">timeout</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">stop</span><span class=""p"">)</span>

        <span class=""n"">urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://quotes.toscrape.com/page/1'</span><span class=""p"">]</span>
        <span class=""k"">for</span> <span class=""n"">url</span> <span class=""ow"">in</span> <span class=""n"">urls</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span><span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()}</span>

    <span class=""k"">def</span> <span class=""nf"">stop</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""o"">.</span><span class=""n"">close_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""s1"">'timeout'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">QuotesSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'quotes'</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">timeout</span> <span class=""o"">=</span> <span class=""nb"">int</span><span class=""p"">(</span><span class=""n"">kwargs</span><span class=""o"">.</span><span class=""n"">pop</span><span class=""p"">(</span><span class=""s1"">'timeout'</span><span class=""p"">,</span> <span class=""s1"">'60'</span><span class=""p"">))</span>
        <span class=""nb"">super</span><span class=""p"">(</span><span class=""n"">QuotesSpider</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""p"">)</span><span class=""o"">.</span><span class=""fm"">__init__</span><span class=""p"">(</span><span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">start_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""kn"">from</span> <span class=""nn"">twisted.internet</span> <span class=""kn"">import</span> <span class=""n"">reactor</span>
        <span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">callLater</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">timeout</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">stop</span><span class=""p"">)</span>

        <span class=""n"">urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://quotes.toscrape.com/page/1'</span><span class=""p"">]</span>
        <span class=""k"">for</span> <span class=""n"">url</span> <span class=""ow"">in</span> <span class=""n"">urls</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span><span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()}</span>

    <span class=""k"">def</span> <span class=""nf"">stop</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""o"">.</span><span class=""n"">close_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""s1"">'timeout'</span><span class=""p"">)</span>
</pre></div>","import scrapy
from twisted.internet import reactor


class QuotesSpider(scrapy.Spider):
    name = 'quotes'

    def __init__(self, *args, **kwargs):
        self.timeout = int(kwargs.pop('timeout', '60'))
        super(QuotesSpider, self).__init__(*args, **kwargs)

    def start_requests(self):
        reactor.callLater(self.timeout, self.stop)

        urls = ['https://quotes.toscrape.com/page/1']
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {'text': quote.css('span.text::text').get()}

    def stop(self):
        self.crawler.engine.close_spider(self, 'timeout')
,import scrapy


class QuotesSpider(scrapy.Spider):
    name = 'quotes'

    def __init__(self, *args, **kwargs):
        self.timeout = int(kwargs.pop('timeout', '60'))
        super(QuotesSpider, self).__init__(*args, **kwargs)

    def start_requests(self):
        from twisted.internet import reactor
        reactor.callLater(self.timeout, self.stop)

        urls = ['https://quotes.toscrape.com/page/1']
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {'text': quote.css('span.text::text').get()}

    def stop(self):
        self.crawler.engine.close_spider(self, 'timeout')
",2
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,URLLENGTH_LIMIT,#urllength-limit,,,110
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,USER_AGENT,#user-agent,,,111
https://docs.scrapy.org/en/latest/topics/settings.html,,###,3,Settings documented elsewhere:,#settings-documented-elsewhere,,,112
https://docs.scrapy.org/en/latest/topics/exceptions.html,,#,1,Exceptions,#module-scrapy.exceptions,"<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse_page</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""k"">if</span> <span class=""s1"">'Bandwidth exceeded'</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">body</span><span class=""p"">:</span>
        <span class=""k"">raise</span> <span class=""n"">CloseSpider</span><span class=""p"">(</span><span class=""s1"">'bandwidth_exceeded'</span><span class=""p"">)</span>
</pre></div>","def parse_page(self, response):
    if 'Bandwidth exceeded' in response.body:
        raise CloseSpider('bandwidth_exceeded')
",1
https://docs.scrapy.org/en/latest/topics/exceptions.html,,##,2,Built-in Exceptions reference,#built-in-exceptions-reference,"<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse_page</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""k"">if</span> <span class=""s1"">'Bandwidth exceeded'</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">body</span><span class=""p"">:</span>
        <span class=""k"">raise</span> <span class=""n"">CloseSpider</span><span class=""p"">(</span><span class=""s1"">'bandwidth_exceeded'</span><span class=""p"">)</span>
</pre></div>","def parse_page(self, response):
    if 'Bandwidth exceeded' in response.body:
        raise CloseSpider('bandwidth_exceeded')
",1
https://docs.scrapy.org/en/latest/topics/exceptions.html,,###,3,CloseSpider,#closespider,"<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse_page</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""k"">if</span> <span class=""s1"">'Bandwidth exceeded'</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">body</span><span class=""p"">:</span>
        <span class=""k"">raise</span> <span class=""n"">CloseSpider</span><span class=""p"">(</span><span class=""s1"">'bandwidth_exceeded'</span><span class=""p"">)</span>
</pre></div>","def parse_page(self, response):
    if 'Bandwidth exceeded' in response.body:
        raise CloseSpider('bandwidth_exceeded')
",1
https://docs.scrapy.org/en/latest/topics/exceptions.html,,###,3,DontCloseSpider,#dontclosespider,,,4
https://docs.scrapy.org/en/latest/topics/exceptions.html,,###,3,DropItem,#dropitem,,,5
https://docs.scrapy.org/en/latest/topics/exceptions.html,,###,3,IgnoreRequest,#ignorerequest,,,6
https://docs.scrapy.org/en/latest/topics/exceptions.html,,###,3,NotConfigured,#notconfigured,,,7
https://docs.scrapy.org/en/latest/topics/exceptions.html,,###,3,NotSupported,#notsupported,,,8
https://docs.scrapy.org/en/latest/topics/exceptions.html,,###,3,StopDownload,#stopdownload,,,9
https://docs.scrapy.org/en/latest/topics/logging.html,,#,1,Logging,#logging,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">warning</span><span class=""p"">(</span><span class=""s2"">""This is a warning""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">log</span><span class=""p"">(</span><span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">WARNING</span><span class=""p"">,</span> <span class=""s2"">""This is a warning""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">()</span>
<span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">warning</span><span class=""p"">(</span><span class=""s2"">""This is a warning""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">(</span><span class=""s1"">'mycustomlogger'</span><span class=""p"">)</span>
<span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">warning</span><span class=""p"">(</span><span class=""s2"">""This is a warning""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">(</span><span class=""vm"">__name__</span><span class=""p"">)</span>
<span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">warning</span><span class=""p"">(</span><span class=""s2"">""This is a warning""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>

    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://scrapy.org'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Parse function called on </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">(</span><span class=""s1"">'mycustomlogger'</span><span class=""p"">)</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>

    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://scrapy.org'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Parse function called on </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">PoliteLogFormatter</span><span class=""p"">(</span><span class=""n"">logformatter</span><span class=""o"">.</span><span class=""n"">LogFormatter</span><span class=""p"">):</span>
    <span class=""k"">def</span> <span class=""nf"">dropped</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">exception</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""p"">{</span>
            <span class=""s1"">'level'</span><span class=""p"">:</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">INFO</span><span class=""p"">,</span> <span class=""c1""># lowering the level from logging.WARNING</span>
            <span class=""s1"">'msg'</span><span class=""p"">:</span> <span class=""s2"">""Dropped: </span><span class=""si"">%(exception)s</span><span class=""s2"">""</span> <span class=""o"">+</span> <span class=""n"">os</span><span class=""o"">.</span><span class=""n"">linesep</span> <span class=""o"">+</span> <span class=""s2"">""</span><span class=""si"">%(item)s</span><span class=""s2"">""</span><span class=""p"">,</span>
            <span class=""s1"">'args'</span><span class=""p"">:</span> <span class=""p"">{</span>
                <span class=""s1"">'exception'</span><span class=""p"">:</span> <span class=""n"">exception</span><span class=""p"">,</span>
                <span class=""s1"">'item'</span><span class=""p"">:</span> <span class=""n"">item</span><span class=""p"">,</span>
            <span class=""p"">}</span>
        <span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">22</span><span class=""p"">:</span><span class=""mi"">00</span><span class=""p"">:</span><span class=""mi"">06</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">spidermiddlewares</span><span class=""o"">.</span><span class=""n"">httperror</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Ignoring</span>
<span class=""n"">response</span> <span class=""o"">&lt;</span><span class=""mi"">500</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">-</span><span class=""mi"">34</span><span class=""o"">/&gt;</span><span class=""p"">:</span> <span class=""n"">HTTP</span> <span class=""n"">status</span> <span class=""n"">code</span>
<span class=""ow"">is</span> <span class=""ow"">not</span> <span class=""n"">handled</span> <span class=""ow"">or</span> <span class=""ow"">not</span> <span class=""n"">allowed</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># ...</span>
    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">(</span><span class=""s1"">'scrapy.spidermiddlewares.httperror'</span><span class=""p"">)</span>
        <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">setLevel</span><span class=""p"">(</span><span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">WARNING</span><span class=""p"">)</span>
        <span class=""nb"">super</span><span class=""p"">()</span><span class=""o"">.</span><span class=""fm"">__init__</span><span class=""p"">(</span><span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">import</span> <span class=""nn"">re</span>

<span class=""k"">class</span> <span class=""nc"">ContentFilter</span><span class=""p"">(</span><span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">Filter</span><span class=""p"">):</span>
    <span class=""k"">def</span> <span class=""nf"">filter</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">record</span><span class=""p"">):</span>
        <span class=""n"">match</span> <span class=""o"">=</span> <span class=""n"">re</span><span class=""o"">.</span><span class=""n"">search</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'\d</span><span class=""si"">{3}</span><span class=""s1""> [Ee]rror, retrying'</span><span class=""p"">,</span> <span class=""n"">record</span><span class=""o"">.</span><span class=""n"">message</span><span class=""p"">)</span>
        <span class=""k"">if</span> <span class=""n"">match</span><span class=""p"">:</span>
            <span class=""k"">return</span> <span class=""kc"">False</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># ...</span>
    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">handler</span> <span class=""ow"">in</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">root</span><span class=""o"">.</span><span class=""n"">handlers</span><span class=""p"">:</span>
            <span class=""n"">handler</span><span class=""o"">.</span><span class=""n"">addFilter</span><span class=""p"">(</span><span class=""n"">ContentFilter</span><span class=""p"">())</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># ...</span>
    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">(</span><span class=""s1"">'my_logger'</span><span class=""p"">)</span>
        <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">addFilter</span><span class=""p"">(</span><span class=""n"">ContentFilter</span><span class=""p"">())</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>

<span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">basicConfig</span><span class=""p"">(</span>
    <span class=""n"">filename</span><span class=""o"">=</span><span class=""s1"">'log.txt'</span><span class=""p"">,</span>
    <span class=""nb"">format</span><span class=""o"">=</span><span class=""s1"">'</span><span class=""si"">%(levelname)s</span><span class=""s1"">: </span><span class=""si"">%(message)s</span><span class=""s1"">'</span><span class=""p"">,</span>
    <span class=""n"">level</span><span class=""o"">=</span><span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">INFO</span>
<span class=""p"">)</span>
</pre></div>","import logging
logging.warning(""This is a warning"")
,import logging
logging.log(logging.WARNING, ""This is a warning"")
,import logging
logger = logging.getLogger()
logger.warning(""This is a warning"")
,import logging
logger = logging.getLogger('mycustomlogger')
logger.warning(""This is a warning"")
,import logging
logger = logging.getLogger(__name__)
logger.warning(""This is a warning"")
,import scrapy

class MySpider(scrapy.Spider):

    name = 'myspider'
    start_urls = ['https://scrapy.org']

    def parse(self, response):
        self.logger.info('Parse function called on %s', response.url)
,import logging
import scrapy

logger = logging.getLogger('mycustomlogger')

class MySpider(scrapy.Spider):

    name = 'myspider'
    start_urls = ['https://scrapy.org']

    def parse(self, response):
        logger.info('Parse function called on %s', response.url)
,class PoliteLogFormatter(logformatter.LogFormatter):
    def dropped(self, item, exception, response, spider):
        return {
            'level': logging.INFO, # lowering the level from logging.WARNING
            'msg': ""Dropped: %(exception)s"" + os.linesep + ""%(item)s"",
            'args': {
                'exception': exception,
                'item': item,
            }
        }
,2016-12-16 22:00:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring
response <500 https://quotes.toscrape.com/page/1-34/>: HTTP status code
is not handled or not allowed
,import logging
import scrapy


class MySpider(scrapy.Spider):
    # ...
    def __init__(self, *args, **kwargs):
        logger = logging.getLogger('scrapy.spidermiddlewares.httperror')
        logger.setLevel(logging.WARNING)
        super().__init__(*args, **kwargs)
,import logging
import re

class ContentFilter(logging.Filter):
    def filter(self, record):
        match = re.search(r'\d{3} [Ee]rror, retrying', record.message)
        if match:
            return False
,import logging
import scrapy

class MySpider(scrapy.Spider):
    # ...
    def __init__(self, *args, **kwargs):
        for handler in logging.root.handlers:
            handler.addFilter(ContentFilter())
,import logging
import scrapy

class MySpider(scrapy.Spider):
    # ...
    def __init__(self, *args, **kwargs):
        logger = logging.getLogger('my_logger')
        logger.addFilter(ContentFilter())
,import logging

logging.basicConfig(
    filename='log.txt',
    format='%(levelname)s: %(message)s',
    level=logging.INFO
)
",14
https://docs.scrapy.org/en/latest/topics/logging.html,,##,2,Log levels,#log-levels,,,2
https://docs.scrapy.org/en/latest/topics/logging.html,,##,2,How to log messages,#how-to-log-messages,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">warning</span><span class=""p"">(</span><span class=""s2"">""This is a warning""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">log</span><span class=""p"">(</span><span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">WARNING</span><span class=""p"">,</span> <span class=""s2"">""This is a warning""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">()</span>
<span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">warning</span><span class=""p"">(</span><span class=""s2"">""This is a warning""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">(</span><span class=""s1"">'mycustomlogger'</span><span class=""p"">)</span>
<span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">warning</span><span class=""p"">(</span><span class=""s2"">""This is a warning""</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">(</span><span class=""vm"">__name__</span><span class=""p"">)</span>
<span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">warning</span><span class=""p"">(</span><span class=""s2"">""This is a warning""</span><span class=""p"">)</span>
</pre></div>","import logging
logging.warning(""This is a warning"")
,import logging
logging.log(logging.WARNING, ""This is a warning"")
,import logging
logger = logging.getLogger()
logger.warning(""This is a warning"")
,import logging
logger = logging.getLogger('mycustomlogger')
logger.warning(""This is a warning"")
,import logging
logger = logging.getLogger(__name__)
logger.warning(""This is a warning"")
",5
https://docs.scrapy.org/en/latest/topics/logging.html,,##,2,Logging from Spiders,#logging-from-spiders,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>

    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://scrapy.org'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Parse function called on </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">(</span><span class=""s1"">'mycustomlogger'</span><span class=""p"">)</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>

    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://scrapy.org'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Parse function called on </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>","import scrapy

class MySpider(scrapy.Spider):

    name = 'myspider'
    start_urls = ['https://scrapy.org']

    def parse(self, response):
        self.logger.info('Parse function called on %s', response.url)
,import logging
import scrapy

logger = logging.getLogger('mycustomlogger')

class MySpider(scrapy.Spider):

    name = 'myspider'
    start_urls = ['https://scrapy.org']

    def parse(self, response):
        logger.info('Parse function called on %s', response.url)
",2
https://docs.scrapy.org/en/latest/topics/logging.html,,##,2,Logging configuration,#logging-configuration,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">PoliteLogFormatter</span><span class=""p"">(</span><span class=""n"">logformatter</span><span class=""o"">.</span><span class=""n"">LogFormatter</span><span class=""p"">):</span>
    <span class=""k"">def</span> <span class=""nf"">dropped</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">exception</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""p"">{</span>
            <span class=""s1"">'level'</span><span class=""p"">:</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">INFO</span><span class=""p"">,</span> <span class=""c1""># lowering the level from logging.WARNING</span>
            <span class=""s1"">'msg'</span><span class=""p"">:</span> <span class=""s2"">""Dropped: </span><span class=""si"">%(exception)s</span><span class=""s2"">""</span> <span class=""o"">+</span> <span class=""n"">os</span><span class=""o"">.</span><span class=""n"">linesep</span> <span class=""o"">+</span> <span class=""s2"">""</span><span class=""si"">%(item)s</span><span class=""s2"">""</span><span class=""p"">,</span>
            <span class=""s1"">'args'</span><span class=""p"">:</span> <span class=""p"">{</span>
                <span class=""s1"">'exception'</span><span class=""p"">:</span> <span class=""n"">exception</span><span class=""p"">,</span>
                <span class=""s1"">'item'</span><span class=""p"">:</span> <span class=""n"">item</span><span class=""p"">,</span>
            <span class=""p"">}</span>
        <span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">22</span><span class=""p"">:</span><span class=""mi"">00</span><span class=""p"">:</span><span class=""mi"">06</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">spidermiddlewares</span><span class=""o"">.</span><span class=""n"">httperror</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Ignoring</span>
<span class=""n"">response</span> <span class=""o"">&lt;</span><span class=""mi"">500</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">-</span><span class=""mi"">34</span><span class=""o"">/&gt;</span><span class=""p"">:</span> <span class=""n"">HTTP</span> <span class=""n"">status</span> <span class=""n"">code</span>
<span class=""ow"">is</span> <span class=""ow"">not</span> <span class=""n"">handled</span> <span class=""ow"">or</span> <span class=""ow"">not</span> <span class=""n"">allowed</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># ...</span>
    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">(</span><span class=""s1"">'scrapy.spidermiddlewares.httperror'</span><span class=""p"">)</span>
        <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">setLevel</span><span class=""p"">(</span><span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">WARNING</span><span class=""p"">)</span>
        <span class=""nb"">super</span><span class=""p"">()</span><span class=""o"">.</span><span class=""fm"">__init__</span><span class=""p"">(</span><span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">import</span> <span class=""nn"">re</span>

<span class=""k"">class</span> <span class=""nc"">ContentFilter</span><span class=""p"">(</span><span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">Filter</span><span class=""p"">):</span>
    <span class=""k"">def</span> <span class=""nf"">filter</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">record</span><span class=""p"">):</span>
        <span class=""n"">match</span> <span class=""o"">=</span> <span class=""n"">re</span><span class=""o"">.</span><span class=""n"">search</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'\d</span><span class=""si"">{3}</span><span class=""s1""> [Ee]rror, retrying'</span><span class=""p"">,</span> <span class=""n"">record</span><span class=""o"">.</span><span class=""n"">message</span><span class=""p"">)</span>
        <span class=""k"">if</span> <span class=""n"">match</span><span class=""p"">:</span>
            <span class=""k"">return</span> <span class=""kc"">False</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># ...</span>
    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">handler</span> <span class=""ow"">in</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">root</span><span class=""o"">.</span><span class=""n"">handlers</span><span class=""p"">:</span>
            <span class=""n"">handler</span><span class=""o"">.</span><span class=""n"">addFilter</span><span class=""p"">(</span><span class=""n"">ContentFilter</span><span class=""p"">())</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># ...</span>
    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">(</span><span class=""s1"">'my_logger'</span><span class=""p"">)</span>
        <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">addFilter</span><span class=""p"">(</span><span class=""n"">ContentFilter</span><span class=""p"">())</span>
</pre></div>","class PoliteLogFormatter(logformatter.LogFormatter):
    def dropped(self, item, exception, response, spider):
        return {
            'level': logging.INFO, # lowering the level from logging.WARNING
            'msg': ""Dropped: %(exception)s"" + os.linesep + ""%(item)s"",
            'args': {
                'exception': exception,
                'item': item,
            }
        }
,2016-12-16 22:00:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring
response <500 https://quotes.toscrape.com/page/1-34/>: HTTP status code
is not handled or not allowed
,import logging
import scrapy


class MySpider(scrapy.Spider):
    # ...
    def __init__(self, *args, **kwargs):
        logger = logging.getLogger('scrapy.spidermiddlewares.httperror')
        logger.setLevel(logging.WARNING)
        super().__init__(*args, **kwargs)
,import logging
import re

class ContentFilter(logging.Filter):
    def filter(self, record):
        match = re.search(r'\d{3} [Ee]rror, retrying', record.message)
        if match:
            return False
,import logging
import scrapy

class MySpider(scrapy.Spider):
    # ...
    def __init__(self, *args, **kwargs):
        for handler in logging.root.handlers:
            handler.addFilter(ContentFilter())
,import logging
import scrapy

class MySpider(scrapy.Spider):
    # ...
    def __init__(self, *args, **kwargs):
        logger = logging.getLogger('my_logger')
        logger.addFilter(ContentFilter())
",6
https://docs.scrapy.org/en/latest/topics/logging.html,,###,3,Logging settings,#logging-settings,,,6
https://docs.scrapy.org/en/latest/topics/logging.html,,###,3,Command-line options,#command-line-options,,,7
https://docs.scrapy.org/en/latest/topics/logging.html,,###,3,Custom Log Formats,#custom-log-formats,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">PoliteLogFormatter</span><span class=""p"">(</span><span class=""n"">logformatter</span><span class=""o"">.</span><span class=""n"">LogFormatter</span><span class=""p"">):</span>
    <span class=""k"">def</span> <span class=""nf"">dropped</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">exception</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""p"">{</span>
            <span class=""s1"">'level'</span><span class=""p"">:</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">INFO</span><span class=""p"">,</span> <span class=""c1""># lowering the level from logging.WARNING</span>
            <span class=""s1"">'msg'</span><span class=""p"">:</span> <span class=""s2"">""Dropped: </span><span class=""si"">%(exception)s</span><span class=""s2"">""</span> <span class=""o"">+</span> <span class=""n"">os</span><span class=""o"">.</span><span class=""n"">linesep</span> <span class=""o"">+</span> <span class=""s2"">""</span><span class=""si"">%(item)s</span><span class=""s2"">""</span><span class=""p"">,</span>
            <span class=""s1"">'args'</span><span class=""p"">:</span> <span class=""p"">{</span>
                <span class=""s1"">'exception'</span><span class=""p"">:</span> <span class=""n"">exception</span><span class=""p"">,</span>
                <span class=""s1"">'item'</span><span class=""p"">:</span> <span class=""n"">item</span><span class=""p"">,</span>
            <span class=""p"">}</span>
        <span class=""p"">}</span>
</pre></div>","class PoliteLogFormatter(logformatter.LogFormatter):
    def dropped(self, item, exception, response, spider):
        return {
            'level': logging.INFO, # lowering the level from logging.WARNING
            'msg': ""Dropped: %(exception)s"" + os.linesep + ""%(item)s"",
            'args': {
                'exception': exception,
                'item': item,
            }
        }
",1
https://docs.scrapy.org/en/latest/topics/logging.html,,###,3,Advanced customization,#advanced-customization,"<div class=""highlight""><pre><span></span><span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">22</span><span class=""p"">:</span><span class=""mi"">00</span><span class=""p"">:</span><span class=""mi"">06</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">spidermiddlewares</span><span class=""o"">.</span><span class=""n"">httperror</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Ignoring</span>
<span class=""n"">response</span> <span class=""o"">&lt;</span><span class=""mi"">500</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">quotes</span><span class=""o"">.</span><span class=""n"">toscrape</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">/</span><span class=""mi"">1</span><span class=""o"">-</span><span class=""mi"">34</span><span class=""o"">/&gt;</span><span class=""p"">:</span> <span class=""n"">HTTP</span> <span class=""n"">status</span> <span class=""n"">code</span>
<span class=""ow"">is</span> <span class=""ow"">not</span> <span class=""n"">handled</span> <span class=""ow"">or</span> <span class=""ow"">not</span> <span class=""n"">allowed</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># ...</span>
    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">(</span><span class=""s1"">'scrapy.spidermiddlewares.httperror'</span><span class=""p"">)</span>
        <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">setLevel</span><span class=""p"">(</span><span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">WARNING</span><span class=""p"">)</span>
        <span class=""nb"">super</span><span class=""p"">()</span><span class=""o"">.</span><span class=""fm"">__init__</span><span class=""p"">(</span><span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">import</span> <span class=""nn"">re</span>

<span class=""k"">class</span> <span class=""nc"">ContentFilter</span><span class=""p"">(</span><span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">Filter</span><span class=""p"">):</span>
    <span class=""k"">def</span> <span class=""nf"">filter</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">record</span><span class=""p"">):</span>
        <span class=""n"">match</span> <span class=""o"">=</span> <span class=""n"">re</span><span class=""o"">.</span><span class=""n"">search</span><span class=""p"">(</span><span class=""sa"">r</span><span class=""s1"">'\d</span><span class=""si"">{3}</span><span class=""s1""> [Ee]rror, retrying'</span><span class=""p"">,</span> <span class=""n"">record</span><span class=""o"">.</span><span class=""n"">message</span><span class=""p"">)</span>
        <span class=""k"">if</span> <span class=""n"">match</span><span class=""p"">:</span>
            <span class=""k"">return</span> <span class=""kc"">False</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># ...</span>
    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">handler</span> <span class=""ow"">in</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">root</span><span class=""o"">.</span><span class=""n"">handlers</span><span class=""p"">:</span>
            <span class=""n"">handler</span><span class=""o"">.</span><span class=""n"">addFilter</span><span class=""p"">(</span><span class=""n"">ContentFilter</span><span class=""p"">())</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># ...</span>
    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">(</span><span class=""s1"">'my_logger'</span><span class=""p"">)</span>
        <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">addFilter</span><span class=""p"">(</span><span class=""n"">ContentFilter</span><span class=""p"">())</span>
</pre></div>","2016-12-16 22:00:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring
response <500 https://quotes.toscrape.com/page/1-34/>: HTTP status code
is not handled or not allowed
,import logging
import scrapy


class MySpider(scrapy.Spider):
    # ...
    def __init__(self, *args, **kwargs):
        logger = logging.getLogger('scrapy.spidermiddlewares.httperror')
        logger.setLevel(logging.WARNING)
        super().__init__(*args, **kwargs)
,import logging
import re

class ContentFilter(logging.Filter):
    def filter(self, record):
        match = re.search(r'\d{3} [Ee]rror, retrying', record.message)
        if match:
            return False
,import logging
import scrapy

class MySpider(scrapy.Spider):
    # ...
    def __init__(self, *args, **kwargs):
        for handler in logging.root.handlers:
            handler.addFilter(ContentFilter())
,import logging
import scrapy

class MySpider(scrapy.Spider):
    # ...
    def __init__(self, *args, **kwargs):
        logger = logging.getLogger('my_logger')
        logger.addFilter(ContentFilter())
",5
https://docs.scrapy.org/en/latest/topics/logging.html,,##,2,scrapy.utils.log module,#module-scrapy.utils.log,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>

<span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">basicConfig</span><span class=""p"">(</span>
    <span class=""n"">filename</span><span class=""o"">=</span><span class=""s1"">'log.txt'</span><span class=""p"">,</span>
    <span class=""nb"">format</span><span class=""o"">=</span><span class=""s1"">'</span><span class=""si"">%(levelname)s</span><span class=""s1"">: </span><span class=""si"">%(message)s</span><span class=""s1"">'</span><span class=""p"">,</span>
    <span class=""n"">level</span><span class=""o"">=</span><span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">INFO</span>
<span class=""p"">)</span>
</pre></div>","import logging

logging.basicConfig(
    filename='log.txt',
    format='%(levelname)s: %(message)s',
    level=logging.INFO
)
",1
https://docs.scrapy.org/en/latest/topics/stats.html,,#,1,Stats Collection,#stats-collection,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">ExtensionThatAccessStats</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">stats</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">stats</span> <span class=""o"">=</span> <span class=""n"">stats</span>

    <span class=""nd"">@classmethod</span>
    <span class=""k"">def</span> <span class=""nf"">from_crawler</span><span class=""p"">(</span><span class=""bp"">cls</span><span class=""p"">,</span> <span class=""n"">crawler</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""bp"">cls</span><span class=""p"">(</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">stats</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">stats</span><span class=""o"">.</span><span class=""n"">set_value</span><span class=""p"">(</span><span class=""s1"">'hostname'</span><span class=""p"">,</span> <span class=""n"">socket</span><span class=""o"">.</span><span class=""n"">gethostname</span><span class=""p"">())</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">stats</span><span class=""o"">.</span><span class=""n"">inc_value</span><span class=""p"">(</span><span class=""s1"">'custom_count'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">stats</span><span class=""o"">.</span><span class=""n"">max_value</span><span class=""p"">(</span><span class=""s1"">'max_items_scraped'</span><span class=""p"">,</span> <span class=""n"">value</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">stats</span><span class=""o"">.</span><span class=""n"">min_value</span><span class=""p"">(</span><span class=""s1"">'min_free_memory_percent'</span><span class=""p"">,</span> <span class=""n"">value</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">stats</span><span class=""o"">.</span><span class=""n"">get_value</span><span class=""p"">(</span><span class=""s1"">'custom_count'</span><span class=""p"">)</span>
<span class=""go"">1</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">stats</span><span class=""o"">.</span><span class=""n"">get_stats</span><span class=""p"">()</span>
<span class=""go"">{'custom_count': 1, 'start_time': datetime.datetime(2009, 7, 14, 21, 47, 28, 977139)}</span>
</pre></div>","class ExtensionThatAccessStats:

    def __init__(self, stats):
        self.stats = stats

    @classmethod
    def from_crawler(cls, crawler):
        return cls(crawler.stats)
,stats.set_value('hostname', socket.gethostname())
,stats.inc_value('custom_count')
,stats.max_value('max_items_scraped', value)
,stats.min_value('min_free_memory_percent', value)
,>>> stats.get_value('custom_count')
1
,>>> stats.get_stats()
{'custom_count': 1, 'start_time': datetime.datetime(2009, 7, 14, 21, 47, 28, 977139)}
",7
https://docs.scrapy.org/en/latest/topics/stats.html,,##,2,Common Stats Collector uses,#common-stats-collector-uses,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">ExtensionThatAccessStats</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">stats</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">stats</span> <span class=""o"">=</span> <span class=""n"">stats</span>

    <span class=""nd"">@classmethod</span>
    <span class=""k"">def</span> <span class=""nf"">from_crawler</span><span class=""p"">(</span><span class=""bp"">cls</span><span class=""p"">,</span> <span class=""n"">crawler</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""bp"">cls</span><span class=""p"">(</span><span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">stats</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">stats</span><span class=""o"">.</span><span class=""n"">set_value</span><span class=""p"">(</span><span class=""s1"">'hostname'</span><span class=""p"">,</span> <span class=""n"">socket</span><span class=""o"">.</span><span class=""n"">gethostname</span><span class=""p"">())</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">stats</span><span class=""o"">.</span><span class=""n"">inc_value</span><span class=""p"">(</span><span class=""s1"">'custom_count'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">stats</span><span class=""o"">.</span><span class=""n"">max_value</span><span class=""p"">(</span><span class=""s1"">'max_items_scraped'</span><span class=""p"">,</span> <span class=""n"">value</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">stats</span><span class=""o"">.</span><span class=""n"">min_value</span><span class=""p"">(</span><span class=""s1"">'min_free_memory_percent'</span><span class=""p"">,</span> <span class=""n"">value</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">stats</span><span class=""o"">.</span><span class=""n"">get_value</span><span class=""p"">(</span><span class=""s1"">'custom_count'</span><span class=""p"">)</span>
<span class=""go"">1</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">stats</span><span class=""o"">.</span><span class=""n"">get_stats</span><span class=""p"">()</span>
<span class=""go"">{'custom_count': 1, 'start_time': datetime.datetime(2009, 7, 14, 21, 47, 28, 977139)}</span>
</pre></div>","class ExtensionThatAccessStats:

    def __init__(self, stats):
        self.stats = stats

    @classmethod
    def from_crawler(cls, crawler):
        return cls(crawler.stats)
,stats.set_value('hostname', socket.gethostname())
,stats.inc_value('custom_count')
,stats.max_value('max_items_scraped', value)
,stats.min_value('min_free_memory_percent', value)
,>>> stats.get_value('custom_count')
1
,>>> stats.get_stats()
{'custom_count': 1, 'start_time': datetime.datetime(2009, 7, 14, 21, 47, 28, 977139)}
",7
https://docs.scrapy.org/en/latest/topics/stats.html,,##,2,Available Stats Collectors,#available-stats-collectors,,,3
https://docs.scrapy.org/en/latest/topics/stats.html,,###,3,MemoryStatsCollector,#memorystatscollector,,,4
https://docs.scrapy.org/en/latest/topics/stats.html,,###,3,DummyStatsCollector,#dummystatscollector,,,5
https://docs.scrapy.org/en/latest/topics/email.html,,#,1,Sending e-mail,#module-scrapy.mail,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.mail</span> <span class=""kn"">import</span> <span class=""n"">MailSender</span>
<span class=""n"">mailer</span> <span class=""o"">=</span> <span class=""n"">MailSender</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">mailer</span> <span class=""o"">=</span> <span class=""n"">MailSender</span><span class=""o"">.</span><span class=""n"">from_settings</span><span class=""p"">(</span><span class=""n"">settings</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">mailer</span><span class=""o"">.</span><span class=""n"">send</span><span class=""p"">(</span><span class=""n"">to</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""someone@example.com""</span><span class=""p"">],</span> <span class=""n"">subject</span><span class=""o"">=</span><span class=""s2"">""Some subject""</span><span class=""p"">,</span> <span class=""n"">body</span><span class=""o"">=</span><span class=""s2"">""Some body""</span><span class=""p"">,</span> <span class=""n"">cc</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""another@example.com""</span><span class=""p"">])</span>
</pre></div>","from scrapy.mail import MailSender
mailer = MailSender()
,mailer = MailSender.from_settings(settings)
,mailer.send(to=[""someone@example.com""], subject=""Some subject"", body=""Some body"", cc=[""another@example.com""])
",3
https://docs.scrapy.org/en/latest/topics/email.html,,##,2,Quick example,#quick-example,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.mail</span> <span class=""kn"">import</span> <span class=""n"">MailSender</span>
<span class=""n"">mailer</span> <span class=""o"">=</span> <span class=""n"">MailSender</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">mailer</span> <span class=""o"">=</span> <span class=""n"">MailSender</span><span class=""o"">.</span><span class=""n"">from_settings</span><span class=""p"">(</span><span class=""n"">settings</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">mailer</span><span class=""o"">.</span><span class=""n"">send</span><span class=""p"">(</span><span class=""n"">to</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""someone@example.com""</span><span class=""p"">],</span> <span class=""n"">subject</span><span class=""o"">=</span><span class=""s2"">""Some subject""</span><span class=""p"">,</span> <span class=""n"">body</span><span class=""o"">=</span><span class=""s2"">""Some body""</span><span class=""p"">,</span> <span class=""n"">cc</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""another@example.com""</span><span class=""p"">])</span>
</pre></div>","from scrapy.mail import MailSender
mailer = MailSender()
,mailer = MailSender.from_settings(settings)
,mailer.send(to=[""someone@example.com""], subject=""Some subject"", body=""Some body"", cc=[""another@example.com""])
",3
https://docs.scrapy.org/en/latest/topics/email.html,,##,2,MailSender class reference,#mailsender-class-reference,,,3
https://docs.scrapy.org/en/latest/topics/email.html,,##,2,Mail settings,#mail-settings,,,4
https://docs.scrapy.org/en/latest/topics/email.html,,###,3,MAIL_FROM,#mail-from,,,5
https://docs.scrapy.org/en/latest/topics/email.html,,###,3,MAIL_HOST,#mail-host,,,6
https://docs.scrapy.org/en/latest/topics/email.html,,###,3,MAIL_PORT,#mail-port,,,7
https://docs.scrapy.org/en/latest/topics/email.html,,###,3,MAIL_USER,#mail-user,,,8
https://docs.scrapy.org/en/latest/topics/email.html,,###,3,MAIL_PASS,#mail-pass,,,9
https://docs.scrapy.org/en/latest/topics/email.html,,###,3,MAIL_TLS,#mail-tls,,,10
https://docs.scrapy.org/en/latest/topics/email.html,,###,3,MAIL_SSL,#mail-ssl,,,11
https://docs.scrapy.org/en/latest/topics/telnetconsole.html,,#,1,Telnet Console,#telnet-console,"<div class=""highlight""><pre><span></span>telnet localhost 6023
Trying localhost...
Connected to localhost.
Escape character is '^]'.
Username:
Password:
&gt;&gt;&gt;
</pre></div>,<div class=""highlight""><pre><span></span>2018-10-16 14:35:21 [scrapy.extensions.telnet] INFO: Telnet Password: 16f92501e8a59326
</pre></div>,<div class=""highlight""><pre><span></span>telnet localhost 6023
&gt;&gt;&gt; est()
Execution engine status

time()-engine.start_time                        : 8.62972998619
len(engine.downloader.active)                   : 16
engine.scraper.is_idle()                        : False
engine.spider.name                              : followall
engine.spider_is_idle()                         : False
engine.slot.closing                             : False
len(engine.slot.inprogress)                     : 16
len(engine.slot.scheduler.dqs or [])            : 0
len(engine.slot.scheduler.mqs)                  : 92
len(engine.scraper.slot.queue)                  : 0
len(engine.scraper.slot.active)                 : 0
engine.scraper.slot.active_size                 : 0
engine.scraper.slot.itemproc_size               : 0
engine.scraper.slot.needs_backout()             : False
</pre></div>,<div class=""highlight""><pre><span></span>telnet localhost 6023
&gt;&gt;&gt; engine.pause()
&gt;&gt;&gt;
</pre></div>,<div class=""highlight""><pre><span></span>telnet localhost 6023
&gt;&gt;&gt; engine.unpause()
&gt;&gt;&gt;
</pre></div>,<div class=""highlight""><pre><span></span>telnet localhost 6023
&gt;&gt;&gt; engine.stop()
Connection closed by foreign host.
</pre></div>","telnet localhost 6023
Trying localhost...
Connected to localhost.
Escape character is '^]'.
Username:
Password:
>>>
,2018-10-16 14:35:21 [scrapy.extensions.telnet] INFO: Telnet Password: 16f92501e8a59326
,telnet localhost 6023
>>> est()
Execution engine status

time()-engine.start_time                        : 8.62972998619
len(engine.downloader.active)                   : 16
engine.scraper.is_idle()                        : False
engine.spider.name                              : followall
engine.spider_is_idle()                         : False
engine.slot.closing                             : False
len(engine.slot.inprogress)                     : 16
len(engine.slot.scheduler.dqs or [])            : 0
len(engine.slot.scheduler.mqs)                  : 92
len(engine.scraper.slot.queue)                  : 0
len(engine.scraper.slot.active)                 : 0
engine.scraper.slot.active_size                 : 0
engine.scraper.slot.itemproc_size               : 0
engine.scraper.slot.needs_backout()             : False
,telnet localhost 6023
>>> engine.pause()
>>>
,telnet localhost 6023
>>> engine.unpause()
>>>
,telnet localhost 6023
>>> engine.stop()
Connection closed by foreign host.
",6
https://docs.scrapy.org/en/latest/topics/telnetconsole.html,,##,2,How to access the telnet console,#how-to-access-the-telnet-console,"<div class=""highlight""><pre><span></span>telnet localhost 6023
Trying localhost...
Connected to localhost.
Escape character is '^]'.
Username:
Password:
&gt;&gt;&gt;
</pre></div>,<div class=""highlight""><pre><span></span>2018-10-16 14:35:21 [scrapy.extensions.telnet] INFO: Telnet Password: 16f92501e8a59326
</pre></div>","telnet localhost 6023
Trying localhost...
Connected to localhost.
Escape character is '^]'.
Username:
Password:
>>>
,2018-10-16 14:35:21 [scrapy.extensions.telnet] INFO: Telnet Password: 16f92501e8a59326
",2
https://docs.scrapy.org/en/latest/topics/telnetconsole.html,,##,2,Available variables in the telnet console,#available-variables-in-the-telnet-console,,,3
https://docs.scrapy.org/en/latest/topics/telnetconsole.html,,##,2,Telnet console usage examples,#telnet-console-usage-examples,"<div class=""highlight""><pre><span></span>telnet localhost 6023
&gt;&gt;&gt; est()
Execution engine status

time()-engine.start_time                        : 8.62972998619
len(engine.downloader.active)                   : 16
engine.scraper.is_idle()                        : False
engine.spider.name                              : followall
engine.spider_is_idle()                         : False
engine.slot.closing                             : False
len(engine.slot.inprogress)                     : 16
len(engine.slot.scheduler.dqs or [])            : 0
len(engine.slot.scheduler.mqs)                  : 92
len(engine.scraper.slot.queue)                  : 0
len(engine.scraper.slot.active)                 : 0
engine.scraper.slot.active_size                 : 0
engine.scraper.slot.itemproc_size               : 0
engine.scraper.slot.needs_backout()             : False
</pre></div>,<div class=""highlight""><pre><span></span>telnet localhost 6023
&gt;&gt;&gt; engine.pause()
&gt;&gt;&gt;
</pre></div>,<div class=""highlight""><pre><span></span>telnet localhost 6023
&gt;&gt;&gt; engine.unpause()
&gt;&gt;&gt;
</pre></div>,<div class=""highlight""><pre><span></span>telnet localhost 6023
&gt;&gt;&gt; engine.stop()
Connection closed by foreign host.
</pre></div>","telnet localhost 6023
>>> est()
Execution engine status

time()-engine.start_time                        : 8.62972998619
len(engine.downloader.active)                   : 16
engine.scraper.is_idle()                        : False
engine.spider.name                              : followall
engine.spider_is_idle()                         : False
engine.slot.closing                             : False
len(engine.slot.inprogress)                     : 16
len(engine.slot.scheduler.dqs or [])            : 0
len(engine.slot.scheduler.mqs)                  : 92
len(engine.scraper.slot.queue)                  : 0
len(engine.scraper.slot.active)                 : 0
engine.scraper.slot.active_size                 : 0
engine.scraper.slot.itemproc_size               : 0
engine.scraper.slot.needs_backout()             : False
,telnet localhost 6023
>>> engine.pause()
>>>
,telnet localhost 6023
>>> engine.unpause()
>>>
,telnet localhost 6023
>>> engine.stop()
Connection closed by foreign host.
",4
https://docs.scrapy.org/en/latest/topics/telnetconsole.html,,###,3,View engine status,#view-engine-status,"<div class=""highlight""><pre><span></span>telnet localhost 6023
&gt;&gt;&gt; est()
Execution engine status

time()-engine.start_time                        : 8.62972998619
len(engine.downloader.active)                   : 16
engine.scraper.is_idle()                        : False
engine.spider.name                              : followall
engine.spider_is_idle()                         : False
engine.slot.closing                             : False
len(engine.slot.inprogress)                     : 16
len(engine.slot.scheduler.dqs or [])            : 0
len(engine.slot.scheduler.mqs)                  : 92
len(engine.scraper.slot.queue)                  : 0
len(engine.scraper.slot.active)                 : 0
engine.scraper.slot.active_size                 : 0
engine.scraper.slot.itemproc_size               : 0
engine.scraper.slot.needs_backout()             : False
</pre></div>","telnet localhost 6023
>>> est()
Execution engine status

time()-engine.start_time                        : 8.62972998619
len(engine.downloader.active)                   : 16
engine.scraper.is_idle()                        : False
engine.spider.name                              : followall
engine.spider_is_idle()                         : False
engine.slot.closing                             : False
len(engine.slot.inprogress)                     : 16
len(engine.slot.scheduler.dqs or [])            : 0
len(engine.slot.scheduler.mqs)                  : 92
len(engine.scraper.slot.queue)                  : 0
len(engine.scraper.slot.active)                 : 0
engine.scraper.slot.active_size                 : 0
engine.scraper.slot.itemproc_size               : 0
engine.scraper.slot.needs_backout()             : False
",1
https://docs.scrapy.org/en/latest/topics/telnetconsole.html,,###,3,"Pause, resume and stop the Scrapy engine",#pause-resume-and-stop-the-scrapy-engine,"<div class=""highlight""><pre><span></span>telnet localhost 6023
&gt;&gt;&gt; engine.pause()
&gt;&gt;&gt;
</pre></div>,<div class=""highlight""><pre><span></span>telnet localhost 6023
&gt;&gt;&gt; engine.unpause()
&gt;&gt;&gt;
</pre></div>,<div class=""highlight""><pre><span></span>telnet localhost 6023
&gt;&gt;&gt; engine.stop()
Connection closed by foreign host.
</pre></div>","telnet localhost 6023
>>> engine.pause()
>>>
,telnet localhost 6023
>>> engine.unpause()
>>>
,telnet localhost 6023
>>> engine.stop()
Connection closed by foreign host.
",3
https://docs.scrapy.org/en/latest/topics/telnetconsole.html,,##,2,Telnet Console signals,#telnet-console-signals,,,7
https://docs.scrapy.org/en/latest/topics/telnetconsole.html,,##,2,Telnet settings,#telnet-settings,,,8
https://docs.scrapy.org/en/latest/topics/telnetconsole.html,,###,3,TELNETCONSOLE_PORT,#telnetconsole-port,,,9
https://docs.scrapy.org/en/latest/topics/telnetconsole.html,,###,3,TELNETCONSOLE_HOST,#telnetconsole-host,,,10
https://docs.scrapy.org/en/latest/topics/telnetconsole.html,,###,3,TELNETCONSOLE_USERNAME,#telnetconsole-username,,,11
https://docs.scrapy.org/en/latest/topics/telnetconsole.html,,###,3,TELNETCONSOLE_PASSWORD,#telnetconsole-password,,,12
https://docs.scrapy.org/en/latest/faq.html,,#,1,Frequently Asked Questions,#frequently-asked-questions,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">bs4</span> <span class=""kn"">import</span> <span class=""n"">BeautifulSoup</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">ExampleSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""example""</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s2"">""example.com""</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">(</span>
        <span class=""s1"">'http://www.example.com/'</span><span class=""p"">,</span>
    <span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""c1""># use lxml to get decent HTML parsing speed</span>
        <span class=""n"">soup</span> <span class=""o"">=</span> <span class=""n"">BeautifulSoup</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">text</span><span class=""p"">,</span> <span class=""s1"">'lxml'</span><span class=""p"">)</span>
        <span class=""k"">yield</span> <span class=""p"">{</span>
            <span class=""s2"">""url""</span><span class=""p"">:</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">,</span>
            <span class=""s2"">""title""</span><span class=""p"">:</span> <span class=""n"">soup</span><span class=""o"">.</span><span class=""n"">h1</span><span class=""o"">.</span><span class=""n"">string</span>
        <span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">DEPTH_PRIORITY</span> <span class=""o"">=</span> <span class=""mi"">1</span>
<span class=""n"">SCHEDULER_DISK_QUEUE</span> <span class=""o"">=</span> <span class=""s1"">'scrapy.squeues.PickleFifoDiskQueue'</span>
<span class=""n"">SCHEDULER_MEMORY_QUEUE</span> <span class=""o"">=</span> <span class=""s1"">'scrapy.squeues.FifoMemoryQueue'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">SPIDER_MIDDLEWARES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
    <span class=""s1"">'myproject.middlewares.CustomOffsiteMiddleware'</span><span class=""p"">:</span> <span class=""mi"">500</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">runspider</span> <span class=""n"">my_spider</span><span class=""o"">.</span><span class=""n"">py</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">CrawlSpider</span><span class=""p"">):</span>

    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>

    <span class=""n"">download_delay</span> <span class=""o"">=</span> <span class=""mi"">2</span>

    <span class=""c1""># [ ... rest of the spider code ... ]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">myspider</span> <span class=""o"">-</span><span class=""n"">O</span> <span class=""n"">items</span><span class=""o"">.</span><span class=""n"">json</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">myspider</span> <span class=""o"">-</span><span class=""n"">O</span> <span class=""n"">items</span><span class=""o"">.</span><span class=""n"">csv</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">myspider</span> <span class=""o"">-</span><span class=""n"">O</span> <span class=""n"">items</span><span class=""o"">.</span><span class=""n"">xml</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">copy</span> <span class=""kn"">import</span> <span class=""n"">deepcopy</span>

<span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">is_item</span><span class=""p"">,</span> <span class=""n"">ItemAdapter</span>

<span class=""k"">class</span> <span class=""nc"">MultiplyItemsMiddleware</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""nf"">process_spider_output</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">result</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">item</span> <span class=""ow"">in</span> <span class=""n"">result</span><span class=""p"">:</span>
            <span class=""k"">if</span> <span class=""n"">is_item</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">):</span>
                <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
                <span class=""k"">for</span> <span class=""n"">_</span> <span class=""ow"">in</span> <span class=""nb"">range</span><span class=""p"">(</span><span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'multiply_by'</span><span class=""p"">]):</span>
                    <span class=""k"">yield</span> <span class=""n"">deepcopy</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
</pre></div>","from bs4 import BeautifulSoup
import scrapy


class ExampleSpider(scrapy.Spider):
    name = ""example""
    allowed_domains = [""example.com""]
    start_urls = (
        'http://www.example.com/',
    )

    def parse(self, response):
        # use lxml to get decent HTML parsing speed
        soup = BeautifulSoup(response.text, 'lxml')
        yield {
            ""url"": response.url,
            ""title"": soup.h1.string
        }
,DEPTH_PRIORITY = 1
SCHEDULER_DISK_QUEUE = 'scrapy.squeues.PickleFifoDiskQueue'
SCHEDULER_MEMORY_QUEUE = 'scrapy.squeues.FifoMemoryQueue'
,SPIDER_MIDDLEWARES = {
    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': None,
    'myproject.middlewares.CustomOffsiteMiddleware': 500,
}
,scrapy runspider my_spider.py
,class MySpider(CrawlSpider):

    name = 'myspider'

    download_delay = 2

    # [ ... rest of the spider code ... ]
,scrapy crawl myspider -O items.json
,scrapy crawl myspider -O items.csv
,scrapy crawl myspider -O items.xml
,from copy import deepcopy

from itemadapter import is_item, ItemAdapter

class MultiplyItemsMiddleware:

    def process_spider_output(self, response, result, spider):
        for item in result:
            if is_item(item):
                adapter = ItemAdapter(item)
                for _ in range(adapter['multiply_by']):
                    yield deepcopy(item)
",9
https://docs.scrapy.org/en/latest/faq.html,,##,2,How does Scrapy compare to BeautifulSoup or lxml?,#how-does-scrapy-compare-to-beautifulsoup-or-lxml,,,2
https://docs.scrapy.org/en/latest/faq.html,,##,2,Can I use Scrapy with BeautifulSoup?,#can-i-use-scrapy-with-beautifulsoup,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">bs4</span> <span class=""kn"">import</span> <span class=""n"">BeautifulSoup</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>


<span class=""k"">class</span> <span class=""nc"">ExampleSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""example""</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s2"">""example.com""</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">(</span>
        <span class=""s1"">'http://www.example.com/'</span><span class=""p"">,</span>
    <span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""c1""># use lxml to get decent HTML parsing speed</span>
        <span class=""n"">soup</span> <span class=""o"">=</span> <span class=""n"">BeautifulSoup</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">text</span><span class=""p"">,</span> <span class=""s1"">'lxml'</span><span class=""p"">)</span>
        <span class=""k"">yield</span> <span class=""p"">{</span>
            <span class=""s2"">""url""</span><span class=""p"">:</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">,</span>
            <span class=""s2"">""title""</span><span class=""p"">:</span> <span class=""n"">soup</span><span class=""o"">.</span><span class=""n"">h1</span><span class=""o"">.</span><span class=""n"">string</span>
        <span class=""p"">}</span>
</pre></div>","from bs4 import BeautifulSoup
import scrapy


class ExampleSpider(scrapy.Spider):
    name = ""example""
    allowed_domains = [""example.com""]
    start_urls = (
        'http://www.example.com/',
    )

    def parse(self, response):
        # use lxml to get decent HTML parsing speed
        soup = BeautifulSoup(response.text, 'lxml')
        yield {
            ""url"": response.url,
            ""title"": soup.h1.string
        }
",1
https://docs.scrapy.org/en/latest/faq.html,,##,2,Did Scrapy “steal” X from Django?,#did-scrapy-steal-x-from-django,,,4
https://docs.scrapy.org/en/latest/faq.html,,##,2,Does Scrapy work with HTTP proxies?,#does-scrapy-work-with-http-proxies,,,5
https://docs.scrapy.org/en/latest/faq.html,,##,2,How can I scrape an item with attributes in different pages?,#how-can-i-scrape-an-item-with-attributes-in-different-pages,,,6
https://docs.scrapy.org/en/latest/faq.html,,##,2,How can I simulate a user login in my spider?,#how-can-i-simulate-a-user-login-in-my-spider,,,7
https://docs.scrapy.org/en/latest/faq.html,,##,2,Does Scrapy crawl in breadth-first or depth-first order?,#does-scrapy-crawl-in-breadth-first-or-depth-first-order,"<div class=""highlight""><pre><span></span><span class=""n"">DEPTH_PRIORITY</span> <span class=""o"">=</span> <span class=""mi"">1</span>
<span class=""n"">SCHEDULER_DISK_QUEUE</span> <span class=""o"">=</span> <span class=""s1"">'scrapy.squeues.PickleFifoDiskQueue'</span>
<span class=""n"">SCHEDULER_MEMORY_QUEUE</span> <span class=""o"">=</span> <span class=""s1"">'scrapy.squeues.FifoMemoryQueue'</span>
</pre></div>","DEPTH_PRIORITY = 1
SCHEDULER_DISK_QUEUE = 'scrapy.squeues.PickleFifoDiskQueue'
SCHEDULER_MEMORY_QUEUE = 'scrapy.squeues.FifoMemoryQueue'
",1
https://docs.scrapy.org/en/latest/faq.html,,##,2,My Scrapy crawler has memory leaks. What can I do?,#my-scrapy-crawler-has-memory-leaks-what-can-i-do,,,9
https://docs.scrapy.org/en/latest/faq.html,,##,2,How can I make Scrapy consume less memory?,#how-can-i-make-scrapy-consume-less-memory,,,10
https://docs.scrapy.org/en/latest/faq.html,,##,2,How can I prevent memory errors due to many allowed domains?,#how-can-i-prevent-memory-errors-due-to-many-allowed-domains,"<div class=""highlight""><pre><span></span><span class=""n"">SPIDER_MIDDLEWARES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
    <span class=""s1"">'myproject.middlewares.CustomOffsiteMiddleware'</span><span class=""p"">:</span> <span class=""mi"">500</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","SPIDER_MIDDLEWARES = {
    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': None,
    'myproject.middlewares.CustomOffsiteMiddleware': 500,
}
",1
https://docs.scrapy.org/en/latest/faq.html,,##,2,Can I use Basic HTTP Authentication in my spiders?,#can-i-use-basic-http-authentication-in-my-spiders,,,12
https://docs.scrapy.org/en/latest/faq.html,,##,2,Why does Scrapy download pages in English instead of my native language?,#why-does-scrapy-download-pages-in-english-instead-of-my-native-language,,,13
https://docs.scrapy.org/en/latest/faq.html,,##,2,Where can I find some example Scrapy projects?,#where-can-i-find-some-example-scrapy-projects,,,14
https://docs.scrapy.org/en/latest/faq.html,,##,2,Can I run a spider without creating a project?,#can-i-run-a-spider-without-creating-a-project,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">runspider</span> <span class=""n"">my_spider</span><span class=""o"">.</span><span class=""n"">py</span>
</pre></div>","scrapy runspider my_spider.py
",1
https://docs.scrapy.org/en/latest/faq.html,,##,2,I get “Filtered offsite request” messages. How can I fix them?,#i-get-filtered-offsite-request-messages-how-can-i-fix-them,,,16
https://docs.scrapy.org/en/latest/faq.html,,##,2,What is the recommended way to deploy a Scrapy crawler in production?,#what-is-the-recommended-way-to-deploy-a-scrapy-crawler-in-production,,,17
https://docs.scrapy.org/en/latest/faq.html,,##,2,Can I use JSON for large exports?,#can-i-use-json-for-large-exports,,,18
https://docs.scrapy.org/en/latest/faq.html,,##,2,Can I return (Twisted) deferreds from signal handlers?,#can-i-return-twisted-deferreds-from-signal-handlers,,,19
https://docs.scrapy.org/en/latest/faq.html,,##,2,What does the response status code 999 means?,#what-does-the-response-status-code-999-means,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">CrawlSpider</span><span class=""p"">):</span>

    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>

    <span class=""n"">download_delay</span> <span class=""o"">=</span> <span class=""mi"">2</span>

    <span class=""c1""># [ ... rest of the spider code ... ]</span>
</pre></div>","class MySpider(CrawlSpider):

    name = 'myspider'

    download_delay = 2

    # [ ... rest of the spider code ... ]
",1
https://docs.scrapy.org/en/latest/faq.html,,##,2,Can I call pdb.set_trace() from my spiders to debug them?,#can-i-call-pdb-set-trace-from-my-spiders-to-debug-them,,,21
https://docs.scrapy.org/en/latest/faq.html,,##,2,Simplest way to dump all my scraped items into a JSON/CSV/XML file?,#simplest-way-to-dump-all-my-scraped-items-into-a-json-csv-xml-file,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">myspider</span> <span class=""o"">-</span><span class=""n"">O</span> <span class=""n"">items</span><span class=""o"">.</span><span class=""n"">json</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">myspider</span> <span class=""o"">-</span><span class=""n"">O</span> <span class=""n"">items</span><span class=""o"">.</span><span class=""n"">csv</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">myspider</span> <span class=""o"">-</span><span class=""n"">O</span> <span class=""n"">items</span><span class=""o"">.</span><span class=""n"">xml</span>
</pre></div>","scrapy crawl myspider -O items.json
,scrapy crawl myspider -O items.csv
,scrapy crawl myspider -O items.xml
",3
https://docs.scrapy.org/en/latest/faq.html,,##,2,What’s this huge cryptic __VIEWSTATE parameter used in some forms?,#what-s-this-huge-cryptic-viewstate-parameter-used-in-some-forms,,,23
https://docs.scrapy.org/en/latest/faq.html,,##,2,What’s the best way to parse big XML/CSV data feeds?,#what-s-the-best-way-to-parse-big-xml-csv-data-feeds,,,24
https://docs.scrapy.org/en/latest/faq.html,,##,2,Does Scrapy manage cookies automatically?,#does-scrapy-manage-cookies-automatically,,,25
https://docs.scrapy.org/en/latest/faq.html,,##,2,How can I see the cookies being sent and received from Scrapy?,#how-can-i-see-the-cookies-being-sent-and-received-from-scrapy,,,26
https://docs.scrapy.org/en/latest/faq.html,,##,2,How can I instruct a spider to stop itself?,#how-can-i-instruct-a-spider-to-stop-itself,,,27
https://docs.scrapy.org/en/latest/faq.html,,##,2,How can I prevent my Scrapy bot from getting banned?,#how-can-i-prevent-my-scrapy-bot-from-getting-banned,,,28
https://docs.scrapy.org/en/latest/faq.html,,##,2,Should I use spider arguments or settings to configure my spider?,#should-i-use-spider-arguments-or-settings-to-configure-my-spider,,,29
https://docs.scrapy.org/en/latest/faq.html,,##,2,I’m scraping a XML document and my XPath selector doesn’t return any items,#i-m-scraping-a-xml-document-and-my-xpath-selector-doesn-t-return-any-items,,,30
https://docs.scrapy.org/en/latest/faq.html,,##,2,How to split an item into multiple items in an item pipeline?,#how-to-split-an-item-into-multiple-items-in-an-item-pipeline,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">copy</span> <span class=""kn"">import</span> <span class=""n"">deepcopy</span>

<span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">is_item</span><span class=""p"">,</span> <span class=""n"">ItemAdapter</span>

<span class=""k"">class</span> <span class=""nc"">MultiplyItemsMiddleware</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""nf"">process_spider_output</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">result</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">item</span> <span class=""ow"">in</span> <span class=""n"">result</span><span class=""p"">:</span>
            <span class=""k"">if</span> <span class=""n"">is_item</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">):</span>
                <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
                <span class=""k"">for</span> <span class=""n"">_</span> <span class=""ow"">in</span> <span class=""nb"">range</span><span class=""p"">(</span><span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'multiply_by'</span><span class=""p"">]):</span>
                    <span class=""k"">yield</span> <span class=""n"">deepcopy</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
</pre></div>","from copy import deepcopy

from itemadapter import is_item, ItemAdapter

class MultiplyItemsMiddleware:

    def process_spider_output(self, response, result, spider):
        for item in result:
            if is_item(item):
                adapter = ItemAdapter(item)
                for _ in range(adapter['multiply_by']):
                    yield deepcopy(item)
",1
https://docs.scrapy.org/en/latest/faq.html,,##,2,Does Scrapy support IPv6 addresses?,#does-scrapy-support-ipv6-addresses,,,32
https://docs.scrapy.org/en/latest/faq.html,,##,2,How to deal with <class 'ValueError'>: filedescriptor out of range in select() exceptions?,#how-to-deal-with-class-valueerror-filedescriptor-out-of-range-in-select-exceptions,,,33
https://docs.scrapy.org/en/latest/faq.html,,##,2,How can I cancel the download of a given response?,#how-can-i-cancel-the-download-of-a-given-response,,,34
https://docs.scrapy.org/en/latest/faq.html,,##,2,Running runspider I get error: No spider found in file: <filename>,#running-runspider-i-get-error-no-spider-found-in-file-filename,,,35
https://docs.scrapy.org/en/latest/topics/debug.html,,#,1,Debugging Spiders,#debugging-spiders,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">myproject.items</span> <span class=""kn"">import</span> <span class=""n"">MyItem</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'myspider'</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">(</span>
        <span class=""s1"">'http://example.com/page1'</span><span class=""p"">,</span>
        <span class=""s1"">'http://example.com/page2'</span><span class=""p"">,</span>
        <span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""c1""># &lt;processing code not shown&gt;</span>
        <span class=""c1""># collect `item_urls`</span>
        <span class=""k"">for</span> <span class=""n"">item_url</span> <span class=""ow"">in</span> <span class=""n"">item_urls</span><span class=""p"">:</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">item_url</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_item</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">parse_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""c1""># &lt;processing code not shown&gt;</span>
        <span class=""n"">item</span> <span class=""o"">=</span> <span class=""n"">MyItem</span><span class=""p"">()</span>
        <span class=""c1""># populate `item` fields</span>
        <span class=""c1""># and extract item_details_url</span>
        <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">item_details_url</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_details</span><span class=""p"">,</span> <span class=""n"">cb_kwargs</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'item'</span><span class=""p"">:</span> <span class=""n"">item</span><span class=""p"">})</span>

    <span class=""k"">def</span> <span class=""nf"">parse_details</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">):</span>
        <span class=""c1""># populate more `item` fields</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy parse --spider=myspider -c parse_item -d 2 &lt;item_url&gt;
[ ... scrapy log lines crawling example.com spider ... ]

&gt;&gt;&gt; STATUS DEPTH LEVEL 2 &lt;&lt;&lt;
# Scraped Items  ------------------------------------------------------------
[{'url': &lt;item_url&gt;}]

# Requests  -----------------------------------------------------------------
[]
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy parse --spider=myspider -c parse_item -d 2 -v &lt;item_url&gt;
[ ... scrapy log lines crawling example.com spider ... ]

&gt;&gt;&gt; DEPTH LEVEL: 1 &lt;&lt;&lt;
# Scraped Items  ------------------------------------------------------------
[]

# Requests  -----------------------------------------------------------------
[&lt;GET item_details_url&gt;]


&gt;&gt;&gt; DEPTH LEVEL: 2 &lt;&lt;&lt;
# Scraped Items  ------------------------------------------------------------
[{'url': &lt;item_url&gt;}]

# Requests  -----------------------------------------------------------------
[]
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy parse --spider=myspider -d 3 'http://example.com/page1'
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.shell</span> <span class=""kn"">import</span> <span class=""n"">inspect_response</span>

<span class=""k"">def</span> <span class=""nf"">parse_details</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">):</span>
    <span class=""k"">if</span> <span class=""n"">item</span><span class=""p"">:</span>
        <span class=""c1""># populate more `item` fields</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
    <span class=""k"">else</span><span class=""p"">:</span>
        <span class=""n"">inspect_response</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.utils.response</span> <span class=""kn"">import</span> <span class=""n"">open_in_browser</span>

<span class=""k"">def</span> <span class=""nf"">parse_details</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""k"">if</span> <span class=""s2"">""item name""</span> <span class=""ow"">not</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">body</span><span class=""p"">:</span>
        <span class=""n"">open_in_browser</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse_details</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">):</span>
    <span class=""k"">if</span> <span class=""n"">item</span><span class=""p"">:</span>
        <span class=""c1""># populate more `item` fields</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
    <span class=""k"">else</span><span class=""p"">:</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">warning</span><span class=""p"">(</span><span class=""s1"">'No item received for </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>","import scrapy
from myproject.items import MyItem

class MySpider(scrapy.Spider):
    name = 'myspider'
    start_urls = (
        'http://example.com/page1',
        'http://example.com/page2',
        )

    def parse(self, response):
        # <processing code not shown>
        # collect `item_urls`
        for item_url in item_urls:
            yield scrapy.Request(item_url, self.parse_item)

    def parse_item(self, response):
        # <processing code not shown>
        item = MyItem()
        # populate `item` fields
        # and extract item_details_url
        yield scrapy.Request(item_details_url, self.parse_details, cb_kwargs={'item': item})

    def parse_details(self, response, item):
        # populate more `item` fields
        return item
,$ scrapy parse --spider=myspider -c parse_item -d 2 <item_url>
[ ... scrapy log lines crawling example.com spider ... ]

>>> STATUS DEPTH LEVEL 2 <<<
# Scraped Items  ------------------------------------------------------------
[{'url': <item_url>}]

# Requests  -----------------------------------------------------------------
[]
,$ scrapy parse --spider=myspider -c parse_item -d 2 -v <item_url>
[ ... scrapy log lines crawling example.com spider ... ]

>>> DEPTH LEVEL: 1 <<<
# Scraped Items  ------------------------------------------------------------
[]

# Requests  -----------------------------------------------------------------
[<GET item_details_url>]


>>> DEPTH LEVEL: 2 <<<
# Scraped Items  ------------------------------------------------------------
[{'url': <item_url>}]

# Requests  -----------------------------------------------------------------
[]
,$ scrapy parse --spider=myspider -d 3 'http://example.com/page1'
,from scrapy.shell import inspect_response

def parse_details(self, response, item=None):
    if item:
        # populate more `item` fields
        return item
    else:
        inspect_response(response, self)
,from scrapy.utils.response import open_in_browser

def parse_details(self, response):
    if ""item name"" not in response.body:
        open_in_browser(response)
,def parse_details(self, response, item=None):
    if item:
        # populate more `item` fields
        return item
    else:
        self.logger.warning('No item received for %s', response.url)
",7
https://docs.scrapy.org/en/latest/topics/debug.html,,##,2,Parse Command,#parse-command,"<div class=""highlight""><pre><span></span>$ scrapy parse --spider=myspider -c parse_item -d 2 &lt;item_url&gt;
[ ... scrapy log lines crawling example.com spider ... ]

&gt;&gt;&gt; STATUS DEPTH LEVEL 2 &lt;&lt;&lt;
# Scraped Items  ------------------------------------------------------------
[{'url': &lt;item_url&gt;}]

# Requests  -----------------------------------------------------------------
[]
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy parse --spider=myspider -c parse_item -d 2 -v &lt;item_url&gt;
[ ... scrapy log lines crawling example.com spider ... ]

&gt;&gt;&gt; DEPTH LEVEL: 1 &lt;&lt;&lt;
# Scraped Items  ------------------------------------------------------------
[]

# Requests  -----------------------------------------------------------------
[&lt;GET item_details_url&gt;]


&gt;&gt;&gt; DEPTH LEVEL: 2 &lt;&lt;&lt;
# Scraped Items  ------------------------------------------------------------
[{'url': &lt;item_url&gt;}]

# Requests  -----------------------------------------------------------------
[]
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy parse --spider=myspider -d 3 'http://example.com/page1'
</pre></div>","$ scrapy parse --spider=myspider -c parse_item -d 2 <item_url>
[ ... scrapy log lines crawling example.com spider ... ]

>>> STATUS DEPTH LEVEL 2 <<<
# Scraped Items  ------------------------------------------------------------
[{'url': <item_url>}]

# Requests  -----------------------------------------------------------------
[]
,$ scrapy parse --spider=myspider -c parse_item -d 2 -v <item_url>
[ ... scrapy log lines crawling example.com spider ... ]

>>> DEPTH LEVEL: 1 <<<
# Scraped Items  ------------------------------------------------------------
[]

# Requests  -----------------------------------------------------------------
[<GET item_details_url>]


>>> DEPTH LEVEL: 2 <<<
# Scraped Items  ------------------------------------------------------------
[{'url': <item_url>}]

# Requests  -----------------------------------------------------------------
[]
,$ scrapy parse --spider=myspider -d 3 'http://example.com/page1'
",3
https://docs.scrapy.org/en/latest/topics/debug.html,,##,2,Scrapy Shell,#scrapy-shell,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.shell</span> <span class=""kn"">import</span> <span class=""n"">inspect_response</span>

<span class=""k"">def</span> <span class=""nf"">parse_details</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">):</span>
    <span class=""k"">if</span> <span class=""n"">item</span><span class=""p"">:</span>
        <span class=""c1""># populate more `item` fields</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
    <span class=""k"">else</span><span class=""p"">:</span>
        <span class=""n"">inspect_response</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""p"">)</span>
</pre></div>","from scrapy.shell import inspect_response

def parse_details(self, response, item=None):
    if item:
        # populate more `item` fields
        return item
    else:
        inspect_response(response, self)
",1
https://docs.scrapy.org/en/latest/topics/debug.html,,##,2,Open in browser,#open-in-browser,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.utils.response</span> <span class=""kn"">import</span> <span class=""n"">open_in_browser</span>

<span class=""k"">def</span> <span class=""nf"">parse_details</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""k"">if</span> <span class=""s2"">""item name""</span> <span class=""ow"">not</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">body</span><span class=""p"">:</span>
        <span class=""n"">open_in_browser</span><span class=""p"">(</span><span class=""n"">response</span><span class=""p"">)</span>
</pre></div>","from scrapy.utils.response import open_in_browser

def parse_details(self, response):
    if ""item name"" not in response.body:
        open_in_browser(response)
",1
https://docs.scrapy.org/en/latest/topics/debug.html,,##,2,Logging,#logging,"<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse_details</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">):</span>
    <span class=""k"">if</span> <span class=""n"">item</span><span class=""p"">:</span>
        <span class=""c1""># populate more `item` fields</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
    <span class=""k"">else</span><span class=""p"">:</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">warning</span><span class=""p"">(</span><span class=""s1"">'No item received for </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>","def parse_details(self, response, item=None):
    if item:
        # populate more `item` fields
        return item
    else:
        self.logger.warning('No item received for %s', response.url)
",1
https://docs.scrapy.org/en/latest/topics/contracts.html,,#,1,Spiders Contracts,#spiders-contracts,"<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""sd"">"""""" This function parses a sample response. Some contracts are mingled</span>
<span class=""sd"">    with this docstring.</span>

<span class=""sd"">    @url http://www.amazon.com/s?field-keywords=selfish+gene</span>
<span class=""sd"">    @returns items 1 16</span>
<span class=""sd"">    @returns requests 0 0</span>
<span class=""sd"">    @scrapes Title Author Year Price</span>
<span class=""sd"">    """"""</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""nd"">@url</span> <span class=""n"">url</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""nd"">@cb_kwargs</span> <span class=""p"">{</span><span class=""s2"">""arg1""</span><span class=""p"">:</span> <span class=""s2"">""value1""</span><span class=""p"">,</span> <span class=""s2"">""arg2""</span><span class=""p"">:</span> <span class=""s2"">""value2""</span><span class=""p"">,</span> <span class=""o"">...</span><span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""nd"">@returns</span> <span class=""n"">item</span><span class=""p"">(</span><span class=""n"">s</span><span class=""p"">)</span><span class=""o"">|</span><span class=""n"">request</span><span class=""p"">(</span><span class=""n"">s</span><span class=""p"">)</span> <span class=""p"">[</span><span class=""nb"">min</span> <span class=""p"">[</span><span class=""nb"">max</span><span class=""p"">]]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""nd"">@scrapes</span> <span class=""n"">field_1</span> <span class=""n"">field_2</span> <span class=""o"">...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">SPIDER_CONTRACTS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'myproject.contracts.ResponseCheck'</span><span class=""p"">:</span> <span class=""mi"">10</span><span class=""p"">,</span>
    <span class=""s1"">'myproject.contracts.ItemValidate'</span><span class=""p"">:</span> <span class=""mi"">10</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.contracts</span> <span class=""kn"">import</span> <span class=""n"">Contract</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exceptions</span> <span class=""kn"">import</span> <span class=""n"">ContractFail</span>

<span class=""k"">class</span> <span class=""nc"">HasHeaderContract</span><span class=""p"">(</span><span class=""n"">Contract</span><span class=""p"">):</span>
    <span class=""sd"">"""""" Demo contract which checks the presence of a custom header</span>
<span class=""sd"">        @has_header X-CustomHeader</span>
<span class=""sd"">    """"""</span>

    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'has_header'</span>

    <span class=""k"">def</span> <span class=""nf"">pre_process</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">header</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">args</span><span class=""p"">:</span>
            <span class=""k"">if</span> <span class=""n"">header</span> <span class=""ow"">not</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">headers</span><span class=""p"">:</span>
                <span class=""k"">raise</span> <span class=""n"">ContractFail</span><span class=""p"">(</span><span class=""s1"">'X-CustomHeader not present'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">os</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">ExampleSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example'</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">os</span><span class=""o"">.</span><span class=""n"">environ</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'SCRAPY_CHECK'</span><span class=""p"">):</span>
            <span class=""k"">pass</span>  <span class=""c1""># Do some scraper adjustments when a check is running</span>
</pre></div>","def parse(self, response):
    """""" This function parses a sample response. Some contracts are mingled
    with this docstring.

    @url http://www.amazon.com/s?field-keywords=selfish+gene
    @returns items 1 16
    @returns requests 0 0
    @scrapes Title Author Year Price
    """"""
,@url url
,@cb_kwargs {""arg1"": ""value1"", ""arg2"": ""value2"", ...}
,@returns item(s)|request(s) [min [max]]
,@scrapes field_1 field_2 ...
,SPIDER_CONTRACTS = {
    'myproject.contracts.ResponseCheck': 10,
    'myproject.contracts.ItemValidate': 10,
}
,from scrapy.contracts import Contract
from scrapy.exceptions import ContractFail

class HasHeaderContract(Contract):
    """""" Demo contract which checks the presence of a custom header
        @has_header X-CustomHeader
    """"""

    name = 'has_header'

    def pre_process(self, response):
        for header in self.args:
            if header not in response.headers:
                raise ContractFail('X-CustomHeader not present')
,import os
import scrapy

class ExampleSpider(scrapy.Spider):
    name = 'example'

    def __init__(self):
        if os.environ.get('SCRAPY_CHECK'):
            pass  # Do some scraper adjustments when a check is running
",8
https://docs.scrapy.org/en/latest/topics/contracts.html,,##,2,Custom Contracts,#custom-contracts,"<div class=""highlight""><pre><span></span><span class=""n"">SPIDER_CONTRACTS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'myproject.contracts.ResponseCheck'</span><span class=""p"">:</span> <span class=""mi"">10</span><span class=""p"">,</span>
    <span class=""s1"">'myproject.contracts.ItemValidate'</span><span class=""p"">:</span> <span class=""mi"">10</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.contracts</span> <span class=""kn"">import</span> <span class=""n"">Contract</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exceptions</span> <span class=""kn"">import</span> <span class=""n"">ContractFail</span>

<span class=""k"">class</span> <span class=""nc"">HasHeaderContract</span><span class=""p"">(</span><span class=""n"">Contract</span><span class=""p"">):</span>
    <span class=""sd"">"""""" Demo contract which checks the presence of a custom header</span>
<span class=""sd"">        @has_header X-CustomHeader</span>
<span class=""sd"">    """"""</span>

    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'has_header'</span>

    <span class=""k"">def</span> <span class=""nf"">pre_process</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">header</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">args</span><span class=""p"">:</span>
            <span class=""k"">if</span> <span class=""n"">header</span> <span class=""ow"">not</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">headers</span><span class=""p"">:</span>
                <span class=""k"">raise</span> <span class=""n"">ContractFail</span><span class=""p"">(</span><span class=""s1"">'X-CustomHeader not present'</span><span class=""p"">)</span>
</pre></div>","SPIDER_CONTRACTS = {
    'myproject.contracts.ResponseCheck': 10,
    'myproject.contracts.ItemValidate': 10,
}
,from scrapy.contracts import Contract
from scrapy.exceptions import ContractFail

class HasHeaderContract(Contract):
    """""" Demo contract which checks the presence of a custom header
        @has_header X-CustomHeader
    """"""

    name = 'has_header'

    def pre_process(self, response):
        for header in self.args:
            if header not in response.headers:
                raise ContractFail('X-CustomHeader not present')
",2
https://docs.scrapy.org/en/latest/topics/contracts.html,,##,2,Detecting check runs,#detecting-check-runs,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">os</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">ExampleSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'example'</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">os</span><span class=""o"">.</span><span class=""n"">environ</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'SCRAPY_CHECK'</span><span class=""p"">):</span>
            <span class=""k"">pass</span>  <span class=""c1""># Do some scraper adjustments when a check is running</span>
</pre></div>","import os
import scrapy

class ExampleSpider(scrapy.Spider):
    name = 'example'

    def __init__(self):
        if os.environ.get('SCRAPY_CHECK'):
            pass  # Do some scraper adjustments when a check is running
",1
https://docs.scrapy.org/en/latest/topics/practices.html,,#,1,Common Practices,#common-practices,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.crawler</span> <span class=""kn"">import</span> <span class=""n"">CrawlerProcess</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># Your spider definition</span>
    <span class=""o"">...</span>

<span class=""n"">process</span> <span class=""o"">=</span> <span class=""n"">CrawlerProcess</span><span class=""p"">(</span><span class=""n"">settings</span><span class=""o"">=</span><span class=""p"">{</span>
    <span class=""s2"">""FEEDS""</span><span class=""p"">:</span> <span class=""p"">{</span>
        <span class=""s2"">""items.json""</span><span class=""p"">:</span> <span class=""p"">{</span><span class=""s2"">""format""</span><span class=""p"">:</span> <span class=""s2"">""json""</span><span class=""p"">},</span>
    <span class=""p"">},</span>
<span class=""p"">})</span>

<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider</span><span class=""p"">)</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">start</span><span class=""p"">()</span> <span class=""c1""># the script will block here until the crawling is finished</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.crawler</span> <span class=""kn"">import</span> <span class=""n"">CrawlerProcess</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.project</span> <span class=""kn"">import</span> <span class=""n"">get_project_settings</span>

<span class=""n"">process</span> <span class=""o"">=</span> <span class=""n"">CrawlerProcess</span><span class=""p"">(</span><span class=""n"">get_project_settings</span><span class=""p"">())</span>

<span class=""c1""># 'followall' is the name of one of the spiders of the project.</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""s1"">'followall'</span><span class=""p"">,</span> <span class=""n"">domain</span><span class=""o"">=</span><span class=""s1"">'scrapy.org'</span><span class=""p"">)</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">start</span><span class=""p"">()</span> <span class=""c1""># the script will block here until the crawling is finished</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">twisted.internet</span> <span class=""kn"">import</span> <span class=""n"">reactor</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.crawler</span> <span class=""kn"">import</span> <span class=""n"">CrawlerRunner</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.log</span> <span class=""kn"">import</span> <span class=""n"">configure_logging</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># Your spider definition</span>
    <span class=""o"">...</span>

<span class=""n"">configure_logging</span><span class=""p"">({</span><span class=""s1"">'LOG_FORMAT'</span><span class=""p"">:</span> <span class=""s1"">'</span><span class=""si"">%(levelname)s</span><span class=""s1"">: </span><span class=""si"">%(message)s</span><span class=""s1"">'</span><span class=""p"">})</span>
<span class=""n"">runner</span> <span class=""o"">=</span> <span class=""n"">CrawlerRunner</span><span class=""p"">()</span>

<span class=""n"">d</span> <span class=""o"">=</span> <span class=""n"">runner</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider</span><span class=""p"">)</span>
<span class=""n"">d</span><span class=""o"">.</span><span class=""n"">addBoth</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">_</span><span class=""p"">:</span> <span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">stop</span><span class=""p"">())</span>
<span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">run</span><span class=""p"">()</span> <span class=""c1""># the script will block here until the crawling is finished</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.crawler</span> <span class=""kn"">import</span> <span class=""n"">CrawlerProcess</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.project</span> <span class=""kn"">import</span> <span class=""n"">get_project_settings</span>

<span class=""k"">class</span> <span class=""nc"">MySpider1</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># Your first spider definition</span>
    <span class=""o"">...</span>

<span class=""k"">class</span> <span class=""nc"">MySpider2</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># Your second spider definition</span>
    <span class=""o"">...</span>

<span class=""n"">settings</span> <span class=""o"">=</span> <span class=""n"">get_project_settings</span><span class=""p"">()</span>
<span class=""n"">process</span> <span class=""o"">=</span> <span class=""n"">CrawlerProcess</span><span class=""p"">(</span><span class=""n"">settings</span><span class=""p"">)</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider1</span><span class=""p"">)</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider2</span><span class=""p"">)</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">start</span><span class=""p"">()</span> <span class=""c1""># the script will block here until all crawling jobs are finished</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">twisted.internet</span> <span class=""kn"">import</span> <span class=""n"">reactor</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.crawler</span> <span class=""kn"">import</span> <span class=""n"">CrawlerRunner</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.log</span> <span class=""kn"">import</span> <span class=""n"">configure_logging</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.project</span> <span class=""kn"">import</span> <span class=""n"">get_project_settings</span>

<span class=""k"">class</span> <span class=""nc"">MySpider1</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># Your first spider definition</span>
    <span class=""o"">...</span>

<span class=""k"">class</span> <span class=""nc"">MySpider2</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># Your second spider definition</span>
    <span class=""o"">...</span>

<span class=""n"">configure_logging</span><span class=""p"">()</span>
<span class=""n"">settings</span> <span class=""o"">=</span> <span class=""n"">get_project_settings</span><span class=""p"">()</span>
<span class=""n"">runner</span> <span class=""o"">=</span> <span class=""n"">CrawlerRunner</span><span class=""p"">(</span><span class=""n"">settings</span><span class=""p"">)</span>
<span class=""n"">runner</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider1</span><span class=""p"">)</span>
<span class=""n"">runner</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider2</span><span class=""p"">)</span>
<span class=""n"">d</span> <span class=""o"">=</span> <span class=""n"">runner</span><span class=""o"">.</span><span class=""n"">join</span><span class=""p"">()</span>
<span class=""n"">d</span><span class=""o"">.</span><span class=""n"">addBoth</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">_</span><span class=""p"">:</span> <span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">stop</span><span class=""p"">())</span>

<span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">run</span><span class=""p"">()</span> <span class=""c1""># the script will block here until all crawling jobs are finished</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">twisted.internet</span> <span class=""kn"">import</span> <span class=""n"">reactor</span><span class=""p"">,</span> <span class=""n"">defer</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.crawler</span> <span class=""kn"">import</span> <span class=""n"">CrawlerRunner</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.log</span> <span class=""kn"">import</span> <span class=""n"">configure_logging</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.project</span> <span class=""kn"">import</span> <span class=""n"">get_project_settings</span>

<span class=""k"">class</span> <span class=""nc"">MySpider1</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># Your first spider definition</span>
    <span class=""o"">...</span>

<span class=""k"">class</span> <span class=""nc"">MySpider2</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># Your second spider definition</span>
    <span class=""o"">...</span>

<span class=""n"">settings</span> <span class=""o"">=</span> <span class=""n"">get_project_settings</span><span class=""p"">()</span>
<span class=""n"">configure_logging</span><span class=""p"">(</span><span class=""n"">settings</span><span class=""p"">)</span>
<span class=""n"">runner</span> <span class=""o"">=</span> <span class=""n"">CrawlerRunner</span><span class=""p"">(</span><span class=""n"">settings</span><span class=""p"">)</span>

<span class=""nd"">@defer</span><span class=""o"">.</span><span class=""n"">inlineCallbacks</span>
<span class=""k"">def</span> <span class=""nf"">crawl</span><span class=""p"">():</span>
    <span class=""k"">yield</span> <span class=""n"">runner</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider1</span><span class=""p"">)</span>
    <span class=""k"">yield</span> <span class=""n"">runner</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider2</span><span class=""p"">)</span>
    <span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">stop</span><span class=""p"">()</span>

<span class=""n"">crawl</span><span class=""p"">()</span>
<span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">run</span><span class=""p"">()</span> <span class=""c1""># the script will block here until the last crawl call is finished</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">somedomain</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">urls</span><span class=""o"">-</span><span class=""n"">to</span><span class=""o"">-</span><span class=""n"">crawl</span><span class=""o"">/</span><span class=""n"">spider1</span><span class=""o"">/</span><span class=""n"">part1</span><span class=""o"">.</span><span class=""n"">list</span>
<span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">somedomain</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">urls</span><span class=""o"">-</span><span class=""n"">to</span><span class=""o"">-</span><span class=""n"">crawl</span><span class=""o"">/</span><span class=""n"">spider1</span><span class=""o"">/</span><span class=""n"">part2</span><span class=""o"">.</span><span class=""n"">list</span>
<span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">somedomain</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">urls</span><span class=""o"">-</span><span class=""n"">to</span><span class=""o"">-</span><span class=""n"">crawl</span><span class=""o"">/</span><span class=""n"">spider1</span><span class=""o"">/</span><span class=""n"">part3</span><span class=""o"">.</span><span class=""n"">list</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">curl</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">scrapy1</span><span class=""o"">.</span><span class=""n"">mycompany</span><span class=""o"">.</span><span class=""n"">com</span><span class=""p"">:</span><span class=""mi"">6800</span><span class=""o"">/</span><span class=""n"">schedule</span><span class=""o"">.</span><span class=""n"">json</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">project</span><span class=""o"">=</span><span class=""n"">myproject</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">spider</span><span class=""o"">=</span><span class=""n"">spider1</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">part</span><span class=""o"">=</span><span class=""mi"">1</span>
<span class=""n"">curl</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">scrapy2</span><span class=""o"">.</span><span class=""n"">mycompany</span><span class=""o"">.</span><span class=""n"">com</span><span class=""p"">:</span><span class=""mi"">6800</span><span class=""o"">/</span><span class=""n"">schedule</span><span class=""o"">.</span><span class=""n"">json</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">project</span><span class=""o"">=</span><span class=""n"">myproject</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">spider</span><span class=""o"">=</span><span class=""n"">spider1</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">part</span><span class=""o"">=</span><span class=""mi"">2</span>
<span class=""n"">curl</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">scrapy3</span><span class=""o"">.</span><span class=""n"">mycompany</span><span class=""o"">.</span><span class=""n"">com</span><span class=""p"">:</span><span class=""mi"">6800</span><span class=""o"">/</span><span class=""n"">schedule</span><span class=""o"">.</span><span class=""n"">json</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">project</span><span class=""o"">=</span><span class=""n"">myproject</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">spider</span><span class=""o"">=</span><span class=""n"">spider1</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">part</span><span class=""o"">=</span><span class=""mi"">3</span>
</pre></div>","import scrapy
from scrapy.crawler import CrawlerProcess

class MySpider(scrapy.Spider):
    # Your spider definition
    ...

process = CrawlerProcess(settings={
    ""FEEDS"": {
        ""items.json"": {""format"": ""json""},
    },
})

process.crawl(MySpider)
process.start() # the script will block here until the crawling is finished
,from scrapy.crawler import CrawlerProcess
from scrapy.utils.project import get_project_settings

process = CrawlerProcess(get_project_settings())

# 'followall' is the name of one of the spiders of the project.
process.crawl('followall', domain='scrapy.org')
process.start() # the script will block here until the crawling is finished
,from twisted.internet import reactor
import scrapy
from scrapy.crawler import CrawlerRunner
from scrapy.utils.log import configure_logging

class MySpider(scrapy.Spider):
    # Your spider definition
    ...

configure_logging({'LOG_FORMAT': '%(levelname)s: %(message)s'})
runner = CrawlerRunner()

d = runner.crawl(MySpider)
d.addBoth(lambda _: reactor.stop())
reactor.run() # the script will block here until the crawling is finished
,import scrapy
from scrapy.crawler import CrawlerProcess
from scrapy.utils.project import get_project_settings

class MySpider1(scrapy.Spider):
    # Your first spider definition
    ...

class MySpider2(scrapy.Spider):
    # Your second spider definition
    ...

settings = get_project_settings()
process = CrawlerProcess(settings)
process.crawl(MySpider1)
process.crawl(MySpider2)
process.start() # the script will block here until all crawling jobs are finished
,import scrapy
from twisted.internet import reactor
from scrapy.crawler import CrawlerRunner
from scrapy.utils.log import configure_logging
from scrapy.utils.project import get_project_settings

class MySpider1(scrapy.Spider):
    # Your first spider definition
    ...

class MySpider2(scrapy.Spider):
    # Your second spider definition
    ...

configure_logging()
settings = get_project_settings()
runner = CrawlerRunner(settings)
runner.crawl(MySpider1)
runner.crawl(MySpider2)
d = runner.join()
d.addBoth(lambda _: reactor.stop())

reactor.run() # the script will block here until all crawling jobs are finished
,from twisted.internet import reactor, defer
from scrapy.crawler import CrawlerRunner
from scrapy.utils.log import configure_logging
from scrapy.utils.project import get_project_settings

class MySpider1(scrapy.Spider):
    # Your first spider definition
    ...

class MySpider2(scrapy.Spider):
    # Your second spider definition
    ...

settings = get_project_settings()
configure_logging(settings)
runner = CrawlerRunner(settings)

@defer.inlineCallbacks
def crawl():
    yield runner.crawl(MySpider1)
    yield runner.crawl(MySpider2)
    reactor.stop()

crawl()
reactor.run() # the script will block here until the last crawl call is finished
,http://somedomain.com/urls-to-crawl/spider1/part1.list
http://somedomain.com/urls-to-crawl/spider1/part2.list
http://somedomain.com/urls-to-crawl/spider1/part3.list
,curl http://scrapy1.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=1
curl http://scrapy2.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=2
curl http://scrapy3.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=3
",8
https://docs.scrapy.org/en/latest/topics/practices.html,,##,2,Run Scrapy from a script,#run-scrapy-from-a-script,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.crawler</span> <span class=""kn"">import</span> <span class=""n"">CrawlerProcess</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># Your spider definition</span>
    <span class=""o"">...</span>

<span class=""n"">process</span> <span class=""o"">=</span> <span class=""n"">CrawlerProcess</span><span class=""p"">(</span><span class=""n"">settings</span><span class=""o"">=</span><span class=""p"">{</span>
    <span class=""s2"">""FEEDS""</span><span class=""p"">:</span> <span class=""p"">{</span>
        <span class=""s2"">""items.json""</span><span class=""p"">:</span> <span class=""p"">{</span><span class=""s2"">""format""</span><span class=""p"">:</span> <span class=""s2"">""json""</span><span class=""p"">},</span>
    <span class=""p"">},</span>
<span class=""p"">})</span>

<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider</span><span class=""p"">)</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">start</span><span class=""p"">()</span> <span class=""c1""># the script will block here until the crawling is finished</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.crawler</span> <span class=""kn"">import</span> <span class=""n"">CrawlerProcess</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.project</span> <span class=""kn"">import</span> <span class=""n"">get_project_settings</span>

<span class=""n"">process</span> <span class=""o"">=</span> <span class=""n"">CrawlerProcess</span><span class=""p"">(</span><span class=""n"">get_project_settings</span><span class=""p"">())</span>

<span class=""c1""># 'followall' is the name of one of the spiders of the project.</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""s1"">'followall'</span><span class=""p"">,</span> <span class=""n"">domain</span><span class=""o"">=</span><span class=""s1"">'scrapy.org'</span><span class=""p"">)</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">start</span><span class=""p"">()</span> <span class=""c1""># the script will block here until the crawling is finished</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">twisted.internet</span> <span class=""kn"">import</span> <span class=""n"">reactor</span>
<span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.crawler</span> <span class=""kn"">import</span> <span class=""n"">CrawlerRunner</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.log</span> <span class=""kn"">import</span> <span class=""n"">configure_logging</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># Your spider definition</span>
    <span class=""o"">...</span>

<span class=""n"">configure_logging</span><span class=""p"">({</span><span class=""s1"">'LOG_FORMAT'</span><span class=""p"">:</span> <span class=""s1"">'</span><span class=""si"">%(levelname)s</span><span class=""s1"">: </span><span class=""si"">%(message)s</span><span class=""s1"">'</span><span class=""p"">})</span>
<span class=""n"">runner</span> <span class=""o"">=</span> <span class=""n"">CrawlerRunner</span><span class=""p"">()</span>

<span class=""n"">d</span> <span class=""o"">=</span> <span class=""n"">runner</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider</span><span class=""p"">)</span>
<span class=""n"">d</span><span class=""o"">.</span><span class=""n"">addBoth</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">_</span><span class=""p"">:</span> <span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">stop</span><span class=""p"">())</span>
<span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">run</span><span class=""p"">()</span> <span class=""c1""># the script will block here until the crawling is finished</span>
</pre></div>","import scrapy
from scrapy.crawler import CrawlerProcess

class MySpider(scrapy.Spider):
    # Your spider definition
    ...

process = CrawlerProcess(settings={
    ""FEEDS"": {
        ""items.json"": {""format"": ""json""},
    },
})

process.crawl(MySpider)
process.start() # the script will block here until the crawling is finished
,from scrapy.crawler import CrawlerProcess
from scrapy.utils.project import get_project_settings

process = CrawlerProcess(get_project_settings())

# 'followall' is the name of one of the spiders of the project.
process.crawl('followall', domain='scrapy.org')
process.start() # the script will block here until the crawling is finished
,from twisted.internet import reactor
import scrapy
from scrapy.crawler import CrawlerRunner
from scrapy.utils.log import configure_logging

class MySpider(scrapy.Spider):
    # Your spider definition
    ...

configure_logging({'LOG_FORMAT': '%(levelname)s: %(message)s'})
runner = CrawlerRunner()

d = runner.crawl(MySpider)
d.addBoth(lambda _: reactor.stop())
reactor.run() # the script will block here until the crawling is finished
",3
https://docs.scrapy.org/en/latest/topics/practices.html,,##,2,Running multiple spiders in the same process,#running-multiple-spiders-in-the-same-process,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.crawler</span> <span class=""kn"">import</span> <span class=""n"">CrawlerProcess</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.project</span> <span class=""kn"">import</span> <span class=""n"">get_project_settings</span>

<span class=""k"">class</span> <span class=""nc"">MySpider1</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># Your first spider definition</span>
    <span class=""o"">...</span>

<span class=""k"">class</span> <span class=""nc"">MySpider2</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># Your second spider definition</span>
    <span class=""o"">...</span>

<span class=""n"">settings</span> <span class=""o"">=</span> <span class=""n"">get_project_settings</span><span class=""p"">()</span>
<span class=""n"">process</span> <span class=""o"">=</span> <span class=""n"">CrawlerProcess</span><span class=""p"">(</span><span class=""n"">settings</span><span class=""p"">)</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider1</span><span class=""p"">)</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider2</span><span class=""p"">)</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">start</span><span class=""p"">()</span> <span class=""c1""># the script will block here until all crawling jobs are finished</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">twisted.internet</span> <span class=""kn"">import</span> <span class=""n"">reactor</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.crawler</span> <span class=""kn"">import</span> <span class=""n"">CrawlerRunner</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.log</span> <span class=""kn"">import</span> <span class=""n"">configure_logging</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.project</span> <span class=""kn"">import</span> <span class=""n"">get_project_settings</span>

<span class=""k"">class</span> <span class=""nc"">MySpider1</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># Your first spider definition</span>
    <span class=""o"">...</span>

<span class=""k"">class</span> <span class=""nc"">MySpider2</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># Your second spider definition</span>
    <span class=""o"">...</span>

<span class=""n"">configure_logging</span><span class=""p"">()</span>
<span class=""n"">settings</span> <span class=""o"">=</span> <span class=""n"">get_project_settings</span><span class=""p"">()</span>
<span class=""n"">runner</span> <span class=""o"">=</span> <span class=""n"">CrawlerRunner</span><span class=""p"">(</span><span class=""n"">settings</span><span class=""p"">)</span>
<span class=""n"">runner</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider1</span><span class=""p"">)</span>
<span class=""n"">runner</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider2</span><span class=""p"">)</span>
<span class=""n"">d</span> <span class=""o"">=</span> <span class=""n"">runner</span><span class=""o"">.</span><span class=""n"">join</span><span class=""p"">()</span>
<span class=""n"">d</span><span class=""o"">.</span><span class=""n"">addBoth</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">_</span><span class=""p"">:</span> <span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">stop</span><span class=""p"">())</span>

<span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">run</span><span class=""p"">()</span> <span class=""c1""># the script will block here until all crawling jobs are finished</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">twisted.internet</span> <span class=""kn"">import</span> <span class=""n"">reactor</span><span class=""p"">,</span> <span class=""n"">defer</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.crawler</span> <span class=""kn"">import</span> <span class=""n"">CrawlerRunner</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.log</span> <span class=""kn"">import</span> <span class=""n"">configure_logging</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.utils.project</span> <span class=""kn"">import</span> <span class=""n"">get_project_settings</span>

<span class=""k"">class</span> <span class=""nc"">MySpider1</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># Your first spider definition</span>
    <span class=""o"">...</span>

<span class=""k"">class</span> <span class=""nc"">MySpider2</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># Your second spider definition</span>
    <span class=""o"">...</span>

<span class=""n"">settings</span> <span class=""o"">=</span> <span class=""n"">get_project_settings</span><span class=""p"">()</span>
<span class=""n"">configure_logging</span><span class=""p"">(</span><span class=""n"">settings</span><span class=""p"">)</span>
<span class=""n"">runner</span> <span class=""o"">=</span> <span class=""n"">CrawlerRunner</span><span class=""p"">(</span><span class=""n"">settings</span><span class=""p"">)</span>

<span class=""nd"">@defer</span><span class=""o"">.</span><span class=""n"">inlineCallbacks</span>
<span class=""k"">def</span> <span class=""nf"">crawl</span><span class=""p"">():</span>
    <span class=""k"">yield</span> <span class=""n"">runner</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider1</span><span class=""p"">)</span>
    <span class=""k"">yield</span> <span class=""n"">runner</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider2</span><span class=""p"">)</span>
    <span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">stop</span><span class=""p"">()</span>

<span class=""n"">crawl</span><span class=""p"">()</span>
<span class=""n"">reactor</span><span class=""o"">.</span><span class=""n"">run</span><span class=""p"">()</span> <span class=""c1""># the script will block here until the last crawl call is finished</span>
</pre></div>","import scrapy
from scrapy.crawler import CrawlerProcess
from scrapy.utils.project import get_project_settings

class MySpider1(scrapy.Spider):
    # Your first spider definition
    ...

class MySpider2(scrapy.Spider):
    # Your second spider definition
    ...

settings = get_project_settings()
process = CrawlerProcess(settings)
process.crawl(MySpider1)
process.crawl(MySpider2)
process.start() # the script will block here until all crawling jobs are finished
,import scrapy
from twisted.internet import reactor
from scrapy.crawler import CrawlerRunner
from scrapy.utils.log import configure_logging
from scrapy.utils.project import get_project_settings

class MySpider1(scrapy.Spider):
    # Your first spider definition
    ...

class MySpider2(scrapy.Spider):
    # Your second spider definition
    ...

configure_logging()
settings = get_project_settings()
runner = CrawlerRunner(settings)
runner.crawl(MySpider1)
runner.crawl(MySpider2)
d = runner.join()
d.addBoth(lambda _: reactor.stop())

reactor.run() # the script will block here until all crawling jobs are finished
,from twisted.internet import reactor, defer
from scrapy.crawler import CrawlerRunner
from scrapy.utils.log import configure_logging
from scrapy.utils.project import get_project_settings

class MySpider1(scrapy.Spider):
    # Your first spider definition
    ...

class MySpider2(scrapy.Spider):
    # Your second spider definition
    ...

settings = get_project_settings()
configure_logging(settings)
runner = CrawlerRunner(settings)

@defer.inlineCallbacks
def crawl():
    yield runner.crawl(MySpider1)
    yield runner.crawl(MySpider2)
    reactor.stop()

crawl()
reactor.run() # the script will block here until the last crawl call is finished
",3
https://docs.scrapy.org/en/latest/topics/practices.html,,##,2,Distributed crawls,#distributed-crawls,"<div class=""highlight""><pre><span></span><span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">somedomain</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">urls</span><span class=""o"">-</span><span class=""n"">to</span><span class=""o"">-</span><span class=""n"">crawl</span><span class=""o"">/</span><span class=""n"">spider1</span><span class=""o"">/</span><span class=""n"">part1</span><span class=""o"">.</span><span class=""n"">list</span>
<span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">somedomain</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">urls</span><span class=""o"">-</span><span class=""n"">to</span><span class=""o"">-</span><span class=""n"">crawl</span><span class=""o"">/</span><span class=""n"">spider1</span><span class=""o"">/</span><span class=""n"">part2</span><span class=""o"">.</span><span class=""n"">list</span>
<span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">somedomain</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">urls</span><span class=""o"">-</span><span class=""n"">to</span><span class=""o"">-</span><span class=""n"">crawl</span><span class=""o"">/</span><span class=""n"">spider1</span><span class=""o"">/</span><span class=""n"">part3</span><span class=""o"">.</span><span class=""n"">list</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">curl</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">scrapy1</span><span class=""o"">.</span><span class=""n"">mycompany</span><span class=""o"">.</span><span class=""n"">com</span><span class=""p"">:</span><span class=""mi"">6800</span><span class=""o"">/</span><span class=""n"">schedule</span><span class=""o"">.</span><span class=""n"">json</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">project</span><span class=""o"">=</span><span class=""n"">myproject</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">spider</span><span class=""o"">=</span><span class=""n"">spider1</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">part</span><span class=""o"">=</span><span class=""mi"">1</span>
<span class=""n"">curl</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">scrapy2</span><span class=""o"">.</span><span class=""n"">mycompany</span><span class=""o"">.</span><span class=""n"">com</span><span class=""p"">:</span><span class=""mi"">6800</span><span class=""o"">/</span><span class=""n"">schedule</span><span class=""o"">.</span><span class=""n"">json</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">project</span><span class=""o"">=</span><span class=""n"">myproject</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">spider</span><span class=""o"">=</span><span class=""n"">spider1</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">part</span><span class=""o"">=</span><span class=""mi"">2</span>
<span class=""n"">curl</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">scrapy3</span><span class=""o"">.</span><span class=""n"">mycompany</span><span class=""o"">.</span><span class=""n"">com</span><span class=""p"">:</span><span class=""mi"">6800</span><span class=""o"">/</span><span class=""n"">schedule</span><span class=""o"">.</span><span class=""n"">json</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">project</span><span class=""o"">=</span><span class=""n"">myproject</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">spider</span><span class=""o"">=</span><span class=""n"">spider1</span> <span class=""o"">-</span><span class=""n"">d</span> <span class=""n"">part</span><span class=""o"">=</span><span class=""mi"">3</span>
</pre></div>","http://somedomain.com/urls-to-crawl/spider1/part1.list
http://somedomain.com/urls-to-crawl/spider1/part2.list
http://somedomain.com/urls-to-crawl/spider1/part3.list
,curl http://scrapy1.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=1
curl http://scrapy2.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=2
curl http://scrapy3.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=3
",2
https://docs.scrapy.org/en/latest/topics/practices.html,,##,2,Avoiding getting banned,#avoiding-getting-banned,,,5
https://docs.scrapy.org/en/latest/topics/broad-crawls.html,,#,1,Broad Crawls,#broad-crawls,"<div class=""highlight""><pre><span></span><span class=""n"">SCHEDULER_PRIORITY_QUEUE</span> <span class=""o"">=</span> <span class=""s1"">'scrapy.pqueues.DownloaderAwarePriorityQueue'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">CONCURRENT_REQUESTS</span> <span class=""o"">=</span> <span class=""mi"">100</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">REACTOR_THREADPOOL_MAXSIZE</span> <span class=""o"">=</span> <span class=""mi"">20</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">LOG_LEVEL</span> <span class=""o"">=</span> <span class=""s1"">'INFO'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">COOKIES_ENABLED</span> <span class=""o"">=</span> <span class=""kc"">False</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">RETRY_ENABLED</span> <span class=""o"">=</span> <span class=""kc"">False</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">DOWNLOAD_TIMEOUT</span> <span class=""o"">=</span> <span class=""mi"">15</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">REDIRECT_ENABLED</span> <span class=""o"">=</span> <span class=""kc"">False</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">AJAXCRAWL_ENABLED</span> <span class=""o"">=</span> <span class=""kc"">True</span>
</pre></div>","SCHEDULER_PRIORITY_QUEUE = 'scrapy.pqueues.DownloaderAwarePriorityQueue'
,CONCURRENT_REQUESTS = 100
,REACTOR_THREADPOOL_MAXSIZE = 20
,LOG_LEVEL = 'INFO'
,COOKIES_ENABLED = False
,RETRY_ENABLED = False
,DOWNLOAD_TIMEOUT = 15
,REDIRECT_ENABLED = False
,AJAXCRAWL_ENABLED = True
",9
https://docs.scrapy.org/en/latest/topics/broad-crawls.html,,##,2,Use the right SCHEDULER_PRIORITY_QUEUE,settings.html#std-setting-SCHEDULER_PRIORITY_QUEUE,"<div class=""highlight""><pre><span></span><span class=""n"">SCHEDULER_PRIORITY_QUEUE</span> <span class=""o"">=</span> <span class=""s1"">'scrapy.pqueues.DownloaderAwarePriorityQueue'</span>
</pre></div>","SCHEDULER_PRIORITY_QUEUE = 'scrapy.pqueues.DownloaderAwarePriorityQueue'
",1
https://docs.scrapy.org/en/latest/topics/broad-crawls.html,,##,2,Increase concurrency,#increase-concurrency,"<div class=""highlight""><pre><span></span><span class=""n"">CONCURRENT_REQUESTS</span> <span class=""o"">=</span> <span class=""mi"">100</span>
</pre></div>","CONCURRENT_REQUESTS = 100
",1
https://docs.scrapy.org/en/latest/topics/broad-crawls.html,,##,2,Increase Twisted IO thread pool maximum size,#increase-twisted-io-thread-pool-maximum-size,"<div class=""highlight""><pre><span></span><span class=""n"">REACTOR_THREADPOOL_MAXSIZE</span> <span class=""o"">=</span> <span class=""mi"">20</span>
</pre></div>","REACTOR_THREADPOOL_MAXSIZE = 20
",1
https://docs.scrapy.org/en/latest/topics/broad-crawls.html,,##,2,Setup your own DNS,#setup-your-own-dns,,,5
https://docs.scrapy.org/en/latest/topics/broad-crawls.html,,##,2,Reduce log level,#reduce-log-level,"<div class=""highlight""><pre><span></span><span class=""n"">LOG_LEVEL</span> <span class=""o"">=</span> <span class=""s1"">'INFO'</span>
</pre></div>","LOG_LEVEL = 'INFO'
",1
https://docs.scrapy.org/en/latest/topics/broad-crawls.html,,##,2,Disable cookies,#disable-cookies,"<div class=""highlight""><pre><span></span><span class=""n"">COOKIES_ENABLED</span> <span class=""o"">=</span> <span class=""kc"">False</span>
</pre></div>","COOKIES_ENABLED = False
",1
https://docs.scrapy.org/en/latest/topics/broad-crawls.html,,##,2,Disable retries,#disable-retries,"<div class=""highlight""><pre><span></span><span class=""n"">RETRY_ENABLED</span> <span class=""o"">=</span> <span class=""kc"">False</span>
</pre></div>","RETRY_ENABLED = False
",1
https://docs.scrapy.org/en/latest/topics/broad-crawls.html,,##,2,Reduce download timeout,#reduce-download-timeout,"<div class=""highlight""><pre><span></span><span class=""n"">DOWNLOAD_TIMEOUT</span> <span class=""o"">=</span> <span class=""mi"">15</span>
</pre></div>","DOWNLOAD_TIMEOUT = 15
",1
https://docs.scrapy.org/en/latest/topics/broad-crawls.html,,##,2,Disable redirects,#disable-redirects,"<div class=""highlight""><pre><span></span><span class=""n"">REDIRECT_ENABLED</span> <span class=""o"">=</span> <span class=""kc"">False</span>
</pre></div>","REDIRECT_ENABLED = False
",1
https://docs.scrapy.org/en/latest/topics/broad-crawls.html,,##,2,Enable crawling of “Ajax Crawlable Pages”,#enable-crawling-of-ajax-crawlable-pages,"<div class=""highlight""><pre><span></span><span class=""n"">AJAXCRAWL_ENABLED</span> <span class=""o"">=</span> <span class=""kc"">True</span>
</pre></div>","AJAXCRAWL_ENABLED = True
",1
https://docs.scrapy.org/en/latest/topics/broad-crawls.html,,##,2,Crawl in BFO order,#crawl-in-bfo-order,,,12
https://docs.scrapy.org/en/latest/topics/broad-crawls.html,,##,2,Be mindful of memory leaks,#be-mindful-of-memory-leaks,,,13
https://docs.scrapy.org/en/latest/topics/broad-crawls.html,,##,2,Install a specific Twisted reactor,#install-a-specific-twisted-reactor,,,14
https://docs.scrapy.org/en/latest/topics/developer-tools.html,,#,1,Using your browser’s Developer Tools for scraping,#using-your-browser-s-developer-tools-for-scraping,"<div class=""highlight""><pre><span></span><span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""quote""</span> <span class=""na"">itemscope</span><span class=""o"">=</span><span class=""s"">""""</span> <span class=""na"">itemtype</span><span class=""o"">=</span><span class=""s"">""http://schema.org/CreativeWork""</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">span</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""text""</span> <span class=""na"">itemprop</span><span class=""o"">=</span><span class=""s"">""text""</span><span class=""p"">&gt;</span>(...)<span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">span</span><span class=""p"">&gt;</span>(...)<span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tags""</span><span class=""p"">&gt;</span>(...)<span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy shell ""https://quotes.toscrape.com/""
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'/html/body/div/div[2]/div[1]/div[1]/span[1]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""quote""</span> <span class=""na"">itemscope</span><span class=""o"">=</span><span class=""s"">""""</span> <span class=""na"">itemtype</span><span class=""o"">=</span><span class=""s"">""http://schema.org/CreativeWork""</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">span</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""text""</span> <span class=""na"">itemprop</span><span class=""o"">=</span><span class=""s"">""text""</span><span class=""p"">&gt;</span>
    “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”
  <span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">span</span><span class=""p"">&gt;</span>(...)<span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tags""</span><span class=""p"">&gt;</span>(...)<span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//span[has-class(""text"")]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',</span>
<span class=""go"">'“It is our choices, Harry, that show what we truly are, far more than our abilities.”',</span>
<span class=""go"">'“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',</span>
<span class=""go"">...]</span>
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy shell ""quotes.toscrape.com/scroll""
(...)
&gt;&gt;&gt; view(response)
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">import</span> <span class=""nn"">json</span>


<span class=""k"">class</span> <span class=""nc"">QuoteSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'quote'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'quotes.toscrape.com'</span><span class=""p"">]</span>
    <span class=""n"">page</span> <span class=""o"">=</span> <span class=""mi"">1</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://quotes.toscrape.com/api/quotes?page=1'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">data</span> <span class=""o"">=</span> <span class=""n"">json</span><span class=""o"">.</span><span class=""n"">loads</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">text</span><span class=""p"">)</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">data</span><span class=""p"">[</span><span class=""s2"">""quotes""</span><span class=""p"">]:</span>
            <span class=""k"">yield</span> <span class=""p"">{</span><span class=""s2"">""quote""</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""p"">[</span><span class=""s2"">""text""</span><span class=""p"">]}</span>
        <span class=""k"">if</span> <span class=""n"">data</span><span class=""p"">[</span><span class=""s2"">""has_next""</span><span class=""p"">]:</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">page</span> <span class=""o"">+=</span> <span class=""mi"">1</span>
            <span class=""n"">url</span> <span class=""o"">=</span> <span class=""sa"">f</span><span class=""s2"">""https://quotes.toscrape.com/api/quotes?page=</span><span class=""si"">{</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">page</span><span class=""si"">}</span><span class=""s2"">""</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">Request</span>

<span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">Request</span><span class=""o"">.</span><span class=""n"">from_curl</span><span class=""p"">(</span>
    <span class=""s2"">""curl 'https://quotes.toscrape.com/api/quotes?page=1' -H 'User-Agent: Mozil""</span>
    <span class=""s2"">""la/5.0 (X11; Linux x86_64; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Acce""</span>
    <span class=""s2"">""pt: */*' -H 'Accept-Language: ca,en-US;q=0.7,en;q=0.3' --compressed -H 'X""</span>
    <span class=""s2"">""-Requested-With: XMLHttpRequest' -H 'Proxy-Authorization: Basic QFRLLTAzM""</span>
    <span class=""s2"">""zEwZTAxLTk5MWUtNDFiNC1iZWRmLTJjNGI4M2ZiNDBmNDpAVEstMDMzMTBlMDEtOTkxZS00MW""</span>
    <span class=""s2"">""I0LWJlZGYtMmM0YjgzZmI0MGY0' -H 'Connection: keep-alive' -H 'Referer: http""</span>
    <span class=""s2"">""://quotes.toscrape.com/scroll' -H 'Cache-Control: max-age=0'""</span><span class=""p"">)</span>
</pre></div>","<div class=""quote"" itemscope="""" itemtype=""http://schema.org/CreativeWork"">
  <span class=""text"" itemprop=""text"">(...)</span>
  <span>(...)</span>
  <div class=""tags"">(...)</div>
</div>
,$ scrapy shell ""https://quotes.toscrape.com/""
,>>> response.xpath('/html/body/div/div[2]/div[1]/div[1]/span[1]/text()').getall()
['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”']
,<div class=""quote"" itemscope="""" itemtype=""http://schema.org/CreativeWork"">
  <span class=""text"" itemprop=""text"">
    “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”
  </span>
  <span>(...)</span>
  <div class=""tags"">(...)</div>
</div>
,>>> response.xpath('//span[has-class(""text"")]/text()').getall()
['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',
'“It is our choices, Harry, that show what we truly are, far more than our abilities.”',
'“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',
...]
,$ scrapy shell ""quotes.toscrape.com/scroll""
(...)
>>> view(response)
,import scrapy
import json


class QuoteSpider(scrapy.Spider):
    name = 'quote'
    allowed_domains = ['quotes.toscrape.com']
    page = 1
    start_urls = ['https://quotes.toscrape.com/api/quotes?page=1']

    def parse(self, response):
        data = json.loads(response.text)
        for quote in data[""quotes""]:
            yield {""quote"": quote[""text""]}
        if data[""has_next""]:
            self.page += 1
            url = f""https://quotes.toscrape.com/api/quotes?page={self.page}""
            yield scrapy.Request(url=url, callback=self.parse)
,from scrapy import Request

request = Request.from_curl(
    ""curl 'https://quotes.toscrape.com/api/quotes?page=1' -H 'User-Agent: Mozil""
    ""la/5.0 (X11; Linux x86_64; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Acce""
    ""pt: */*' -H 'Accept-Language: ca,en-US;q=0.7,en;q=0.3' --compressed -H 'X""
    ""-Requested-With: XMLHttpRequest' -H 'Proxy-Authorization: Basic QFRLLTAzM""
    ""zEwZTAxLTk5MWUtNDFiNC1iZWRmLTJjNGI4M2ZiNDBmNDpAVEstMDMzMTBlMDEtOTkxZS00MW""
    ""I0LWJlZGYtMmM0YjgzZmI0MGY0' -H 'Connection: keep-alive' -H 'Referer: http""
    ""://quotes.toscrape.com/scroll' -H 'Cache-Control: max-age=0'"")
",8
https://docs.scrapy.org/en/latest/topics/developer-tools.html,,##,2,Caveats with inspecting the live browser DOM,#caveats-with-inspecting-the-live-browser-dom,,,2
https://docs.scrapy.org/en/latest/topics/developer-tools.html,,##,2,Inspecting a website,#inspecting-a-website,"<div class=""highlight""><pre><span></span><span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""quote""</span> <span class=""na"">itemscope</span><span class=""o"">=</span><span class=""s"">""""</span> <span class=""na"">itemtype</span><span class=""o"">=</span><span class=""s"">""http://schema.org/CreativeWork""</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">span</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""text""</span> <span class=""na"">itemprop</span><span class=""o"">=</span><span class=""s"">""text""</span><span class=""p"">&gt;</span>(...)<span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">span</span><span class=""p"">&gt;</span>(...)<span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tags""</span><span class=""p"">&gt;</span>(...)<span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span>$ scrapy shell ""https://quotes.toscrape.com/""
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'/html/body/div/div[2]/div[1]/div[1]/span[1]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""quote""</span> <span class=""na"">itemscope</span><span class=""o"">=</span><span class=""s"">""""</span> <span class=""na"">itemtype</span><span class=""o"">=</span><span class=""s"">""http://schema.org/CreativeWork""</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">span</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""text""</span> <span class=""na"">itemprop</span><span class=""o"">=</span><span class=""s"">""text""</span><span class=""p"">&gt;</span>
    “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”
  <span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">span</span><span class=""p"">&gt;</span>(...)<span class=""p"">&lt;/</span><span class=""nt"">span</span><span class=""p"">&gt;</span>
  <span class=""p"">&lt;</span><span class=""nt"">div</span> <span class=""na"">class</span><span class=""o"">=</span><span class=""s"">""tags""</span><span class=""p"">&gt;</span>(...)<span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
<span class=""p"">&lt;/</span><span class=""nt"">div</span><span class=""p"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">xpath</span><span class=""p"">(</span><span class=""s1"">'//span[has-class(""text"")]/text()'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">()</span>
<span class=""go"">['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',</span>
<span class=""go"">'“It is our choices, Harry, that show what we truly are, far more than our abilities.”',</span>
<span class=""go"">'“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',</span>
<span class=""go"">...]</span>
</pre></div>","<div class=""quote"" itemscope="""" itemtype=""http://schema.org/CreativeWork"">
  <span class=""text"" itemprop=""text"">(...)</span>
  <span>(...)</span>
  <div class=""tags"">(...)</div>
</div>
,$ scrapy shell ""https://quotes.toscrape.com/""
,>>> response.xpath('/html/body/div/div[2]/div[1]/div[1]/span[1]/text()').getall()
['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”']
,<div class=""quote"" itemscope="""" itemtype=""http://schema.org/CreativeWork"">
  <span class=""text"" itemprop=""text"">
    “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”
  </span>
  <span>(...)</span>
  <div class=""tags"">(...)</div>
</div>
,>>> response.xpath('//span[has-class(""text"")]/text()').getall()
['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',
'“It is our choices, Harry, that show what we truly are, far more than our abilities.”',
'“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',
...]
",5
https://docs.scrapy.org/en/latest/topics/developer-tools.html,,##,2,The Network-tool,#the-network-tool,"<div class=""highlight""><pre><span></span>$ scrapy shell ""quotes.toscrape.com/scroll""
(...)
&gt;&gt;&gt; view(response)
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">import</span> <span class=""nn"">json</span>


<span class=""k"">class</span> <span class=""nc"">QuoteSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'quote'</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'quotes.toscrape.com'</span><span class=""p"">]</span>
    <span class=""n"">page</span> <span class=""o"">=</span> <span class=""mi"">1</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://quotes.toscrape.com/api/quotes?page=1'</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">data</span> <span class=""o"">=</span> <span class=""n"">json</span><span class=""o"">.</span><span class=""n"">loads</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">text</span><span class=""p"">)</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">data</span><span class=""p"">[</span><span class=""s2"">""quotes""</span><span class=""p"">]:</span>
            <span class=""k"">yield</span> <span class=""p"">{</span><span class=""s2"">""quote""</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""p"">[</span><span class=""s2"">""text""</span><span class=""p"">]}</span>
        <span class=""k"">if</span> <span class=""n"">data</span><span class=""p"">[</span><span class=""s2"">""has_next""</span><span class=""p"">]:</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">page</span> <span class=""o"">+=</span> <span class=""mi"">1</span>
            <span class=""n"">url</span> <span class=""o"">=</span> <span class=""sa"">f</span><span class=""s2"">""https://quotes.toscrape.com/api/quotes?page=</span><span class=""si"">{</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">page</span><span class=""si"">}</span><span class=""s2"">""</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">Request</span>

<span class=""n"">request</span> <span class=""o"">=</span> <span class=""n"">Request</span><span class=""o"">.</span><span class=""n"">from_curl</span><span class=""p"">(</span>
    <span class=""s2"">""curl 'https://quotes.toscrape.com/api/quotes?page=1' -H 'User-Agent: Mozil""</span>
    <span class=""s2"">""la/5.0 (X11; Linux x86_64; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Acce""</span>
    <span class=""s2"">""pt: */*' -H 'Accept-Language: ca,en-US;q=0.7,en;q=0.3' --compressed -H 'X""</span>
    <span class=""s2"">""-Requested-With: XMLHttpRequest' -H 'Proxy-Authorization: Basic QFRLLTAzM""</span>
    <span class=""s2"">""zEwZTAxLTk5MWUtNDFiNC1iZWRmLTJjNGI4M2ZiNDBmNDpAVEstMDMzMTBlMDEtOTkxZS00MW""</span>
    <span class=""s2"">""I0LWJlZGYtMmM0YjgzZmI0MGY0' -H 'Connection: keep-alive' -H 'Referer: http""</span>
    <span class=""s2"">""://quotes.toscrape.com/scroll' -H 'Cache-Control: max-age=0'""</span><span class=""p"">)</span>
</pre></div>","$ scrapy shell ""quotes.toscrape.com/scroll""
(...)
>>> view(response)
,import scrapy
import json


class QuoteSpider(scrapy.Spider):
    name = 'quote'
    allowed_domains = ['quotes.toscrape.com']
    page = 1
    start_urls = ['https://quotes.toscrape.com/api/quotes?page=1']

    def parse(self, response):
        data = json.loads(response.text)
        for quote in data[""quotes""]:
            yield {""quote"": quote[""text""]}
        if data[""has_next""]:
            self.page += 1
            url = f""https://quotes.toscrape.com/api/quotes?page={self.page}""
            yield scrapy.Request(url=url, callback=self.parse)
,from scrapy import Request

request = Request.from_curl(
    ""curl 'https://quotes.toscrape.com/api/quotes?page=1' -H 'User-Agent: Mozil""
    ""la/5.0 (X11; Linux x86_64; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Acce""
    ""pt: */*' -H 'Accept-Language: ca,en-US;q=0.7,en;q=0.3' --compressed -H 'X""
    ""-Requested-With: XMLHttpRequest' -H 'Proxy-Authorization: Basic QFRLLTAzM""
    ""zEwZTAxLTk5MWUtNDFiNC1iZWRmLTJjNGI4M2ZiNDBmNDpAVEstMDMzMTBlMDEtOTkxZS00MW""
    ""I0LWJlZGYtMmM0YjgzZmI0MGY0' -H 'Connection: keep-alive' -H 'Referer: http""
    ""://quotes.toscrape.com/scroll' -H 'Cache-Control: max-age=0'"")
",3
https://docs.scrapy.org/en/latest/topics/dynamic-content.html,,#,1,Selecting dynamically-loaded content,#selecting-dynamically-loaded-content,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">fetch</span> <span class=""o"">--</span><span class=""n"">nolog</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span> <span class=""o"">&gt;</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">html</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">data</span> <span class=""o"">=</span> <span class=""n"">json</span><span class=""o"">.</span><span class=""n"">loads</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">text</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">selector</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">data</span><span class=""p"">[</span><span class=""s1"">'html'</span><span class=""p"">])</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">pattern</span> <span class=""o"">=</span> <span class=""sa"">r</span><span class=""s1"">'\bvar\s+data\s*=\s*(\{.*?\})\s*;\s*\n'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">json_data</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'script::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re_first</span><span class=""p"">(</span><span class=""n"">pattern</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">json</span><span class=""o"">.</span><span class=""n"">loads</span><span class=""p"">(</span><span class=""n"">json_data</span><span class=""p"">)</span>
<span class=""go"">{'field': 'value'}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">import</span> <span class=""nn"">chompjs</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">javascript</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'script::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">data</span> <span class=""o"">=</span> <span class=""n"">chompjs</span><span class=""o"">.</span><span class=""n"">parse_js_object</span><span class=""p"">(</span><span class=""n"">javascript</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">data</span>
<span class=""go"">{'field': 'value', 'secondField': 'second value'}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">import</span> <span class=""nn"">js2xml</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">import</span> <span class=""nn"">lxml.etree</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">parsel</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">javascript</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'script::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xml</span> <span class=""o"">=</span> <span class=""n"">lxml</span><span class=""o"">.</span><span class=""n"">etree</span><span class=""o"">.</span><span class=""n"">tostring</span><span class=""p"">(</span><span class=""n"">js2xml</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">(</span><span class=""n"">javascript</span><span class=""p"">),</span> <span class=""n"">encoding</span><span class=""o"">=</span><span class=""s1"">'unicode'</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">selector</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">xml</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">selector</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'var[name=""data""]'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'&lt;var name=""data""&gt;&lt;object&gt;&lt;property name=""field""&gt;&lt;string&gt;value&lt;/string&gt;&lt;/property&gt;&lt;/object&gt;&lt;/var&gt;'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">playwright.async_api</span> <span class=""kn"">import</span> <span class=""n"">async_playwright</span>

<span class=""k"">class</span> <span class=""nc"">PlaywrightSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""playwright""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s2"">""data:,""</span><span class=""p"">]</span>  <span class=""c1""># avoid using the default Scrapy downloader</span>

    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">async</span> <span class=""k"">with</span> <span class=""n"">async_playwright</span><span class=""p"">()</span> <span class=""k"">as</span> <span class=""n"">pw</span><span class=""p"">:</span>
            <span class=""n"">browser</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">pw</span><span class=""o"">.</span><span class=""n"">chromium</span><span class=""o"">.</span><span class=""n"">launch</span><span class=""p"">()</span>
            <span class=""n"">page</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">browser</span><span class=""o"">.</span><span class=""n"">new_page</span><span class=""p"">()</span>
            <span class=""k"">await</span> <span class=""n"">page</span><span class=""o"">.</span><span class=""n"">goto</span><span class=""p"">(</span><span class=""s2"">""https:/example.org""</span><span class=""p"">)</span>
            <span class=""n"">title</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">page</span><span class=""o"">.</span><span class=""n"">title</span><span class=""p"">()</span>
            <span class=""k"">return</span> <span class=""p"">{</span><span class=""s2"">""title""</span><span class=""p"">:</span> <span class=""n"">title</span><span class=""p"">}</span>
</pre></div>","scrapy fetch --nolog https://example.com > response.html
,data = json.loads(response.text)
,selector = Selector(data['html'])
,>>> pattern = r'\bvar\s+data\s*=\s*(\{.*?\})\s*;\s*\n'
>>> json_data = response.css('script::text').re_first(pattern)
>>> json.loads(json_data)
{'field': 'value'}
,>>> import chompjs
>>> javascript = response.css('script::text').get()
>>> data = chompjs.parse_js_object(javascript)
>>> data
{'field': 'value', 'secondField': 'second value'}
,>>> import js2xml
>>> import lxml.etree
>>> from parsel import Selector
>>> javascript = response.css('script::text').get()
>>> xml = lxml.etree.tostring(js2xml.parse(javascript), encoding='unicode')
>>> selector = Selector(text=xml)
>>> selector.css('var[name=""data""]').get()
'<var name=""data""><object><property name=""field""><string>value</string></property></object></var>'
,import scrapy
from playwright.async_api import async_playwright

class PlaywrightSpider(scrapy.Spider):
    name = ""playwright""
    start_urls = [""data:,""]  # avoid using the default Scrapy downloader

    async def parse(self, response):
        async with async_playwright() as pw:
            browser = await pw.chromium.launch()
            page = await browser.new_page()
            await page.goto(""https:/example.org"")
            title = await page.title()
            return {""title"": title}
",7
https://docs.scrapy.org/en/latest/topics/dynamic-content.html,,##,2,Finding the data source,#finding-the-data-source,,,2
https://docs.scrapy.org/en/latest/topics/dynamic-content.html,,##,2,Inspecting the source code of a webpage,#inspecting-the-source-code-of-a-webpage,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">fetch</span> <span class=""o"">--</span><span class=""n"">nolog</span> <span class=""n"">https</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span> <span class=""o"">&gt;</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">html</span>
</pre></div>","scrapy fetch --nolog https://example.com > response.html
",1
https://docs.scrapy.org/en/latest/topics/dynamic-content.html,,##,2,Reproducing requests,#reproducing-requests,,,4
https://docs.scrapy.org/en/latest/topics/dynamic-content.html,,##,2,Handling different response formats,#handling-different-response-formats,"<div class=""highlight""><pre><span></span><span class=""n"">data</span> <span class=""o"">=</span> <span class=""n"">json</span><span class=""o"">.</span><span class=""n"">loads</span><span class=""p"">(</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">text</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">selector</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">data</span><span class=""p"">[</span><span class=""s1"">'html'</span><span class=""p"">])</span>
</pre></div>","data = json.loads(response.text)
,selector = Selector(data['html'])
",2
https://docs.scrapy.org/en/latest/topics/dynamic-content.html,,##,2,Parsing JavaScript code,#parsing-javascript-code,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">pattern</span> <span class=""o"">=</span> <span class=""sa"">r</span><span class=""s1"">'\bvar\s+data\s*=\s*(\{.*?\})\s*;\s*\n'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">json_data</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'script::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">re_first</span><span class=""p"">(</span><span class=""n"">pattern</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">json</span><span class=""o"">.</span><span class=""n"">loads</span><span class=""p"">(</span><span class=""n"">json_data</span><span class=""p"">)</span>
<span class=""go"">{'field': 'value'}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">import</span> <span class=""nn"">chompjs</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">javascript</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'script::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">data</span> <span class=""o"">=</span> <span class=""n"">chompjs</span><span class=""o"">.</span><span class=""n"">parse_js_object</span><span class=""p"">(</span><span class=""n"">javascript</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">data</span>
<span class=""go"">{'field': 'value', 'secondField': 'second value'}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">import</span> <span class=""nn"">js2xml</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">import</span> <span class=""nn"">lxml.etree</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">parsel</span> <span class=""kn"">import</span> <span class=""n"">Selector</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">javascript</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'script::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">xml</span> <span class=""o"">=</span> <span class=""n"">lxml</span><span class=""o"">.</span><span class=""n"">etree</span><span class=""o"">.</span><span class=""n"">tostring</span><span class=""p"">(</span><span class=""n"">js2xml</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">(</span><span class=""n"">javascript</span><span class=""p"">),</span> <span class=""n"">encoding</span><span class=""o"">=</span><span class=""s1"">'unicode'</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">selector</span> <span class=""o"">=</span> <span class=""n"">Selector</span><span class=""p"">(</span><span class=""n"">text</span><span class=""o"">=</span><span class=""n"">xml</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">selector</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'var[name=""data""]'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">()</span>
<span class=""go"">'&lt;var name=""data""&gt;&lt;object&gt;&lt;property name=""field""&gt;&lt;string&gt;value&lt;/string&gt;&lt;/property&gt;&lt;/object&gt;&lt;/var&gt;'</span>
</pre></div>",">>> pattern = r'\bvar\s+data\s*=\s*(\{.*?\})\s*;\s*\n'
>>> json_data = response.css('script::text').re_first(pattern)
>>> json.loads(json_data)
{'field': 'value'}
,>>> import chompjs
>>> javascript = response.css('script::text').get()
>>> data = chompjs.parse_js_object(javascript)
>>> data
{'field': 'value', 'secondField': 'second value'}
,>>> import js2xml
>>> import lxml.etree
>>> from parsel import Selector
>>> javascript = response.css('script::text').get()
>>> xml = lxml.etree.tostring(js2xml.parse(javascript), encoding='unicode')
>>> selector = Selector(text=xml)
>>> selector.css('var[name=""data""]').get()
'<var name=""data""><object><property name=""field""><string>value</string></property></object></var>'
",3
https://docs.scrapy.org/en/latest/topics/dynamic-content.html,,##,2,Pre-rendering JavaScript,#pre-rendering-javascript,,,7
https://docs.scrapy.org/en/latest/topics/dynamic-content.html,,##,2,Using a headless browser,#using-a-headless-browser,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">playwright.async_api</span> <span class=""kn"">import</span> <span class=""n"">async_playwright</span>

<span class=""k"">class</span> <span class=""nc"">PlaywrightSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""playwright""</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s2"">""data:,""</span><span class=""p"">]</span>  <span class=""c1""># avoid using the default Scrapy downloader</span>

    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">async</span> <span class=""k"">with</span> <span class=""n"">async_playwright</span><span class=""p"">()</span> <span class=""k"">as</span> <span class=""n"">pw</span><span class=""p"">:</span>
            <span class=""n"">browser</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">pw</span><span class=""o"">.</span><span class=""n"">chromium</span><span class=""o"">.</span><span class=""n"">launch</span><span class=""p"">()</span>
            <span class=""n"">page</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">browser</span><span class=""o"">.</span><span class=""n"">new_page</span><span class=""p"">()</span>
            <span class=""k"">await</span> <span class=""n"">page</span><span class=""o"">.</span><span class=""n"">goto</span><span class=""p"">(</span><span class=""s2"">""https:/example.org""</span><span class=""p"">)</span>
            <span class=""n"">title</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">page</span><span class=""o"">.</span><span class=""n"">title</span><span class=""p"">()</span>
            <span class=""k"">return</span> <span class=""p"">{</span><span class=""s2"">""title""</span><span class=""p"">:</span> <span class=""n"">title</span><span class=""p"">}</span>
</pre></div>","import scrapy
from playwright.async_api import async_playwright

class PlaywrightSpider(scrapy.Spider):
    name = ""playwright""
    start_urls = [""data:,""]  # avoid using the default Scrapy downloader

    async def parse(self, response):
        async with async_playwright() as pw:
            browser = await pw.chromium.launch()
            page = await browser.new_page()
            await page.goto(""https:/example.org"")
            title = await page.title()
            return {""title"": title}
",1
https://docs.scrapy.org/en/latest/topics/leaks.html,,#,1,Debugging memory leaks,#debugging-memory-leaks,"<div class=""highlight""><pre><span></span><span class=""n"">telnet</span> <span class=""n"">localhost</span> <span class=""mi"">6023</span>

<span class=""o"">&gt;&gt;&gt;</span> <span class=""n"">prefs</span><span class=""p"">()</span>
<span class=""n"">Live</span> <span class=""n"">References</span>

<span class=""n"">ExampleSpider</span>                       <span class=""mi"">1</span>   <span class=""n"">oldest</span><span class=""p"">:</span> <span class=""mi"">15</span><span class=""n"">s</span> <span class=""n"">ago</span>
<span class=""n"">HtmlResponse</span>                       <span class=""mi"">10</span>   <span class=""n"">oldest</span><span class=""p"">:</span> <span class=""mi"">1</span><span class=""n"">s</span> <span class=""n"">ago</span>
<span class=""n"">Selector</span>                            <span class=""mi"">2</span>   <span class=""n"">oldest</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""n"">s</span> <span class=""n"">ago</span>
<span class=""n"">FormRequest</span>                       <span class=""mi"">878</span>   <span class=""n"">oldest</span><span class=""p"">:</span> <span class=""mi"">7</span><span class=""n"">s</span> <span class=""n"">ago</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">return</span> <span class=""n"">Request</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s2"">""http://www.somenastyspider.com/product.php?pid=</span><span class=""si"">{</span><span class=""n"">product_id</span><span class=""si"">}</span><span class=""s2"">""</span><span class=""p"">,</span>
               <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">,</span> <span class=""n"">cb_kwargs</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'referer'</span><span class=""p"">:</span> <span class=""n"">response</span><span class=""p"">})</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">prefs</span><span class=""p"">()</span>
<span class=""go"">Live References</span>

<span class=""go"">SomenastySpider                     1   oldest: 15s ago</span>
<span class=""go"">HtmlResponse                     3890   oldest: 265s ago</span>
<span class=""go"">Selector                            2   oldest: 0s ago</span>
<span class=""go"">Request                          3878   oldest: 250s ago</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.utils.trackref</span> <span class=""kn"">import</span> <span class=""n"">get_oldest</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">r</span> <span class=""o"">=</span> <span class=""n"">get_oldest</span><span class=""p"">(</span><span class=""s1"">'HtmlResponse'</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">r</span><span class=""o"">.</span><span class=""n"">url</span>
<span class=""go"">'http://www.somenastyspider.com/product.php?pid=123'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.utils.trackref</span> <span class=""kn"">import</span> <span class=""n"">iter_all</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""p"">[</span><span class=""n"">r</span><span class=""o"">.</span><span class=""n"">url</span> <span class=""k"">for</span> <span class=""n"">r</span> <span class=""ow"">in</span> <span class=""n"">iter_all</span><span class=""p"">(</span><span class=""s1"">'HtmlResponse'</span><span class=""p"">)]</span>
<span class=""go"">['http://www.somenastyspider.com/product.php?pid=123',</span>
<span class=""go""> 'http://www.somenastyspider.com/product.php?pid=584',</span>
<span class=""go"">...]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">Spider</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">prefs</span><span class=""p"">(</span><span class=""n"">ignore</span><span class=""o"">=</span><span class=""n"">Spider</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">pip</span> <span class=""n"">install</span> <span class=""n"">Pympler</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">pympler</span> <span class=""kn"">import</span> <span class=""n"">muppy</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">all_objects</span> <span class=""o"">=</span> <span class=""n"">muppy</span><span class=""o"">.</span><span class=""n"">get_objects</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""nb"">len</span><span class=""p"">(</span><span class=""n"">all_objects</span><span class=""p"">)</span>
<span class=""go"">28667</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">pympler</span> <span class=""kn"">import</span> <span class=""n"">summary</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">suml</span> <span class=""o"">=</span> <span class=""n"">summary</span><span class=""o"">.</span><span class=""n"">summarize</span><span class=""p"">(</span><span class=""n"">all_objects</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">summary</span><span class=""o"">.</span><span class=""n"">print_</span><span class=""p"">(</span><span class=""n"">suml</span><span class=""p"">)</span>
<span class=""go"">                               types |   # objects |   total size</span>
<span class=""go"">==================================== | =========== | ============</span>
<span class=""go"">                         &lt;class 'str |        9822 |      1.10 MB</span>
<span class=""go"">                        &lt;class 'dict |        1658 |    856.62 KB</span>
<span class=""go"">                        &lt;class 'type |         436 |    443.60 KB</span>
<span class=""go"">                        &lt;class 'code |        2974 |    419.56 KB</span>
<span class=""go"">          &lt;class '_io.BufferedWriter |           2 |    256.34 KB</span>
<span class=""go"">                         &lt;class 'set |         420 |    159.88 KB</span>
<span class=""go"">          &lt;class '_io.BufferedReader |           1 |    128.17 KB</span>
<span class=""go"">          &lt;class 'wrapper_descriptor |        1130 |     88.28 KB</span>
<span class=""go"">                       &lt;class 'tuple |        1304 |     86.57 KB</span>
<span class=""go"">                     &lt;class 'weakref |        1013 |     79.14 KB</span>
<span class=""go"">  &lt;class 'builtin_function_or_method |         958 |     67.36 KB</span>
<span class=""go"">           &lt;class 'method_descriptor |         865 |     60.82 KB</span>
<span class=""go"">                 &lt;class 'abc.ABCMeta |          62 |     59.96 KB</span>
<span class=""go"">                        &lt;class 'list |         446 |     58.52 KB</span>
<span class=""go"">                         &lt;class 'int |        1425 |     43.20 KB</span>
</pre></div>","telnet localhost 6023

>>> prefs()
Live References

ExampleSpider                       1   oldest: 15s ago
HtmlResponse                       10   oldest: 1s ago
Selector                            2   oldest: 0s ago
FormRequest                       878   oldest: 7s ago
,return Request(f""http://www.somenastyspider.com/product.php?pid={product_id}"",
               callback=self.parse, cb_kwargs={'referer': response})
,>>> prefs()
Live References

SomenastySpider                     1   oldest: 15s ago
HtmlResponse                     3890   oldest: 265s ago
Selector                            2   oldest: 0s ago
Request                          3878   oldest: 250s ago
,>>> from scrapy.utils.trackref import get_oldest
>>> r = get_oldest('HtmlResponse')
>>> r.url
'http://www.somenastyspider.com/product.php?pid=123'
,>>> from scrapy.utils.trackref import iter_all
>>> [r.url for r in iter_all('HtmlResponse')]
['http://www.somenastyspider.com/product.php?pid=123',
 'http://www.somenastyspider.com/product.php?pid=584',
...]
,>>> from scrapy.spiders import Spider
>>> prefs(ignore=Spider)
,pip install Pympler
,>>> from pympler import muppy
>>> all_objects = muppy.get_objects()
>>> len(all_objects)
28667
>>> from pympler import summary
>>> suml = summary.summarize(all_objects)
>>> summary.print_(suml)
                               types |   # objects |   total size
==================================== | =========== | ============
                         <class 'str |        9822 |      1.10 MB
                        <class 'dict |        1658 |    856.62 KB
                        <class 'type |         436 |    443.60 KB
                        <class 'code |        2974 |    419.56 KB
          <class '_io.BufferedWriter |           2 |    256.34 KB
                         <class 'set |         420 |    159.88 KB
          <class '_io.BufferedReader |           1 |    128.17 KB
          <class 'wrapper_descriptor |        1130 |     88.28 KB
                       <class 'tuple |        1304 |     86.57 KB
                     <class 'weakref |        1013 |     79.14 KB
  <class 'builtin_function_or_method |         958 |     67.36 KB
           <class 'method_descriptor |         865 |     60.82 KB
                 <class 'abc.ABCMeta |          62 |     59.96 KB
                        <class 'list |         446 |     58.52 KB
                         <class 'int |        1425 |     43.20 KB
",8
https://docs.scrapy.org/en/latest/topics/leaks.html,,##,2,Common causes of memory leaks,#common-causes-of-memory-leaks,,,2
https://docs.scrapy.org/en/latest/topics/leaks.html,,###,3,Too Many Requests?,#too-many-requests,,,3
https://docs.scrapy.org/en/latest/topics/leaks.html,,##,2,Debugging memory leaks with trackref,#debugging-memory-leaks-with-trackref,"<div class=""highlight""><pre><span></span><span class=""n"">telnet</span> <span class=""n"">localhost</span> <span class=""mi"">6023</span>

<span class=""o"">&gt;&gt;&gt;</span> <span class=""n"">prefs</span><span class=""p"">()</span>
<span class=""n"">Live</span> <span class=""n"">References</span>

<span class=""n"">ExampleSpider</span>                       <span class=""mi"">1</span>   <span class=""n"">oldest</span><span class=""p"">:</span> <span class=""mi"">15</span><span class=""n"">s</span> <span class=""n"">ago</span>
<span class=""n"">HtmlResponse</span>                       <span class=""mi"">10</span>   <span class=""n"">oldest</span><span class=""p"">:</span> <span class=""mi"">1</span><span class=""n"">s</span> <span class=""n"">ago</span>
<span class=""n"">Selector</span>                            <span class=""mi"">2</span>   <span class=""n"">oldest</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""n"">s</span> <span class=""n"">ago</span>
<span class=""n"">FormRequest</span>                       <span class=""mi"">878</span>   <span class=""n"">oldest</span><span class=""p"">:</span> <span class=""mi"">7</span><span class=""n"">s</span> <span class=""n"">ago</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">return</span> <span class=""n"">Request</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s2"">""http://www.somenastyspider.com/product.php?pid=</span><span class=""si"">{</span><span class=""n"">product_id</span><span class=""si"">}</span><span class=""s2"">""</span><span class=""p"">,</span>
               <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">,</span> <span class=""n"">cb_kwargs</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'referer'</span><span class=""p"">:</span> <span class=""n"">response</span><span class=""p"">})</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">prefs</span><span class=""p"">()</span>
<span class=""go"">Live References</span>

<span class=""go"">SomenastySpider                     1   oldest: 15s ago</span>
<span class=""go"">HtmlResponse                     3890   oldest: 265s ago</span>
<span class=""go"">Selector                            2   oldest: 0s ago</span>
<span class=""go"">Request                          3878   oldest: 250s ago</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.utils.trackref</span> <span class=""kn"">import</span> <span class=""n"">get_oldest</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">r</span> <span class=""o"">=</span> <span class=""n"">get_oldest</span><span class=""p"">(</span><span class=""s1"">'HtmlResponse'</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">r</span><span class=""o"">.</span><span class=""n"">url</span>
<span class=""go"">'http://www.somenastyspider.com/product.php?pid=123'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.utils.trackref</span> <span class=""kn"">import</span> <span class=""n"">iter_all</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""p"">[</span><span class=""n"">r</span><span class=""o"">.</span><span class=""n"">url</span> <span class=""k"">for</span> <span class=""n"">r</span> <span class=""ow"">in</span> <span class=""n"">iter_all</span><span class=""p"">(</span><span class=""s1"">'HtmlResponse'</span><span class=""p"">)]</span>
<span class=""go"">['http://www.somenastyspider.com/product.php?pid=123',</span>
<span class=""go""> 'http://www.somenastyspider.com/product.php?pid=584',</span>
<span class=""go"">...]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">Spider</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">prefs</span><span class=""p"">(</span><span class=""n"">ignore</span><span class=""o"">=</span><span class=""n"">Spider</span><span class=""p"">)</span>
</pre></div>","telnet localhost 6023

>>> prefs()
Live References

ExampleSpider                       1   oldest: 15s ago
HtmlResponse                       10   oldest: 1s ago
Selector                            2   oldest: 0s ago
FormRequest                       878   oldest: 7s ago
,return Request(f""http://www.somenastyspider.com/product.php?pid={product_id}"",
               callback=self.parse, cb_kwargs={'referer': response})
,>>> prefs()
Live References

SomenastySpider                     1   oldest: 15s ago
HtmlResponse                     3890   oldest: 265s ago
Selector                            2   oldest: 0s ago
Request                          3878   oldest: 250s ago
,>>> from scrapy.utils.trackref import get_oldest
>>> r = get_oldest('HtmlResponse')
>>> r.url
'http://www.somenastyspider.com/product.php?pid=123'
,>>> from scrapy.utils.trackref import iter_all
>>> [r.url for r in iter_all('HtmlResponse')]
['http://www.somenastyspider.com/product.php?pid=123',
 'http://www.somenastyspider.com/product.php?pid=584',
...]
,>>> from scrapy.spiders import Spider
>>> prefs(ignore=Spider)
",6
https://docs.scrapy.org/en/latest/topics/leaks.html,,###,3,Which objects are tracked?,#which-objects-are-tracked,,,5
https://docs.scrapy.org/en/latest/topics/leaks.html,,###,3,A real example,#a-real-example,"<div class=""highlight""><pre><span></span><span class=""k"">return</span> <span class=""n"">Request</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s2"">""http://www.somenastyspider.com/product.php?pid=</span><span class=""si"">{</span><span class=""n"">product_id</span><span class=""si"">}</span><span class=""s2"">""</span><span class=""p"">,</span>
               <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">,</span> <span class=""n"">cb_kwargs</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'referer'</span><span class=""p"">:</span> <span class=""n"">response</span><span class=""p"">})</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">prefs</span><span class=""p"">()</span>
<span class=""go"">Live References</span>

<span class=""go"">SomenastySpider                     1   oldest: 15s ago</span>
<span class=""go"">HtmlResponse                     3890   oldest: 265s ago</span>
<span class=""go"">Selector                            2   oldest: 0s ago</span>
<span class=""go"">Request                          3878   oldest: 250s ago</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.utils.trackref</span> <span class=""kn"">import</span> <span class=""n"">get_oldest</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">r</span> <span class=""o"">=</span> <span class=""n"">get_oldest</span><span class=""p"">(</span><span class=""s1"">'HtmlResponse'</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">r</span><span class=""o"">.</span><span class=""n"">url</span>
<span class=""go"">'http://www.somenastyspider.com/product.php?pid=123'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.utils.trackref</span> <span class=""kn"">import</span> <span class=""n"">iter_all</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""p"">[</span><span class=""n"">r</span><span class=""o"">.</span><span class=""n"">url</span> <span class=""k"">for</span> <span class=""n"">r</span> <span class=""ow"">in</span> <span class=""n"">iter_all</span><span class=""p"">(</span><span class=""s1"">'HtmlResponse'</span><span class=""p"">)]</span>
<span class=""go"">['http://www.somenastyspider.com/product.php?pid=123',</span>
<span class=""go""> 'http://www.somenastyspider.com/product.php?pid=584',</span>
<span class=""go"">...]</span>
</pre></div>","return Request(f""http://www.somenastyspider.com/product.php?pid={product_id}"",
               callback=self.parse, cb_kwargs={'referer': response})
,>>> prefs()
Live References

SomenastySpider                     1   oldest: 15s ago
HtmlResponse                     3890   oldest: 265s ago
Selector                            2   oldest: 0s ago
Request                          3878   oldest: 250s ago
,>>> from scrapy.utils.trackref import get_oldest
>>> r = get_oldest('HtmlResponse')
>>> r.url
'http://www.somenastyspider.com/product.php?pid=123'
,>>> from scrapy.utils.trackref import iter_all
>>> [r.url for r in iter_all('HtmlResponse')]
['http://www.somenastyspider.com/product.php?pid=123',
 'http://www.somenastyspider.com/product.php?pid=584',
...]
",4
https://docs.scrapy.org/en/latest/topics/leaks.html,,###,3,Too many spiders?,#too-many-spiders,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">Spider</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">prefs</span><span class=""p"">(</span><span class=""n"">ignore</span><span class=""o"">=</span><span class=""n"">Spider</span><span class=""p"">)</span>
</pre></div>",">>> from scrapy.spiders import Spider
>>> prefs(ignore=Spider)
",1
https://docs.scrapy.org/en/latest/topics/leaks.html,,###,3,scrapy.utils.trackref module,#scrapy-utils-trackref-module,,,8
https://docs.scrapy.org/en/latest/topics/leaks.html,,##,2,Debugging memory leaks with muppy,#debugging-memory-leaks-with-muppy,"<div class=""highlight""><pre><span></span><span class=""n"">pip</span> <span class=""n"">install</span> <span class=""n"">Pympler</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">pympler</span> <span class=""kn"">import</span> <span class=""n"">muppy</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">all_objects</span> <span class=""o"">=</span> <span class=""n"">muppy</span><span class=""o"">.</span><span class=""n"">get_objects</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""nb"">len</span><span class=""p"">(</span><span class=""n"">all_objects</span><span class=""p"">)</span>
<span class=""go"">28667</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">from</span> <span class=""nn"">pympler</span> <span class=""kn"">import</span> <span class=""n"">summary</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">suml</span> <span class=""o"">=</span> <span class=""n"">summary</span><span class=""o"">.</span><span class=""n"">summarize</span><span class=""p"">(</span><span class=""n"">all_objects</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">summary</span><span class=""o"">.</span><span class=""n"">print_</span><span class=""p"">(</span><span class=""n"">suml</span><span class=""p"">)</span>
<span class=""go"">                               types |   # objects |   total size</span>
<span class=""go"">==================================== | =========== | ============</span>
<span class=""go"">                         &lt;class 'str |        9822 |      1.10 MB</span>
<span class=""go"">                        &lt;class 'dict |        1658 |    856.62 KB</span>
<span class=""go"">                        &lt;class 'type |         436 |    443.60 KB</span>
<span class=""go"">                        &lt;class 'code |        2974 |    419.56 KB</span>
<span class=""go"">          &lt;class '_io.BufferedWriter |           2 |    256.34 KB</span>
<span class=""go"">                         &lt;class 'set |         420 |    159.88 KB</span>
<span class=""go"">          &lt;class '_io.BufferedReader |           1 |    128.17 KB</span>
<span class=""go"">          &lt;class 'wrapper_descriptor |        1130 |     88.28 KB</span>
<span class=""go"">                       &lt;class 'tuple |        1304 |     86.57 KB</span>
<span class=""go"">                     &lt;class 'weakref |        1013 |     79.14 KB</span>
<span class=""go"">  &lt;class 'builtin_function_or_method |         958 |     67.36 KB</span>
<span class=""go"">           &lt;class 'method_descriptor |         865 |     60.82 KB</span>
<span class=""go"">                 &lt;class 'abc.ABCMeta |          62 |     59.96 KB</span>
<span class=""go"">                        &lt;class 'list |         446 |     58.52 KB</span>
<span class=""go"">                         &lt;class 'int |        1425 |     43.20 KB</span>
</pre></div>","pip install Pympler
,>>> from pympler import muppy
>>> all_objects = muppy.get_objects()
>>> len(all_objects)
28667
>>> from pympler import summary
>>> suml = summary.summarize(all_objects)
>>> summary.print_(suml)
                               types |   # objects |   total size
==================================== | =========== | ============
                         <class 'str |        9822 |      1.10 MB
                        <class 'dict |        1658 |    856.62 KB
                        <class 'type |         436 |    443.60 KB
                        <class 'code |        2974 |    419.56 KB
          <class '_io.BufferedWriter |           2 |    256.34 KB
                         <class 'set |         420 |    159.88 KB
          <class '_io.BufferedReader |           1 |    128.17 KB
          <class 'wrapper_descriptor |        1130 |     88.28 KB
                       <class 'tuple |        1304 |     86.57 KB
                     <class 'weakref |        1013 |     79.14 KB
  <class 'builtin_function_or_method |         958 |     67.36 KB
           <class 'method_descriptor |         865 |     60.82 KB
                 <class 'abc.ABCMeta |          62 |     59.96 KB
                        <class 'list |         446 |     58.52 KB
                         <class 'int |        1425 |     43.20 KB
",2
https://docs.scrapy.org/en/latest/topics/leaks.html,,##,2,Leaks without leaks,#leaks-without-leaks,,,10
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,#,1,Downloading and processing files and images,#downloading-and-processing-files-and-images,"<div class=""highlight""><pre><span></span><span class=""n"">ITEM_PIPELINES</span> <span class=""o"">=</span> <span class=""p"">{</span><span class=""s1"">'scrapy.pipelines.images.ImagesPipeline'</span><span class=""p"">:</span> <span class=""mi"">1</span><span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">ITEM_PIPELINES</span> <span class=""o"">=</span> <span class=""p"">{</span><span class=""s1"">'scrapy.pipelines.files.FilesPipeline'</span><span class=""p"">:</span> <span class=""mi"">1</span><span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">FILES_STORE</span> <span class=""o"">=</span> <span class=""s1"">'/path/to/valid/dir'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_STORE</span> <span class=""o"">=</span> <span class=""s1"">'/path/to/valid/dir'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">image</span><span class=""o"">.</span><span class=""n"">jpg</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">3</span><span class=""n"">afec3b4765f8f0a07b78f98c07b83f013567a0a</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">3</span><span class=""n"">afec3b4765f8f0a07b78f98c07b83f013567a0a</span><span class=""o"">.</span><span class=""n"">jpg</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">product</span><span class=""o"">/</span><span class=""n"">images</span><span class=""o"">/</span><span class=""n"">large</span><span class=""o"">/</span><span class=""n"">front</span><span class=""o"">/</span><span class=""mi"">0000000004166</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">00</span><span class=""n"">b08510e4_front</span><span class=""o"">.</span><span class=""n"">jpg</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">hashlib</span>
<span class=""kn"">from</span> <span class=""nn"">os.path</span> <span class=""kn"">import</span> <span class=""n"">splitext</span>

<span class=""k"">def</span> <span class=""nf"">file_path</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""n"">info</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">):</span>
    <span class=""n"">image_url_hash</span> <span class=""o"">=</span> <span class=""n"">hashlib</span><span class=""o"">.</span><span class=""n"">shake_256</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""o"">.</span><span class=""n"">encode</span><span class=""p"">())</span><span class=""o"">.</span><span class=""n"">hexdigest</span><span class=""p"">(</span><span class=""mi"">5</span><span class=""p"">)</span>
    <span class=""n"">image_perspective</span> <span class=""o"">=</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""o"">.</span><span class=""n"">split</span><span class=""p"">(</span><span class=""s1"">'/'</span><span class=""p"">)[</span><span class=""o"">-</span><span class=""mi"">2</span><span class=""p"">]</span>
    <span class=""n"">image_filename</span> <span class=""o"">=</span> <span class=""sa"">f</span><span class=""s1"">'</span><span class=""si"">{</span><span class=""n"">image_url_hash</span><span class=""si"">}</span><span class=""s1"">_</span><span class=""si"">{</span><span class=""n"">image_perspective</span><span class=""si"">}</span><span class=""s1"">.jpg'</span>

    <span class=""k"">return</span> <span class=""n"">image_filename</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">IMAGES_STORE</span><span class=""o"">&gt;/</span><span class=""n"">full</span><span class=""o"">/&lt;</span><span class=""n"">FILE_NAME</span><span class=""o"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">ftp</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">username</span><span class=""p"">:</span><span class=""n"">password</span><span class=""nd"">@address</span><span class=""p"">:</span><span class=""n"">port</span><span class=""o"">/</span><span class=""n"">path</span>
<span class=""n"">ftp</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">address</span><span class=""p"">:</span><span class=""n"">port</span><span class=""o"">/</span><span class=""n"">path</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_STORE</span> <span class=""o"">=</span> <span class=""s1"">'s3://bucket/images'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_STORE_S3_ACL</span> <span class=""o"">=</span> <span class=""s1"">'public-read'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">AWS_ENDPOINT_URL</span> <span class=""o"">=</span> <span class=""s1"">'http://minio.example.com:9000'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">AWS_USE_SSL</span> <span class=""o"">=</span> <span class=""kc"">False</span> <span class=""c1""># or True (None by default)</span>
<span class=""n"">AWS_VERIFY</span> <span class=""o"">=</span> <span class=""kc"">False</span> <span class=""c1""># or True (None by default)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_STORE</span> <span class=""o"">=</span> <span class=""s1"">'gs://bucket/images/'</span>
<span class=""n"">GCS_PROJECT_ID</span> <span class=""o"">=</span> <span class=""s1"">'project_id'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_STORE_GCS_ACL</span> <span class=""o"">=</span> <span class=""s1"">'publicRead'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MyItem</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""c1""># ... other item fields ...</span>
    <span class=""n"">image_urls</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">images</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">FILES_URLS_FIELD</span> <span class=""o"">=</span> <span class=""s1"">'field_name_for_your_files_urls'</span>
<span class=""n"">FILES_RESULT_FIELD</span> <span class=""o"">=</span> <span class=""s1"">'field_name_for_your_processed_files'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_URLS_FIELD</span> <span class=""o"">=</span> <span class=""s1"">'field_name_for_your_images_urls'</span>
<span class=""n"">IMAGES_RESULT_FIELD</span> <span class=""o"">=</span> <span class=""s1"">'field_name_for_your_processed_images'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""c1""># 120 days of delay for files expiration</span>
<span class=""n"">FILES_EXPIRES</span> <span class=""o"">=</span> <span class=""mi"">120</span>

<span class=""c1""># 30 days of delay for images expiration</span>
<span class=""n"">IMAGES_EXPIRES</span> <span class=""o"">=</span> <span class=""mi"">30</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_THUMBS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'small'</span><span class=""p"">:</span> <span class=""p"">(</span><span class=""mi"">50</span><span class=""p"">,</span> <span class=""mi"">50</span><span class=""p"">),</span>
    <span class=""s1"">'big'</span><span class=""p"">:</span> <span class=""p"">(</span><span class=""mi"">270</span><span class=""p"">,</span> <span class=""mi"">270</span><span class=""p"">),</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">IMAGES_STORE</span><span class=""o"">&gt;/</span><span class=""n"">thumbs</span><span class=""o"">/&lt;</span><span class=""n"">size_name</span><span class=""o"">&gt;/&lt;</span><span class=""n"">image_id</span><span class=""o"">&gt;.</span><span class=""n"">jpg</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">IMAGES_STORE</span><span class=""o"">&gt;/</span><span class=""n"">full</span><span class=""o"">/</span><span class=""mi"">63</span><span class=""n"">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=""o"">.</span><span class=""n"">jpg</span>
<span class=""o"">&lt;</span><span class=""n"">IMAGES_STORE</span><span class=""o"">&gt;/</span><span class=""n"">thumbs</span><span class=""o"">/</span><span class=""n"">small</span><span class=""o"">/</span><span class=""mi"">63</span><span class=""n"">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=""o"">.</span><span class=""n"">jpg</span>
<span class=""o"">&lt;</span><span class=""n"">IMAGES_STORE</span><span class=""o"">&gt;/</span><span class=""n"">thumbs</span><span class=""o"">/</span><span class=""n"">big</span><span class=""o"">/</span><span class=""mi"">63</span><span class=""n"">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=""o"">.</span><span class=""n"">jpg</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_MIN_HEIGHT</span> <span class=""o"">=</span> <span class=""mi"">110</span>
<span class=""n"">IMAGES_MIN_WIDTH</span> <span class=""o"">=</span> <span class=""mi"">110</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">MEDIA_ALLOW_REDIRECTS</span> <span class=""o"">=</span> <span class=""kc"">True</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">os</span>
<span class=""kn"">from</span> <span class=""nn"">urllib.parse</span> <span class=""kn"">import</span> <span class=""n"">urlparse</span>

<span class=""kn"">from</span> <span class=""nn"">scrapy.pipelines.files</span> <span class=""kn"">import</span> <span class=""n"">FilesPipeline</span>

<span class=""k"">class</span> <span class=""nc"">MyFilesPipeline</span><span class=""p"">(</span><span class=""n"">FilesPipeline</span><span class=""p"">):</span>

    <span class=""k"">def</span> <span class=""nf"">file_path</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""n"">info</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""s1"">'files/'</span> <span class=""o"">+</span> <span class=""n"">os</span><span class=""o"">.</span><span class=""n"">path</span><span class=""o"">.</span><span class=""n"">basename</span><span class=""p"">(</span><span class=""n"">urlparse</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">path</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>

<span class=""k"">def</span> <span class=""nf"">get_media_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">info</span><span class=""p"">):</span>
    <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
    <span class=""k"">for</span> <span class=""n"">file_url</span> <span class=""ow"">in</span> <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'file_urls'</span><span class=""p"">]:</span>
        <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">file_url</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">[(</span><span class=""kc"">True</span><span class=""p"">,</span>
  <span class=""p"">{</span><span class=""s1"">'checksum'</span><span class=""p"">:</span> <span class=""s1"">'2b00042f7481c7b056c4b410d28f33cf'</span><span class=""p"">,</span>
   <span class=""s1"">'path'</span><span class=""p"">:</span> <span class=""s1"">'full/0a79c461a4062ac383dc4fade7bc09f1384a3910.jpg'</span><span class=""p"">,</span>
   <span class=""s1"">'url'</span><span class=""p"">:</span> <span class=""s1"">'http://www.example.com/files/product1.pdf'</span><span class=""p"">,</span>
   <span class=""s1"">'status'</span><span class=""p"">:</span> <span class=""s1"">'downloaded'</span><span class=""p"">}),</span>
 <span class=""p"">(</span><span class=""kc"">False</span><span class=""p"">,</span>
  <span class=""n"">Failure</span><span class=""p"">(</span><span class=""o"">...</span><span class=""p"">))]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exceptions</span> <span class=""kn"">import</span> <span class=""n"">DropItem</span>

<span class=""k"">def</span> <span class=""nf"">item_completed</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">results</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">info</span><span class=""p"">):</span>
    <span class=""n"">file_paths</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""n"">x</span><span class=""p"">[</span><span class=""s1"">'path'</span><span class=""p"">]</span> <span class=""k"">for</span> <span class=""n"">ok</span><span class=""p"">,</span> <span class=""n"">x</span> <span class=""ow"">in</span> <span class=""n"">results</span> <span class=""k"">if</span> <span class=""n"">ok</span><span class=""p"">]</span>
    <span class=""k"">if</span> <span class=""ow"">not</span> <span class=""n"">file_paths</span><span class=""p"">:</span>
        <span class=""k"">raise</span> <span class=""n"">DropItem</span><span class=""p"">(</span><span class=""s2"">""Item contains no files""</span><span class=""p"">)</span>
    <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
    <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'file_paths'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">file_paths</span>
    <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">os</span>
<span class=""kn"">from</span> <span class=""nn"">urllib.parse</span> <span class=""kn"">import</span> <span class=""n"">urlparse</span>

<span class=""kn"">from</span> <span class=""nn"">scrapy.pipelines.images</span> <span class=""kn"">import</span> <span class=""n"">ImagesPipeline</span>

<span class=""k"">class</span> <span class=""nc"">MyImagesPipeline</span><span class=""p"">(</span><span class=""n"">ImagesPipeline</span><span class=""p"">):</span>

    <span class=""k"">def</span> <span class=""nf"">file_path</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""n"">info</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""s1"">'files/'</span> <span class=""o"">+</span> <span class=""n"">os</span><span class=""o"">.</span><span class=""n"">path</span><span class=""o"">.</span><span class=""n"">basename</span><span class=""p"">(</span><span class=""n"">urlparse</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">path</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exceptions</span> <span class=""kn"">import</span> <span class=""n"">DropItem</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.pipelines.images</span> <span class=""kn"">import</span> <span class=""n"">ImagesPipeline</span>

<span class=""k"">class</span> <span class=""nc"">MyImagesPipeline</span><span class=""p"">(</span><span class=""n"">ImagesPipeline</span><span class=""p"">):</span>

    <span class=""k"">def</span> <span class=""nf"">get_media_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">info</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">image_url</span> <span class=""ow"">in</span> <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'image_urls'</span><span class=""p"">]:</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">image_url</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">item_completed</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">results</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">info</span><span class=""p"">):</span>
        <span class=""n"">image_paths</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""n"">x</span><span class=""p"">[</span><span class=""s1"">'path'</span><span class=""p"">]</span> <span class=""k"">for</span> <span class=""n"">ok</span><span class=""p"">,</span> <span class=""n"">x</span> <span class=""ow"">in</span> <span class=""n"">results</span> <span class=""k"">if</span> <span class=""n"">ok</span><span class=""p"">]</span>
        <span class=""k"">if</span> <span class=""ow"">not</span> <span class=""n"">image_paths</span><span class=""p"">:</span>
            <span class=""k"">raise</span> <span class=""n"">DropItem</span><span class=""p"">(</span><span class=""s2"">""Item contains no images""</span><span class=""p"">)</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'image_paths'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">image_paths</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">ITEM_PIPELINES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'myproject.pipelines.MyImagesPipeline'</span><span class=""p"">:</span> <span class=""mi"">300</span>
<span class=""p"">}</span>
</pre></div>","ITEM_PIPELINES = {'scrapy.pipelines.images.ImagesPipeline': 1}
,ITEM_PIPELINES = {'scrapy.pipelines.files.FilesPipeline': 1}
,FILES_STORE = '/path/to/valid/dir'
,IMAGES_STORE = '/path/to/valid/dir'
,http://www.example.com/image.jpg
,3afec3b4765f8f0a07b78f98c07b83f013567a0a
,3afec3b4765f8f0a07b78f98c07b83f013567a0a.jpg
,http://www.example.com/product/images/large/front/0000000004166
,00b08510e4_front.jpg
,import hashlib
from os.path import splitext

def file_path(self, request, response=None, info=None, *, item=None):
    image_url_hash = hashlib.shake_256(request.url.encode()).hexdigest(5)
    image_perspective = request.url.split('/')[-2]
    image_filename = f'{image_url_hash}_{image_perspective}.jpg'

    return image_filename
,<IMAGES_STORE>/full/<FILE_NAME>
,ftp://username:password@address:port/path
ftp://address:port/path
,IMAGES_STORE = 's3://bucket/images'
,IMAGES_STORE_S3_ACL = 'public-read'
,AWS_ENDPOINT_URL = 'http://minio.example.com:9000'
,AWS_USE_SSL = False # or True (None by default)
AWS_VERIFY = False # or True (None by default)
,IMAGES_STORE = 'gs://bucket/images/'
GCS_PROJECT_ID = 'project_id'
,IMAGES_STORE_GCS_ACL = 'publicRead'
,import scrapy

class MyItem(scrapy.Item):
    # ... other item fields ...
    image_urls = scrapy.Field()
    images = scrapy.Field()
,FILES_URLS_FIELD = 'field_name_for_your_files_urls'
FILES_RESULT_FIELD = 'field_name_for_your_processed_files'
,IMAGES_URLS_FIELD = 'field_name_for_your_images_urls'
IMAGES_RESULT_FIELD = 'field_name_for_your_processed_images'
,# 120 days of delay for files expiration
FILES_EXPIRES = 120

# 30 days of delay for images expiration
IMAGES_EXPIRES = 30
,IMAGES_THUMBS = {
    'small': (50, 50),
    'big': (270, 270),
}
,<IMAGES_STORE>/thumbs/<size_name>/<image_id>.jpg
,<IMAGES_STORE>/full/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg
<IMAGES_STORE>/thumbs/small/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg
<IMAGES_STORE>/thumbs/big/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg
,IMAGES_MIN_HEIGHT = 110
IMAGES_MIN_WIDTH = 110
,MEDIA_ALLOW_REDIRECTS = True
,import os
from urllib.parse import urlparse

from scrapy.pipelines.files import FilesPipeline

class MyFilesPipeline(FilesPipeline):

    def file_path(self, request, response=None, info=None, *, item=None):
        return 'files/' + os.path.basename(urlparse(request.url).path)
,from itemadapter import ItemAdapter

def get_media_requests(self, item, info):
    adapter = ItemAdapter(item)
    for file_url in adapter['file_urls']:
        yield scrapy.Request(file_url)
,[(True,
  {'checksum': '2b00042f7481c7b056c4b410d28f33cf',
   'path': 'full/0a79c461a4062ac383dc4fade7bc09f1384a3910.jpg',
   'url': 'http://www.example.com/files/product1.pdf',
   'status': 'downloaded'}),
 (False,
  Failure(...))]
,from itemadapter import ItemAdapter
from scrapy.exceptions import DropItem

def item_completed(self, results, item, info):
    file_paths = [x['path'] for ok, x in results if ok]
    if not file_paths:
        raise DropItem(""Item contains no files"")
    adapter = ItemAdapter(item)
    adapter['file_paths'] = file_paths
    return item
,import os
from urllib.parse import urlparse

from scrapy.pipelines.images import ImagesPipeline

class MyImagesPipeline(ImagesPipeline):

    def file_path(self, request, response=None, info=None, *, item=None):
        return 'files/' + os.path.basename(urlparse(request.url).path)
,import scrapy
from itemadapter import ItemAdapter
from scrapy.exceptions import DropItem
from scrapy.pipelines.images import ImagesPipeline

class MyImagesPipeline(ImagesPipeline):

    def get_media_requests(self, item, info):
        for image_url in item['image_urls']:
            yield scrapy.Request(image_url)

    def item_completed(self, results, item, info):
        image_paths = [x['path'] for ok, x in results if ok]
        if not image_paths:
            raise DropItem(""Item contains no images"")
        adapter = ItemAdapter(item)
        adapter['image_paths'] = image_paths
        return item
,ITEM_PIPELINES = {
    'myproject.pipelines.MyImagesPipeline': 300
}
",34
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,##,2,Using the Files Pipeline,#using-the-files-pipeline,,,2
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,##,2,Using the Images Pipeline,#using-the-images-pipeline,,,3
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,##,2,Enabling your Media Pipeline,#enabling-your-media-pipeline,"<div class=""highlight""><pre><span></span><span class=""n"">ITEM_PIPELINES</span> <span class=""o"">=</span> <span class=""p"">{</span><span class=""s1"">'scrapy.pipelines.images.ImagesPipeline'</span><span class=""p"">:</span> <span class=""mi"">1</span><span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">ITEM_PIPELINES</span> <span class=""o"">=</span> <span class=""p"">{</span><span class=""s1"">'scrapy.pipelines.files.FilesPipeline'</span><span class=""p"">:</span> <span class=""mi"">1</span><span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">FILES_STORE</span> <span class=""o"">=</span> <span class=""s1"">'/path/to/valid/dir'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_STORE</span> <span class=""o"">=</span> <span class=""s1"">'/path/to/valid/dir'</span>
</pre></div>","ITEM_PIPELINES = {'scrapy.pipelines.images.ImagesPipeline': 1}
,ITEM_PIPELINES = {'scrapy.pipelines.files.FilesPipeline': 1}
,FILES_STORE = '/path/to/valid/dir'
,IMAGES_STORE = '/path/to/valid/dir'
",4
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,##,2,File Naming,#file-naming,"<div class=""highlight""><pre><span></span><span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">image</span><span class=""o"">.</span><span class=""n"">jpg</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">3</span><span class=""n"">afec3b4765f8f0a07b78f98c07b83f013567a0a</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">3</span><span class=""n"">afec3b4765f8f0a07b78f98c07b83f013567a0a</span><span class=""o"">.</span><span class=""n"">jpg</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">product</span><span class=""o"">/</span><span class=""n"">images</span><span class=""o"">/</span><span class=""n"">large</span><span class=""o"">/</span><span class=""n"">front</span><span class=""o"">/</span><span class=""mi"">0000000004166</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">00</span><span class=""n"">b08510e4_front</span><span class=""o"">.</span><span class=""n"">jpg</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">hashlib</span>
<span class=""kn"">from</span> <span class=""nn"">os.path</span> <span class=""kn"">import</span> <span class=""n"">splitext</span>

<span class=""k"">def</span> <span class=""nf"">file_path</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""n"">info</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">):</span>
    <span class=""n"">image_url_hash</span> <span class=""o"">=</span> <span class=""n"">hashlib</span><span class=""o"">.</span><span class=""n"">shake_256</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""o"">.</span><span class=""n"">encode</span><span class=""p"">())</span><span class=""o"">.</span><span class=""n"">hexdigest</span><span class=""p"">(</span><span class=""mi"">5</span><span class=""p"">)</span>
    <span class=""n"">image_perspective</span> <span class=""o"">=</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""o"">.</span><span class=""n"">split</span><span class=""p"">(</span><span class=""s1"">'/'</span><span class=""p"">)[</span><span class=""o"">-</span><span class=""mi"">2</span><span class=""p"">]</span>
    <span class=""n"">image_filename</span> <span class=""o"">=</span> <span class=""sa"">f</span><span class=""s1"">'</span><span class=""si"">{</span><span class=""n"">image_url_hash</span><span class=""si"">}</span><span class=""s1"">_</span><span class=""si"">{</span><span class=""n"">image_perspective</span><span class=""si"">}</span><span class=""s1"">.jpg'</span>

    <span class=""k"">return</span> <span class=""n"">image_filename</span>
</pre></div>","http://www.example.com/image.jpg
,3afec3b4765f8f0a07b78f98c07b83f013567a0a
,3afec3b4765f8f0a07b78f98c07b83f013567a0a.jpg
,http://www.example.com/product/images/large/front/0000000004166
,00b08510e4_front.jpg
,import hashlib
from os.path import splitext

def file_path(self, request, response=None, info=None, *, item=None):
    image_url_hash = hashlib.shake_256(request.url.encode()).hexdigest(5)
    image_perspective = request.url.split('/')[-2]
    image_filename = f'{image_url_hash}_{image_perspective}.jpg'

    return image_filename
",6
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,###,3,Default File Naming,#default-file-naming,"<div class=""highlight""><pre><span></span><span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">image</span><span class=""o"">.</span><span class=""n"">jpg</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">3</span><span class=""n"">afec3b4765f8f0a07b78f98c07b83f013567a0a</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">3</span><span class=""n"">afec3b4765f8f0a07b78f98c07b83f013567a0a</span><span class=""o"">.</span><span class=""n"">jpg</span>
</pre></div>","http://www.example.com/image.jpg
,3afec3b4765f8f0a07b78f98c07b83f013567a0a
,3afec3b4765f8f0a07b78f98c07b83f013567a0a.jpg
",3
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,###,3,Custom File Naming,#custom-file-naming,"<div class=""highlight""><pre><span></span><span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">product</span><span class=""o"">/</span><span class=""n"">images</span><span class=""o"">/</span><span class=""n"">large</span><span class=""o"">/</span><span class=""n"">front</span><span class=""o"">/</span><span class=""mi"">0000000004166</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">00</span><span class=""n"">b08510e4_front</span><span class=""o"">.</span><span class=""n"">jpg</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">hashlib</span>
<span class=""kn"">from</span> <span class=""nn"">os.path</span> <span class=""kn"">import</span> <span class=""n"">splitext</span>

<span class=""k"">def</span> <span class=""nf"">file_path</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""n"">info</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">):</span>
    <span class=""n"">image_url_hash</span> <span class=""o"">=</span> <span class=""n"">hashlib</span><span class=""o"">.</span><span class=""n"">shake_256</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""o"">.</span><span class=""n"">encode</span><span class=""p"">())</span><span class=""o"">.</span><span class=""n"">hexdigest</span><span class=""p"">(</span><span class=""mi"">5</span><span class=""p"">)</span>
    <span class=""n"">image_perspective</span> <span class=""o"">=</span> <span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""o"">.</span><span class=""n"">split</span><span class=""p"">(</span><span class=""s1"">'/'</span><span class=""p"">)[</span><span class=""o"">-</span><span class=""mi"">2</span><span class=""p"">]</span>
    <span class=""n"">image_filename</span> <span class=""o"">=</span> <span class=""sa"">f</span><span class=""s1"">'</span><span class=""si"">{</span><span class=""n"">image_url_hash</span><span class=""si"">}</span><span class=""s1"">_</span><span class=""si"">{</span><span class=""n"">image_perspective</span><span class=""si"">}</span><span class=""s1"">.jpg'</span>

    <span class=""k"">return</span> <span class=""n"">image_filename</span>
</pre></div>","http://www.example.com/product/images/large/front/0000000004166
,00b08510e4_front.jpg
,import hashlib
from os.path import splitext

def file_path(self, request, response=None, info=None, *, item=None):
    image_url_hash = hashlib.shake_256(request.url.encode()).hexdigest(5)
    image_perspective = request.url.split('/')[-2]
    image_filename = f'{image_url_hash}_{image_perspective}.jpg'

    return image_filename
",3
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,##,2,Supported Storage,#supported-storage,"<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">IMAGES_STORE</span><span class=""o"">&gt;/</span><span class=""n"">full</span><span class=""o"">/&lt;</span><span class=""n"">FILE_NAME</span><span class=""o"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">ftp</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">username</span><span class=""p"">:</span><span class=""n"">password</span><span class=""nd"">@address</span><span class=""p"">:</span><span class=""n"">port</span><span class=""o"">/</span><span class=""n"">path</span>
<span class=""n"">ftp</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">address</span><span class=""p"">:</span><span class=""n"">port</span><span class=""o"">/</span><span class=""n"">path</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_STORE</span> <span class=""o"">=</span> <span class=""s1"">'s3://bucket/images'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_STORE_S3_ACL</span> <span class=""o"">=</span> <span class=""s1"">'public-read'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">AWS_ENDPOINT_URL</span> <span class=""o"">=</span> <span class=""s1"">'http://minio.example.com:9000'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">AWS_USE_SSL</span> <span class=""o"">=</span> <span class=""kc"">False</span> <span class=""c1""># or True (None by default)</span>
<span class=""n"">AWS_VERIFY</span> <span class=""o"">=</span> <span class=""kc"">False</span> <span class=""c1""># or True (None by default)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_STORE</span> <span class=""o"">=</span> <span class=""s1"">'gs://bucket/images/'</span>
<span class=""n"">GCS_PROJECT_ID</span> <span class=""o"">=</span> <span class=""s1"">'project_id'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_STORE_GCS_ACL</span> <span class=""o"">=</span> <span class=""s1"">'publicRead'</span>
</pre></div>","<IMAGES_STORE>/full/<FILE_NAME>
,ftp://username:password@address:port/path
ftp://address:port/path
,IMAGES_STORE = 's3://bucket/images'
,IMAGES_STORE_S3_ACL = 'public-read'
,AWS_ENDPOINT_URL = 'http://minio.example.com:9000'
,AWS_USE_SSL = False # or True (None by default)
AWS_VERIFY = False # or True (None by default)
,IMAGES_STORE = 'gs://bucket/images/'
GCS_PROJECT_ID = 'project_id'
,IMAGES_STORE_GCS_ACL = 'publicRead'
",8
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,###,3,File system storage,#file-system-storage,"<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">IMAGES_STORE</span><span class=""o"">&gt;/</span><span class=""n"">full</span><span class=""o"">/&lt;</span><span class=""n"">FILE_NAME</span><span class=""o"">&gt;</span>
</pre></div>","<IMAGES_STORE>/full/<FILE_NAME>
",1
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,###,3,FTP server storage,#ftp-server-storage,"<div class=""highlight""><pre><span></span><span class=""n"">ftp</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">username</span><span class=""p"">:</span><span class=""n"">password</span><span class=""nd"">@address</span><span class=""p"">:</span><span class=""n"">port</span><span class=""o"">/</span><span class=""n"">path</span>
<span class=""n"">ftp</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">address</span><span class=""p"">:</span><span class=""n"">port</span><span class=""o"">/</span><span class=""n"">path</span>
</pre></div>","ftp://username:password@address:port/path
ftp://address:port/path
",1
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,###,3,Amazon S3 storage,#amazon-s3-storage,"<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_STORE</span> <span class=""o"">=</span> <span class=""s1"">'s3://bucket/images'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_STORE_S3_ACL</span> <span class=""o"">=</span> <span class=""s1"">'public-read'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">AWS_ENDPOINT_URL</span> <span class=""o"">=</span> <span class=""s1"">'http://minio.example.com:9000'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">AWS_USE_SSL</span> <span class=""o"">=</span> <span class=""kc"">False</span> <span class=""c1""># or True (None by default)</span>
<span class=""n"">AWS_VERIFY</span> <span class=""o"">=</span> <span class=""kc"">False</span> <span class=""c1""># or True (None by default)</span>
</pre></div>","IMAGES_STORE = 's3://bucket/images'
,IMAGES_STORE_S3_ACL = 'public-read'
,AWS_ENDPOINT_URL = 'http://minio.example.com:9000'
,AWS_USE_SSL = False # or True (None by default)
AWS_VERIFY = False # or True (None by default)
",4
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,###,3,Google Cloud Storage,#google-cloud-storage,"<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_STORE</span> <span class=""o"">=</span> <span class=""s1"">'gs://bucket/images/'</span>
<span class=""n"">GCS_PROJECT_ID</span> <span class=""o"">=</span> <span class=""s1"">'project_id'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_STORE_GCS_ACL</span> <span class=""o"">=</span> <span class=""s1"">'publicRead'</span>
</pre></div>","IMAGES_STORE = 'gs://bucket/images/'
GCS_PROJECT_ID = 'project_id'
,IMAGES_STORE_GCS_ACL = 'publicRead'
",2
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,##,2,Usage example,#usage-example,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MyItem</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""c1""># ... other item fields ...</span>
    <span class=""n"">image_urls</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">images</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">FILES_URLS_FIELD</span> <span class=""o"">=</span> <span class=""s1"">'field_name_for_your_files_urls'</span>
<span class=""n"">FILES_RESULT_FIELD</span> <span class=""o"">=</span> <span class=""s1"">'field_name_for_your_processed_files'</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_URLS_FIELD</span> <span class=""o"">=</span> <span class=""s1"">'field_name_for_your_images_urls'</span>
<span class=""n"">IMAGES_RESULT_FIELD</span> <span class=""o"">=</span> <span class=""s1"">'field_name_for_your_processed_images'</span>
</pre></div>","import scrapy

class MyItem(scrapy.Item):
    # ... other item fields ...
    image_urls = scrapy.Field()
    images = scrapy.Field()
,FILES_URLS_FIELD = 'field_name_for_your_files_urls'
FILES_RESULT_FIELD = 'field_name_for_your_processed_files'
,IMAGES_URLS_FIELD = 'field_name_for_your_images_urls'
IMAGES_RESULT_FIELD = 'field_name_for_your_processed_images'
",3
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,##,2,Additional features,#additional-features,"<div class=""highlight""><pre><span></span><span class=""c1""># 120 days of delay for files expiration</span>
<span class=""n"">FILES_EXPIRES</span> <span class=""o"">=</span> <span class=""mi"">120</span>

<span class=""c1""># 30 days of delay for images expiration</span>
<span class=""n"">IMAGES_EXPIRES</span> <span class=""o"">=</span> <span class=""mi"">30</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_THUMBS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'small'</span><span class=""p"">:</span> <span class=""p"">(</span><span class=""mi"">50</span><span class=""p"">,</span> <span class=""mi"">50</span><span class=""p"">),</span>
    <span class=""s1"">'big'</span><span class=""p"">:</span> <span class=""p"">(</span><span class=""mi"">270</span><span class=""p"">,</span> <span class=""mi"">270</span><span class=""p"">),</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">IMAGES_STORE</span><span class=""o"">&gt;/</span><span class=""n"">thumbs</span><span class=""o"">/&lt;</span><span class=""n"">size_name</span><span class=""o"">&gt;/&lt;</span><span class=""n"">image_id</span><span class=""o"">&gt;.</span><span class=""n"">jpg</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">IMAGES_STORE</span><span class=""o"">&gt;/</span><span class=""n"">full</span><span class=""o"">/</span><span class=""mi"">63</span><span class=""n"">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=""o"">.</span><span class=""n"">jpg</span>
<span class=""o"">&lt;</span><span class=""n"">IMAGES_STORE</span><span class=""o"">&gt;/</span><span class=""n"">thumbs</span><span class=""o"">/</span><span class=""n"">small</span><span class=""o"">/</span><span class=""mi"">63</span><span class=""n"">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=""o"">.</span><span class=""n"">jpg</span>
<span class=""o"">&lt;</span><span class=""n"">IMAGES_STORE</span><span class=""o"">&gt;/</span><span class=""n"">thumbs</span><span class=""o"">/</span><span class=""n"">big</span><span class=""o"">/</span><span class=""mi"">63</span><span class=""n"">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=""o"">.</span><span class=""n"">jpg</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_MIN_HEIGHT</span> <span class=""o"">=</span> <span class=""mi"">110</span>
<span class=""n"">IMAGES_MIN_WIDTH</span> <span class=""o"">=</span> <span class=""mi"">110</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">MEDIA_ALLOW_REDIRECTS</span> <span class=""o"">=</span> <span class=""kc"">True</span>
</pre></div>","# 120 days of delay for files expiration
FILES_EXPIRES = 120

# 30 days of delay for images expiration
IMAGES_EXPIRES = 30
,IMAGES_THUMBS = {
    'small': (50, 50),
    'big': (270, 270),
}
,<IMAGES_STORE>/thumbs/<size_name>/<image_id>.jpg
,<IMAGES_STORE>/full/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg
<IMAGES_STORE>/thumbs/small/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg
<IMAGES_STORE>/thumbs/big/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg
,IMAGES_MIN_HEIGHT = 110
IMAGES_MIN_WIDTH = 110
,MEDIA_ALLOW_REDIRECTS = True
",6
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,###,3,File expiration,#file-expiration,"<div class=""highlight""><pre><span></span><span class=""c1""># 120 days of delay for files expiration</span>
<span class=""n"">FILES_EXPIRES</span> <span class=""o"">=</span> <span class=""mi"">120</span>

<span class=""c1""># 30 days of delay for images expiration</span>
<span class=""n"">IMAGES_EXPIRES</span> <span class=""o"">=</span> <span class=""mi"">30</span>
</pre></div>","# 120 days of delay for files expiration
FILES_EXPIRES = 120

# 30 days of delay for images expiration
IMAGES_EXPIRES = 30
",1
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,###,3,Thumbnail generation for images,#thumbnail-generation-for-images,"<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_THUMBS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'small'</span><span class=""p"">:</span> <span class=""p"">(</span><span class=""mi"">50</span><span class=""p"">,</span> <span class=""mi"">50</span><span class=""p"">),</span>
    <span class=""s1"">'big'</span><span class=""p"">:</span> <span class=""p"">(</span><span class=""mi"">270</span><span class=""p"">,</span> <span class=""mi"">270</span><span class=""p"">),</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">IMAGES_STORE</span><span class=""o"">&gt;/</span><span class=""n"">thumbs</span><span class=""o"">/&lt;</span><span class=""n"">size_name</span><span class=""o"">&gt;/&lt;</span><span class=""n"">image_id</span><span class=""o"">&gt;.</span><span class=""n"">jpg</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">&lt;</span><span class=""n"">IMAGES_STORE</span><span class=""o"">&gt;/</span><span class=""n"">full</span><span class=""o"">/</span><span class=""mi"">63</span><span class=""n"">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=""o"">.</span><span class=""n"">jpg</span>
<span class=""o"">&lt;</span><span class=""n"">IMAGES_STORE</span><span class=""o"">&gt;/</span><span class=""n"">thumbs</span><span class=""o"">/</span><span class=""n"">small</span><span class=""o"">/</span><span class=""mi"">63</span><span class=""n"">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=""o"">.</span><span class=""n"">jpg</span>
<span class=""o"">&lt;</span><span class=""n"">IMAGES_STORE</span><span class=""o"">&gt;/</span><span class=""n"">thumbs</span><span class=""o"">/</span><span class=""n"">big</span><span class=""o"">/</span><span class=""mi"">63</span><span class=""n"">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class=""o"">.</span><span class=""n"">jpg</span>
</pre></div>","IMAGES_THUMBS = {
    'small': (50, 50),
    'big': (270, 270),
}
,<IMAGES_STORE>/thumbs/<size_name>/<image_id>.jpg
,<IMAGES_STORE>/full/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg
<IMAGES_STORE>/thumbs/small/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg
<IMAGES_STORE>/thumbs/big/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg
",3
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,###,3,Filtering out small images,#filtering-out-small-images,"<div class=""highlight""><pre><span></span><span class=""n"">IMAGES_MIN_HEIGHT</span> <span class=""o"">=</span> <span class=""mi"">110</span>
<span class=""n"">IMAGES_MIN_WIDTH</span> <span class=""o"">=</span> <span class=""mi"">110</span>
</pre></div>","IMAGES_MIN_HEIGHT = 110
IMAGES_MIN_WIDTH = 110
",1
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,###,3,Allowing redirections,#allowing-redirections,"<div class=""highlight""><pre><span></span><span class=""n"">MEDIA_ALLOW_REDIRECTS</span> <span class=""o"">=</span> <span class=""kc"">True</span>
</pre></div>","MEDIA_ALLOW_REDIRECTS = True
",1
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,##,2,Extending the Media Pipelines,#module-scrapy.pipelines.files,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">os</span>
<span class=""kn"">from</span> <span class=""nn"">urllib.parse</span> <span class=""kn"">import</span> <span class=""n"">urlparse</span>

<span class=""kn"">from</span> <span class=""nn"">scrapy.pipelines.files</span> <span class=""kn"">import</span> <span class=""n"">FilesPipeline</span>

<span class=""k"">class</span> <span class=""nc"">MyFilesPipeline</span><span class=""p"">(</span><span class=""n"">FilesPipeline</span><span class=""p"">):</span>

    <span class=""k"">def</span> <span class=""nf"">file_path</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""n"">info</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""s1"">'files/'</span> <span class=""o"">+</span> <span class=""n"">os</span><span class=""o"">.</span><span class=""n"">path</span><span class=""o"">.</span><span class=""n"">basename</span><span class=""p"">(</span><span class=""n"">urlparse</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">path</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>

<span class=""k"">def</span> <span class=""nf"">get_media_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">info</span><span class=""p"">):</span>
    <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
    <span class=""k"">for</span> <span class=""n"">file_url</span> <span class=""ow"">in</span> <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'file_urls'</span><span class=""p"">]:</span>
        <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">file_url</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">[(</span><span class=""kc"">True</span><span class=""p"">,</span>
  <span class=""p"">{</span><span class=""s1"">'checksum'</span><span class=""p"">:</span> <span class=""s1"">'2b00042f7481c7b056c4b410d28f33cf'</span><span class=""p"">,</span>
   <span class=""s1"">'path'</span><span class=""p"">:</span> <span class=""s1"">'full/0a79c461a4062ac383dc4fade7bc09f1384a3910.jpg'</span><span class=""p"">,</span>
   <span class=""s1"">'url'</span><span class=""p"">:</span> <span class=""s1"">'http://www.example.com/files/product1.pdf'</span><span class=""p"">,</span>
   <span class=""s1"">'status'</span><span class=""p"">:</span> <span class=""s1"">'downloaded'</span><span class=""p"">}),</span>
 <span class=""p"">(</span><span class=""kc"">False</span><span class=""p"">,</span>
  <span class=""n"">Failure</span><span class=""p"">(</span><span class=""o"">...</span><span class=""p"">))]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exceptions</span> <span class=""kn"">import</span> <span class=""n"">DropItem</span>

<span class=""k"">def</span> <span class=""nf"">item_completed</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">results</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">info</span><span class=""p"">):</span>
    <span class=""n"">file_paths</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""n"">x</span><span class=""p"">[</span><span class=""s1"">'path'</span><span class=""p"">]</span> <span class=""k"">for</span> <span class=""n"">ok</span><span class=""p"">,</span> <span class=""n"">x</span> <span class=""ow"">in</span> <span class=""n"">results</span> <span class=""k"">if</span> <span class=""n"">ok</span><span class=""p"">]</span>
    <span class=""k"">if</span> <span class=""ow"">not</span> <span class=""n"">file_paths</span><span class=""p"">:</span>
        <span class=""k"">raise</span> <span class=""n"">DropItem</span><span class=""p"">(</span><span class=""s2"">""Item contains no files""</span><span class=""p"">)</span>
    <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
    <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'file_paths'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">file_paths</span>
    <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">os</span>
<span class=""kn"">from</span> <span class=""nn"">urllib.parse</span> <span class=""kn"">import</span> <span class=""n"">urlparse</span>

<span class=""kn"">from</span> <span class=""nn"">scrapy.pipelines.images</span> <span class=""kn"">import</span> <span class=""n"">ImagesPipeline</span>

<span class=""k"">class</span> <span class=""nc"">MyImagesPipeline</span><span class=""p"">(</span><span class=""n"">ImagesPipeline</span><span class=""p"">):</span>

    <span class=""k"">def</span> <span class=""nf"">file_path</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">request</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""n"">info</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""s1"">'files/'</span> <span class=""o"">+</span> <span class=""n"">os</span><span class=""o"">.</span><span class=""n"">path</span><span class=""o"">.</span><span class=""n"">basename</span><span class=""p"">(</span><span class=""n"">urlparse</span><span class=""p"">(</span><span class=""n"">request</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">path</span><span class=""p"">)</span>
</pre></div>","import os
from urllib.parse import urlparse

from scrapy.pipelines.files import FilesPipeline

class MyFilesPipeline(FilesPipeline):

    def file_path(self, request, response=None, info=None, *, item=None):
        return 'files/' + os.path.basename(urlparse(request.url).path)
,from itemadapter import ItemAdapter

def get_media_requests(self, item, info):
    adapter = ItemAdapter(item)
    for file_url in adapter['file_urls']:
        yield scrapy.Request(file_url)
,[(True,
  {'checksum': '2b00042f7481c7b056c4b410d28f33cf',
   'path': 'full/0a79c461a4062ac383dc4fade7bc09f1384a3910.jpg',
   'url': 'http://www.example.com/files/product1.pdf',
   'status': 'downloaded'}),
 (False,
  Failure(...))]
,from itemadapter import ItemAdapter
from scrapy.exceptions import DropItem

def item_completed(self, results, item, info):
    file_paths = [x['path'] for ok, x in results if ok]
    if not file_paths:
        raise DropItem(""Item contains no files"")
    adapter = ItemAdapter(item)
    adapter['file_paths'] = file_paths
    return item
,import os
from urllib.parse import urlparse

from scrapy.pipelines.images import ImagesPipeline

class MyImagesPipeline(ImagesPipeline):

    def file_path(self, request, response=None, info=None, *, item=None):
        return 'files/' + os.path.basename(urlparse(request.url).path)
",5
https://docs.scrapy.org/en/latest/topics/media-pipeline.html,,##,2,Custom Images pipeline example,#custom-images-pipeline-example,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>
<span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exceptions</span> <span class=""kn"">import</span> <span class=""n"">DropItem</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.pipelines.images</span> <span class=""kn"">import</span> <span class=""n"">ImagesPipeline</span>

<span class=""k"">class</span> <span class=""nc"">MyImagesPipeline</span><span class=""p"">(</span><span class=""n"">ImagesPipeline</span><span class=""p"">):</span>

    <span class=""k"">def</span> <span class=""nf"">get_media_requests</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">info</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">image_url</span> <span class=""ow"">in</span> <span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'image_urls'</span><span class=""p"">]:</span>
            <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">image_url</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">item_completed</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">results</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">info</span><span class=""p"">):</span>
        <span class=""n"">image_paths</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""n"">x</span><span class=""p"">[</span><span class=""s1"">'path'</span><span class=""p"">]</span> <span class=""k"">for</span> <span class=""n"">ok</span><span class=""p"">,</span> <span class=""n"">x</span> <span class=""ow"">in</span> <span class=""n"">results</span> <span class=""k"">if</span> <span class=""n"">ok</span><span class=""p"">]</span>
        <span class=""k"">if</span> <span class=""ow"">not</span> <span class=""n"">image_paths</span><span class=""p"">:</span>
            <span class=""k"">raise</span> <span class=""n"">DropItem</span><span class=""p"">(</span><span class=""s2"">""Item contains no images""</span><span class=""p"">)</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'image_paths'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">image_paths</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">ITEM_PIPELINES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'myproject.pipelines.MyImagesPipeline'</span><span class=""p"">:</span> <span class=""mi"">300</span>
<span class=""p"">}</span>
</pre></div>","import scrapy
from itemadapter import ItemAdapter
from scrapy.exceptions import DropItem
from scrapy.pipelines.images import ImagesPipeline

class MyImagesPipeline(ImagesPipeline):

    def get_media_requests(self, item, info):
        for image_url in item['image_urls']:
            yield scrapy.Request(image_url)

    def item_completed(self, results, item, info):
        image_paths = [x['path'] for ok, x in results if ok]
        if not image_paths:
            raise DropItem(""Item contains no images"")
        adapter = ItemAdapter(item)
        adapter['image_paths'] = image_paths
        return item
,ITEM_PIPELINES = {
    'myproject.pipelines.MyImagesPipeline': 300
}
",2
https://docs.scrapy.org/en/latest/topics/deploy.html,,#,1,Deploying Spiders,#deploying-spiders,,,1
https://docs.scrapy.org/en/latest/topics/deploy.html,,##,2,Deploying to a Scrapyd Server,#deploying-to-a-scrapyd-server,,,2
https://docs.scrapy.org/en/latest/topics/deploy.html,,##,2,Deploying to Zyte Scrapy Cloud,#deploying-to-zyte-scrapy-cloud,,,3
https://docs.scrapy.org/en/latest/topics/autothrottle.html,,#,1,AutoThrottle extension,#autothrottle-extension,,,1
https://docs.scrapy.org/en/latest/topics/autothrottle.html,,##,2,Design goals,#design-goals,,,2
https://docs.scrapy.org/en/latest/topics/autothrottle.html,,##,2,How it works,#how-it-works,,,3
https://docs.scrapy.org/en/latest/topics/autothrottle.html,,##,2,Throttling algorithm,#throttling-algorithm,,,4
https://docs.scrapy.org/en/latest/topics/autothrottle.html,,##,2,Settings,#settings,,,5
https://docs.scrapy.org/en/latest/topics/autothrottle.html,,###,3,AUTOTHROTTLE_ENABLED,#autothrottle-enabled,,,6
https://docs.scrapy.org/en/latest/topics/autothrottle.html,,###,3,AUTOTHROTTLE_START_DELAY,#autothrottle-start-delay,,,7
https://docs.scrapy.org/en/latest/topics/autothrottle.html,,###,3,AUTOTHROTTLE_MAX_DELAY,#autothrottle-max-delay,,,8
https://docs.scrapy.org/en/latest/topics/autothrottle.html,,###,3,AUTOTHROTTLE_TARGET_CONCURRENCY,#autothrottle-target-concurrency,,,9
https://docs.scrapy.org/en/latest/topics/autothrottle.html,,###,3,AUTOTHROTTLE_DEBUG,#autothrottle-debug,,,10
https://docs.scrapy.org/en/latest/topics/benchmarking.html,,#,1,Benchmarking,#benchmarking,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">bench</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">48</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">utils</span><span class=""o"">.</span><span class=""n"">log</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Scrapy</span> <span class=""mf"">1.2.2</span> <span class=""n"">started</span> <span class=""p"">(</span><span class=""n"">bot</span><span class=""p"">:</span> <span class=""n"">quotesbot</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">48</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">utils</span><span class=""o"">.</span><span class=""n"">log</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Overridden</span> <span class=""n"">settings</span><span class=""p"">:</span> <span class=""p"">{</span><span class=""s1"">'CLOSESPIDER_TIMEOUT'</span><span class=""p"">:</span> <span class=""mi"">10</span><span class=""p"">,</span> <span class=""s1"">'ROBOTSTXT_OBEY'</span><span class=""p"">:</span> <span class=""kc"">True</span><span class=""p"">,</span> <span class=""s1"">'SPIDER_MODULES'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""s1"">'quotesbot.spiders'</span><span class=""p"">],</span> <span class=""s1"">'LOGSTATS_INTERVAL'</span><span class=""p"">:</span> <span class=""mi"">1</span><span class=""p"">,</span> <span class=""s1"">'BOT_NAME'</span><span class=""p"">:</span> <span class=""s1"">'quotesbot'</span><span class=""p"">,</span> <span class=""s1"">'LOG_LEVEL'</span><span class=""p"">:</span> <span class=""s1"">'INFO'</span><span class=""p"">,</span> <span class=""s1"">'NEWSPIDER_MODULE'</span><span class=""p"">:</span> <span class=""s1"">'quotesbot.spiders'</span><span class=""p"">}</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">49</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">middleware</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Enabled</span> <span class=""n"">extensions</span><span class=""p"">:</span>
<span class=""p"">[</span><span class=""s1"">'scrapy.extensions.closespider.CloseSpider'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.extensions.logstats.LogStats'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.extensions.telnet.TelnetConsole'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.extensions.corestats.CoreStats'</span><span class=""p"">]</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">49</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">middleware</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Enabled</span> <span class=""n"">downloader</span> <span class=""n"">middlewares</span><span class=""p"">:</span>
<span class=""p"">[</span><span class=""s1"">'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.downloadermiddlewares.retry.RetryMiddleware'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.downloadermiddlewares.cookies.CookiesMiddleware'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.downloadermiddlewares.stats.DownloaderStats'</span><span class=""p"">]</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">49</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">middleware</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Enabled</span> <span class=""n"">spider</span> <span class=""n"">middlewares</span><span class=""p"">:</span>
<span class=""p"">[</span><span class=""s1"">'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.spidermiddlewares.referer.RefererMiddleware'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware'</span><span class=""p"">,</span>
 <span class=""s1"">'scrapy.spidermiddlewares.depth.DepthMiddleware'</span><span class=""p"">]</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">49</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">middleware</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Enabled</span> <span class=""n"">item</span> <span class=""n"">pipelines</span><span class=""p"">:</span>
<span class=""p"">[]</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">49</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Spider</span> <span class=""n"">opened</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">49</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">logstats</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""mi"">0</span> <span class=""n"">pages</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">pages</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">),</span> <span class=""n"">scraped</span> <span class=""mi"">0</span> <span class=""n"">items</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">items</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">50</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">logstats</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""mi"">70</span> <span class=""n"">pages</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">4200</span> <span class=""n"">pages</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">),</span> <span class=""n"">scraped</span> <span class=""mi"">0</span> <span class=""n"">items</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">items</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">51</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">logstats</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""mi"">134</span> <span class=""n"">pages</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">3840</span> <span class=""n"">pages</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">),</span> <span class=""n"">scraped</span> <span class=""mi"">0</span> <span class=""n"">items</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">items</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">52</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">logstats</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""mi"">198</span> <span class=""n"">pages</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">3840</span> <span class=""n"">pages</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">),</span> <span class=""n"">scraped</span> <span class=""mi"">0</span> <span class=""n"">items</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">items</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">53</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">logstats</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""mi"">254</span> <span class=""n"">pages</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">3360</span> <span class=""n"">pages</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">),</span> <span class=""n"">scraped</span> <span class=""mi"">0</span> <span class=""n"">items</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">items</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">54</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">logstats</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""mi"">302</span> <span class=""n"">pages</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">2880</span> <span class=""n"">pages</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">),</span> <span class=""n"">scraped</span> <span class=""mi"">0</span> <span class=""n"">items</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">items</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">55</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">logstats</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""mi"">358</span> <span class=""n"">pages</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">3360</span> <span class=""n"">pages</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">),</span> <span class=""n"">scraped</span> <span class=""mi"">0</span> <span class=""n"">items</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">items</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">56</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">logstats</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""mi"">406</span> <span class=""n"">pages</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">2880</span> <span class=""n"">pages</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">),</span> <span class=""n"">scraped</span> <span class=""mi"">0</span> <span class=""n"">items</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">items</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">57</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">logstats</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""mi"">438</span> <span class=""n"">pages</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">1920</span> <span class=""n"">pages</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">),</span> <span class=""n"">scraped</span> <span class=""mi"">0</span> <span class=""n"">items</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">items</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">58</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">logstats</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""mi"">470</span> <span class=""n"">pages</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">1920</span> <span class=""n"">pages</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">),</span> <span class=""n"">scraped</span> <span class=""mi"">0</span> <span class=""n"">items</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">items</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">59</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Closing</span> <span class=""n"">spider</span> <span class=""p"">(</span><span class=""n"">closespider_timeout</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">18</span><span class=""p"">:</span><span class=""mi"">59</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">extensions</span><span class=""o"">.</span><span class=""n"">logstats</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""mi"">518</span> <span class=""n"">pages</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">2880</span> <span class=""n"">pages</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">),</span> <span class=""n"">scraped</span> <span class=""mi"">0</span> <span class=""n"">items</span> <span class=""p"">(</span><span class=""n"">at</span> <span class=""mi"">0</span> <span class=""n"">items</span><span class=""o"">/</span><span class=""nb"">min</span><span class=""p"">)</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">19</span><span class=""p"">:</span><span class=""mi"">00</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">statscollectors</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Dumping</span> <span class=""n"">Scrapy</span> <span class=""n"">stats</span><span class=""p"">:</span>
<span class=""p"">{</span><span class=""s1"">'downloader/request_bytes'</span><span class=""p"">:</span> <span class=""mi"">229995</span><span class=""p"">,</span>
 <span class=""s1"">'downloader/request_count'</span><span class=""p"">:</span> <span class=""mi"">534</span><span class=""p"">,</span>
 <span class=""s1"">'downloader/request_method_count/GET'</span><span class=""p"">:</span> <span class=""mi"">534</span><span class=""p"">,</span>
 <span class=""s1"">'downloader/response_bytes'</span><span class=""p"">:</span> <span class=""mi"">1565504</span><span class=""p"">,</span>
 <span class=""s1"">'downloader/response_count'</span><span class=""p"">:</span> <span class=""mi"">534</span><span class=""p"">,</span>
 <span class=""s1"">'downloader/response_status_count/200'</span><span class=""p"">:</span> <span class=""mi"">534</span><span class=""p"">,</span>
 <span class=""s1"">'finish_reason'</span><span class=""p"">:</span> <span class=""s1"">'closespider_timeout'</span><span class=""p"">,</span>
 <span class=""s1"">'finish_time'</span><span class=""p"">:</span> <span class=""n"">datetime</span><span class=""o"">.</span><span class=""n"">datetime</span><span class=""p"">(</span><span class=""mi"">2016</span><span class=""p"">,</span> <span class=""mi"">12</span><span class=""p"">,</span> <span class=""mi"">16</span><span class=""p"">,</span> <span class=""mi"">16</span><span class=""p"">,</span> <span class=""mi"">19</span><span class=""p"">,</span> <span class=""mi"">0</span><span class=""p"">,</span> <span class=""mi"">647725</span><span class=""p"">),</span>
 <span class=""s1"">'log_count/INFO'</span><span class=""p"">:</span> <span class=""mi"">17</span><span class=""p"">,</span>
 <span class=""s1"">'request_depth_max'</span><span class=""p"">:</span> <span class=""mi"">19</span><span class=""p"">,</span>
 <span class=""s1"">'response_received_count'</span><span class=""p"">:</span> <span class=""mi"">534</span><span class=""p"">,</span>
 <span class=""s1"">'scheduler/dequeued'</span><span class=""p"">:</span> <span class=""mi"">533</span><span class=""p"">,</span>
 <span class=""s1"">'scheduler/dequeued/memory'</span><span class=""p"">:</span> <span class=""mi"">533</span><span class=""p"">,</span>
 <span class=""s1"">'scheduler/enqueued'</span><span class=""p"">:</span> <span class=""mi"">10661</span><span class=""p"">,</span>
 <span class=""s1"">'scheduler/enqueued/memory'</span><span class=""p"">:</span> <span class=""mi"">10661</span><span class=""p"">,</span>
 <span class=""s1"">'start_time'</span><span class=""p"">:</span> <span class=""n"">datetime</span><span class=""o"">.</span><span class=""n"">datetime</span><span class=""p"">(</span><span class=""mi"">2016</span><span class=""p"">,</span> <span class=""mi"">12</span><span class=""p"">,</span> <span class=""mi"">16</span><span class=""p"">,</span> <span class=""mi"">16</span><span class=""p"">,</span> <span class=""mi"">18</span><span class=""p"">,</span> <span class=""mi"">49</span><span class=""p"">,</span> <span class=""mi"">799869</span><span class=""p"">)}</span>
<span class=""mi"">2016</span><span class=""o"">-</span><span class=""mi"">12</span><span class=""o"">-</span><span class=""mi"">16</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">19</span><span class=""p"">:</span><span class=""mi"">00</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Spider</span> <span class=""n"">closed</span> <span class=""p"">(</span><span class=""n"">closespider_timeout</span><span class=""p"">)</span>
</pre></div>","scrapy bench
,2016-12-16 21:18:48 [scrapy.utils.log] INFO: Scrapy 1.2.2 started (bot: quotesbot)
2016-12-16 21:18:48 [scrapy.utils.log] INFO: Overridden settings: {'CLOSESPIDER_TIMEOUT': 10, 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['quotesbot.spiders'], 'LOGSTATS_INTERVAL': 1, 'BOT_NAME': 'quotesbot', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'quotesbot.spiders'}
2016-12-16 21:18:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-12-16 21:18:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-12-16 21:18:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-12-16 21:18:49 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2016-12-16 21:18:49 [scrapy.core.engine] INFO: Spider opened
2016-12-16 21:18:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-16 21:18:50 [scrapy.extensions.logstats] INFO: Crawled 70 pages (at 4200 pages/min), scraped 0 items (at 0 items/min)
2016-12-16 21:18:51 [scrapy.extensions.logstats] INFO: Crawled 134 pages (at 3840 pages/min), scraped 0 items (at 0 items/min)
2016-12-16 21:18:52 [scrapy.extensions.logstats] INFO: Crawled 198 pages (at 3840 pages/min), scraped 0 items (at 0 items/min)
2016-12-16 21:18:53 [scrapy.extensions.logstats] INFO: Crawled 254 pages (at 3360 pages/min), scraped 0 items (at 0 items/min)
2016-12-16 21:18:54 [scrapy.extensions.logstats] INFO: Crawled 302 pages (at 2880 pages/min), scraped 0 items (at 0 items/min)
2016-12-16 21:18:55 [scrapy.extensions.logstats] INFO: Crawled 358 pages (at 3360 pages/min), scraped 0 items (at 0 items/min)
2016-12-16 21:18:56 [scrapy.extensions.logstats] INFO: Crawled 406 pages (at 2880 pages/min), scraped 0 items (at 0 items/min)
2016-12-16 21:18:57 [scrapy.extensions.logstats] INFO: Crawled 438 pages (at 1920 pages/min), scraped 0 items (at 0 items/min)
2016-12-16 21:18:58 [scrapy.extensions.logstats] INFO: Crawled 470 pages (at 1920 pages/min), scraped 0 items (at 0 items/min)
2016-12-16 21:18:59 [scrapy.core.engine] INFO: Closing spider (closespider_timeout)
2016-12-16 21:18:59 [scrapy.extensions.logstats] INFO: Crawled 518 pages (at 2880 pages/min), scraped 0 items (at 0 items/min)
2016-12-16 21:19:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 229995,
 'downloader/request_count': 534,
 'downloader/request_method_count/GET': 534,
 'downloader/response_bytes': 1565504,
 'downloader/response_count': 534,
 'downloader/response_status_count/200': 534,
 'finish_reason': 'closespider_timeout',
 'finish_time': datetime.datetime(2016, 12, 16, 16, 19, 0, 647725),
 'log_count/INFO': 17,
 'request_depth_max': 19,
 'response_received_count': 534,
 'scheduler/dequeued': 533,
 'scheduler/dequeued/memory': 533,
 'scheduler/enqueued': 10661,
 'scheduler/enqueued/memory': 10661,
 'start_time': datetime.datetime(2016, 12, 16, 16, 18, 49, 799869)}
2016-12-16 21:19:00 [scrapy.core.engine] INFO: Spider closed (closespider_timeout)
",2
https://docs.scrapy.org/en/latest/topics/jobs.html,,#,1,Jobs: pausing and resuming crawls,#jobs-pausing-and-resuming-crawls,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">somespider</span> <span class=""o"">-</span><span class=""n"">s</span> <span class=""n"">JOBDIR</span><span class=""o"">=</span><span class=""n"">crawls</span><span class=""o"">/</span><span class=""n"">somespider</span><span class=""o"">-</span><span class=""mi"">1</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">somespider</span> <span class=""o"">-</span><span class=""n"">s</span> <span class=""n"">JOBDIR</span><span class=""o"">=</span><span class=""n"">crawls</span><span class=""o"">/</span><span class=""n"">somespider</span><span class=""o"">-</span><span class=""mi"">1</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""c1""># parse item here</span>
    <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">state</span><span class=""p"">[</span><span class=""s1"">'items_count'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">state</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'items_count'</span><span class=""p"">,</span> <span class=""mi"">0</span><span class=""p"">)</span> <span class=""o"">+</span> <span class=""mi"">1</span>
</pre></div>","scrapy crawl somespider -s JOBDIR=crawls/somespider-1
,scrapy crawl somespider -s JOBDIR=crawls/somespider-1
,def parse_item(self, response):
    # parse item here
    self.state['items_count'] = self.state.get('items_count', 0) + 1
",3
https://docs.scrapy.org/en/latest/topics/jobs.html,,##,2,Job directory,#job-directory,,,2
https://docs.scrapy.org/en/latest/topics/jobs.html,,##,2,How to use it,#how-to-use-it,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">somespider</span> <span class=""o"">-</span><span class=""n"">s</span> <span class=""n"">JOBDIR</span><span class=""o"">=</span><span class=""n"">crawls</span><span class=""o"">/</span><span class=""n"">somespider</span><span class=""o"">-</span><span class=""mi"">1</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span> <span class=""n"">crawl</span> <span class=""n"">somespider</span> <span class=""o"">-</span><span class=""n"">s</span> <span class=""n"">JOBDIR</span><span class=""o"">=</span><span class=""n"">crawls</span><span class=""o"">/</span><span class=""n"">somespider</span><span class=""o"">-</span><span class=""mi"">1</span>
</pre></div>","scrapy crawl somespider -s JOBDIR=crawls/somespider-1
,scrapy crawl somespider -s JOBDIR=crawls/somespider-1
",2
https://docs.scrapy.org/en/latest/topics/jobs.html,,##,2,Keeping persistent state between batches,#keeping-persistent-state-between-batches,"<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""c1""># parse item here</span>
    <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">state</span><span class=""p"">[</span><span class=""s1"">'items_count'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">state</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'items_count'</span><span class=""p"">,</span> <span class=""mi"">0</span><span class=""p"">)</span> <span class=""o"">+</span> <span class=""mi"">1</span>
</pre></div>","def parse_item(self, response):
    # parse item here
    self.state['items_count'] = self.state.get('items_count', 0) + 1
",1
https://docs.scrapy.org/en/latest/topics/jobs.html,,##,2,Persistence gotchas,#persistence-gotchas,,,5
https://docs.scrapy.org/en/latest/topics/jobs.html,,###,3,Cookies expiration,#cookies-expiration,,,6
https://docs.scrapy.org/en/latest/topics/jobs.html,,###,3,Request serialization,#request-serialization,,,7
https://docs.scrapy.org/en/latest/topics/coroutines.html,,#,1,Coroutines,#coroutines,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>

<span class=""k"">class</span> <span class=""nc"">DbPipeline</span><span class=""p"">:</span>
    <span class=""k"">def</span> <span class=""nf"">_update_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">data</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'field'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">data</span>
        <span class=""k"">return</span> <span class=""n"">item</span>

    <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""n"">dfd</span> <span class=""o"">=</span> <span class=""n"">db</span><span class=""o"">.</span><span class=""n"">get_some_data</span><span class=""p"">(</span><span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">])</span>
        <span class=""n"">dfd</span><span class=""o"">.</span><span class=""n"">addCallback</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">_update_item</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""n"">dfd</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>

<span class=""k"">class</span> <span class=""nc"">DbPipeline</span><span class=""p"">:</span>
    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'field'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">db</span><span class=""o"">.</span><span class=""n"">get_some_data</span><span class=""p"">(</span><span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">])</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpiderDeferred</span><span class=""p"">(</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># ...</span>
    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">additional_response</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">treq</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'https://additional.url'</span><span class=""p"">)</span>
        <span class=""n"">additional_data</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">treq</span><span class=""o"">.</span><span class=""n"">content</span><span class=""p"">(</span><span class=""n"">additional_response</span><span class=""p"">)</span>
        <span class=""c1""># ... use response and additional_data to yield items and requests</span>

<span class=""k"">class</span> <span class=""nc"">MySpiderAsyncio</span><span class=""p"">(</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># ...</span>
    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">async</span> <span class=""k"">with</span> <span class=""n"">aiohttp</span><span class=""o"">.</span><span class=""n"">ClientSession</span><span class=""p"">()</span> <span class=""k"">as</span> <span class=""n"">session</span><span class=""p"">:</span>
            <span class=""k"">async</span> <span class=""k"">with</span> <span class=""n"">session</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'https://additional.url'</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">additional_response</span><span class=""p"">:</span>
                <span class=""n"">additional_data</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">additional_response</span><span class=""o"">.</span><span class=""n"">text</span><span class=""p"">()</span>
        <span class=""c1""># ... use response and additional_data to yield items and requests</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">UniversalSpiderMiddleware</span><span class=""p"">:</span>
    <span class=""k"">def</span> <span class=""nf"">process_spider_output</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">result</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">r</span> <span class=""ow"">in</span> <span class=""n"">result</span><span class=""p"">:</span>
            <span class=""c1""># ... do something with r</span>
            <span class=""k"">yield</span> <span class=""n"">r</span>

    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">process_spider_output_async</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">result</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""k"">async</span> <span class=""k"">for</span> <span class=""n"">r</span> <span class=""ow"">in</span> <span class=""n"">result</span><span class=""p"">:</span>
            <span class=""c1""># ... do something with r</span>
            <span class=""k"">yield</span> <span class=""n"">r</span>
</pre></div>","from itemadapter import ItemAdapter

class DbPipeline:
    def _update_item(self, data, item):
        adapter = ItemAdapter(item)
        adapter['field'] = data
        return item

    def process_item(self, item, spider):
        adapter = ItemAdapter(item)
        dfd = db.get_some_data(adapter['id'])
        dfd.addCallback(self._update_item, item)
        return dfd
,from itemadapter import ItemAdapter

class DbPipeline:
    async def process_item(self, item, spider):
        adapter = ItemAdapter(item)
        adapter['field'] = await db.get_some_data(adapter['id'])
        return item
,class MySpiderDeferred(Spider):
    # ...
    async def parse(self, response):
        additional_response = await treq.get('https://additional.url')
        additional_data = await treq.content(additional_response)
        # ... use response and additional_data to yield items and requests

class MySpiderAsyncio(Spider):
    # ...
    async def parse(self, response):
        async with aiohttp.ClientSession() as session:
            async with session.get('https://additional.url') as additional_response:
                additional_data = await additional_response.text()
        # ... use response and additional_data to yield items and requests
,class UniversalSpiderMiddleware:
    def process_spider_output(self, response, result, spider):
        for r in result:
            # ... do something with r
            yield r

    async def process_spider_output_async(self, response, result, spider):
        async for r in result:
            # ... do something with r
            yield r
",4
https://docs.scrapy.org/en/latest/topics/coroutines.html,,##,2,Supported callables,#supported-callables,,,2
https://docs.scrapy.org/en/latest/topics/coroutines.html,,##,2,General usage,#general-usage,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>

<span class=""k"">class</span> <span class=""nc"">DbPipeline</span><span class=""p"">:</span>
    <span class=""k"">def</span> <span class=""nf"">_update_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">data</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'field'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">data</span>
        <span class=""k"">return</span> <span class=""n"">item</span>

    <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""n"">dfd</span> <span class=""o"">=</span> <span class=""n"">db</span><span class=""o"">.</span><span class=""n"">get_some_data</span><span class=""p"">(</span><span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">])</span>
        <span class=""n"">dfd</span><span class=""o"">.</span><span class=""n"">addCallback</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">_update_item</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""n"">dfd</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>

<span class=""k"">class</span> <span class=""nc"">DbPipeline</span><span class=""p"">:</span>
    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'field'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">db</span><span class=""o"">.</span><span class=""n"">get_some_data</span><span class=""p"">(</span><span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'id'</span><span class=""p"">])</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpiderDeferred</span><span class=""p"">(</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># ...</span>
    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">additional_response</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">treq</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'https://additional.url'</span><span class=""p"">)</span>
        <span class=""n"">additional_data</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">treq</span><span class=""o"">.</span><span class=""n"">content</span><span class=""p"">(</span><span class=""n"">additional_response</span><span class=""p"">)</span>
        <span class=""c1""># ... use response and additional_data to yield items and requests</span>

<span class=""k"">class</span> <span class=""nc"">MySpiderAsyncio</span><span class=""p"">(</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""c1""># ...</span>
    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">async</span> <span class=""k"">with</span> <span class=""n"">aiohttp</span><span class=""o"">.</span><span class=""n"">ClientSession</span><span class=""p"">()</span> <span class=""k"">as</span> <span class=""n"">session</span><span class=""p"">:</span>
            <span class=""k"">async</span> <span class=""k"">with</span> <span class=""n"">session</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'https://additional.url'</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">additional_response</span><span class=""p"">:</span>
                <span class=""n"">additional_data</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">additional_response</span><span class=""o"">.</span><span class=""n"">text</span><span class=""p"">()</span>
        <span class=""c1""># ... use response and additional_data to yield items and requests</span>
</pre></div>","from itemadapter import ItemAdapter

class DbPipeline:
    def _update_item(self, data, item):
        adapter = ItemAdapter(item)
        adapter['field'] = data
        return item

    def process_item(self, item, spider):
        adapter = ItemAdapter(item)
        dfd = db.get_some_data(adapter['id'])
        dfd.addCallback(self._update_item, item)
        return dfd
,from itemadapter import ItemAdapter

class DbPipeline:
    async def process_item(self, item, spider):
        adapter = ItemAdapter(item)
        adapter['field'] = await db.get_some_data(adapter['id'])
        return item
,class MySpiderDeferred(Spider):
    # ...
    async def parse(self, response):
        additional_response = await treq.get('https://additional.url')
        additional_data = await treq.content(additional_response)
        # ... use response and additional_data to yield items and requests

class MySpiderAsyncio(Spider):
    # ...
    async def parse(self, response):
        async with aiohttp.ClientSession() as session:
            async with session.get('https://additional.url') as additional_response:
                additional_data = await additional_response.text()
        # ... use response and additional_data to yield items and requests
",3
https://docs.scrapy.org/en/latest/topics/coroutines.html,,##,2,Mixing synchronous and asynchronous spider middlewares,#mixing-synchronous-and-asynchronous-spider-middlewares,,,4
https://docs.scrapy.org/en/latest/topics/coroutines.html,,##,2,Universal spider middlewares,#universal-spider-middlewares,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">UniversalSpiderMiddleware</span><span class=""p"">:</span>
    <span class=""k"">def</span> <span class=""nf"">process_spider_output</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">result</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">r</span> <span class=""ow"">in</span> <span class=""n"">result</span><span class=""p"">:</span>
            <span class=""c1""># ... do something with r</span>
            <span class=""k"">yield</span> <span class=""n"">r</span>

    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">process_spider_output_async</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">,</span> <span class=""n"">result</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""k"">async</span> <span class=""k"">for</span> <span class=""n"">r</span> <span class=""ow"">in</span> <span class=""n"">result</span><span class=""p"">:</span>
            <span class=""c1""># ... do something with r</span>
            <span class=""k"">yield</span> <span class=""n"">r</span>
</pre></div>","class UniversalSpiderMiddleware:
    def process_spider_output(self, response, result, spider):
        for r in result:
            # ... do something with r
            yield r

    async def process_spider_output_async(self, response, result, spider):
        async for r in result:
            # ... do something with r
            yield r
",1
https://docs.scrapy.org/en/latest/topics/asyncio.html,,#,1,asyncio,#asyncio,"<div class=""highlight""><pre><span></span><span class=""n"">install_reactor</span><span class=""p"">(</span><span class=""s1"">'twisted.internet.asyncioreactor.AsyncioSelectorReactor'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">asyncio</span>
<span class=""n"">asyncio</span><span class=""o"">.</span><span class=""n"">set_event_loop_policy</span><span class=""p"">(</span><span class=""n"">asyncio</span><span class=""o"">.</span><span class=""n"">WindowsSelectorEventLoopPolicy</span><span class=""p"">())</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""o"">...</span>
    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">d</span> <span class=""o"">=</span> <span class=""n"">treq</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'https://example.com/additional'</span><span class=""p"">)</span>
        <span class=""n"">additional_response</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">deferred_to_future</span><span class=""p"">(</span><span class=""n"">d</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""o"">...</span>
    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">d</span> <span class=""o"">=</span> <span class=""n"">treq</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'https://example.com/additional'</span><span class=""p"">)</span>
        <span class=""n"">extra_response</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">maybe_deferred_to_future</span><span class=""p"">(</span><span class=""n"">d</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.utils.reactor</span> <span class=""kn"">import</span> <span class=""n"">is_asyncio_reactor_installed</span>

<span class=""k"">class</span> <span class=""nc"">MyComponent</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""ow"">not</span> <span class=""n"">is_asyncio_reactor_installed</span><span class=""p"">():</span>
            <span class=""k"">raise</span> <span class=""ne"">ValueError</span><span class=""p"">(</span>
                <span class=""sa"">f</span><span class=""s2"">""</span><span class=""si"">{</span><span class=""n"">MyComponent</span><span class=""o"">.</span><span class=""vm"">__qualname__</span><span class=""si"">}</span><span class=""s2""> requires the asyncio Twisted ""</span>
                <span class=""sa"">f</span><span class=""s2"">""reactor. Make sure you have it configured in the ""</span>
                <span class=""sa"">f</span><span class=""s2"">""TWISTED_REACTOR setting. See the asyncio documentation ""</span>
                <span class=""sa"">f</span><span class=""s2"">""of Scrapy for more information.""</span>
            <span class=""p"">)</span>
</pre></div>","install_reactor('twisted.internet.asyncioreactor.AsyncioSelectorReactor')
,import asyncio
asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
,class MySpider(Spider):
    ...
    async def parse(self, response):
        d = treq.get('https://example.com/additional')
        additional_response = await deferred_to_future(d)
,class MySpider(Spider):
    ...
    async def parse(self, response):
        d = treq.get('https://example.com/additional')
        extra_response = await maybe_deferred_to_future(d)
,from scrapy.utils.reactor import is_asyncio_reactor_installed

class MyComponent:

    def __init__(self):
        if not is_asyncio_reactor_installed():
            raise ValueError(
                f""{MyComponent.__qualname__} requires the asyncio Twisted ""
                f""reactor. Make sure you have it configured in the ""
                f""TWISTED_REACTOR setting. See the asyncio documentation ""
                f""of Scrapy for more information.""
            )
",5
https://docs.scrapy.org/en/latest/topics/asyncio.html,,##,2,Installing the asyncio reactor,#installing-the-asyncio-reactor,"<div class=""highlight""><pre><span></span><span class=""n"">install_reactor</span><span class=""p"">(</span><span class=""s1"">'twisted.internet.asyncioreactor.AsyncioSelectorReactor'</span><span class=""p"">)</span>
</pre></div>","install_reactor('twisted.internet.asyncioreactor.AsyncioSelectorReactor')
",1
https://docs.scrapy.org/en/latest/topics/asyncio.html,,##,2,Using custom asyncio loops,#using-custom-asyncio-loops,,,3
https://docs.scrapy.org/en/latest/topics/asyncio.html,,##,2,Windows-specific notes,#windows-specific-notes,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">asyncio</span>
<span class=""n"">asyncio</span><span class=""o"">.</span><span class=""n"">set_event_loop_policy</span><span class=""p"">(</span><span class=""n"">asyncio</span><span class=""o"">.</span><span class=""n"">WindowsSelectorEventLoopPolicy</span><span class=""p"">())</span>
</pre></div>","import asyncio
asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
",1
https://docs.scrapy.org/en/latest/topics/asyncio.html,,##,2,Awaiting on Deferreds,#awaiting-on-deferreds,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""o"">...</span>
    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">d</span> <span class=""o"">=</span> <span class=""n"">treq</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'https://example.com/additional'</span><span class=""p"">)</span>
        <span class=""n"">additional_response</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">deferred_to_future</span><span class=""p"">(</span><span class=""n"">d</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""o"">...</span>
    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""n"">d</span> <span class=""o"">=</span> <span class=""n"">treq</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(</span><span class=""s1"">'https://example.com/additional'</span><span class=""p"">)</span>
        <span class=""n"">extra_response</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">maybe_deferred_to_future</span><span class=""p"">(</span><span class=""n"">d</span><span class=""p"">)</span>
</pre></div>","class MySpider(Spider):
    ...
    async def parse(self, response):
        d = treq.get('https://example.com/additional')
        additional_response = await deferred_to_future(d)
,class MySpider(Spider):
    ...
    async def parse(self, response):
        d = treq.get('https://example.com/additional')
        extra_response = await maybe_deferred_to_future(d)
",2
https://docs.scrapy.org/en/latest/topics/asyncio.html,,##,2,Enforcing asyncio as a requirement,#enforcing-asyncio-as-a-requirement,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.utils.reactor</span> <span class=""kn"">import</span> <span class=""n"">is_asyncio_reactor_installed</span>

<span class=""k"">class</span> <span class=""nc"">MyComponent</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""ow"">not</span> <span class=""n"">is_asyncio_reactor_installed</span><span class=""p"">():</span>
            <span class=""k"">raise</span> <span class=""ne"">ValueError</span><span class=""p"">(</span>
                <span class=""sa"">f</span><span class=""s2"">""</span><span class=""si"">{</span><span class=""n"">MyComponent</span><span class=""o"">.</span><span class=""vm"">__qualname__</span><span class=""si"">}</span><span class=""s2""> requires the asyncio Twisted ""</span>
                <span class=""sa"">f</span><span class=""s2"">""reactor. Make sure you have it configured in the ""</span>
                <span class=""sa"">f</span><span class=""s2"">""TWISTED_REACTOR setting. See the asyncio documentation ""</span>
                <span class=""sa"">f</span><span class=""s2"">""of Scrapy for more information.""</span>
            <span class=""p"">)</span>
</pre></div>","from scrapy.utils.reactor import is_asyncio_reactor_installed

class MyComponent:

    def __init__(self):
        if not is_asyncio_reactor_installed():
            raise ValueError(
                f""{MyComponent.__qualname__} requires the asyncio Twisted ""
                f""reactor. Make sure you have it configured in the ""
                f""TWISTED_REACTOR setting. See the asyncio documentation ""
                f""of Scrapy for more information.""
            )
",1
https://docs.scrapy.org/en/latest/topics/architecture.html,,#,1,Architecture overview,#architecture-overview,,,1
https://docs.scrapy.org/en/latest/topics/architecture.html,,##,2,Overview,#overview,,,2
https://docs.scrapy.org/en/latest/topics/architecture.html,,##,2,Data flow,#data-flow,,,3
https://docs.scrapy.org/en/latest/topics/architecture.html,,##,2,Components,#components,,,4
https://docs.scrapy.org/en/latest/topics/architecture.html,,###,3,Scrapy Engine,#scrapy-engine,,,5
https://docs.scrapy.org/en/latest/topics/architecture.html,,###,3,Scheduler,#scheduler,,,6
https://docs.scrapy.org/en/latest/topics/architecture.html,,###,3,Downloader,#downloader,,,7
https://docs.scrapy.org/en/latest/topics/architecture.html,,###,3,Spiders,#spiders,,,8
https://docs.scrapy.org/en/latest/topics/architecture.html,,###,3,Item Pipeline,#item-pipeline,,,9
https://docs.scrapy.org/en/latest/topics/architecture.html,,###,3,Downloader middlewares,#downloader-middlewares,,,10
https://docs.scrapy.org/en/latest/topics/architecture.html,,###,3,Spider middlewares,#spider-middlewares,,,11
https://docs.scrapy.org/en/latest/topics/architecture.html,,##,2,Event-driven networking,#event-driven-networking,,,12
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#,1,Downloader Middleware,#downloader-middleware,"<div class=""highlight""><pre><span></span><span class=""n"">DOWNLOADER_MIDDLEWARES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'myproject.middlewares.CustomDownloaderMiddleware'</span><span class=""p"">:</span> <span class=""mi"">543</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">DOWNLOADER_MIDDLEWARES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'myproject.middlewares.CustomDownloaderMiddleware'</span><span class=""p"">:</span> <span class=""mi"">543</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">i</span><span class=""p"">,</span> <span class=""n"">url</span> <span class=""ow"">in</span> <span class=""nb"">enumerate</span><span class=""p"">(</span><span class=""n"">urls</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">meta</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'cookiejar'</span><span class=""p"">:</span> <span class=""n"">i</span><span class=""p"">},</span>
        <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_page</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse_page</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""c1""># do some processing</span>
    <span class=""k"">return</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s2"">""http://www.example.com/otherpage""</span><span class=""p"">,</span>
        <span class=""n"">meta</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'cookiejar'</span><span class=""p"">:</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">meta</span><span class=""p"">[</span><span class=""s1"">'cookiejar'</span><span class=""p"">]},</span>
        <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_other_page</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">2011</span><span class=""o"">-</span><span class=""mi"">04</span><span class=""o"">-</span><span class=""mi"">06</span> <span class=""mi"">14</span><span class=""p"">:</span><span class=""mi"">35</span><span class=""p"">:</span><span class=""mi"">10</span><span class=""o"">-</span><span class=""mi"">0300</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Spider</span> <span class=""n"">opened</span>
<span class=""mi"">2011</span><span class=""o"">-</span><span class=""mi"">04</span><span class=""o"">-</span><span class=""mi"">06</span> <span class=""mi"">14</span><span class=""p"">:</span><span class=""mi"">35</span><span class=""p"">:</span><span class=""mi"">10</span><span class=""o"">-</span><span class=""mi"">0300</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">downloadermiddlewares</span><span class=""o"">.</span><span class=""n"">cookies</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Sending</span> <span class=""n"">cookies</span> <span class=""n"">to</span><span class=""p"">:</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">diningcity</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">netherlands</span><span class=""o"">/</span><span class=""n"">index</span><span class=""o"">.</span><span class=""n"">html</span><span class=""o"">&gt;</span>
        <span class=""n"">Cookie</span><span class=""p"">:</span> <span class=""n"">clientlanguage_nl</span><span class=""o"">=</span><span class=""n"">en_EN</span>
<span class=""mi"">2011</span><span class=""o"">-</span><span class=""mi"">04</span><span class=""o"">-</span><span class=""mi"">06</span> <span class=""mi"">14</span><span class=""p"">:</span><span class=""mi"">35</span><span class=""p"">:</span><span class=""mi"">14</span><span class=""o"">-</span><span class=""mi"">0300</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">downloadermiddlewares</span><span class=""o"">.</span><span class=""n"">cookies</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Received</span> <span class=""n"">cookies</span> <span class=""n"">from</span><span class=""p"">:</span> <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">diningcity</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">netherlands</span><span class=""o"">/</span><span class=""n"">index</span><span class=""o"">.</span><span class=""n"">html</span><span class=""o"">&gt;</span>
        <span class=""n"">Set</span><span class=""o"">-</span><span class=""n"">Cookie</span><span class=""p"">:</span> <span class=""n"">JSESSIONID</span><span class=""o"">=</span><span class=""n"">B</span><span class=""o"">~</span><span class=""n"">FA4DC0C496C8762AE4F1A620EAB34F38</span><span class=""p"">;</span> <span class=""n"">Path</span><span class=""o"">=/</span>
        <span class=""n"">Set</span><span class=""o"">-</span><span class=""n"">Cookie</span><span class=""p"">:</span> <span class=""n"">ip_isocode</span><span class=""o"">=</span><span class=""n"">US</span>
        <span class=""n"">Set</span><span class=""o"">-</span><span class=""n"">Cookie</span><span class=""p"">:</span> <span class=""n"">clientlanguage_nl</span><span class=""o"">=</span><span class=""n"">en_EN</span><span class=""p"">;</span> <span class=""n"">Expires</span><span class=""o"">=</span><span class=""n"">Thu</span><span class=""p"">,</span> <span class=""mi"">07</span><span class=""o"">-</span><span class=""n"">Apr</span><span class=""o"">-</span><span class=""mi"">2011</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">34</span> <span class=""n"">GMT</span><span class=""p"">;</span> <span class=""n"">Path</span><span class=""o"">=/</span>
<span class=""mi"">2011</span><span class=""o"">-</span><span class=""mi"">04</span><span class=""o"">-</span><span class=""mi"">06</span> <span class=""mi"">14</span><span class=""p"">:</span><span class=""mi"">49</span><span class=""p"">:</span><span class=""mi"">50</span><span class=""o"">-</span><span class=""mi"">0300</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">diningcity</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">netherlands</span><span class=""o"">/</span><span class=""n"">index</span><span class=""o"">.</span><span class=""n"">html</span><span class=""o"">&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""o"">...</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">CrawlSpider</span>

<span class=""k"">class</span> <span class=""nc"">SomeIntranetSiteSpider</span><span class=""p"">(</span><span class=""n"">CrawlSpider</span><span class=""p"">):</span>

    <span class=""n"">http_user</span> <span class=""o"">=</span> <span class=""s1"">'someuser'</span>
    <span class=""n"">http_pass</span> <span class=""o"">=</span> <span class=""s1"">'somepass'</span>
    <span class=""n"">http_auth_domain</span> <span class=""o"">=</span> <span class=""s1"">'intranet.example.com'</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'intranet.example.com'</span>

    <span class=""c1""># .. rest of the spider code omitted ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">/</span><span class=""n"">path</span><span class=""o"">/</span><span class=""n"">to</span><span class=""o"">/</span><span class=""n"">cache</span><span class=""o"">/</span><span class=""nb"">dir</span><span class=""o"">/</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""mi"">72</span><span class=""o"">/</span><span class=""mi"">72811</span><span class=""n"">f648e718090f041317756c03adb0ada46c7</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">CrawlSpider</span><span class=""p"">):</span>
    <span class=""n"">handle_httpstatus_list</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""mi"">301</span><span class=""p"">,</span> <span class=""mi"">302</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""k"">if</span> <span class=""ow"">not</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">text</span><span class=""p"">:</span>
        <span class=""n"">new_request_or_none</span> <span class=""o"">=</span> <span class=""n"">get_retry_request</span><span class=""p"">(</span>
            <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">request</span><span class=""p"">,</span>
            <span class=""n"">spider</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""p"">,</span>
            <span class=""n"">reason</span><span class=""o"">=</span><span class=""s1"">'empty'</span><span class=""p"">,</span>
        <span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""n"">new_request_or_none</span>
</pre></div>","DOWNLOADER_MIDDLEWARES = {
    'myproject.middlewares.CustomDownloaderMiddleware': 543,
}
,DOWNLOADER_MIDDLEWARES = {
    'myproject.middlewares.CustomDownloaderMiddleware': 543,
    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,
}
,for i, url in enumerate(urls):
    yield scrapy.Request(url, meta={'cookiejar': i},
        callback=self.parse_page)
,def parse_page(self, response):
    # do some processing
    return scrapy.Request(""http://www.example.com/otherpage"",
        meta={'cookiejar': response.meta['cookiejar']},
        callback=self.parse_other_page)
,2011-04-06 14:35:10-0300 [scrapy.core.engine] INFO: Spider opened
2011-04-06 14:35:10-0300 [scrapy.downloadermiddlewares.cookies] DEBUG: Sending cookies to: <GET http://www.diningcity.com/netherlands/index.html>
        Cookie: clientlanguage_nl=en_EN
2011-04-06 14:35:14-0300 [scrapy.downloadermiddlewares.cookies] DEBUG: Received cookies from: <200 http://www.diningcity.com/netherlands/index.html>
        Set-Cookie: JSESSIONID=B~FA4DC0C496C8762AE4F1A620EAB34F38; Path=/
        Set-Cookie: ip_isocode=US
        Set-Cookie: clientlanguage_nl=en_EN; Expires=Thu, 07-Apr-2011 21:21:34 GMT; Path=/
2011-04-06 14:49:50-0300 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.diningcity.com/netherlands/index.html> (referer: None)
[...]
,from scrapy.spiders import CrawlSpider

class SomeIntranetSiteSpider(CrawlSpider):

    http_user = 'someuser'
    http_pass = 'somepass'
    http_auth_domain = 'intranet.example.com'
    name = 'intranet.example.com'

    # .. rest of the spider code omitted ...
,/path/to/cache/dir/example.com/72/72811f648e718090f041317756c03adb0ada46c7
,class MySpider(CrawlSpider):
    handle_httpstatus_list = [301, 302]
,def parse(self, response):
    if not response.text:
        new_request_or_none = get_retry_request(
            response.request,
            spider=self,
            reason='empty',
        )
        return new_request_or_none
",9
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,##,2,Activating a downloader middleware,#activating-a-downloader-middleware,"<div class=""highlight""><pre><span></span><span class=""n"">DOWNLOADER_MIDDLEWARES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'myproject.middlewares.CustomDownloaderMiddleware'</span><span class=""p"">:</span> <span class=""mi"">543</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">DOWNLOADER_MIDDLEWARES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'myproject.middlewares.CustomDownloaderMiddleware'</span><span class=""p"">:</span> <span class=""mi"">543</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","DOWNLOADER_MIDDLEWARES = {
    'myproject.middlewares.CustomDownloaderMiddleware': 543,
}
,DOWNLOADER_MIDDLEWARES = {
    'myproject.middlewares.CustomDownloaderMiddleware': 543,
    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,
}
",2
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,##,2,Writing your own downloader middleware,#writing-your-own-downloader-middleware,,,3
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,##,2,Built-in downloader middleware reference,#built-in-downloader-middleware-reference,"<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">i</span><span class=""p"">,</span> <span class=""n"">url</span> <span class=""ow"">in</span> <span class=""nb"">enumerate</span><span class=""p"">(</span><span class=""n"">urls</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">meta</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'cookiejar'</span><span class=""p"">:</span> <span class=""n"">i</span><span class=""p"">},</span>
        <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_page</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse_page</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""c1""># do some processing</span>
    <span class=""k"">return</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s2"">""http://www.example.com/otherpage""</span><span class=""p"">,</span>
        <span class=""n"">meta</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'cookiejar'</span><span class=""p"">:</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">meta</span><span class=""p"">[</span><span class=""s1"">'cookiejar'</span><span class=""p"">]},</span>
        <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_other_page</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">2011</span><span class=""o"">-</span><span class=""mi"">04</span><span class=""o"">-</span><span class=""mi"">06</span> <span class=""mi"">14</span><span class=""p"">:</span><span class=""mi"">35</span><span class=""p"">:</span><span class=""mi"">10</span><span class=""o"">-</span><span class=""mi"">0300</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Spider</span> <span class=""n"">opened</span>
<span class=""mi"">2011</span><span class=""o"">-</span><span class=""mi"">04</span><span class=""o"">-</span><span class=""mi"">06</span> <span class=""mi"">14</span><span class=""p"">:</span><span class=""mi"">35</span><span class=""p"">:</span><span class=""mi"">10</span><span class=""o"">-</span><span class=""mi"">0300</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">downloadermiddlewares</span><span class=""o"">.</span><span class=""n"">cookies</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Sending</span> <span class=""n"">cookies</span> <span class=""n"">to</span><span class=""p"">:</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">diningcity</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">netherlands</span><span class=""o"">/</span><span class=""n"">index</span><span class=""o"">.</span><span class=""n"">html</span><span class=""o"">&gt;</span>
        <span class=""n"">Cookie</span><span class=""p"">:</span> <span class=""n"">clientlanguage_nl</span><span class=""o"">=</span><span class=""n"">en_EN</span>
<span class=""mi"">2011</span><span class=""o"">-</span><span class=""mi"">04</span><span class=""o"">-</span><span class=""mi"">06</span> <span class=""mi"">14</span><span class=""p"">:</span><span class=""mi"">35</span><span class=""p"">:</span><span class=""mi"">14</span><span class=""o"">-</span><span class=""mi"">0300</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">downloadermiddlewares</span><span class=""o"">.</span><span class=""n"">cookies</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Received</span> <span class=""n"">cookies</span> <span class=""n"">from</span><span class=""p"">:</span> <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">diningcity</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">netherlands</span><span class=""o"">/</span><span class=""n"">index</span><span class=""o"">.</span><span class=""n"">html</span><span class=""o"">&gt;</span>
        <span class=""n"">Set</span><span class=""o"">-</span><span class=""n"">Cookie</span><span class=""p"">:</span> <span class=""n"">JSESSIONID</span><span class=""o"">=</span><span class=""n"">B</span><span class=""o"">~</span><span class=""n"">FA4DC0C496C8762AE4F1A620EAB34F38</span><span class=""p"">;</span> <span class=""n"">Path</span><span class=""o"">=/</span>
        <span class=""n"">Set</span><span class=""o"">-</span><span class=""n"">Cookie</span><span class=""p"">:</span> <span class=""n"">ip_isocode</span><span class=""o"">=</span><span class=""n"">US</span>
        <span class=""n"">Set</span><span class=""o"">-</span><span class=""n"">Cookie</span><span class=""p"">:</span> <span class=""n"">clientlanguage_nl</span><span class=""o"">=</span><span class=""n"">en_EN</span><span class=""p"">;</span> <span class=""n"">Expires</span><span class=""o"">=</span><span class=""n"">Thu</span><span class=""p"">,</span> <span class=""mi"">07</span><span class=""o"">-</span><span class=""n"">Apr</span><span class=""o"">-</span><span class=""mi"">2011</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">34</span> <span class=""n"">GMT</span><span class=""p"">;</span> <span class=""n"">Path</span><span class=""o"">=/</span>
<span class=""mi"">2011</span><span class=""o"">-</span><span class=""mi"">04</span><span class=""o"">-</span><span class=""mi"">06</span> <span class=""mi"">14</span><span class=""p"">:</span><span class=""mi"">49</span><span class=""p"">:</span><span class=""mi"">50</span><span class=""o"">-</span><span class=""mi"">0300</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">diningcity</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">netherlands</span><span class=""o"">/</span><span class=""n"">index</span><span class=""o"">.</span><span class=""n"">html</span><span class=""o"">&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""o"">...</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">CrawlSpider</span>

<span class=""k"">class</span> <span class=""nc"">SomeIntranetSiteSpider</span><span class=""p"">(</span><span class=""n"">CrawlSpider</span><span class=""p"">):</span>

    <span class=""n"">http_user</span> <span class=""o"">=</span> <span class=""s1"">'someuser'</span>
    <span class=""n"">http_pass</span> <span class=""o"">=</span> <span class=""s1"">'somepass'</span>
    <span class=""n"">http_auth_domain</span> <span class=""o"">=</span> <span class=""s1"">'intranet.example.com'</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'intranet.example.com'</span>

    <span class=""c1""># .. rest of the spider code omitted ...</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""o"">/</span><span class=""n"">path</span><span class=""o"">/</span><span class=""n"">to</span><span class=""o"">/</span><span class=""n"">cache</span><span class=""o"">/</span><span class=""nb"">dir</span><span class=""o"">/</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""mi"">72</span><span class=""o"">/</span><span class=""mi"">72811</span><span class=""n"">f648e718090f041317756c03adb0ada46c7</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">CrawlSpider</span><span class=""p"">):</span>
    <span class=""n"">handle_httpstatus_list</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""mi"">301</span><span class=""p"">,</span> <span class=""mi"">302</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""k"">if</span> <span class=""ow"">not</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">text</span><span class=""p"">:</span>
        <span class=""n"">new_request_or_none</span> <span class=""o"">=</span> <span class=""n"">get_retry_request</span><span class=""p"">(</span>
            <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">request</span><span class=""p"">,</span>
            <span class=""n"">spider</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""p"">,</span>
            <span class=""n"">reason</span><span class=""o"">=</span><span class=""s1"">'empty'</span><span class=""p"">,</span>
        <span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""n"">new_request_or_none</span>
</pre></div>","for i, url in enumerate(urls):
    yield scrapy.Request(url, meta={'cookiejar': i},
        callback=self.parse_page)
,def parse_page(self, response):
    # do some processing
    return scrapy.Request(""http://www.example.com/otherpage"",
        meta={'cookiejar': response.meta['cookiejar']},
        callback=self.parse_other_page)
,2011-04-06 14:35:10-0300 [scrapy.core.engine] INFO: Spider opened
2011-04-06 14:35:10-0300 [scrapy.downloadermiddlewares.cookies] DEBUG: Sending cookies to: <GET http://www.diningcity.com/netherlands/index.html>
        Cookie: clientlanguage_nl=en_EN
2011-04-06 14:35:14-0300 [scrapy.downloadermiddlewares.cookies] DEBUG: Received cookies from: <200 http://www.diningcity.com/netherlands/index.html>
        Set-Cookie: JSESSIONID=B~FA4DC0C496C8762AE4F1A620EAB34F38; Path=/
        Set-Cookie: ip_isocode=US
        Set-Cookie: clientlanguage_nl=en_EN; Expires=Thu, 07-Apr-2011 21:21:34 GMT; Path=/
2011-04-06 14:49:50-0300 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.diningcity.com/netherlands/index.html> (referer: None)
[...]
,from scrapy.spiders import CrawlSpider

class SomeIntranetSiteSpider(CrawlSpider):

    http_user = 'someuser'
    http_pass = 'somepass'
    http_auth_domain = 'intranet.example.com'
    name = 'intranet.example.com'

    # .. rest of the spider code omitted ...
,/path/to/cache/dir/example.com/72/72811f648e718090f041317756c03adb0ada46c7
,class MySpider(CrawlSpider):
    handle_httpstatus_list = [301, 302]
,def parse(self, response):
    if not response.text:
        new_request_or_none = get_retry_request(
            response.request,
            spider=self,
            reason='empty',
        )
        return new_request_or_none
",7
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,###,3,CookiesMiddleware,#module-scrapy.downloadermiddlewares.cookies,"<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">i</span><span class=""p"">,</span> <span class=""n"">url</span> <span class=""ow"">in</span> <span class=""nb"">enumerate</span><span class=""p"">(</span><span class=""n"">urls</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">meta</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'cookiejar'</span><span class=""p"">:</span> <span class=""n"">i</span><span class=""p"">},</span>
        <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_page</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse_page</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""c1""># do some processing</span>
    <span class=""k"">return</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s2"">""http://www.example.com/otherpage""</span><span class=""p"">,</span>
        <span class=""n"">meta</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'cookiejar'</span><span class=""p"">:</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">meta</span><span class=""p"">[</span><span class=""s1"">'cookiejar'</span><span class=""p"">]},</span>
        <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_other_page</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">2011</span><span class=""o"">-</span><span class=""mi"">04</span><span class=""o"">-</span><span class=""mi"">06</span> <span class=""mi"">14</span><span class=""p"">:</span><span class=""mi"">35</span><span class=""p"">:</span><span class=""mi"">10</span><span class=""o"">-</span><span class=""mi"">0300</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Spider</span> <span class=""n"">opened</span>
<span class=""mi"">2011</span><span class=""o"">-</span><span class=""mi"">04</span><span class=""o"">-</span><span class=""mi"">06</span> <span class=""mi"">14</span><span class=""p"">:</span><span class=""mi"">35</span><span class=""p"">:</span><span class=""mi"">10</span><span class=""o"">-</span><span class=""mi"">0300</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">downloadermiddlewares</span><span class=""o"">.</span><span class=""n"">cookies</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Sending</span> <span class=""n"">cookies</span> <span class=""n"">to</span><span class=""p"">:</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">diningcity</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">netherlands</span><span class=""o"">/</span><span class=""n"">index</span><span class=""o"">.</span><span class=""n"">html</span><span class=""o"">&gt;</span>
        <span class=""n"">Cookie</span><span class=""p"">:</span> <span class=""n"">clientlanguage_nl</span><span class=""o"">=</span><span class=""n"">en_EN</span>
<span class=""mi"">2011</span><span class=""o"">-</span><span class=""mi"">04</span><span class=""o"">-</span><span class=""mi"">06</span> <span class=""mi"">14</span><span class=""p"">:</span><span class=""mi"">35</span><span class=""p"">:</span><span class=""mi"">14</span><span class=""o"">-</span><span class=""mi"">0300</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">downloadermiddlewares</span><span class=""o"">.</span><span class=""n"">cookies</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Received</span> <span class=""n"">cookies</span> <span class=""n"">from</span><span class=""p"">:</span> <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">diningcity</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">netherlands</span><span class=""o"">/</span><span class=""n"">index</span><span class=""o"">.</span><span class=""n"">html</span><span class=""o"">&gt;</span>
        <span class=""n"">Set</span><span class=""o"">-</span><span class=""n"">Cookie</span><span class=""p"">:</span> <span class=""n"">JSESSIONID</span><span class=""o"">=</span><span class=""n"">B</span><span class=""o"">~</span><span class=""n"">FA4DC0C496C8762AE4F1A620EAB34F38</span><span class=""p"">;</span> <span class=""n"">Path</span><span class=""o"">=/</span>
        <span class=""n"">Set</span><span class=""o"">-</span><span class=""n"">Cookie</span><span class=""p"">:</span> <span class=""n"">ip_isocode</span><span class=""o"">=</span><span class=""n"">US</span>
        <span class=""n"">Set</span><span class=""o"">-</span><span class=""n"">Cookie</span><span class=""p"">:</span> <span class=""n"">clientlanguage_nl</span><span class=""o"">=</span><span class=""n"">en_EN</span><span class=""p"">;</span> <span class=""n"">Expires</span><span class=""o"">=</span><span class=""n"">Thu</span><span class=""p"">,</span> <span class=""mi"">07</span><span class=""o"">-</span><span class=""n"">Apr</span><span class=""o"">-</span><span class=""mi"">2011</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">34</span> <span class=""n"">GMT</span><span class=""p"">;</span> <span class=""n"">Path</span><span class=""o"">=/</span>
<span class=""mi"">2011</span><span class=""o"">-</span><span class=""mi"">04</span><span class=""o"">-</span><span class=""mi"">06</span> <span class=""mi"">14</span><span class=""p"">:</span><span class=""mi"">49</span><span class=""p"">:</span><span class=""mi"">50</span><span class=""o"">-</span><span class=""mi"">0300</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">diningcity</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">netherlands</span><span class=""o"">/</span><span class=""n"">index</span><span class=""o"">.</span><span class=""n"">html</span><span class=""o"">&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""o"">...</span><span class=""p"">]</span>
</pre></div>","for i, url in enumerate(urls):
    yield scrapy.Request(url, meta={'cookiejar': i},
        callback=self.parse_page)
,def parse_page(self, response):
    # do some processing
    return scrapy.Request(""http://www.example.com/otherpage"",
        meta={'cookiejar': response.meta['cookiejar']},
        callback=self.parse_other_page)
,2011-04-06 14:35:10-0300 [scrapy.core.engine] INFO: Spider opened
2011-04-06 14:35:10-0300 [scrapy.downloadermiddlewares.cookies] DEBUG: Sending cookies to: <GET http://www.diningcity.com/netherlands/index.html>
        Cookie: clientlanguage_nl=en_EN
2011-04-06 14:35:14-0300 [scrapy.downloadermiddlewares.cookies] DEBUG: Received cookies from: <200 http://www.diningcity.com/netherlands/index.html>
        Set-Cookie: JSESSIONID=B~FA4DC0C496C8762AE4F1A620EAB34F38; Path=/
        Set-Cookie: ip_isocode=US
        Set-Cookie: clientlanguage_nl=en_EN; Expires=Thu, 07-Apr-2011 21:21:34 GMT; Path=/
2011-04-06 14:49:50-0300 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.diningcity.com/netherlands/index.html> (referer: None)
[...]
",3
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,Multiple cookie sessions per spider,#multiple-cookie-sessions-per-spider,"<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">i</span><span class=""p"">,</span> <span class=""n"">url</span> <span class=""ow"">in</span> <span class=""nb"">enumerate</span><span class=""p"">(</span><span class=""n"">urls</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">meta</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'cookiejar'</span><span class=""p"">:</span> <span class=""n"">i</span><span class=""p"">},</span>
        <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_page</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse_page</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""c1""># do some processing</span>
    <span class=""k"">return</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""s2"">""http://www.example.com/otherpage""</span><span class=""p"">,</span>
        <span class=""n"">meta</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s1"">'cookiejar'</span><span class=""p"">:</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">meta</span><span class=""p"">[</span><span class=""s1"">'cookiejar'</span><span class=""p"">]},</span>
        <span class=""n"">callback</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse_other_page</span><span class=""p"">)</span>
</pre></div>","for i, url in enumerate(urls):
    yield scrapy.Request(url, meta={'cookiejar': i},
        callback=self.parse_page)
,def parse_page(self, response):
    # do some processing
    return scrapy.Request(""http://www.example.com/otherpage"",
        meta={'cookiejar': response.meta['cookiejar']},
        callback=self.parse_other_page)
",2
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,COOKIES_ENABLED,#cookies-enabled,,,7
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,COOKIES_DEBUG,#cookies-debug,"<div class=""highlight""><pre><span></span><span class=""mi"">2011</span><span class=""o"">-</span><span class=""mi"">04</span><span class=""o"">-</span><span class=""mi"">06</span> <span class=""mi"">14</span><span class=""p"">:</span><span class=""mi"">35</span><span class=""p"">:</span><span class=""mi"">10</span><span class=""o"">-</span><span class=""mi"">0300</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">INFO</span><span class=""p"">:</span> <span class=""n"">Spider</span> <span class=""n"">opened</span>
<span class=""mi"">2011</span><span class=""o"">-</span><span class=""mi"">04</span><span class=""o"">-</span><span class=""mi"">06</span> <span class=""mi"">14</span><span class=""p"">:</span><span class=""mi"">35</span><span class=""p"">:</span><span class=""mi"">10</span><span class=""o"">-</span><span class=""mi"">0300</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">downloadermiddlewares</span><span class=""o"">.</span><span class=""n"">cookies</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Sending</span> <span class=""n"">cookies</span> <span class=""n"">to</span><span class=""p"">:</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">diningcity</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">netherlands</span><span class=""o"">/</span><span class=""n"">index</span><span class=""o"">.</span><span class=""n"">html</span><span class=""o"">&gt;</span>
        <span class=""n"">Cookie</span><span class=""p"">:</span> <span class=""n"">clientlanguage_nl</span><span class=""o"">=</span><span class=""n"">en_EN</span>
<span class=""mi"">2011</span><span class=""o"">-</span><span class=""mi"">04</span><span class=""o"">-</span><span class=""mi"">06</span> <span class=""mi"">14</span><span class=""p"">:</span><span class=""mi"">35</span><span class=""p"">:</span><span class=""mi"">14</span><span class=""o"">-</span><span class=""mi"">0300</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">downloadermiddlewares</span><span class=""o"">.</span><span class=""n"">cookies</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Received</span> <span class=""n"">cookies</span> <span class=""n"">from</span><span class=""p"">:</span> <span class=""o"">&lt;</span><span class=""mi"">200</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">diningcity</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">netherlands</span><span class=""o"">/</span><span class=""n"">index</span><span class=""o"">.</span><span class=""n"">html</span><span class=""o"">&gt;</span>
        <span class=""n"">Set</span><span class=""o"">-</span><span class=""n"">Cookie</span><span class=""p"">:</span> <span class=""n"">JSESSIONID</span><span class=""o"">=</span><span class=""n"">B</span><span class=""o"">~</span><span class=""n"">FA4DC0C496C8762AE4F1A620EAB34F38</span><span class=""p"">;</span> <span class=""n"">Path</span><span class=""o"">=/</span>
        <span class=""n"">Set</span><span class=""o"">-</span><span class=""n"">Cookie</span><span class=""p"">:</span> <span class=""n"">ip_isocode</span><span class=""o"">=</span><span class=""n"">US</span>
        <span class=""n"">Set</span><span class=""o"">-</span><span class=""n"">Cookie</span><span class=""p"">:</span> <span class=""n"">clientlanguage_nl</span><span class=""o"">=</span><span class=""n"">en_EN</span><span class=""p"">;</span> <span class=""n"">Expires</span><span class=""o"">=</span><span class=""n"">Thu</span><span class=""p"">,</span> <span class=""mi"">07</span><span class=""o"">-</span><span class=""n"">Apr</span><span class=""o"">-</span><span class=""mi"">2011</span> <span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">21</span><span class=""p"">:</span><span class=""mi"">34</span> <span class=""n"">GMT</span><span class=""p"">;</span> <span class=""n"">Path</span><span class=""o"">=/</span>
<span class=""mi"">2011</span><span class=""o"">-</span><span class=""mi"">04</span><span class=""o"">-</span><span class=""mi"">06</span> <span class=""mi"">14</span><span class=""p"">:</span><span class=""mi"">49</span><span class=""p"">:</span><span class=""mi"">50</span><span class=""o"">-</span><span class=""mi"">0300</span> <span class=""p"">[</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">core</span><span class=""o"">.</span><span class=""n"">engine</span><span class=""p"">]</span> <span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Crawled</span> <span class=""p"">(</span><span class=""mi"">200</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">diningcity</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">netherlands</span><span class=""o"">/</span><span class=""n"">index</span><span class=""o"">.</span><span class=""n"">html</span><span class=""o"">&gt;</span> <span class=""p"">(</span><span class=""n"">referer</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""p"">[</span><span class=""o"">...</span><span class=""p"">]</span>
</pre></div>","2011-04-06 14:35:10-0300 [scrapy.core.engine] INFO: Spider opened
2011-04-06 14:35:10-0300 [scrapy.downloadermiddlewares.cookies] DEBUG: Sending cookies to: <GET http://www.diningcity.com/netherlands/index.html>
        Cookie: clientlanguage_nl=en_EN
2011-04-06 14:35:14-0300 [scrapy.downloadermiddlewares.cookies] DEBUG: Received cookies from: <200 http://www.diningcity.com/netherlands/index.html>
        Set-Cookie: JSESSIONID=B~FA4DC0C496C8762AE4F1A620EAB34F38; Path=/
        Set-Cookie: ip_isocode=US
        Set-Cookie: clientlanguage_nl=en_EN; Expires=Thu, 07-Apr-2011 21:21:34 GMT; Path=/
2011-04-06 14:49:50-0300 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.diningcity.com/netherlands/index.html> (referer: None)
[...]
",1
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,###,3,DefaultHeadersMiddleware,#module-scrapy.downloadermiddlewares.defaultheaders,,,9
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,###,3,DownloadTimeoutMiddleware,#module-scrapy.downloadermiddlewares.downloadtimeout,,,10
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,###,3,HttpAuthMiddleware,#module-scrapy.downloadermiddlewares.httpauth,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.spiders</span> <span class=""kn"">import</span> <span class=""n"">CrawlSpider</span>

<span class=""k"">class</span> <span class=""nc"">SomeIntranetSiteSpider</span><span class=""p"">(</span><span class=""n"">CrawlSpider</span><span class=""p"">):</span>

    <span class=""n"">http_user</span> <span class=""o"">=</span> <span class=""s1"">'someuser'</span>
    <span class=""n"">http_pass</span> <span class=""o"">=</span> <span class=""s1"">'somepass'</span>
    <span class=""n"">http_auth_domain</span> <span class=""o"">=</span> <span class=""s1"">'intranet.example.com'</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'intranet.example.com'</span>

    <span class=""c1""># .. rest of the spider code omitted ...</span>
</pre></div>","from scrapy.spiders import CrawlSpider

class SomeIntranetSiteSpider(CrawlSpider):

    http_user = 'someuser'
    http_pass = 'somepass'
    http_auth_domain = 'intranet.example.com'
    name = 'intranet.example.com'

    # .. rest of the spider code omitted ...
",1
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,###,3,HttpCacheMiddleware,#module-scrapy.downloadermiddlewares.httpcache,"<div class=""highlight""><pre><span></span><span class=""o"">/</span><span class=""n"">path</span><span class=""o"">/</span><span class=""n"">to</span><span class=""o"">/</span><span class=""n"">cache</span><span class=""o"">/</span><span class=""nb"">dir</span><span class=""o"">/</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""mi"">72</span><span class=""o"">/</span><span class=""mi"">72811</span><span class=""n"">f648e718090f041317756c03adb0ada46c7</span>
</pre></div>","/path/to/cache/dir/example.com/72/72811f648e718090f041317756c03adb0ada46c7
",1
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,Dummy policy (default),#dummy-policy-default,,,13
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,RFC2616 policy,#rfc2616-policy,,,14
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,Filesystem storage backend (default),#filesystem-storage-backend-default,"<div class=""highlight""><pre><span></span><span class=""o"">/</span><span class=""n"">path</span><span class=""o"">/</span><span class=""n"">to</span><span class=""o"">/</span><span class=""n"">cache</span><span class=""o"">/</span><span class=""nb"">dir</span><span class=""o"">/</span><span class=""n"">example</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""mi"">72</span><span class=""o"">/</span><span class=""mi"">72811</span><span class=""n"">f648e718090f041317756c03adb0ada46c7</span>
</pre></div>","/path/to/cache/dir/example.com/72/72811f648e718090f041317756c03adb0ada46c7
",1
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,DBM storage backend,#dbm-storage-backend,,,16
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,Writing your own storage backend,#writing-your-own-storage-backend,,,17
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,HTTPCache middleware settings,#httpcache-middleware-settings,,,18
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,HTTPCACHE_ENABLED,#httpcache-enabled,,,19
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,HTTPCACHE_EXPIRATION_SECS,#httpcache-expiration-secs,,,20
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,HTTPCACHE_DIR,#httpcache-dir,,,21
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,HTTPCACHE_IGNORE_HTTP_CODES,#httpcache-ignore-http-codes,,,22
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,HTTPCACHE_IGNORE_MISSING,#httpcache-ignore-missing,,,23
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,HTTPCACHE_IGNORE_SCHEMES,#httpcache-ignore-schemes,,,24
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,HTTPCACHE_STORAGE,#httpcache-storage,,,25
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,HTTPCACHE_DBM_MODULE,#httpcache-dbm-module,,,26
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,HTTPCACHE_POLICY,#httpcache-policy,,,27
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,HTTPCACHE_GZIP,#httpcache-gzip,,,28
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,HTTPCACHE_ALWAYS_STORE,#httpcache-always-store,,,29
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,HTTPCACHE_IGNORE_RESPONSE_CACHE_CONTROLS,#httpcache-ignore-response-cache-controls,,,30
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,###,3,HttpCompressionMiddleware,#module-scrapy.downloadermiddlewares.httpcompression,,,31
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,HttpCompressionMiddleware Settings,#httpcompressionmiddleware-settings,,,32
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,COMPRESSION_ENABLED,#compression-enabled,,,33
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,###,3,HttpProxyMiddleware,#module-scrapy.downloadermiddlewares.httpproxy,,,34
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,###,3,RedirectMiddleware,#module-scrapy.downloadermiddlewares.redirect,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">CrawlSpider</span><span class=""p"">):</span>
    <span class=""n"">handle_httpstatus_list</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""mi"">301</span><span class=""p"">,</span> <span class=""mi"">302</span><span class=""p"">]</span>
</pre></div>","class MySpider(CrawlSpider):
    handle_httpstatus_list = [301, 302]
",1
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,RedirectMiddleware settings,#redirectmiddleware-settings,,,36
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,REDIRECT_ENABLED,#redirect-enabled,,,37
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,REDIRECT_MAX_TIMES,#redirect-max-times,,,38
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,###,3,MetaRefreshMiddleware,#metarefreshmiddleware,,,39
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,MetaRefreshMiddleware settings,#metarefreshmiddleware-settings,,,40
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,METAREFRESH_ENABLED,#metarefresh-enabled,,,41
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,METAREFRESH_IGNORE_TAGS,#metarefresh-ignore-tags,,,42
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,METAREFRESH_MAXDELAY,#metarefresh-maxdelay,,,43
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,###,3,RetryMiddleware,#module-scrapy.downloadermiddlewares.retry,"<div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
    <span class=""k"">if</span> <span class=""ow"">not</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">text</span><span class=""p"">:</span>
        <span class=""n"">new_request_or_none</span> <span class=""o"">=</span> <span class=""n"">get_retry_request</span><span class=""p"">(</span>
            <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">request</span><span class=""p"">,</span>
            <span class=""n"">spider</span><span class=""o"">=</span><span class=""bp"">self</span><span class=""p"">,</span>
            <span class=""n"">reason</span><span class=""o"">=</span><span class=""s1"">'empty'</span><span class=""p"">,</span>
        <span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""n"">new_request_or_none</span>
</pre></div>","def parse(self, response):
    if not response.text:
        new_request_or_none = get_retry_request(
            response.request,
            spider=self,
            reason='empty',
        )
        return new_request_or_none
",1
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,RetryMiddleware Settings,#retrymiddleware-settings,,,45
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,RETRY_ENABLED,#retry-enabled,,,46
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,RETRY_TIMES,#retry-times,,,47
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,RETRY_HTTP_CODES,#retry-http-codes,,,48
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,RETRY_PRIORITY_ADJUST,#retry-priority-adjust,,,49
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,###,3,RobotsTxtMiddleware,#module-scrapy.downloadermiddlewares.robotstxt,,,50
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,Protego parser,#protego-parser,,,51
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,RobotFileParser,#robotfileparser,,,52
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,Reppy parser,#reppy-parser,,,53
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,Robotexclusionrulesparser,#robotexclusionrulesparser,,,54
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,Implementing support for a new parser,#implementing-support-for-a-new-parser,,,55
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,###,3,DownloaderStats,#module-scrapy.downloadermiddlewares.stats,,,56
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,###,3,UserAgentMiddleware,#module-scrapy.downloadermiddlewares.useragent,,,57
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,###,3,AjaxCrawlMiddleware,#module-scrapy.downloadermiddlewares.ajaxcrawl,,,58
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,AjaxCrawlMiddleware Settings,#ajaxcrawlmiddleware-settings,,,59
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,AJAXCRAWL_ENABLED,#ajaxcrawl-enabled,,,60
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,####,4,HttpProxyMiddleware settings,#httpproxymiddleware-settings,,,61
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,HTTPPROXY_ENABLED,#httpproxy-enabled,,,62
https://docs.scrapy.org/en/latest/topics/downloader-middleware.html,,#####,5,HTTPPROXY_AUTH_ENCODING,#httpproxy-auth-encoding,,,63
https://docs.scrapy.org/en/latest/topics/spider-middleware.html,,#,1,Spider Middleware,#spider-middleware,"<div class=""highlight""><pre><span></span><span class=""n"">SPIDER_MIDDLEWARES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'myproject.middlewares.CustomSpiderMiddleware'</span><span class=""p"">:</span> <span class=""mi"">543</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">SPIDER_MIDDLEWARES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'myproject.middlewares.CustomSpiderMiddleware'</span><span class=""p"">:</span> <span class=""mi"">543</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">CrawlSpider</span><span class=""p"">):</span>
    <span class=""n"">handle_httpstatus_list</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""mi"">404</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Filtered</span> <span class=""n"">offsite</span> <span class=""n"">request</span> <span class=""n"">to</span> <span class=""s1"">'www.othersite.com'</span><span class=""p"">:</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">othersite</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">some</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">.</span><span class=""n"">html</span><span class=""o"">&gt;</span>
</pre></div>","SPIDER_MIDDLEWARES = {
    'myproject.middlewares.CustomSpiderMiddleware': 543,
}
,SPIDER_MIDDLEWARES = {
    'myproject.middlewares.CustomSpiderMiddleware': 543,
    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': None,
}
,class MySpider(CrawlSpider):
    handle_httpstatus_list = [404]
,DEBUG: Filtered offsite request to 'www.othersite.com': <GET http://www.othersite.com/some/page.html>
",4
https://docs.scrapy.org/en/latest/topics/spider-middleware.html,,##,2,Activating a spider middleware,#activating-a-spider-middleware,"<div class=""highlight""><pre><span></span><span class=""n"">SPIDER_MIDDLEWARES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'myproject.middlewares.CustomSpiderMiddleware'</span><span class=""p"">:</span> <span class=""mi"">543</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">SPIDER_MIDDLEWARES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'myproject.middlewares.CustomSpiderMiddleware'</span><span class=""p"">:</span> <span class=""mi"">543</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","SPIDER_MIDDLEWARES = {
    'myproject.middlewares.CustomSpiderMiddleware': 543,
}
,SPIDER_MIDDLEWARES = {
    'myproject.middlewares.CustomSpiderMiddleware': 543,
    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': None,
}
",2
https://docs.scrapy.org/en/latest/topics/spider-middleware.html,,##,2,Writing your own spider middleware,#writing-your-own-spider-middleware,,,3
https://docs.scrapy.org/en/latest/topics/spider-middleware.html,,##,2,Built-in spider middleware reference,#built-in-spider-middleware-reference,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">CrawlSpider</span><span class=""p"">):</span>
    <span class=""n"">handle_httpstatus_list</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""mi"">404</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Filtered</span> <span class=""n"">offsite</span> <span class=""n"">request</span> <span class=""n"">to</span> <span class=""s1"">'www.othersite.com'</span><span class=""p"">:</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">othersite</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">some</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">.</span><span class=""n"">html</span><span class=""o"">&gt;</span>
</pre></div>","class MySpider(CrawlSpider):
    handle_httpstatus_list = [404]
,DEBUG: Filtered offsite request to 'www.othersite.com': <GET http://www.othersite.com/some/page.html>
",2
https://docs.scrapy.org/en/latest/topics/spider-middleware.html,,###,3,DepthMiddleware,#module-scrapy.spidermiddlewares.depth,,,5
https://docs.scrapy.org/en/latest/topics/spider-middleware.html,,###,3,HttpErrorMiddleware,#module-scrapy.spidermiddlewares.httperror,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">CrawlSpider</span><span class=""p"">):</span>
    <span class=""n"">handle_httpstatus_list</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""mi"">404</span><span class=""p"">]</span>
</pre></div>","class MySpider(CrawlSpider):
    handle_httpstatus_list = [404]
",1
https://docs.scrapy.org/en/latest/topics/spider-middleware.html,,####,4,HttpErrorMiddleware settings,#httperrormiddleware-settings,,,7
https://docs.scrapy.org/en/latest/topics/spider-middleware.html,,#####,5,HTTPERROR_ALLOWED_CODES,#httperror-allowed-codes,,,8
https://docs.scrapy.org/en/latest/topics/spider-middleware.html,,#####,5,HTTPERROR_ALLOW_ALL,#httperror-allow-all,,,9
https://docs.scrapy.org/en/latest/topics/spider-middleware.html,,###,3,OffsiteMiddleware,#module-scrapy.spidermiddlewares.offsite,"<div class=""highlight""><pre><span></span><span class=""n"">DEBUG</span><span class=""p"">:</span> <span class=""n"">Filtered</span> <span class=""n"">offsite</span> <span class=""n"">request</span> <span class=""n"">to</span> <span class=""s1"">'www.othersite.com'</span><span class=""p"">:</span> <span class=""o"">&lt;</span><span class=""n"">GET</span> <span class=""n"">http</span><span class=""p"">:</span><span class=""o"">//</span><span class=""n"">www</span><span class=""o"">.</span><span class=""n"">othersite</span><span class=""o"">.</span><span class=""n"">com</span><span class=""o"">/</span><span class=""n"">some</span><span class=""o"">/</span><span class=""n"">page</span><span class=""o"">.</span><span class=""n"">html</span><span class=""o"">&gt;</span>
</pre></div>","DEBUG: Filtered offsite request to 'www.othersite.com': <GET http://www.othersite.com/some/page.html>
",1
https://docs.scrapy.org/en/latest/topics/spider-middleware.html,,###,3,RefererMiddleware,#module-scrapy.spidermiddlewares.referer,,,11
https://docs.scrapy.org/en/latest/topics/spider-middleware.html,,####,4,RefererMiddleware settings,#referermiddleware-settings,,,12
https://docs.scrapy.org/en/latest/topics/spider-middleware.html,,#####,5,REFERER_ENABLED,#referer-enabled,,,13
https://docs.scrapy.org/en/latest/topics/spider-middleware.html,,#####,5,REFERRER_POLICY,#referrer-policy,,,14
https://docs.scrapy.org/en/latest/topics/spider-middleware.html,,######,6,Acceptable values for REFERRER_POLICY,#acceptable-values-for-referrer-policy,,,15
https://docs.scrapy.org/en/latest/topics/spider-middleware.html,,###,3,UrlLengthMiddleware,#module-scrapy.spidermiddlewares.urllength,,,16
https://docs.scrapy.org/en/latest/topics/extensions.html,,#,1,Extensions,#extensions,"<div class=""highlight""><pre><span></span><span class=""n"">EXTENSIONS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'scrapy.extensions.corestats.CoreStats'</span><span class=""p"">:</span> <span class=""mi"">500</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.telnet.TelnetConsole'</span><span class=""p"">:</span> <span class=""mi"">500</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">EXTENSIONS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'scrapy.extensions.corestats.CoreStats'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">signals</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exceptions</span> <span class=""kn"">import</span> <span class=""n"">NotConfigured</span>

<span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">(</span><span class=""vm"">__name__</span><span class=""p"">)</span>

<span class=""k"">class</span> <span class=""nc"">SpiderOpenCloseLogging</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item_count</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">item_count</span> <span class=""o"">=</span> <span class=""n"">item_count</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">items_scraped</span> <span class=""o"">=</span> <span class=""mi"">0</span>

    <span class=""nd"">@classmethod</span>
    <span class=""k"">def</span> <span class=""nf"">from_crawler</span><span class=""p"">(</span><span class=""bp"">cls</span><span class=""p"">,</span> <span class=""n"">crawler</span><span class=""p"">):</span>
        <span class=""c1""># first check if the extension should be enabled and raise</span>
        <span class=""c1""># NotConfigured otherwise</span>
        <span class=""k"">if</span> <span class=""ow"">not</span> <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">getbool</span><span class=""p"">(</span><span class=""s1"">'MYEXT_ENABLED'</span><span class=""p"">):</span>
            <span class=""k"">raise</span> <span class=""n"">NotConfigured</span>

        <span class=""c1""># get the number of items from settings</span>
        <span class=""n"">item_count</span> <span class=""o"">=</span> <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">getint</span><span class=""p"">(</span><span class=""s1"">'MYEXT_ITEMCOUNT'</span><span class=""p"">,</span> <span class=""mi"">1000</span><span class=""p"">)</span>

        <span class=""c1""># instantiate the extension object</span>
        <span class=""n"">ext</span> <span class=""o"">=</span> <span class=""bp"">cls</span><span class=""p"">(</span><span class=""n"">item_count</span><span class=""p"">)</span>

        <span class=""c1""># connect the extension object to signals</span>
        <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""n"">ext</span><span class=""o"">.</span><span class=""n"">spider_opened</span><span class=""p"">,</span> <span class=""n"">signal</span><span class=""o"">=</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">spider_opened</span><span class=""p"">)</span>
        <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""n"">ext</span><span class=""o"">.</span><span class=""n"">spider_closed</span><span class=""p"">,</span> <span class=""n"">signal</span><span class=""o"">=</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">spider_closed</span><span class=""p"">)</span>
        <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""n"">ext</span><span class=""o"">.</span><span class=""n"">item_scraped</span><span class=""p"">,</span> <span class=""n"">signal</span><span class=""o"">=</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">item_scraped</span><span class=""p"">)</span>

        <span class=""c1""># return the extension object</span>
        <span class=""k"">return</span> <span class=""n"">ext</span>

    <span class=""k"">def</span> <span class=""nf"">spider_opened</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s2"">""opened spider </span><span class=""si"">%s</span><span class=""s2"">""</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">name</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">spider_closed</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s2"">""closed spider </span><span class=""si"">%s</span><span class=""s2"">""</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">name</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">item_scraped</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">items_scraped</span> <span class=""o"">+=</span> <span class=""mi"">1</span>
        <span class=""k"">if</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">items_scraped</span> <span class=""o"">%</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">item_count</span> <span class=""o"">==</span> <span class=""mi"">0</span><span class=""p"">:</span>
            <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s2"">""scraped </span><span class=""si"">%d</span><span class=""s2""> items""</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">items_scraped</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">kill</span> <span class=""o"">-</span><span class=""n"">QUIT</span> <span class=""o"">&lt;</span><span class=""n"">pid</span><span class=""o"">&gt;</span>
</pre></div>","EXTENSIONS = {
    'scrapy.extensions.corestats.CoreStats': 500,
    'scrapy.extensions.telnet.TelnetConsole': 500,
}
,EXTENSIONS = {
    'scrapy.extensions.corestats.CoreStats': None,
}
,import logging
from scrapy import signals
from scrapy.exceptions import NotConfigured

logger = logging.getLogger(__name__)

class SpiderOpenCloseLogging:

    def __init__(self, item_count):
        self.item_count = item_count
        self.items_scraped = 0

    @classmethod
    def from_crawler(cls, crawler):
        # first check if the extension should be enabled and raise
        # NotConfigured otherwise
        if not crawler.settings.getbool('MYEXT_ENABLED'):
            raise NotConfigured

        # get the number of items from settings
        item_count = crawler.settings.getint('MYEXT_ITEMCOUNT', 1000)

        # instantiate the extension object
        ext = cls(item_count)

        # connect the extension object to signals
        crawler.signals.connect(ext.spider_opened, signal=signals.spider_opened)
        crawler.signals.connect(ext.spider_closed, signal=signals.spider_closed)
        crawler.signals.connect(ext.item_scraped, signal=signals.item_scraped)

        # return the extension object
        return ext

    def spider_opened(self, spider):
        logger.info(""opened spider %s"", spider.name)

    def spider_closed(self, spider):
        logger.info(""closed spider %s"", spider.name)

    def item_scraped(self, item, spider):
        self.items_scraped += 1
        if self.items_scraped % self.item_count == 0:
            logger.info(""scraped %d items"", self.items_scraped)
,kill -QUIT <pid>
",4
https://docs.scrapy.org/en/latest/topics/extensions.html,,##,2,Extension settings,#extension-settings,,,2
https://docs.scrapy.org/en/latest/topics/extensions.html,,##,2,Loading & activating extensions,#loading-activating-extensions,"<div class=""highlight""><pre><span></span><span class=""n"">EXTENSIONS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'scrapy.extensions.corestats.CoreStats'</span><span class=""p"">:</span> <span class=""mi"">500</span><span class=""p"">,</span>
    <span class=""s1"">'scrapy.extensions.telnet.TelnetConsole'</span><span class=""p"">:</span> <span class=""mi"">500</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","EXTENSIONS = {
    'scrapy.extensions.corestats.CoreStats': 500,
    'scrapy.extensions.telnet.TelnetConsole': 500,
}
",1
https://docs.scrapy.org/en/latest/topics/extensions.html,,##,2,"Available, enabled and disabled extensions",#available-enabled-and-disabled-extensions,,,4
https://docs.scrapy.org/en/latest/topics/extensions.html,,##,2,Disabling an extension,#disabling-an-extension,"<div class=""highlight""><pre><span></span><span class=""n"">EXTENSIONS</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'scrapy.extensions.corestats.CoreStats'</span><span class=""p"">:</span> <span class=""kc"">None</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","EXTENSIONS = {
    'scrapy.extensions.corestats.CoreStats': None,
}
",1
https://docs.scrapy.org/en/latest/topics/extensions.html,,##,2,Writing your own extension,#writing-your-own-extension,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">signals</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exceptions</span> <span class=""kn"">import</span> <span class=""n"">NotConfigured</span>

<span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">(</span><span class=""vm"">__name__</span><span class=""p"">)</span>

<span class=""k"">class</span> <span class=""nc"">SpiderOpenCloseLogging</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item_count</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">item_count</span> <span class=""o"">=</span> <span class=""n"">item_count</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">items_scraped</span> <span class=""o"">=</span> <span class=""mi"">0</span>

    <span class=""nd"">@classmethod</span>
    <span class=""k"">def</span> <span class=""nf"">from_crawler</span><span class=""p"">(</span><span class=""bp"">cls</span><span class=""p"">,</span> <span class=""n"">crawler</span><span class=""p"">):</span>
        <span class=""c1""># first check if the extension should be enabled and raise</span>
        <span class=""c1""># NotConfigured otherwise</span>
        <span class=""k"">if</span> <span class=""ow"">not</span> <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">getbool</span><span class=""p"">(</span><span class=""s1"">'MYEXT_ENABLED'</span><span class=""p"">):</span>
            <span class=""k"">raise</span> <span class=""n"">NotConfigured</span>

        <span class=""c1""># get the number of items from settings</span>
        <span class=""n"">item_count</span> <span class=""o"">=</span> <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">getint</span><span class=""p"">(</span><span class=""s1"">'MYEXT_ITEMCOUNT'</span><span class=""p"">,</span> <span class=""mi"">1000</span><span class=""p"">)</span>

        <span class=""c1""># instantiate the extension object</span>
        <span class=""n"">ext</span> <span class=""o"">=</span> <span class=""bp"">cls</span><span class=""p"">(</span><span class=""n"">item_count</span><span class=""p"">)</span>

        <span class=""c1""># connect the extension object to signals</span>
        <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""n"">ext</span><span class=""o"">.</span><span class=""n"">spider_opened</span><span class=""p"">,</span> <span class=""n"">signal</span><span class=""o"">=</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">spider_opened</span><span class=""p"">)</span>
        <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""n"">ext</span><span class=""o"">.</span><span class=""n"">spider_closed</span><span class=""p"">,</span> <span class=""n"">signal</span><span class=""o"">=</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">spider_closed</span><span class=""p"">)</span>
        <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""n"">ext</span><span class=""o"">.</span><span class=""n"">item_scraped</span><span class=""p"">,</span> <span class=""n"">signal</span><span class=""o"">=</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">item_scraped</span><span class=""p"">)</span>

        <span class=""c1""># return the extension object</span>
        <span class=""k"">return</span> <span class=""n"">ext</span>

    <span class=""k"">def</span> <span class=""nf"">spider_opened</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s2"">""opened spider </span><span class=""si"">%s</span><span class=""s2"">""</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">name</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">spider_closed</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s2"">""closed spider </span><span class=""si"">%s</span><span class=""s2"">""</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">name</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">item_scraped</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">items_scraped</span> <span class=""o"">+=</span> <span class=""mi"">1</span>
        <span class=""k"">if</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">items_scraped</span> <span class=""o"">%</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">item_count</span> <span class=""o"">==</span> <span class=""mi"">0</span><span class=""p"">:</span>
            <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s2"">""scraped </span><span class=""si"">%d</span><span class=""s2""> items""</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">items_scraped</span><span class=""p"">)</span>
</pre></div>","import logging
from scrapy import signals
from scrapy.exceptions import NotConfigured

logger = logging.getLogger(__name__)

class SpiderOpenCloseLogging:

    def __init__(self, item_count):
        self.item_count = item_count
        self.items_scraped = 0

    @classmethod
    def from_crawler(cls, crawler):
        # first check if the extension should be enabled and raise
        # NotConfigured otherwise
        if not crawler.settings.getbool('MYEXT_ENABLED'):
            raise NotConfigured

        # get the number of items from settings
        item_count = crawler.settings.getint('MYEXT_ITEMCOUNT', 1000)

        # instantiate the extension object
        ext = cls(item_count)

        # connect the extension object to signals
        crawler.signals.connect(ext.spider_opened, signal=signals.spider_opened)
        crawler.signals.connect(ext.spider_closed, signal=signals.spider_closed)
        crawler.signals.connect(ext.item_scraped, signal=signals.item_scraped)

        # return the extension object
        return ext

    def spider_opened(self, spider):
        logger.info(""opened spider %s"", spider.name)

    def spider_closed(self, spider):
        logger.info(""closed spider %s"", spider.name)

    def item_scraped(self, item, spider):
        self.items_scraped += 1
        if self.items_scraped % self.item_count == 0:
            logger.info(""scraped %d items"", self.items_scraped)
",1
https://docs.scrapy.org/en/latest/topics/extensions.html,,###,3,Sample extension,#sample-extension,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">signals</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exceptions</span> <span class=""kn"">import</span> <span class=""n"">NotConfigured</span>

<span class=""n"">logger</span> <span class=""o"">=</span> <span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">getLogger</span><span class=""p"">(</span><span class=""vm"">__name__</span><span class=""p"">)</span>

<span class=""k"">class</span> <span class=""nc"">SpiderOpenCloseLogging</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item_count</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">item_count</span> <span class=""o"">=</span> <span class=""n"">item_count</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">items_scraped</span> <span class=""o"">=</span> <span class=""mi"">0</span>

    <span class=""nd"">@classmethod</span>
    <span class=""k"">def</span> <span class=""nf"">from_crawler</span><span class=""p"">(</span><span class=""bp"">cls</span><span class=""p"">,</span> <span class=""n"">crawler</span><span class=""p"">):</span>
        <span class=""c1""># first check if the extension should be enabled and raise</span>
        <span class=""c1""># NotConfigured otherwise</span>
        <span class=""k"">if</span> <span class=""ow"">not</span> <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">getbool</span><span class=""p"">(</span><span class=""s1"">'MYEXT_ENABLED'</span><span class=""p"">):</span>
            <span class=""k"">raise</span> <span class=""n"">NotConfigured</span>

        <span class=""c1""># get the number of items from settings</span>
        <span class=""n"">item_count</span> <span class=""o"">=</span> <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">settings</span><span class=""o"">.</span><span class=""n"">getint</span><span class=""p"">(</span><span class=""s1"">'MYEXT_ITEMCOUNT'</span><span class=""p"">,</span> <span class=""mi"">1000</span><span class=""p"">)</span>

        <span class=""c1""># instantiate the extension object</span>
        <span class=""n"">ext</span> <span class=""o"">=</span> <span class=""bp"">cls</span><span class=""p"">(</span><span class=""n"">item_count</span><span class=""p"">)</span>

        <span class=""c1""># connect the extension object to signals</span>
        <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""n"">ext</span><span class=""o"">.</span><span class=""n"">spider_opened</span><span class=""p"">,</span> <span class=""n"">signal</span><span class=""o"">=</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">spider_opened</span><span class=""p"">)</span>
        <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""n"">ext</span><span class=""o"">.</span><span class=""n"">spider_closed</span><span class=""p"">,</span> <span class=""n"">signal</span><span class=""o"">=</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">spider_closed</span><span class=""p"">)</span>
        <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""n"">ext</span><span class=""o"">.</span><span class=""n"">item_scraped</span><span class=""p"">,</span> <span class=""n"">signal</span><span class=""o"">=</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">item_scraped</span><span class=""p"">)</span>

        <span class=""c1""># return the extension object</span>
        <span class=""k"">return</span> <span class=""n"">ext</span>

    <span class=""k"">def</span> <span class=""nf"">spider_opened</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s2"">""opened spider </span><span class=""si"">%s</span><span class=""s2"">""</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">name</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">spider_closed</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s2"">""closed spider </span><span class=""si"">%s</span><span class=""s2"">""</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">name</span><span class=""p"">)</span>

    <span class=""k"">def</span> <span class=""nf"">item_scraped</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">items_scraped</span> <span class=""o"">+=</span> <span class=""mi"">1</span>
        <span class=""k"">if</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">items_scraped</span> <span class=""o"">%</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">item_count</span> <span class=""o"">==</span> <span class=""mi"">0</span><span class=""p"">:</span>
            <span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s2"">""scraped </span><span class=""si"">%d</span><span class=""s2""> items""</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">items_scraped</span><span class=""p"">)</span>
</pre></div>","import logging
from scrapy import signals
from scrapy.exceptions import NotConfigured

logger = logging.getLogger(__name__)

class SpiderOpenCloseLogging:

    def __init__(self, item_count):
        self.item_count = item_count
        self.items_scraped = 0

    @classmethod
    def from_crawler(cls, crawler):
        # first check if the extension should be enabled and raise
        # NotConfigured otherwise
        if not crawler.settings.getbool('MYEXT_ENABLED'):
            raise NotConfigured

        # get the number of items from settings
        item_count = crawler.settings.getint('MYEXT_ITEMCOUNT', 1000)

        # instantiate the extension object
        ext = cls(item_count)

        # connect the extension object to signals
        crawler.signals.connect(ext.spider_opened, signal=signals.spider_opened)
        crawler.signals.connect(ext.spider_closed, signal=signals.spider_closed)
        crawler.signals.connect(ext.item_scraped, signal=signals.item_scraped)

        # return the extension object
        return ext

    def spider_opened(self, spider):
        logger.info(""opened spider %s"", spider.name)

    def spider_closed(self, spider):
        logger.info(""closed spider %s"", spider.name)

    def item_scraped(self, item, spider):
        self.items_scraped += 1
        if self.items_scraped % self.item_count == 0:
            logger.info(""scraped %d items"", self.items_scraped)
",1
https://docs.scrapy.org/en/latest/topics/extensions.html,,##,2,Built-in extensions reference,#built-in-extensions-reference,"<div class=""highlight""><pre><span></span><span class=""n"">kill</span> <span class=""o"">-</span><span class=""n"">QUIT</span> <span class=""o"">&lt;</span><span class=""n"">pid</span><span class=""o"">&gt;</span>
</pre></div>","kill -QUIT <pid>
",1
https://docs.scrapy.org/en/latest/topics/extensions.html,,###,3,General purpose extensions,#general-purpose-extensions,,,9
https://docs.scrapy.org/en/latest/topics/extensions.html,,####,4,Log Stats extension,#module-scrapy.extensions.logstats,,,10
https://docs.scrapy.org/en/latest/topics/extensions.html,,####,4,Core Stats extension,#module-scrapy.extensions.corestats,,,11
https://docs.scrapy.org/en/latest/topics/extensions.html,,####,4,Telnet console extension,#module-scrapy.extensions.telnet,,,12
https://docs.scrapy.org/en/latest/topics/extensions.html,,####,4,Memory usage extension,#module-scrapy.extensions.memusage,,,13
https://docs.scrapy.org/en/latest/topics/extensions.html,,####,4,Memory debugger extension,#module-scrapy.extensions.memdebug,,,14
https://docs.scrapy.org/en/latest/topics/extensions.html,,####,4,Close spider extension,#module-scrapy.extensions.closespider,,,15
https://docs.scrapy.org/en/latest/topics/extensions.html,,#####,5,CLOSESPIDER_TIMEOUT,#closespider-timeout,,,16
https://docs.scrapy.org/en/latest/topics/extensions.html,,#####,5,CLOSESPIDER_ITEMCOUNT,#closespider-itemcount,,,17
https://docs.scrapy.org/en/latest/topics/extensions.html,,#####,5,CLOSESPIDER_PAGECOUNT,#closespider-pagecount,,,18
https://docs.scrapy.org/en/latest/topics/extensions.html,,#####,5,CLOSESPIDER_ERRORCOUNT,#closespider-errorcount,,,19
https://docs.scrapy.org/en/latest/topics/extensions.html,,####,4,StatsMailer extension,#module-scrapy.extensions.statsmailer,,,20
https://docs.scrapy.org/en/latest/topics/extensions.html,,###,3,Debugging extensions,#debugging-extensions,"<div class=""highlight""><pre><span></span><span class=""n"">kill</span> <span class=""o"">-</span><span class=""n"">QUIT</span> <span class=""o"">&lt;</span><span class=""n"">pid</span><span class=""o"">&gt;</span>
</pre></div>","kill -QUIT <pid>
",1
https://docs.scrapy.org/en/latest/topics/extensions.html,,####,4,Stack trace dump extension,#stack-trace-dump-extension,"<div class=""highlight""><pre><span></span><span class=""n"">kill</span> <span class=""o"">-</span><span class=""n"">QUIT</span> <span class=""o"">&lt;</span><span class=""n"">pid</span><span class=""o"">&gt;</span>
</pre></div>","kill -QUIT <pid>
",1
https://docs.scrapy.org/en/latest/topics/extensions.html,,####,4,Debugger extension,#debugger-extension,,,23
https://docs.scrapy.org/en/latest/topics/signals.html,,#,1,Signals,#signals,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">signals</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">Spider</span>


<span class=""k"">class</span> <span class=""nc"">DmozSpider</span><span class=""p"">(</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s2"">""dmoz""</span>
    <span class=""n"">allowed_domains</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s2"">""dmoz.org""</span><span class=""p"">]</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span>
        <span class=""s2"">""http://www.dmoz.org/Computers/Programming/Languages/Python/Books/""</span><span class=""p"">,</span>
        <span class=""s2"">""http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/""</span><span class=""p"">,</span>
    <span class=""p"">]</span>


    <span class=""nd"">@classmethod</span>
    <span class=""k"">def</span> <span class=""nf"">from_crawler</span><span class=""p"">(</span><span class=""bp"">cls</span><span class=""p"">,</span> <span class=""n"">crawler</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""n"">spider</span> <span class=""o"">=</span> <span class=""nb"">super</span><span class=""p"">(</span><span class=""n"">DmozSpider</span><span class=""p"">,</span> <span class=""bp"">cls</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">from_crawler</span><span class=""p"">(</span><span class=""n"">crawler</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">)</span>
        <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">spider_closed</span><span class=""p"">,</span> <span class=""n"">signal</span><span class=""o"">=</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">spider_closed</span><span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""n"">spider</span>


    <span class=""k"">def</span> <span class=""nf"">spider_closed</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Spider closed: </span><span class=""si"">%s</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">name</span><span class=""p"">)</span>


    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">pass</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">SignalSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'signals'</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://quotes.toscrape.com/page/1/'</span><span class=""p"">]</span>

    <span class=""nd"">@classmethod</span>
    <span class=""k"">def</span> <span class=""nf"">from_crawler</span><span class=""p"">(</span><span class=""bp"">cls</span><span class=""p"">,</span> <span class=""n"">crawler</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""n"">spider</span> <span class=""o"">=</span> <span class=""nb"">super</span><span class=""p"">(</span><span class=""n"">SignalSpider</span><span class=""p"">,</span> <span class=""bp"">cls</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">from_crawler</span><span class=""p"">(</span><span class=""n"">crawler</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">)</span>
        <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">item_scraped</span><span class=""p"">,</span> <span class=""n"">signal</span><span class=""o"">=</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">item_scraped</span><span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""n"">spider</span>

    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">item_scraped</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">):</span>
        <span class=""c1""># Send the scraped item to the server</span>
        <span class=""n"">response</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">treq</span><span class=""o"">.</span><span class=""n"">post</span><span class=""p"">(</span>
            <span class=""s1"">'http://example.com/post'</span><span class=""p"">,</span>
            <span class=""n"">json</span><span class=""o"">.</span><span class=""n"">dumps</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">encode</span><span class=""p"">(</span><span class=""s1"">'ascii'</span><span class=""p"">),</span>
            <span class=""n"">headers</span><span class=""o"">=</span><span class=""p"">{</span><span class=""sa"">b</span><span class=""s1"">'Content-Type'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""sa"">b</span><span class=""s1"">'application/json'</span><span class=""p"">]}</span>
        <span class=""p"">)</span>

        <span class=""k"">return</span> <span class=""n"">response</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span>
                <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'small.author::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'tags'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.tags a.tag::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">(),</span>
            <span class=""p"">}</span>
</pre></div>","from scrapy import signals
from scrapy import Spider


class DmozSpider(Spider):
    name = ""dmoz""
    allowed_domains = [""dmoz.org""]
    start_urls = [
        ""http://www.dmoz.org/Computers/Programming/Languages/Python/Books/"",
        ""http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/"",
    ]


    @classmethod
    def from_crawler(cls, crawler, *args, **kwargs):
        spider = super(DmozSpider, cls).from_crawler(crawler, *args, **kwargs)
        crawler.signals.connect(spider.spider_closed, signal=signals.spider_closed)
        return spider


    def spider_closed(self, spider):
        spider.logger.info('Spider closed: %s', spider.name)


    def parse(self, response):
        pass
,class SignalSpider(scrapy.Spider):
    name = 'signals'
    start_urls = ['https://quotes.toscrape.com/page/1/']

    @classmethod
    def from_crawler(cls, crawler, *args, **kwargs):
        spider = super(SignalSpider, cls).from_crawler(crawler, *args, **kwargs)
        crawler.signals.connect(spider.item_scraped, signal=signals.item_scraped)
        return spider

    async def item_scraped(self, item):
        # Send the scraped item to the server
        response = await treq.post(
            'http://example.com/post',
            json.dumps(item).encode('ascii'),
            headers={b'Content-Type': [b'application/json']}
        )

        return response

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('small.author::text').get(),
                'tags': quote.css('div.tags a.tag::text').getall(),
            }
",2
https://docs.scrapy.org/en/latest/topics/signals.html,,##,2,Deferred signal handlers,#deferred-signal-handlers,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">SignalSpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""s1"">'signals'</span>
    <span class=""n"">start_urls</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'https://quotes.toscrape.com/page/1/'</span><span class=""p"">]</span>

    <span class=""nd"">@classmethod</span>
    <span class=""k"">def</span> <span class=""nf"">from_crawler</span><span class=""p"">(</span><span class=""bp"">cls</span><span class=""p"">,</span> <span class=""n"">crawler</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">):</span>
        <span class=""n"">spider</span> <span class=""o"">=</span> <span class=""nb"">super</span><span class=""p"">(</span><span class=""n"">SignalSpider</span><span class=""p"">,</span> <span class=""bp"">cls</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">from_crawler</span><span class=""p"">(</span><span class=""n"">crawler</span><span class=""p"">,</span> <span class=""o"">*</span><span class=""n"">args</span><span class=""p"">,</span> <span class=""o"">**</span><span class=""n"">kwargs</span><span class=""p"">)</span>
        <span class=""n"">crawler</span><span class=""o"">.</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""n"">spider</span><span class=""o"">.</span><span class=""n"">item_scraped</span><span class=""p"">,</span> <span class=""n"">signal</span><span class=""o"">=</span><span class=""n"">signals</span><span class=""o"">.</span><span class=""n"">item_scraped</span><span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""n"">spider</span>

    <span class=""k"">async</span> <span class=""k"">def</span> <span class=""nf"">item_scraped</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">):</span>
        <span class=""c1""># Send the scraped item to the server</span>
        <span class=""n"">response</span> <span class=""o"">=</span> <span class=""k"">await</span> <span class=""n"">treq</span><span class=""o"">.</span><span class=""n"">post</span><span class=""p"">(</span>
            <span class=""s1"">'http://example.com/post'</span><span class=""p"">,</span>
            <span class=""n"">json</span><span class=""o"">.</span><span class=""n"">dumps</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">encode</span><span class=""p"">(</span><span class=""s1"">'ascii'</span><span class=""p"">),</span>
            <span class=""n"">headers</span><span class=""o"">=</span><span class=""p"">{</span><span class=""sa"">b</span><span class=""s1"">'Content-Type'</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""sa"">b</span><span class=""s1"">'application/json'</span><span class=""p"">]}</span>
        <span class=""p"">)</span>

        <span class=""k"">return</span> <span class=""n"">response</span>

    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">quote</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.quote'</span><span class=""p"">):</span>
            <span class=""k"">yield</span> <span class=""p"">{</span>
                <span class=""s1"">'text'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'span.text::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'author'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'small.author::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">get</span><span class=""p"">(),</span>
                <span class=""s1"">'tags'</span><span class=""p"">:</span> <span class=""n"">quote</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'div.tags a.tag::text'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">getall</span><span class=""p"">(),</span>
            <span class=""p"">}</span>
</pre></div>","class SignalSpider(scrapy.Spider):
    name = 'signals'
    start_urls = ['https://quotes.toscrape.com/page/1/']

    @classmethod
    def from_crawler(cls, crawler, *args, **kwargs):
        spider = super(SignalSpider, cls).from_crawler(crawler, *args, **kwargs)
        crawler.signals.connect(spider.item_scraped, signal=signals.item_scraped)
        return spider

    async def item_scraped(self, item):
        # Send the scraped item to the server
        response = await treq.post(
            'http://example.com/post',
            json.dumps(item).encode('ascii'),
            headers={b'Content-Type': [b'application/json']}
        )

        return response

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('small.author::text').get(),
                'tags': quote.css('div.tags a.tag::text').getall(),
            }
",1
https://docs.scrapy.org/en/latest/topics/signals.html,,##,2,Built-in signals reference,#module-scrapy.signals,,,3
https://docs.scrapy.org/en/latest/topics/signals.html,,###,3,Engine signals,#engine-signals,,,4
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,engine_started,#engine-started,,,5
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,engine_stopped,#engine-stopped,,,6
https://docs.scrapy.org/en/latest/topics/signals.html,,###,3,Item signals,#item-signals,,,7
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,item_scraped,#item-scraped,,,8
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,item_dropped,#item-dropped,,,9
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,item_error,#item-error,,,10
https://docs.scrapy.org/en/latest/topics/signals.html,,###,3,Spider signals,#spider-signals,,,11
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,spider_closed,#spider-closed,,,12
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,spider_opened,#spider-opened,,,13
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,spider_idle,#spider-idle,,,14
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,spider_error,#spider-error,,,15
https://docs.scrapy.org/en/latest/topics/signals.html,,###,3,Request signals,#request-signals,,,16
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,request_scheduled,#request-scheduled,,,17
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,request_dropped,#request-dropped,,,18
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,request_reached_downloader,#request-reached-downloader,,,19
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,request_left_downloader,#request-left-downloader,,,20
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,bytes_received,#bytes-received,,,21
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,headers_received,#headers-received,,,22
https://docs.scrapy.org/en/latest/topics/signals.html,,###,3,Response signals,#response-signals,,,23
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,response_received,#response-received,,,24
https://docs.scrapy.org/en/latest/topics/signals.html,,####,4,response_downloaded,#response-downloaded,,,25
https://docs.scrapy.org/en/latest/topics/scheduler.html,,#,1,Scheduler,#module-scrapy.core.scheduler,,,1
https://docs.scrapy.org/en/latest/topics/scheduler.html,,##,2,Overriding the default scheduler,#overriding-the-default-scheduler,,,2
https://docs.scrapy.org/en/latest/topics/scheduler.html,,##,2,Minimal scheduler interface,#minimal-scheduler-interface,,,3
https://docs.scrapy.org/en/latest/topics/scheduler.html,,##,2,Default Scrapy scheduler,#default-scrapy-scheduler,,,4
https://docs.scrapy.org/en/latest/topics/exporters.html,,#,1,Item Exporters,#module-scrapy.exporters,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exporters</span> <span class=""kn"">import</span> <span class=""n"">XmlItemExporter</span>

<span class=""k"">class</span> <span class=""nc"">PerYearXmlExportPipeline</span><span class=""p"">:</span>
    <span class=""sd"">""""""Distribute items across multiple XML files according to their 'year' field""""""</span>

    <span class=""k"">def</span> <span class=""nf"">open_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">year_to_exporter</span> <span class=""o"">=</span> <span class=""p"">{}</span>

    <span class=""k"">def</span> <span class=""nf"">close_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">exporter</span><span class=""p"">,</span> <span class=""n"">xml_file</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">year_to_exporter</span><span class=""o"">.</span><span class=""n"">values</span><span class=""p"">():</span>
            <span class=""n"">exporter</span><span class=""o"">.</span><span class=""n"">finish_exporting</span><span class=""p"">()</span>
            <span class=""n"">xml_file</span><span class=""o"">.</span><span class=""n"">close</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">_exporter_for_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""n"">year</span> <span class=""o"">=</span> <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'year'</span><span class=""p"">]</span>
        <span class=""k"">if</span> <span class=""n"">year</span> <span class=""ow"">not</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">year_to_exporter</span><span class=""p"">:</span>
            <span class=""n"">xml_file</span> <span class=""o"">=</span> <span class=""nb"">open</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s1"">'</span><span class=""si"">{</span><span class=""n"">year</span><span class=""si"">}</span><span class=""s1"">.xml'</span><span class=""p"">,</span> <span class=""s1"">'wb'</span><span class=""p"">)</span>
            <span class=""n"">exporter</span> <span class=""o"">=</span> <span class=""n"">XmlItemExporter</span><span class=""p"">(</span><span class=""n"">xml_file</span><span class=""p"">)</span>
            <span class=""n"">exporter</span><span class=""o"">.</span><span class=""n"">start_exporting</span><span class=""p"">()</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">year_to_exporter</span><span class=""p"">[</span><span class=""n"">year</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""p"">(</span><span class=""n"">exporter</span><span class=""p"">,</span> <span class=""n"">xml_file</span><span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">year_to_exporter</span><span class=""p"">[</span><span class=""n"">year</span><span class=""p"">][</span><span class=""mi"">0</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">exporter</span> <span class=""o"">=</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">_exporter_for_item</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""n"">exporter</span><span class=""o"">.</span><span class=""n"">export_item</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">def</span> <span class=""nf"">serialize_price</span><span class=""p"">(</span><span class=""n"">value</span><span class=""p"">):</span>
    <span class=""k"">return</span> <span class=""sa"">f</span><span class=""s1"">'$ </span><span class=""si"">{</span><span class=""nb"">str</span><span class=""p"">(</span><span class=""n"">value</span><span class=""p"">)</span><span class=""si"">}</span><span class=""s1"">'</span>

<span class=""k"">class</span> <span class=""nc"">Product</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">price</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">(</span><span class=""n"">serializer</span><span class=""o"">=</span><span class=""n"">serialize_price</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.exporters</span> <span class=""kn"">import</span> <span class=""n"">XmlItemExporter</span>

<span class=""k"">class</span> <span class=""nc"">ProductXmlExporter</span><span class=""p"">(</span><span class=""n"">XmlItemExporter</span><span class=""p"">):</span>

    <span class=""k"">def</span> <span class=""nf"">serialize_field</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">field</span><span class=""p"">,</span> <span class=""n"">name</span><span class=""p"">,</span> <span class=""n"">value</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">name</span> <span class=""o"">==</span> <span class=""s1"">'price'</span><span class=""p"">:</span>
            <span class=""k"">return</span> <span class=""sa"">f</span><span class=""s1"">'$ </span><span class=""si"">{</span><span class=""nb"">str</span><span class=""p"">(</span><span class=""n"">value</span><span class=""p"">)</span><span class=""si"">}</span><span class=""s1"">'</span>
        <span class=""k"">return</span> <span class=""nb"">super</span><span class=""p"">()</span><span class=""o"">.</span><span class=""n"">serialize_field</span><span class=""p"">(</span><span class=""n"">field</span><span class=""p"">,</span> <span class=""n"">name</span><span class=""p"">,</span> <span class=""n"">value</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">Item</span><span class=""p"">(</span><span class=""n"">name</span><span class=""o"">=</span><span class=""s1"">'Color TV'</span><span class=""p"">,</span> <span class=""n"">price</span><span class=""o"">=</span><span class=""s1"">'1200'</span><span class=""p"">)</span>
<span class=""n"">Item</span><span class=""p"">(</span><span class=""n"">name</span><span class=""o"">=</span><span class=""s1"">'DVD player'</span><span class=""p"">,</span> <span class=""n"">price</span><span class=""o"">=</span><span class=""s1"">'200'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">[</span><span class=""s1"">'field1'</span><span class=""p"">,</span> <span class=""s1"">'field2'</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span><span class=""s1"">'field1'</span><span class=""p"">:</span> <span class=""s1"">'Field 1'</span><span class=""p"">,</span> <span class=""s1"">'field2'</span><span class=""p"">:</span> <span class=""s1"">'Field 2'</span><span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;items&gt;
  &lt;item&gt;
    &lt;name&gt;Color TV&lt;/name&gt;
    &lt;price&gt;1200&lt;/price&gt;
 &lt;/item&gt;
  &lt;item&gt;
    &lt;name&gt;DVD player&lt;/name&gt;
    &lt;price&gt;200&lt;/price&gt;
 &lt;/item&gt;
&lt;/items&gt;
</pre></div>,<div class=""highlight""><pre><span></span>Item(name=['John', 'Doe'], age='23')
</pre></div>,<div class=""highlight""><pre><span></span>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;items&gt;
  &lt;item&gt;
    &lt;name&gt;
      &lt;value&gt;John&lt;/value&gt;
      &lt;value&gt;Doe&lt;/value&gt;
    &lt;/name&gt;
    &lt;age&gt;23&lt;/age&gt;
  &lt;/item&gt;
&lt;/items&gt;
</pre></div>,<div class=""highlight""><pre><span></span>product,price
Color TV,1200
DVD player,200
</pre></div>,<div class=""highlight""><pre><span></span>{'name': 'Color TV', 'price': '1200'}
{'name': 'DVD player', 'price': '200'}
</pre></div>,<div class=""highlight""><pre><span></span>[{""name"": ""Color TV"", ""price"": ""1200""},
{""name"": ""DVD player"", ""price"": ""200""}]
</pre></div>,<div class=""highlight""><pre><span></span>{""name"": ""Color TV"", ""price"": ""1200""}
{""name"": ""DVD player"", ""price"": ""200""}
</pre></div>","from itemadapter import ItemAdapter
from scrapy.exporters import XmlItemExporter

class PerYearXmlExportPipeline:
    """"""Distribute items across multiple XML files according to their 'year' field""""""

    def open_spider(self, spider):
        self.year_to_exporter = {}

    def close_spider(self, spider):
        for exporter, xml_file in self.year_to_exporter.values():
            exporter.finish_exporting()
            xml_file.close()

    def _exporter_for_item(self, item):
        adapter = ItemAdapter(item)
        year = adapter['year']
        if year not in self.year_to_exporter:
            xml_file = open(f'{year}.xml', 'wb')
            exporter = XmlItemExporter(xml_file)
            exporter.start_exporting()
            self.year_to_exporter[year] = (exporter, xml_file)
        return self.year_to_exporter[year][0]

    def process_item(self, item, spider):
        exporter = self._exporter_for_item(item)
        exporter.export_item(item)
        return item
,import scrapy

def serialize_price(value):
    return f'$ {str(value)}'

class Product(scrapy.Item):
    name = scrapy.Field()
    price = scrapy.Field(serializer=serialize_price)
,from scrapy.exporters import XmlItemExporter

class ProductXmlExporter(XmlItemExporter):

    def serialize_field(self, field, name, value):
        if name == 'price':
            return f'$ {str(value)}'
        return super().serialize_field(field, name, value)
,Item(name='Color TV', price='1200')
Item(name='DVD player', price='200')
,['field1', 'field2']
,{'field1': 'Field 1', 'field2': 'Field 2'}
,<?xml version=""1.0"" encoding=""utf-8""?>
<items>
  <item>
    <name>Color TV</name>
    <price>1200</price>
 </item>
  <item>
    <name>DVD player</name>
    <price>200</price>
 </item>
</items>
,Item(name=['John', 'Doe'], age='23')
,<?xml version=""1.0"" encoding=""utf-8""?>
<items>
  <item>
    <name>
      <value>John</value>
      <value>Doe</value>
    </name>
    <age>23</age>
  </item>
</items>
,product,price
Color TV,1200
DVD player,200
,{'name': 'Color TV', 'price': '1200'}
{'name': 'DVD player', 'price': '200'}
,[{""name"": ""Color TV"", ""price"": ""1200""},
{""name"": ""DVD player"", ""price"": ""200""}]
,{""name"": ""Color TV"", ""price"": ""1200""}
{""name"": ""DVD player"", ""price"": ""200""}
",13
https://docs.scrapy.org/en/latest/topics/exporters.html,,##,2,Using Item Exporters,#using-item-exporters,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">itemadapter</span> <span class=""kn"">import</span> <span class=""n"">ItemAdapter</span>
<span class=""kn"">from</span> <span class=""nn"">scrapy.exporters</span> <span class=""kn"">import</span> <span class=""n"">XmlItemExporter</span>

<span class=""k"">class</span> <span class=""nc"">PerYearXmlExportPipeline</span><span class=""p"">:</span>
    <span class=""sd"">""""""Distribute items across multiple XML files according to their 'year' field""""""</span>

    <span class=""k"">def</span> <span class=""nf"">open_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">year_to_exporter</span> <span class=""o"">=</span> <span class=""p"">{}</span>

    <span class=""k"">def</span> <span class=""nf"">close_spider</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""k"">for</span> <span class=""n"">exporter</span><span class=""p"">,</span> <span class=""n"">xml_file</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">year_to_exporter</span><span class=""o"">.</span><span class=""n"">values</span><span class=""p"">():</span>
            <span class=""n"">exporter</span><span class=""o"">.</span><span class=""n"">finish_exporting</span><span class=""p"">()</span>
            <span class=""n"">xml_file</span><span class=""o"">.</span><span class=""n"">close</span><span class=""p"">()</span>

    <span class=""k"">def</span> <span class=""nf"">_exporter_for_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">):</span>
        <span class=""n"">adapter</span> <span class=""o"">=</span> <span class=""n"">ItemAdapter</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""n"">year</span> <span class=""o"">=</span> <span class=""n"">adapter</span><span class=""p"">[</span><span class=""s1"">'year'</span><span class=""p"">]</span>
        <span class=""k"">if</span> <span class=""n"">year</span> <span class=""ow"">not</span> <span class=""ow"">in</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">year_to_exporter</span><span class=""p"">:</span>
            <span class=""n"">xml_file</span> <span class=""o"">=</span> <span class=""nb"">open</span><span class=""p"">(</span><span class=""sa"">f</span><span class=""s1"">'</span><span class=""si"">{</span><span class=""n"">year</span><span class=""si"">}</span><span class=""s1"">.xml'</span><span class=""p"">,</span> <span class=""s1"">'wb'</span><span class=""p"">)</span>
            <span class=""n"">exporter</span> <span class=""o"">=</span> <span class=""n"">XmlItemExporter</span><span class=""p"">(</span><span class=""n"">xml_file</span><span class=""p"">)</span>
            <span class=""n"">exporter</span><span class=""o"">.</span><span class=""n"">start_exporting</span><span class=""p"">()</span>
            <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">year_to_exporter</span><span class=""p"">[</span><span class=""n"">year</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""p"">(</span><span class=""n"">exporter</span><span class=""p"">,</span> <span class=""n"">xml_file</span><span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">year_to_exporter</span><span class=""p"">[</span><span class=""n"">year</span><span class=""p"">][</span><span class=""mi"">0</span><span class=""p"">]</span>

    <span class=""k"">def</span> <span class=""nf"">process_item</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">item</span><span class=""p"">,</span> <span class=""n"">spider</span><span class=""p"">):</span>
        <span class=""n"">exporter</span> <span class=""o"">=</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">_exporter_for_item</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""n"">exporter</span><span class=""o"">.</span><span class=""n"">export_item</span><span class=""p"">(</span><span class=""n"">item</span><span class=""p"">)</span>
        <span class=""k"">return</span> <span class=""n"">item</span>
</pre></div>","from itemadapter import ItemAdapter
from scrapy.exporters import XmlItemExporter

class PerYearXmlExportPipeline:
    """"""Distribute items across multiple XML files according to their 'year' field""""""

    def open_spider(self, spider):
        self.year_to_exporter = {}

    def close_spider(self, spider):
        for exporter, xml_file in self.year_to_exporter.values():
            exporter.finish_exporting()
            xml_file.close()

    def _exporter_for_item(self, item):
        adapter = ItemAdapter(item)
        year = adapter['year']
        if year not in self.year_to_exporter:
            xml_file = open(f'{year}.xml', 'wb')
            exporter = XmlItemExporter(xml_file)
            exporter.start_exporting()
            self.year_to_exporter[year] = (exporter, xml_file)
        return self.year_to_exporter[year][0]

    def process_item(self, item, spider):
        exporter = self._exporter_for_item(item)
        exporter.export_item(item)
        return item
",1
https://docs.scrapy.org/en/latest/topics/exporters.html,,##,2,Serialization of item fields,#serialization-of-item-fields,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">def</span> <span class=""nf"">serialize_price</span><span class=""p"">(</span><span class=""n"">value</span><span class=""p"">):</span>
    <span class=""k"">return</span> <span class=""sa"">f</span><span class=""s1"">'$ </span><span class=""si"">{</span><span class=""nb"">str</span><span class=""p"">(</span><span class=""n"">value</span><span class=""p"">)</span><span class=""si"">}</span><span class=""s1"">'</span>

<span class=""k"">class</span> <span class=""nc"">Product</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">price</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">(</span><span class=""n"">serializer</span><span class=""o"">=</span><span class=""n"">serialize_price</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.exporters</span> <span class=""kn"">import</span> <span class=""n"">XmlItemExporter</span>

<span class=""k"">class</span> <span class=""nc"">ProductXmlExporter</span><span class=""p"">(</span><span class=""n"">XmlItemExporter</span><span class=""p"">):</span>

    <span class=""k"">def</span> <span class=""nf"">serialize_field</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">field</span><span class=""p"">,</span> <span class=""n"">name</span><span class=""p"">,</span> <span class=""n"">value</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">name</span> <span class=""o"">==</span> <span class=""s1"">'price'</span><span class=""p"">:</span>
            <span class=""k"">return</span> <span class=""sa"">f</span><span class=""s1"">'$ </span><span class=""si"">{</span><span class=""nb"">str</span><span class=""p"">(</span><span class=""n"">value</span><span class=""p"">)</span><span class=""si"">}</span><span class=""s1"">'</span>
        <span class=""k"">return</span> <span class=""nb"">super</span><span class=""p"">()</span><span class=""o"">.</span><span class=""n"">serialize_field</span><span class=""p"">(</span><span class=""n"">field</span><span class=""p"">,</span> <span class=""n"">name</span><span class=""p"">,</span> <span class=""n"">value</span><span class=""p"">)</span>
</pre></div>","import scrapy

def serialize_price(value):
    return f'$ {str(value)}'

class Product(scrapy.Item):
    name = scrapy.Field()
    price = scrapy.Field(serializer=serialize_price)
,from scrapy.exporters import XmlItemExporter

class ProductXmlExporter(XmlItemExporter):

    def serialize_field(self, field, name, value):
        if name == 'price':
            return f'$ {str(value)}'
        return super().serialize_field(field, name, value)
",2
https://docs.scrapy.org/en/latest/topics/exporters.html,,###,3,1. Declaring a serializer in the field,#declaring-a-serializer-in-the-field,"<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">def</span> <span class=""nf"">serialize_price</span><span class=""p"">(</span><span class=""n"">value</span><span class=""p"">):</span>
    <span class=""k"">return</span> <span class=""sa"">f</span><span class=""s1"">'$ </span><span class=""si"">{</span><span class=""nb"">str</span><span class=""p"">(</span><span class=""n"">value</span><span class=""p"">)</span><span class=""si"">}</span><span class=""s1"">'</span>

<span class=""k"">class</span> <span class=""nc"">Product</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""n"">name</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>
    <span class=""n"">price</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">(</span><span class=""n"">serializer</span><span class=""o"">=</span><span class=""n"">serialize_price</span><span class=""p"">)</span>
</pre></div>","import scrapy

def serialize_price(value):
    return f'$ {str(value)}'

class Product(scrapy.Item):
    name = scrapy.Field()
    price = scrapy.Field(serializer=serialize_price)
",1
https://docs.scrapy.org/en/latest/topics/exporters.html,,###,3,2. Overriding the serialize_field() method,#overriding-the-serialize-field-method,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.exporters</span> <span class=""kn"">import</span> <span class=""n"">XmlItemExporter</span>

<span class=""k"">class</span> <span class=""nc"">ProductXmlExporter</span><span class=""p"">(</span><span class=""n"">XmlItemExporter</span><span class=""p"">):</span>

    <span class=""k"">def</span> <span class=""nf"">serialize_field</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">field</span><span class=""p"">,</span> <span class=""n"">name</span><span class=""p"">,</span> <span class=""n"">value</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">name</span> <span class=""o"">==</span> <span class=""s1"">'price'</span><span class=""p"">:</span>
            <span class=""k"">return</span> <span class=""sa"">f</span><span class=""s1"">'$ </span><span class=""si"">{</span><span class=""nb"">str</span><span class=""p"">(</span><span class=""n"">value</span><span class=""p"">)</span><span class=""si"">}</span><span class=""s1"">'</span>
        <span class=""k"">return</span> <span class=""nb"">super</span><span class=""p"">()</span><span class=""o"">.</span><span class=""n"">serialize_field</span><span class=""p"">(</span><span class=""n"">field</span><span class=""p"">,</span> <span class=""n"">name</span><span class=""p"">,</span> <span class=""n"">value</span><span class=""p"">)</span>
</pre></div>","from scrapy.exporters import XmlItemExporter

class ProductXmlExporter(XmlItemExporter):

    def serialize_field(self, field, name, value):
        if name == 'price':
            return f'$ {str(value)}'
        return super().serialize_field(field, name, value)
",1
https://docs.scrapy.org/en/latest/topics/exporters.html,,##,2,Built-in Item Exporters reference,#built-in-item-exporters-reference,"<div class=""highlight""><pre><span></span><span class=""n"">Item</span><span class=""p"">(</span><span class=""n"">name</span><span class=""o"">=</span><span class=""s1"">'Color TV'</span><span class=""p"">,</span> <span class=""n"">price</span><span class=""o"">=</span><span class=""s1"">'1200'</span><span class=""p"">)</span>
<span class=""n"">Item</span><span class=""p"">(</span><span class=""n"">name</span><span class=""o"">=</span><span class=""s1"">'DVD player'</span><span class=""p"">,</span> <span class=""n"">price</span><span class=""o"">=</span><span class=""s1"">'200'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">[</span><span class=""s1"">'field1'</span><span class=""p"">,</span> <span class=""s1"">'field2'</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span><span class=""s1"">'field1'</span><span class=""p"">:</span> <span class=""s1"">'Field 1'</span><span class=""p"">,</span> <span class=""s1"">'field2'</span><span class=""p"">:</span> <span class=""s1"">'Field 2'</span><span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;items&gt;
  &lt;item&gt;
    &lt;name&gt;Color TV&lt;/name&gt;
    &lt;price&gt;1200&lt;/price&gt;
 &lt;/item&gt;
  &lt;item&gt;
    &lt;name&gt;DVD player&lt;/name&gt;
    &lt;price&gt;200&lt;/price&gt;
 &lt;/item&gt;
&lt;/items&gt;
</pre></div>,<div class=""highlight""><pre><span></span>Item(name=['John', 'Doe'], age='23')
</pre></div>,<div class=""highlight""><pre><span></span>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;items&gt;
  &lt;item&gt;
    &lt;name&gt;
      &lt;value&gt;John&lt;/value&gt;
      &lt;value&gt;Doe&lt;/value&gt;
    &lt;/name&gt;
    &lt;age&gt;23&lt;/age&gt;
  &lt;/item&gt;
&lt;/items&gt;
</pre></div>,<div class=""highlight""><pre><span></span>product,price
Color TV,1200
DVD player,200
</pre></div>,<div class=""highlight""><pre><span></span>{'name': 'Color TV', 'price': '1200'}
{'name': 'DVD player', 'price': '200'}
</pre></div>,<div class=""highlight""><pre><span></span>[{""name"": ""Color TV"", ""price"": ""1200""},
{""name"": ""DVD player"", ""price"": ""200""}]
</pre></div>,<div class=""highlight""><pre><span></span>{""name"": ""Color TV"", ""price"": ""1200""}
{""name"": ""DVD player"", ""price"": ""200""}
</pre></div>","Item(name='Color TV', price='1200')
Item(name='DVD player', price='200')
,['field1', 'field2']
,{'field1': 'Field 1', 'field2': 'Field 2'}
,<?xml version=""1.0"" encoding=""utf-8""?>
<items>
  <item>
    <name>Color TV</name>
    <price>1200</price>
 </item>
  <item>
    <name>DVD player</name>
    <price>200</price>
 </item>
</items>
,Item(name=['John', 'Doe'], age='23')
,<?xml version=""1.0"" encoding=""utf-8""?>
<items>
  <item>
    <name>
      <value>John</value>
      <value>Doe</value>
    </name>
    <age>23</age>
  </item>
</items>
,product,price
Color TV,1200
DVD player,200
,{'name': 'Color TV', 'price': '1200'}
{'name': 'DVD player', 'price': '200'}
,[{""name"": ""Color TV"", ""price"": ""1200""},
{""name"": ""DVD player"", ""price"": ""200""}]
,{""name"": ""Color TV"", ""price"": ""1200""}
{""name"": ""DVD player"", ""price"": ""200""}
",10
https://docs.scrapy.org/en/latest/topics/exporters.html,,###,3,BaseItemExporter,#baseitemexporter,"<div class=""highlight""><pre><span></span><span class=""p"">[</span><span class=""s1"">'field1'</span><span class=""p"">,</span> <span class=""s1"">'field2'</span><span class=""p"">]</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""p"">{</span><span class=""s1"">'field1'</span><span class=""p"">:</span> <span class=""s1"">'Field 1'</span><span class=""p"">,</span> <span class=""s1"">'field2'</span><span class=""p"">:</span> <span class=""s1"">'Field 2'</span><span class=""p"">}</span>
</pre></div>","['field1', 'field2']
,{'field1': 'Field 1', 'field2': 'Field 2'}
",2
https://docs.scrapy.org/en/latest/topics/exporters.html,,###,3,PythonItemExporter,#pythonitemexporter,,,8
https://docs.scrapy.org/en/latest/topics/exporters.html,,###,3,XmlItemExporter,#xmlitemexporter,"<div class=""highlight""><pre><span></span>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;items&gt;
  &lt;item&gt;
    &lt;name&gt;Color TV&lt;/name&gt;
    &lt;price&gt;1200&lt;/price&gt;
 &lt;/item&gt;
  &lt;item&gt;
    &lt;name&gt;DVD player&lt;/name&gt;
    &lt;price&gt;200&lt;/price&gt;
 &lt;/item&gt;
&lt;/items&gt;
</pre></div>,<div class=""highlight""><pre><span></span>Item(name=['John', 'Doe'], age='23')
</pre></div>,<div class=""highlight""><pre><span></span>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;items&gt;
  &lt;item&gt;
    &lt;name&gt;
      &lt;value&gt;John&lt;/value&gt;
      &lt;value&gt;Doe&lt;/value&gt;
    &lt;/name&gt;
    &lt;age&gt;23&lt;/age&gt;
  &lt;/item&gt;
&lt;/items&gt;
</pre></div>","<?xml version=""1.0"" encoding=""utf-8""?>
<items>
  <item>
    <name>Color TV</name>
    <price>1200</price>
 </item>
  <item>
    <name>DVD player</name>
    <price>200</price>
 </item>
</items>
,Item(name=['John', 'Doe'], age='23')
,<?xml version=""1.0"" encoding=""utf-8""?>
<items>
  <item>
    <name>
      <value>John</value>
      <value>Doe</value>
    </name>
    <age>23</age>
  </item>
</items>
",3
https://docs.scrapy.org/en/latest/topics/exporters.html,,###,3,CsvItemExporter,#csvitemexporter,"<div class=""highlight""><pre><span></span>product,price
Color TV,1200
DVD player,200
</pre></div>","product,price
Color TV,1200
DVD player,200
",1
https://docs.scrapy.org/en/latest/topics/exporters.html,,###,3,PickleItemExporter,#pickleitemexporter,,,11
https://docs.scrapy.org/en/latest/topics/exporters.html,,###,3,PprintItemExporter,#pprintitemexporter,"<div class=""highlight""><pre><span></span>{'name': 'Color TV', 'price': '1200'}
{'name': 'DVD player', 'price': '200'}
</pre></div>","{'name': 'Color TV', 'price': '1200'}
{'name': 'DVD player', 'price': '200'}
",1
https://docs.scrapy.org/en/latest/topics/exporters.html,,###,3,JsonItemExporter,#jsonitemexporter,"<div class=""highlight""><pre><span></span>[{""name"": ""Color TV"", ""price"": ""1200""},
{""name"": ""DVD player"", ""price"": ""200""}]
</pre></div>","[{""name"": ""Color TV"", ""price"": ""1200""},
{""name"": ""DVD player"", ""price"": ""200""}]
",1
https://docs.scrapy.org/en/latest/topics/exporters.html,,###,3,JsonLinesItemExporter,#jsonlinesitemexporter,"<div class=""highlight""><pre><span></span>{""name"": ""Color TV"", ""price"": ""1200""}
{""name"": ""DVD player"", ""price"": ""200""}
</pre></div>","{""name"": ""Color TV"", ""price"": ""1200""}
{""name"": ""DVD player"", ""price"": ""200""}
",1
https://docs.scrapy.org/en/latest/topics/exporters.html,,###,3,MarshalItemExporter,#marshalitemexporter,,,15
https://docs.scrapy.org/en/latest/topics/components.html,,#,1,Components,#components,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">pkg_resources</span> <span class=""kn"">import</span> <span class=""n"">parse_version</span>

<span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MyComponent</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">parse_version</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">__version__</span><span class=""p"">)</span> <span class=""o"">&lt;</span> <span class=""n"">parse_version</span><span class=""p"">(</span><span class=""s1"">'2.7'</span><span class=""p"">):</span>
            <span class=""k"">raise</span> <span class=""ne"">RuntimeError</span><span class=""p"">(</span>
                <span class=""sa"">f</span><span class=""s2"">""</span><span class=""si"">{</span><span class=""n"">MyComponent</span><span class=""o"">.</span><span class=""vm"">__qualname__</span><span class=""si"">}</span><span class=""s2""> requires Scrapy 2.7 or ""</span>
                <span class=""sa"">f</span><span class=""s2"">""later, which allow defining the process_spider_output ""</span>
                <span class=""sa"">f</span><span class=""s2"">""method of spider middlewares as an asynchronous ""</span>
                <span class=""sa"">f</span><span class=""s2"">""generator.""</span>
            <span class=""p"">)</span>
</pre></div>","from pkg_resources import parse_version

import scrapy

class MyComponent:

    def __init__(self):
        if parse_version(scrapy.__version__) < parse_version('2.7'):
            raise RuntimeError(
                f""{MyComponent.__qualname__} requires Scrapy 2.7 or ""
                f""later, which allow defining the process_spider_output ""
                f""method of spider middlewares as an asynchronous ""
                f""generator.""
            )
",1
https://docs.scrapy.org/en/latest/topics/components.html,,##,2,Enforcing component requirements,#enforcing-component-requirements,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">pkg_resources</span> <span class=""kn"">import</span> <span class=""n"">parse_version</span>

<span class=""kn"">import</span> <span class=""nn"">scrapy</span>

<span class=""k"">class</span> <span class=""nc"">MyComponent</span><span class=""p"">:</span>

    <span class=""k"">def</span> <span class=""fm"">__init__</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">):</span>
        <span class=""k"">if</span> <span class=""n"">parse_version</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">__version__</span><span class=""p"">)</span> <span class=""o"">&lt;</span> <span class=""n"">parse_version</span><span class=""p"">(</span><span class=""s1"">'2.7'</span><span class=""p"">):</span>
            <span class=""k"">raise</span> <span class=""ne"">RuntimeError</span><span class=""p"">(</span>
                <span class=""sa"">f</span><span class=""s2"">""</span><span class=""si"">{</span><span class=""n"">MyComponent</span><span class=""o"">.</span><span class=""vm"">__qualname__</span><span class=""si"">}</span><span class=""s2""> requires Scrapy 2.7 or ""</span>
                <span class=""sa"">f</span><span class=""s2"">""later, which allow defining the process_spider_output ""</span>
                <span class=""sa"">f</span><span class=""s2"">""method of spider middlewares as an asynchronous ""</span>
                <span class=""sa"">f</span><span class=""s2"">""generator.""</span>
            <span class=""p"">)</span>
</pre></div>","from pkg_resources import parse_version

import scrapy

class MyComponent:

    def __init__(self):
        if parse_version(scrapy.__version__) < parse_version('2.7'):
            raise RuntimeError(
                f""{MyComponent.__qualname__} requires Scrapy 2.7 or ""
                f""later, which allow defining the process_spider_output ""
                f""method of spider middlewares as an asynchronous ""
                f""generator.""
            )
",1
https://docs.scrapy.org/en/latest/topics/api.html,,#,1,Core API,#core-api,"<div class=""highlight""><pre><span></span><span class=""n"">SETTINGS_PRIORITIES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'default'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'command'</span><span class=""p"">:</span> <span class=""mi"">10</span><span class=""p"">,</span>
    <span class=""s1"">'project'</span><span class=""p"">:</span> <span class=""mi"">20</span><span class=""p"">,</span>
    <span class=""s1"">'spider'</span><span class=""p"">:</span> <span class=""mi"">30</span><span class=""p"">,</span>
    <span class=""s1"">'cmdline'</span><span class=""p"">:</span> <span class=""mi"">40</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","SETTINGS_PRIORITIES = {
    'default': 0,
    'command': 10,
    'project': 20,
    'spider': 30,
    'cmdline': 40,
}
",1
https://docs.scrapy.org/en/latest/topics/api.html,,##,2,Crawler API,#crawler-api,,,2
https://docs.scrapy.org/en/latest/topics/api.html,,##,2,Settings API,#module-scrapy.settings,"<div class=""highlight""><pre><span></span><span class=""n"">SETTINGS_PRIORITIES</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'default'</span><span class=""p"">:</span> <span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""s1"">'command'</span><span class=""p"">:</span> <span class=""mi"">10</span><span class=""p"">,</span>
    <span class=""s1"">'project'</span><span class=""p"">:</span> <span class=""mi"">20</span><span class=""p"">,</span>
    <span class=""s1"">'spider'</span><span class=""p"">:</span> <span class=""mi"">30</span><span class=""p"">,</span>
    <span class=""s1"">'cmdline'</span><span class=""p"">:</span> <span class=""mi"">40</span><span class=""p"">,</span>
<span class=""p"">}</span>
</pre></div>","SETTINGS_PRIORITIES = {
    'default': 0,
    'command': 10,
    'project': 20,
    'spider': 30,
    'cmdline': 40,
}
",1
https://docs.scrapy.org/en/latest/topics/api.html,,##,2,SpiderLoader API,#module-scrapy.spiderloader,,,4
https://docs.scrapy.org/en/latest/topics/api.html,,##,2,Signals API,#module-scrapy.signalmanager,,,5
https://docs.scrapy.org/en/latest/topics/api.html,,##,2,Stats Collector API,#stats-collector-api,,,6
https://docs.scrapy.org/en/latest/news.html,,#,1,Release notes,#release-notes,"<div class=""highlight""><pre><span></span><span class=""n"">feedexport</span><span class=""o"">/</span><span class=""n"">success_count</span><span class=""o"">/&lt;</span><span class=""n"">storage</span> <span class=""nb"">type</span><span class=""o"">&gt;</span>
<span class=""n"">feedexport</span><span class=""o"">/</span><span class=""n"">failed_count</span><span class=""o"">/&lt;</span><span class=""n"">storage</span> <span class=""nb"">type</span><span class=""o"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">urllength</span><span class=""o"">/</span><span class=""n"">request_ignored_count</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">httpcompression</span><span class=""o"">/</span><span class=""n"">response_bytes</span>
<span class=""n"">httpcompression</span><span class=""o"">/</span><span class=""n"">response_count</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">item</span> <span class=""o"">=</span> <span class=""n"">MyItem</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'field'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""s1"">'value1'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">loader</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">item</span><span class=""o"">=</span><span class=""n"">item</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'field'</span><span class=""p"">]</span>
<span class=""go"">['value1']</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">href</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.page a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">extract</span><span class=""p"">():</span>
    <span class=""n"">url</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">urljoin</span><span class=""p"">(</span><span class=""n"">href</span><span class=""p"">)</span>
    <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">,</span> <span class=""n"">encoding</span><span class=""o"">=</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">encoding</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">a</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.page a'</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">a</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MyItem</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""n"">url</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""n"">MyItem</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""p"">{</span><span class=""s1"">'url'</span><span class=""p"">:</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">custom_settings</span> <span class=""o"">=</span> <span class=""p"">{</span>
        <span class=""s2"">""DOWNLOAD_DELAY""</span><span class=""p"">:</span> <span class=""mf"">5.0</span><span class=""p"">,</span>
        <span class=""s2"">""RETRY_ENABLED""</span><span class=""p"">:</span> <span class=""kc"">False</span><span class=""p"">,</span>
    <span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">log</span>
<span class=""n"">log</span><span class=""o"">.</span><span class=""n"">msg</span><span class=""p"">(</span><span class=""s1"">'MESSAGE'</span><span class=""p"">,</span> <span class=""n"">log</span><span class=""o"">.</span><span class=""n"">INFO</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'MESSAGE'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Response received'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.crawler</span> <span class=""kn"">import</span> <span class=""n"">CrawlerProcess</span>

<span class=""n"">process</span> <span class=""o"">=</span> <span class=""n"">CrawlerProcess</span><span class=""p"">({</span>
    <span class=""s1"">'USER_AGENT'</span><span class=""p"">:</span> <span class=""s1"">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'</span>
<span class=""p"">})</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider</span><span class=""p"">)</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">start</span><span class=""p"">()</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">69</span> <span class=""n"">Daniel</span> <span class=""n"">Graña</span> <span class=""o"">&lt;</span><span class=""n"">dangra</span><span class=""o"">@...&gt;</span>
<span class=""mi"">37</span> <span class=""n"">Pablo</span> <span class=""n"">Hoffman</span> <span class=""o"">&lt;</span><span class=""n"">pablo</span><span class=""o"">@...&gt;</span>
<span class=""mi"">13</span> <span class=""n"">Mikhail</span> <span class=""n"">Korobov</span> <span class=""o"">&lt;</span><span class=""n"">kmike84</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">9</span> <span class=""n"">Alex</span> <span class=""n"">Cepoi</span> <span class=""o"">&lt;</span><span class=""n"">alex</span><span class=""o"">.</span><span class=""n"">cepoi</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">9</span> <span class=""n"">alexanderlukanin13</span> <span class=""o"">&lt;</span><span class=""n"">alexander</span><span class=""o"">.</span><span class=""n"">lukanin</span><span class=""mf"">.13</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">8</span> <span class=""n"">Rolando</span> <span class=""n"">Espinoza</span> <span class=""n"">La</span> <span class=""n"">fuente</span> <span class=""o"">&lt;</span><span class=""n"">darkrho</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">8</span> <span class=""n"">Lukasz</span> <span class=""n"">Biedrycki</span> <span class=""o"">&lt;</span><span class=""n"">lukasz</span><span class=""o"">.</span><span class=""n"">biedrycki</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">6</span> <span class=""n"">Nicolas</span> <span class=""n"">Ramirez</span> <span class=""o"">&lt;</span><span class=""n"">nramirez</span><span class=""o"">.</span><span class=""n"">uy</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">3</span> <span class=""n"">Paul</span> <span class=""n"">Tremberth</span> <span class=""o"">&lt;</span><span class=""n"">paul</span><span class=""o"">.</span><span class=""n"">tremberth</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">2</span> <span class=""n"">Martin</span> <span class=""n"">Olveyra</span> <span class=""o"">&lt;</span><span class=""n"">molveyra</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">2</span> <span class=""n"">Stefan</span> <span class=""o"">&lt;</span><span class=""n"">misc</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">2</span> <span class=""n"">Rolando</span> <span class=""n"">Espinoza</span> <span class=""o"">&lt;</span><span class=""n"">darkrho</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">2</span> <span class=""n"">Loren</span> <span class=""n"">Davie</span> <span class=""o"">&lt;</span><span class=""n"">loren</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">2</span> <span class=""n"">irgmedeiros</span> <span class=""o"">&lt;</span><span class=""n"">irgmedeiros</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Stefan</span> <span class=""n"">Koch</span> <span class=""o"">&lt;</span><span class=""n"">taikano</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Stefan</span> <span class=""o"">&lt;</span><span class=""n"">cct</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">scraperdragon</span> <span class=""o"">&lt;</span><span class=""n"">dragon</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Kumara</span> <span class=""n"">Tharmalingam</span> <span class=""o"">&lt;</span><span class=""n"">ktharmal</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Francesco</span> <span class=""n"">Piccinno</span> <span class=""o"">&lt;</span><span class=""n"">stack</span><span class=""o"">.</span><span class=""n"">box</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Marcos</span> <span class=""n"">Campal</span> <span class=""o"">&lt;</span><span class=""n"">duendex</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Dragon</span> <span class=""n"">Dave</span> <span class=""o"">&lt;</span><span class=""n"">dragon</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Capi</span> <span class=""n"">Etheriel</span> <span class=""o"">&lt;</span><span class=""n"">barraponto</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">cacovsky</span> <span class=""o"">&lt;</span><span class=""n"">amarquesferraz</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Berend</span> <span class=""n"">Iwema</span> <span class=""o"">&lt;</span><span class=""n"">berend</span><span class=""o"">@...&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""mi"">130</span> <span class=""n"">Pablo</span> <span class=""n"">Hoffman</span> <span class=""o"">&lt;</span><span class=""n"">pablo</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">97</span> <span class=""n"">Daniel</span> <span class=""n"">Graña</span> <span class=""o"">&lt;</span><span class=""n"">dangra</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">20</span> <span class=""n"">Nicolás</span> <span class=""n"">Ramírez</span> <span class=""o"">&lt;</span><span class=""n"">nramirez</span><span class=""o"">.</span><span class=""n"">uy</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">13</span> <span class=""n"">Mikhail</span> <span class=""n"">Korobov</span> <span class=""o"">&lt;</span><span class=""n"">kmike84</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">12</span> <span class=""n"">Pedro</span> <span class=""n"">Faustino</span> <span class=""o"">&lt;</span><span class=""n"">pedrobandim</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">11</span> <span class=""n"">Steven</span> <span class=""n"">Almeroth</span> <span class=""o"">&lt;</span><span class=""n"">sroth77</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">5</span> <span class=""n"">Rolando</span> <span class=""n"">Espinoza</span> <span class=""n"">La</span> <span class=""n"">fuente</span> <span class=""o"">&lt;</span><span class=""n"">darkrho</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">4</span> <span class=""n"">Michal</span> <span class=""n"">Danilak</span> <span class=""o"">&lt;</span><span class=""n"">mimino</span><span class=""o"">.</span><span class=""n"">coder</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">4</span> <span class=""n"">Alex</span> <span class=""n"">Cepoi</span> <span class=""o"">&lt;</span><span class=""n"">alex</span><span class=""o"">.</span><span class=""n"">cepoi</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">4</span> <span class=""n"">Alexandr</span> <span class=""n"">N</span> <span class=""n"">Zamaraev</span> <span class=""p"">(</span><span class=""n"">aka</span> <span class=""n"">tonal</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">tonal</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">3</span> <span class=""n"">paul</span> <span class=""o"">&lt;</span><span class=""n"">paul</span><span class=""o"">.</span><span class=""n"">tremberth</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">3</span> <span class=""n"">Martin</span> <span class=""n"">Olveyra</span> <span class=""o"">&lt;</span><span class=""n"">molveyra</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">3</span> <span class=""n"">Jordi</span> <span class=""n"">Llonch</span> <span class=""o"">&lt;</span><span class=""n"">llonchj</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">3</span> <span class=""n"">arijitchakraborty</span> <span class=""o"">&lt;</span><span class=""n"">myself</span><span class=""o"">.</span><span class=""n"">arijit</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">2</span> <span class=""n"">Shane</span> <span class=""n"">Evans</span> <span class=""o"">&lt;</span><span class=""n"">shane</span><span class=""o"">.</span><span class=""n"">evans</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">2</span> <span class=""n"">joehillen</span> <span class=""o"">&lt;</span><span class=""n"">joehillen</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">2</span> <span class=""n"">Hart</span> <span class=""o"">&lt;</span><span class=""n"">HartSimha</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">2</span> <span class=""n"">Dan</span> <span class=""o"">&lt;</span><span class=""n"">ellisd23</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Zuhao</span> <span class=""n"">Wan</span> <span class=""o"">&lt;</span><span class=""n"">wanzuhao</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">whodatninja</span> <span class=""o"">&lt;</span><span class=""n"">blake</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">vkrest</span> <span class=""o"">&lt;</span><span class=""n"">v</span><span class=""o"">.</span><span class=""n"">krestiannykov</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">tpeng</span> <span class=""o"">&lt;</span><span class=""n"">pengtaoo</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Tom</span> <span class=""n"">Mortimer</span><span class=""o"">-</span><span class=""n"">Jones</span> <span class=""o"">&lt;</span><span class=""n"">tom</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Rocio</span> <span class=""n"">Aramberri</span> <span class=""o"">&lt;</span><span class=""n"">roschegel</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Pedro</span> <span class=""o"">&lt;</span><span class=""n"">pedro</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">notsobad</span> <span class=""o"">&lt;</span><span class=""n"">wangxiaohugg</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Natan</span> <span class=""n"">L</span> <span class=""o"">&lt;</span><span class=""n"">kuyanatan</span><span class=""o"">.</span><span class=""n"">nlao</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Mark</span> <span class=""n"">Grey</span> <span class=""o"">&lt;</span><span class=""n"">mark</span><span class=""o"">.</span><span class=""n"">grey</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Luan</span> <span class=""o"">&lt;</span><span class=""n"">luanpab</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Libor</span> <span class=""n"">Nenadál</span> <span class=""o"">&lt;</span><span class=""n"">libor</span><span class=""o"">.</span><span class=""n"">nenadal</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Juan</span> <span class=""n"">M</span> <span class=""n"">Uys</span> <span class=""o"">&lt;</span><span class=""n"">opyate</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Jonas</span> <span class=""n"">Brunsgaard</span> <span class=""o"">&lt;</span><span class=""n"">jonas</span><span class=""o"">.</span><span class=""n"">brunsgaard</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Ilya</span> <span class=""n"">Baryshev</span> <span class=""o"">&lt;</span><span class=""n"">baryshev</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Hasnain</span> <span class=""n"">Lakhani</span> <span class=""o"">&lt;</span><span class=""n"">m</span><span class=""o"">.</span><span class=""n"">hasnain</span><span class=""o"">.</span><span class=""n"">lakhani</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Emanuel</span> <span class=""n"">Schorsch</span> <span class=""o"">&lt;</span><span class=""n"">emschorsch</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Chris</span> <span class=""n"">Tilden</span> <span class=""o"">&lt;</span><span class=""n"">chris</span><span class=""o"">.</span><span class=""n"">tilden</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Capi</span> <span class=""n"">Etheriel</span> <span class=""o"">&lt;</span><span class=""n"">barraponto</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">cacovsky</span> <span class=""o"">&lt;</span><span class=""n"">amarquesferraz</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Berend</span> <span class=""n"">Iwema</span> <span class=""o"">&lt;</span><span class=""n"">berend</span><span class=""o"">@...&gt;</span>
</pre></div>","feedexport/success_count/<storage type>
feedexport/failed_count/<storage type>
,urllength/request_ignored_count
,httpcompression/response_bytes
httpcompression/response_count
,>>> item = MyItem()
>>> item['field'] = 'value1'
>>> loader = ItemLoader(item=item)
>>> item['field']
['value1']
,for href in response.css('li.page a::attr(href)').extract():
    url = response.urljoin(href)
    yield scrapy.Request(url, self.parse, encoding=response.encoding)
,for a in response.css('li.page a'):
    yield response.follow(a, self.parse)
,class MyItem(scrapy.Item):
    url = scrapy.Field()

class MySpider(scrapy.Spider):
    def parse(self, response):
        return MyItem(url=response.url)
,class MySpider(scrapy.Spider):
    def parse(self, response):
        return {'url': response.url}
,class MySpider(scrapy.Spider):
    custom_settings = {
        ""DOWNLOAD_DELAY"": 5.0,
        ""RETRY_ENABLED"": False,
    }
,from scrapy import log
log.msg('MESSAGE', log.INFO)
,import logging
logging.info('MESSAGE')
,class MySpider(scrapy.Spider):
    def parse(self, response):
        self.logger.info('Response received')
,from scrapy.crawler import CrawlerProcess

process = CrawlerProcess({
    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'
})
process.crawl(MySpider)
process.start()
,69 Daniel Graña <dangra@...>
37 Pablo Hoffman <pablo@...>
13 Mikhail Korobov <kmike84@...>
 9 Alex Cepoi <alex.cepoi@...>
 9 alexanderlukanin13 <alexander.lukanin.13@...>
 8 Rolando Espinoza La fuente <darkrho@...>
 8 Lukasz Biedrycki <lukasz.biedrycki@...>
 6 Nicolas Ramirez <nramirez.uy@...>
 3 Paul Tremberth <paul.tremberth@...>
 2 Martin Olveyra <molveyra@...>
 2 Stefan <misc@...>
 2 Rolando Espinoza <darkrho@...>
 2 Loren Davie <loren@...>
 2 irgmedeiros <irgmedeiros@...>
 1 Stefan Koch <taikano@...>
 1 Stefan <cct@...>
 1 scraperdragon <dragon@...>
 1 Kumara Tharmalingam <ktharmal@...>
 1 Francesco Piccinno <stack.box@...>
 1 Marcos Campal <duendex@...>
 1 Dragon Dave <dragon@...>
 1 Capi Etheriel <barraponto@...>
 1 cacovsky <amarquesferraz@...>
 1 Berend Iwema <berend@...>
,130 Pablo Hoffman <pablo@...>
 97 Daniel Graña <dangra@...>
 20 Nicolás Ramírez <nramirez.uy@...>
 13 Mikhail Korobov <kmike84@...>
 12 Pedro Faustino <pedrobandim@...>
 11 Steven Almeroth <sroth77@...>
  5 Rolando Espinoza La fuente <darkrho@...>
  4 Michal Danilak <mimino.coder@...>
  4 Alex Cepoi <alex.cepoi@...>
  4 Alexandr N Zamaraev (aka tonal) <tonal@...>
  3 paul <paul.tremberth@...>
  3 Martin Olveyra <molveyra@...>
  3 Jordi Llonch <llonchj@...>
  3 arijitchakraborty <myself.arijit@...>
  2 Shane Evans <shane.evans@...>
  2 joehillen <joehillen@...>
  2 Hart <HartSimha@...>
  2 Dan <ellisd23@...>
  1 Zuhao Wan <wanzuhao@...>
  1 whodatninja <blake@...>
  1 vkrest <v.krestiannykov@...>
  1 tpeng <pengtaoo@...>
  1 Tom Mortimer-Jones <tom@...>
  1 Rocio Aramberri <roschegel@...>
  1 Pedro <pedro@...>
  1 notsobad <wangxiaohugg@...>
  1 Natan L <kuyanatan.nlao@...>
  1 Mark Grey <mark.grey@...>
  1 Luan <luanpab@...>
  1 Libor Nenadál <libor.nenadal@...>
  1 Juan M Uys <opyate@...>
  1 Jonas Brunsgaard <jonas.brunsgaard@...>
  1 Ilya Baryshev <baryshev@...>
  1 Hasnain Lakhani <m.hasnain.lakhani@...>
  1 Emanuel Schorsch <emschorsch@...>
  1 Chris Tilden <chris.tilden@...>
  1 Capi Etheriel <barraponto@...>
  1 cacovsky <amarquesferraz@...>
  1 Berend Iwema <berend@...>
",15
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 2.7.1 (2022-11-02),#scrapy-2-7-1-2022-11-02,,,2
https://docs.scrapy.org/en/latest/news.html,,###,3,New features,#new-features,,,3
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#bug-fixes,,,4
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#documentation,,,5
https://docs.scrapy.org/en/latest/news.html,,###,3,Quality assurance,#quality-assurance,,,6
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 2.7.0 (2022-10-17),#scrapy-2-7-0-2022-10-17,,,7
https://docs.scrapy.org/en/latest/news.html,,###,3,Modified requirements,#modified-requirements,,,8
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecations,#deprecations,,,9
https://docs.scrapy.org/en/latest/news.html,,###,3,New features,#id1,,,10
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id2,,,11
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id3,,,12
https://docs.scrapy.org/en/latest/news.html,,###,3,Quality assurance,#id4,,,13
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 2.6.3 (2022-09-27),#scrapy-2-6-3-2022-09-27,,,14
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 2.6.2 (2022-07-25),#scrapy-2-6-2-2022-07-25,,,15
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 2.6.1 (2022-03-01),#scrapy-2-6-1-2022-03-01,,,16
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 2.6.0 (2022-03-01),#scrapy-2-6-0-2022-03-01,,,17
https://docs.scrapy.org/en/latest/news.html,,###,3,Security bug fixes,#security-bug-fixes,,,18
https://docs.scrapy.org/en/latest/news.html,,###,3,Modified requirements,#id5,,,19
https://docs.scrapy.org/en/latest/news.html,,###,3,Backward-incompatible changes,#backward-incompatible-changes,,,20
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecation removals,#deprecation-removals,,,21
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecations,#id6,,,22
https://docs.scrapy.org/en/latest/news.html,,###,3,New features,#id7,,,23
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id8,,,24
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id9,,,25
https://docs.scrapy.org/en/latest/news.html,,###,3,Quality Assurance,#id10,,,26
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 2.5.1 (2021-10-05),#scrapy-2-5-1-2021-10-05,,,27
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 2.5.0 (2021-04-06),#scrapy-2-5-0-2021-04-06,"<div class=""highlight""><pre><span></span><span class=""n"">feedexport</span><span class=""o"">/</span><span class=""n"">success_count</span><span class=""o"">/&lt;</span><span class=""n"">storage</span> <span class=""nb"">type</span><span class=""o"">&gt;</span>
<span class=""n"">feedexport</span><span class=""o"">/</span><span class=""n"">failed_count</span><span class=""o"">/&lt;</span><span class=""n"">storage</span> <span class=""nb"">type</span><span class=""o"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">urllength</span><span class=""o"">/</span><span class=""n"">request_ignored_count</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">httpcompression</span><span class=""o"">/</span><span class=""n"">response_bytes</span>
<span class=""n"">httpcompression</span><span class=""o"">/</span><span class=""n"">response_count</span>
</pre></div>","feedexport/success_count/<storage type>
feedexport/failed_count/<storage type>
,urllength/request_ignored_count
,httpcompression/response_bytes
httpcompression/response_count
",3
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecation removals,#id11,,,29
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecations,#id12,,,30
https://docs.scrapy.org/en/latest/news.html,,###,3,New features,#id13,"<div class=""highlight""><pre><span></span><span class=""n"">feedexport</span><span class=""o"">/</span><span class=""n"">success_count</span><span class=""o"">/&lt;</span><span class=""n"">storage</span> <span class=""nb"">type</span><span class=""o"">&gt;</span>
<span class=""n"">feedexport</span><span class=""o"">/</span><span class=""n"">failed_count</span><span class=""o"">/&lt;</span><span class=""n"">storage</span> <span class=""nb"">type</span><span class=""o"">&gt;</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">urllength</span><span class=""o"">/</span><span class=""n"">request_ignored_count</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">httpcompression</span><span class=""o"">/</span><span class=""n"">response_bytes</span>
<span class=""n"">httpcompression</span><span class=""o"">/</span><span class=""n"">response_count</span>
</pre></div>","feedexport/success_count/<storage type>
feedexport/failed_count/<storage type>
,urllength/request_ignored_count
,httpcompression/response_bytes
httpcompression/response_count
",3
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id14,,,32
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id15,,,33
https://docs.scrapy.org/en/latest/news.html,,###,3,Quality Assurance,#id16,,,34
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 2.4.1 (2020-11-17),#scrapy-2-4-1-2020-11-17,,,35
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 2.4.0 (2020-10-11),#scrapy-2-4-0-2020-10-11,,,36
https://docs.scrapy.org/en/latest/news.html,,###,3,Modified requirements,#id17,,,37
https://docs.scrapy.org/en/latest/news.html,,###,3,Backward-incompatible changes,#id18,,,38
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecation removals,#id19,,,39
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecations,#id21,,,40
https://docs.scrapy.org/en/latest/news.html,,###,3,New features,#id22,,,41
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id23,,,42
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id24,,,43
https://docs.scrapy.org/en/latest/news.html,,###,3,Quality assurance,#id25,,,44
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 2.3.0 (2020-08-04),#scrapy-2-3-0-2020-08-04,,,45
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecation removals,#id26,,,46
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecations,#id27,,,47
https://docs.scrapy.org/en/latest/news.html,,###,3,New features,#id28,,,48
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id29,,,49
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id30,,,50
https://docs.scrapy.org/en/latest/news.html,,###,3,Quality assurance,#id31,,,51
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 2.2.1 (2020-07-17),#scrapy-2-2-1-2020-07-17,,,52
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 2.2.0 (2020-06-24),#scrapy-2-2-0-2020-06-24,,,53
https://docs.scrapy.org/en/latest/news.html,,###,3,Backward-incompatible changes,#id32,,,54
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecations,#id33,,,55
https://docs.scrapy.org/en/latest/news.html,,###,3,New features,#id34,,,56
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id35,,,57
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id36,,,58
https://docs.scrapy.org/en/latest/news.html,,###,3,Quality assurance,#id37,,,59
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 2.1.0 (2020-04-24),#scrapy-2-1-0-2020-04-24,,,60
https://docs.scrapy.org/en/latest/news.html,,###,3,Backward-incompatible changes,#id38,,,61
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecation removals,#id39,,,62
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecations,#id40,,,63
https://docs.scrapy.org/en/latest/news.html,,###,3,New features,#id41,,,64
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id42,,,65
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id43,,,66
https://docs.scrapy.org/en/latest/news.html,,###,3,Quality assurance,#id44,,,67
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 2.0.1 (2020-03-18),#scrapy-2-0-1-2020-03-18,,,68
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 2.0.0 (2020-03-03),#scrapy-2-0-0-2020-03-03,,,69
https://docs.scrapy.org/en/latest/news.html,,###,3,Backward-incompatible changes,#id45,,,70
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecation removals,#id46,,,71
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecations,#id47,,,72
https://docs.scrapy.org/en/latest/news.html,,###,3,New features,#id48,,,73
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id49,,,74
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id50,,,75
https://docs.scrapy.org/en/latest/news.html,,###,3,Quality assurance,#id51,,,76
https://docs.scrapy.org/en/latest/news.html,,###,3,Changes to scheduler queue classes,#changes-to-scheduler-queue-classes,,,77
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.8.3 (2022-07-25),#scrapy-1-8-3-2022-07-25,,,78
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.8.2 (2022-03-01),#scrapy-1-8-2-2022-03-01,,,79
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.8.1 (2021-10-05),#scrapy-1-8-1-2021-10-05,,,80
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.8.0 (2019-10-28),#scrapy-1-8-0-2019-10-28,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">item</span> <span class=""o"">=</span> <span class=""n"">MyItem</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'field'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""s1"">'value1'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">loader</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">item</span><span class=""o"">=</span><span class=""n"">item</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'field'</span><span class=""p"">]</span>
<span class=""go"">['value1']</span>
</pre></div>",">>> item = MyItem()
>>> item['field'] = 'value1'
>>> loader = ItemLoader(item=item)
>>> item['field']
['value1']
",1
https://docs.scrapy.org/en/latest/news.html,,###,3,Backward-incompatible changes,#id56,"<div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">item</span> <span class=""o"">=</span> <span class=""n"">MyItem</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'field'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""s1"">'value1'</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">loader</span> <span class=""o"">=</span> <span class=""n"">ItemLoader</span><span class=""p"">(</span><span class=""n"">item</span><span class=""o"">=</span><span class=""n"">item</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">item</span><span class=""p"">[</span><span class=""s1"">'field'</span><span class=""p"">]</span>
<span class=""go"">['value1']</span>
</pre></div>",">>> item = MyItem()
>>> item['field'] = 'value1'
>>> loader = ItemLoader(item=item)
>>> item['field']
['value1']
",1
https://docs.scrapy.org/en/latest/news.html,,###,3,New features,#id57,,,83
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id58,,,84
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id59,,,85
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecation removals,#id60,,,86
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecations,#id62,,,87
https://docs.scrapy.org/en/latest/news.html,,###,3,Other changes,#other-changes,,,88
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.7.4 (2019-10-21),#scrapy-1-7-4-2019-10-21,,,89
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.7.3 (2019-08-01),#scrapy-1-7-3-2019-08-01,,,90
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.7.2 (2019-07-23),#scrapy-1-7-2-2019-07-23,,,91
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.7.1 (2019-07-18),#scrapy-1-7-1-2019-07-18,,,92
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.7.0 (2019-07-18),#scrapy-1-7-0-2019-07-18,,,93
https://docs.scrapy.org/en/latest/news.html,,###,3,Backward-incompatible changes,#id64,,,94
https://docs.scrapy.org/en/latest/news.html,,###,3,New features,#id65,,,95
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id66,,,96
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id67,,,97
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecation removals,#id68,,,98
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecations,#id70,,,99
https://docs.scrapy.org/en/latest/news.html,,###,3,Other changes,#id72,,,100
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.6.0 (2019-01-30),#scrapy-1-6-0-2019-01-30,,,101
https://docs.scrapy.org/en/latest/news.html,,###,3,Selector API changes,#selector-api-changes,,,102
https://docs.scrapy.org/en/latest/news.html,,###,3,Telnet console,#telnet-console,,,103
https://docs.scrapy.org/en/latest/news.html,,###,3,New extensibility features,#new-extensibility-features,,,104
https://docs.scrapy.org/en/latest/news.html,,###,3,New FilePipeline and MediaPipeline features,#new-filepipeline-and-mediapipeline-features,,,105
https://docs.scrapy.org/en/latest/news.html,,###,3,scrapy.contracts improvements,#scrapy-contracts-improvements,,,106
https://docs.scrapy.org/en/latest/news.html,,###,3,Usability improvements,#usability-improvements,,,107
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id73,,,108
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation improvements,#documentation-improvements,,,109
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecation removals,#id74,,,110
https://docs.scrapy.org/en/latest/news.html,,###,3,"Other improvements, cleanups",#other-improvements-cleanups,,,111
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.5.2 (2019-01-22),#scrapy-1-5-2-2019-01-22,,,112
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.5.1 (2018-07-12),#scrapy-1-5-1-2018-07-12,,,113
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.5.0 (2017-12-29),#scrapy-1-5-0-2017-12-29,,,114
https://docs.scrapy.org/en/latest/news.html,,###,3,Backward Incompatible Changes,#id75,,,115
https://docs.scrapy.org/en/latest/news.html,,###,3,New features,#id76,,,116
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id77,,,117
https://docs.scrapy.org/en/latest/news.html,,###,3,Docs,#docs,,,118
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.4.0 (2017-05-18),#scrapy-1-4-0-2017-05-18,"<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">href</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.page a::attr(href)'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">extract</span><span class=""p"">():</span>
    <span class=""n"">url</span> <span class=""o"">=</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">urljoin</span><span class=""p"">(</span><span class=""n"">href</span><span class=""p"">)</span>
    <span class=""k"">yield</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Request</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">,</span> <span class=""n"">encoding</span><span class=""o"">=</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">encoding</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">a</span> <span class=""ow"">in</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">css</span><span class=""p"">(</span><span class=""s1"">'li.page a'</span><span class=""p"">):</span>
    <span class=""k"">yield</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">follow</span><span class=""p"">(</span><span class=""n"">a</span><span class=""p"">,</span> <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">parse</span><span class=""p"">)</span>
</pre></div>","for href in response.css('li.page a::attr(href)').extract():
    url = response.urljoin(href)
    yield scrapy.Request(url, self.parse, encoding=response.encoding)
,for a in response.css('li.page a'):
    yield response.follow(a, self.parse)
",2
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecations and Backward Incompatible Changes,#deprecations-and-backward-incompatible-changes,,,120
https://docs.scrapy.org/en/latest/news.html,,###,3,New Features,#id78,,,121
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id79,,,122
https://docs.scrapy.org/en/latest/news.html,,###,3,Cleanups & Refactoring,#cleanups-refactoring,,,123
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id80,,,124
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.3.3 (2017-03-10),#scrapy-1-3-3-2017-03-10,,,125
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id81,,,126
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.3.2 (2017-02-13),#scrapy-1-3-2-2017-02-13,,,127
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id82,,,128
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.3.1 (2017-02-08),#scrapy-1-3-1-2017-02-08,,,129
https://docs.scrapy.org/en/latest/news.html,,###,3,New features,#id83,,,130
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id84,,,131
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id85,,,132
https://docs.scrapy.org/en/latest/news.html,,###,3,Cleanups,#cleanups,,,133
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.3.0 (2016-12-21),#scrapy-1-3-0-2016-12-21,,,134
https://docs.scrapy.org/en/latest/news.html,,###,3,New Features,#id86,,,135
https://docs.scrapy.org/en/latest/news.html,,###,3,Dependencies & Cleanups,#dependencies-cleanups,,,136
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.2.3 (2017-03-03),#scrapy-1-2-3-2017-03-03,,,137
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.2.2 (2016-12-06),#scrapy-1-2-2-2016-12-06,,,138
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id87,,,139
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id88,,,140
https://docs.scrapy.org/en/latest/news.html,,###,3,Other changes,#id89,,,141
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.2.1 (2016-10-21),#scrapy-1-2-1-2016-10-21,,,142
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id90,,,143
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id91,,,144
https://docs.scrapy.org/en/latest/news.html,,###,3,Other changes,#id92,,,145
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.2.0 (2016-10-03),#scrapy-1-2-0-2016-10-03,,,146
https://docs.scrapy.org/en/latest/news.html,,###,3,New Features,#id93,,,147
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id94,,,148
https://docs.scrapy.org/en/latest/news.html,,###,3,Refactoring,#refactoring,,,149
https://docs.scrapy.org/en/latest/news.html,,###,3,Tests & Requirements,#tests-requirements,,,150
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id95,,,151
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.1.4 (2017-03-03),#scrapy-1-1-4-2017-03-03,,,152
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.1.3 (2016-09-22),#scrapy-1-1-3-2016-09-22,,,153
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id96,,,154
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id97,,,155
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.1.2 (2016-08-18),#scrapy-1-1-2-2016-08-18,,,156
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id98,,,157
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.1.1 (2016-07-13),#scrapy-1-1-1-2016-07-13,,,158
https://docs.scrapy.org/en/latest/news.html,,###,3,Bug fixes,#id99,,,159
https://docs.scrapy.org/en/latest/news.html,,###,3,New features,#id100,,,160
https://docs.scrapy.org/en/latest/news.html,,###,3,Documentation,#id101,,,161
https://docs.scrapy.org/en/latest/news.html,,###,3,Tests,#tests,,,162
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.1.0 (2016-05-11),#scrapy-1-1-0-2016-05-11,,,163
https://docs.scrapy.org/en/latest/news.html,,###,3,Beta Python 3 Support,#beta-python-3-support,,,164
https://docs.scrapy.org/en/latest/news.html,,###,3,Additional New Features and Enhancements,#additional-new-features-and-enhancements,,,165
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecations and Removals,#deprecations-and-removals,,,166
https://docs.scrapy.org/en/latest/news.html,,###,3,Relocations,#relocations,,,167
https://docs.scrapy.org/en/latest/news.html,,###,3,Bugfixes,#bugfixes,,,168
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.0.7 (2017-03-03),#scrapy-1-0-7-2017-03-03,,,169
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.0.6 (2016-05-04),#scrapy-1-0-6-2016-05-04,,,170
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.0.5 (2016-02-04),#scrapy-1-0-5-2016-02-04,,,171
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.0.4 (2015-12-30),#scrapy-1-0-4-2015-12-30,,,172
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.0.3 (2015-08-11),#scrapy-1-0-3-2015-08-11,,,173
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.0.2 (2015-08-06),#scrapy-1-0-2-2015-08-06,,,174
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.0.1 (2015-07-01),#scrapy-1-0-1-2015-07-01,,,175
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 1.0.0 (2015-06-19),#scrapy-1-0-0-2015-06-19,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MyItem</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""n"">url</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""n"">MyItem</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""p"">{</span><span class=""s1"">'url'</span><span class=""p"">:</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">custom_settings</span> <span class=""o"">=</span> <span class=""p"">{</span>
        <span class=""s2"">""DOWNLOAD_DELAY""</span><span class=""p"">:</span> <span class=""mf"">5.0</span><span class=""p"">,</span>
        <span class=""s2"">""RETRY_ENABLED""</span><span class=""p"">:</span> <span class=""kc"">False</span><span class=""p"">,</span>
    <span class=""p"">}</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">log</span>
<span class=""n"">log</span><span class=""o"">.</span><span class=""n"">msg</span><span class=""p"">(</span><span class=""s1"">'MESSAGE'</span><span class=""p"">,</span> <span class=""n"">log</span><span class=""o"">.</span><span class=""n"">INFO</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'MESSAGE'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Response received'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.crawler</span> <span class=""kn"">import</span> <span class=""n"">CrawlerProcess</span>

<span class=""n"">process</span> <span class=""o"">=</span> <span class=""n"">CrawlerProcess</span><span class=""p"">({</span>
    <span class=""s1"">'USER_AGENT'</span><span class=""p"">:</span> <span class=""s1"">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'</span>
<span class=""p"">})</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider</span><span class=""p"">)</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">start</span><span class=""p"">()</span>
</pre></div>","class MyItem(scrapy.Item):
    url = scrapy.Field()

class MySpider(scrapy.Spider):
    def parse(self, response):
        return MyItem(url=response.url)
,class MySpider(scrapy.Spider):
    def parse(self, response):
        return {'url': response.url}
,class MySpider(scrapy.Spider):
    custom_settings = {
        ""DOWNLOAD_DELAY"": 5.0,
        ""RETRY_ENABLED"": False,
    }
,from scrapy import log
log.msg('MESSAGE', log.INFO)
,import logging
logging.info('MESSAGE')
,class MySpider(scrapy.Spider):
    def parse(self, response):
        self.logger.info('Response received')
,from scrapy.crawler import CrawlerProcess

process = CrawlerProcess({
    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'
})
process.crawl(MySpider)
process.start()
",7
https://docs.scrapy.org/en/latest/news.html,,###,3,Support for returning dictionaries in spiders,#support-for-returning-dictionaries-in-spiders,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MyItem</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Item</span><span class=""p"">):</span>
    <span class=""n"">url</span> <span class=""o"">=</span> <span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Field</span><span class=""p"">()</span>

<span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""n"">MyItem</span><span class=""p"">(</span><span class=""n"">url</span><span class=""o"">=</span><span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""k"">return</span> <span class=""p"">{</span><span class=""s1"">'url'</span><span class=""p"">:</span> <span class=""n"">response</span><span class=""o"">.</span><span class=""n"">url</span><span class=""p"">}</span>
</pre></div>","class MyItem(scrapy.Item):
    url = scrapy.Field()

class MySpider(scrapy.Spider):
    def parse(self, response):
        return MyItem(url=response.url)
,class MySpider(scrapy.Spider):
    def parse(self, response):
        return {'url': response.url}
",2
https://docs.scrapy.org/en/latest/news.html,,###,3,Per-spider settings (GSoC 2014),#per-spider-settings-gsoc-2014,"<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""n"">custom_settings</span> <span class=""o"">=</span> <span class=""p"">{</span>
        <span class=""s2"">""DOWNLOAD_DELAY""</span><span class=""p"">:</span> <span class=""mf"">5.0</span><span class=""p"">,</span>
        <span class=""s2"">""RETRY_ENABLED""</span><span class=""p"">:</span> <span class=""kc"">False</span><span class=""p"">,</span>
    <span class=""p"">}</span>
</pre></div>","class MySpider(scrapy.Spider):
    custom_settings = {
        ""DOWNLOAD_DELAY"": 5.0,
        ""RETRY_ENABLED"": False,
    }
",1
https://docs.scrapy.org/en/latest/news.html,,###,3,Python Logging,#python-logging,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy</span> <span class=""kn"">import</span> <span class=""n"">log</span>
<span class=""n"">log</span><span class=""o"">.</span><span class=""n"">msg</span><span class=""p"">(</span><span class=""s1"">'MESSAGE'</span><span class=""p"">,</span> <span class=""n"">log</span><span class=""o"">.</span><span class=""n"">INFO</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">logging</span>
<span class=""n"">logging</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'MESSAGE'</span><span class=""p"">)</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MySpider</span><span class=""p"">(</span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">Spider</span><span class=""p"">):</span>
    <span class=""k"">def</span> <span class=""nf"">parse</span><span class=""p"">(</span><span class=""bp"">self</span><span class=""p"">,</span> <span class=""n"">response</span><span class=""p"">):</span>
        <span class=""bp"">self</span><span class=""o"">.</span><span class=""n"">logger</span><span class=""o"">.</span><span class=""n"">info</span><span class=""p"">(</span><span class=""s1"">'Response received'</span><span class=""p"">)</span>
</pre></div>","from scrapy import log
log.msg('MESSAGE', log.INFO)
,import logging
logging.info('MESSAGE')
,class MySpider(scrapy.Spider):
    def parse(self, response):
        self.logger.info('Response received')
",3
https://docs.scrapy.org/en/latest/news.html,,###,3,Crawler API refactoring (GSoC 2014),#crawler-api-refactoring-gsoc-2014,"<div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">scrapy.crawler</span> <span class=""kn"">import</span> <span class=""n"">CrawlerProcess</span>

<span class=""n"">process</span> <span class=""o"">=</span> <span class=""n"">CrawlerProcess</span><span class=""p"">({</span>
    <span class=""s1"">'USER_AGENT'</span><span class=""p"">:</span> <span class=""s1"">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'</span>
<span class=""p"">})</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">crawl</span><span class=""p"">(</span><span class=""n"">MySpider</span><span class=""p"">)</span>
<span class=""n"">process</span><span class=""o"">.</span><span class=""n"">start</span><span class=""p"">()</span>
</pre></div>","from scrapy.crawler import CrawlerProcess

process = CrawlerProcess({
    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'
})
process.crawl(MySpider)
process.start()
",1
https://docs.scrapy.org/en/latest/news.html,,###,3,Module Relocations,#module-relocations,,,181
https://docs.scrapy.org/en/latest/news.html,,####,4,Full list of relocations,#full-list-of-relocations,,,182
https://docs.scrapy.org/en/latest/news.html,,###,3,Changelog,#changelog,,,183
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.24.6 (2015-04-20),#scrapy-0-24-6-2015-04-20,,,184
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.24.5 (2015-02-25),#scrapy-0-24-5-2015-02-25,,,185
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.24.4 (2014-08-09),#scrapy-0-24-4-2014-08-09,,,186
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.24.3 (2014-08-09),#scrapy-0-24-3-2014-08-09,,,187
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.24.2 (2014-07-08),#scrapy-0-24-2-2014-07-08,,,188
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.24.1 (2014-06-27),#scrapy-0-24-1-2014-06-27,,,189
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.24.0 (2014-06-26),#scrapy-0-24-0-2014-06-26,,,190
https://docs.scrapy.org/en/latest/news.html,,###,3,Enhancements,#enhancements,,,191
https://docs.scrapy.org/en/latest/news.html,,###,3,Bugfixes,#id103,,,192
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.22.2 (released 2014-02-14),#scrapy-0-22-2-released-2014-02-14,,,193
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.22.1 (released 2014-02-08),#scrapy-0-22-1-released-2014-02-08,,,194
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.22.0 (released 2014-01-17),#scrapy-0-22-0-released-2014-01-17,,,195
https://docs.scrapy.org/en/latest/news.html,,###,3,Enhancements,#id104,,,196
https://docs.scrapy.org/en/latest/news.html,,###,3,Fixes,#fixes,,,197
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.20.2 (released 2013-12-09),#scrapy-0-20-2-released-2013-12-09,,,198
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.20.1 (released 2013-11-28),#scrapy-0-20-1-released-2013-11-28,,,199
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.20.0 (released 2013-11-08),#scrapy-0-20-0-released-2013-11-08,"<div class=""highlight""><pre><span></span><span class=""mi"">69</span> <span class=""n"">Daniel</span> <span class=""n"">Graña</span> <span class=""o"">&lt;</span><span class=""n"">dangra</span><span class=""o"">@...&gt;</span>
<span class=""mi"">37</span> <span class=""n"">Pablo</span> <span class=""n"">Hoffman</span> <span class=""o"">&lt;</span><span class=""n"">pablo</span><span class=""o"">@...&gt;</span>
<span class=""mi"">13</span> <span class=""n"">Mikhail</span> <span class=""n"">Korobov</span> <span class=""o"">&lt;</span><span class=""n"">kmike84</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">9</span> <span class=""n"">Alex</span> <span class=""n"">Cepoi</span> <span class=""o"">&lt;</span><span class=""n"">alex</span><span class=""o"">.</span><span class=""n"">cepoi</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">9</span> <span class=""n"">alexanderlukanin13</span> <span class=""o"">&lt;</span><span class=""n"">alexander</span><span class=""o"">.</span><span class=""n"">lukanin</span><span class=""mf"">.13</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">8</span> <span class=""n"">Rolando</span> <span class=""n"">Espinoza</span> <span class=""n"">La</span> <span class=""n"">fuente</span> <span class=""o"">&lt;</span><span class=""n"">darkrho</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">8</span> <span class=""n"">Lukasz</span> <span class=""n"">Biedrycki</span> <span class=""o"">&lt;</span><span class=""n"">lukasz</span><span class=""o"">.</span><span class=""n"">biedrycki</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">6</span> <span class=""n"">Nicolas</span> <span class=""n"">Ramirez</span> <span class=""o"">&lt;</span><span class=""n"">nramirez</span><span class=""o"">.</span><span class=""n"">uy</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">3</span> <span class=""n"">Paul</span> <span class=""n"">Tremberth</span> <span class=""o"">&lt;</span><span class=""n"">paul</span><span class=""o"">.</span><span class=""n"">tremberth</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">2</span> <span class=""n"">Martin</span> <span class=""n"">Olveyra</span> <span class=""o"">&lt;</span><span class=""n"">molveyra</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">2</span> <span class=""n"">Stefan</span> <span class=""o"">&lt;</span><span class=""n"">misc</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">2</span> <span class=""n"">Rolando</span> <span class=""n"">Espinoza</span> <span class=""o"">&lt;</span><span class=""n"">darkrho</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">2</span> <span class=""n"">Loren</span> <span class=""n"">Davie</span> <span class=""o"">&lt;</span><span class=""n"">loren</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">2</span> <span class=""n"">irgmedeiros</span> <span class=""o"">&lt;</span><span class=""n"">irgmedeiros</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Stefan</span> <span class=""n"">Koch</span> <span class=""o"">&lt;</span><span class=""n"">taikano</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Stefan</span> <span class=""o"">&lt;</span><span class=""n"">cct</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">scraperdragon</span> <span class=""o"">&lt;</span><span class=""n"">dragon</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Kumara</span> <span class=""n"">Tharmalingam</span> <span class=""o"">&lt;</span><span class=""n"">ktharmal</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Francesco</span> <span class=""n"">Piccinno</span> <span class=""o"">&lt;</span><span class=""n"">stack</span><span class=""o"">.</span><span class=""n"">box</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Marcos</span> <span class=""n"">Campal</span> <span class=""o"">&lt;</span><span class=""n"">duendex</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Dragon</span> <span class=""n"">Dave</span> <span class=""o"">&lt;</span><span class=""n"">dragon</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Capi</span> <span class=""n"">Etheriel</span> <span class=""o"">&lt;</span><span class=""n"">barraponto</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">cacovsky</span> <span class=""o"">&lt;</span><span class=""n"">amarquesferraz</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Berend</span> <span class=""n"">Iwema</span> <span class=""o"">&lt;</span><span class=""n"">berend</span><span class=""o"">@...&gt;</span>
</pre></div>","69 Daniel Graña <dangra@...>
37 Pablo Hoffman <pablo@...>
13 Mikhail Korobov <kmike84@...>
 9 Alex Cepoi <alex.cepoi@...>
 9 alexanderlukanin13 <alexander.lukanin.13@...>
 8 Rolando Espinoza La fuente <darkrho@...>
 8 Lukasz Biedrycki <lukasz.biedrycki@...>
 6 Nicolas Ramirez <nramirez.uy@...>
 3 Paul Tremberth <paul.tremberth@...>
 2 Martin Olveyra <molveyra@...>
 2 Stefan <misc@...>
 2 Rolando Espinoza <darkrho@...>
 2 Loren Davie <loren@...>
 2 irgmedeiros <irgmedeiros@...>
 1 Stefan Koch <taikano@...>
 1 Stefan <cct@...>
 1 scraperdragon <dragon@...>
 1 Kumara Tharmalingam <ktharmal@...>
 1 Francesco Piccinno <stack.box@...>
 1 Marcos Campal <duendex@...>
 1 Dragon Dave <dragon@...>
 1 Capi Etheriel <barraponto@...>
 1 cacovsky <amarquesferraz@...>
 1 Berend Iwema <berend@...>
",1
https://docs.scrapy.org/en/latest/news.html,,###,3,Enhancements,#id105,,,201
https://docs.scrapy.org/en/latest/news.html,,###,3,Bugfixes,#id106,,,202
https://docs.scrapy.org/en/latest/news.html,,###,3,Other,#other,,,203
https://docs.scrapy.org/en/latest/news.html,,###,3,Thanks,#thanks,"<div class=""highlight""><pre><span></span><span class=""mi"">69</span> <span class=""n"">Daniel</span> <span class=""n"">Graña</span> <span class=""o"">&lt;</span><span class=""n"">dangra</span><span class=""o"">@...&gt;</span>
<span class=""mi"">37</span> <span class=""n"">Pablo</span> <span class=""n"">Hoffman</span> <span class=""o"">&lt;</span><span class=""n"">pablo</span><span class=""o"">@...&gt;</span>
<span class=""mi"">13</span> <span class=""n"">Mikhail</span> <span class=""n"">Korobov</span> <span class=""o"">&lt;</span><span class=""n"">kmike84</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">9</span> <span class=""n"">Alex</span> <span class=""n"">Cepoi</span> <span class=""o"">&lt;</span><span class=""n"">alex</span><span class=""o"">.</span><span class=""n"">cepoi</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">9</span> <span class=""n"">alexanderlukanin13</span> <span class=""o"">&lt;</span><span class=""n"">alexander</span><span class=""o"">.</span><span class=""n"">lukanin</span><span class=""mf"">.13</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">8</span> <span class=""n"">Rolando</span> <span class=""n"">Espinoza</span> <span class=""n"">La</span> <span class=""n"">fuente</span> <span class=""o"">&lt;</span><span class=""n"">darkrho</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">8</span> <span class=""n"">Lukasz</span> <span class=""n"">Biedrycki</span> <span class=""o"">&lt;</span><span class=""n"">lukasz</span><span class=""o"">.</span><span class=""n"">biedrycki</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">6</span> <span class=""n"">Nicolas</span> <span class=""n"">Ramirez</span> <span class=""o"">&lt;</span><span class=""n"">nramirez</span><span class=""o"">.</span><span class=""n"">uy</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">3</span> <span class=""n"">Paul</span> <span class=""n"">Tremberth</span> <span class=""o"">&lt;</span><span class=""n"">paul</span><span class=""o"">.</span><span class=""n"">tremberth</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">2</span> <span class=""n"">Martin</span> <span class=""n"">Olveyra</span> <span class=""o"">&lt;</span><span class=""n"">molveyra</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">2</span> <span class=""n"">Stefan</span> <span class=""o"">&lt;</span><span class=""n"">misc</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">2</span> <span class=""n"">Rolando</span> <span class=""n"">Espinoza</span> <span class=""o"">&lt;</span><span class=""n"">darkrho</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">2</span> <span class=""n"">Loren</span> <span class=""n"">Davie</span> <span class=""o"">&lt;</span><span class=""n"">loren</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">2</span> <span class=""n"">irgmedeiros</span> <span class=""o"">&lt;</span><span class=""n"">irgmedeiros</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Stefan</span> <span class=""n"">Koch</span> <span class=""o"">&lt;</span><span class=""n"">taikano</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Stefan</span> <span class=""o"">&lt;</span><span class=""n"">cct</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">scraperdragon</span> <span class=""o"">&lt;</span><span class=""n"">dragon</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Kumara</span> <span class=""n"">Tharmalingam</span> <span class=""o"">&lt;</span><span class=""n"">ktharmal</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Francesco</span> <span class=""n"">Piccinno</span> <span class=""o"">&lt;</span><span class=""n"">stack</span><span class=""o"">.</span><span class=""n"">box</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Marcos</span> <span class=""n"">Campal</span> <span class=""o"">&lt;</span><span class=""n"">duendex</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Dragon</span> <span class=""n"">Dave</span> <span class=""o"">&lt;</span><span class=""n"">dragon</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Capi</span> <span class=""n"">Etheriel</span> <span class=""o"">&lt;</span><span class=""n"">barraponto</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">cacovsky</span> <span class=""o"">&lt;</span><span class=""n"">amarquesferraz</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">1</span> <span class=""n"">Berend</span> <span class=""n"">Iwema</span> <span class=""o"">&lt;</span><span class=""n"">berend</span><span class=""o"">@...&gt;</span>
</pre></div>","69 Daniel Graña <dangra@...>
37 Pablo Hoffman <pablo@...>
13 Mikhail Korobov <kmike84@...>
 9 Alex Cepoi <alex.cepoi@...>
 9 alexanderlukanin13 <alexander.lukanin.13@...>
 8 Rolando Espinoza La fuente <darkrho@...>
 8 Lukasz Biedrycki <lukasz.biedrycki@...>
 6 Nicolas Ramirez <nramirez.uy@...>
 3 Paul Tremberth <paul.tremberth@...>
 2 Martin Olveyra <molveyra@...>
 2 Stefan <misc@...>
 2 Rolando Espinoza <darkrho@...>
 2 Loren Davie <loren@...>
 2 irgmedeiros <irgmedeiros@...>
 1 Stefan Koch <taikano@...>
 1 Stefan <cct@...>
 1 scraperdragon <dragon@...>
 1 Kumara Tharmalingam <ktharmal@...>
 1 Francesco Piccinno <stack.box@...>
 1 Marcos Campal <duendex@...>
 1 Dragon Dave <dragon@...>
 1 Capi Etheriel <barraponto@...>
 1 cacovsky <amarquesferraz@...>
 1 Berend Iwema <berend@...>
",1
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.18.4 (released 2013-10-10),#scrapy-0-18-4-released-2013-10-10,,,205
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.18.3 (released 2013-10-03),#scrapy-0-18-3-released-2013-10-03,,,206
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.18.2 (released 2013-09-03),#scrapy-0-18-2-released-2013-09-03,,,207
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.18.1 (released 2013-08-27),#scrapy-0-18-1-released-2013-08-27,,,208
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.18.0 (released 2013-08-09),#scrapy-0-18-0-released-2013-08-09,"<div class=""highlight""><pre><span></span><span class=""mi"">130</span> <span class=""n"">Pablo</span> <span class=""n"">Hoffman</span> <span class=""o"">&lt;</span><span class=""n"">pablo</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">97</span> <span class=""n"">Daniel</span> <span class=""n"">Graña</span> <span class=""o"">&lt;</span><span class=""n"">dangra</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">20</span> <span class=""n"">Nicolás</span> <span class=""n"">Ramírez</span> <span class=""o"">&lt;</span><span class=""n"">nramirez</span><span class=""o"">.</span><span class=""n"">uy</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">13</span> <span class=""n"">Mikhail</span> <span class=""n"">Korobov</span> <span class=""o"">&lt;</span><span class=""n"">kmike84</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">12</span> <span class=""n"">Pedro</span> <span class=""n"">Faustino</span> <span class=""o"">&lt;</span><span class=""n"">pedrobandim</span><span class=""o"">@...&gt;</span>
 <span class=""mi"">11</span> <span class=""n"">Steven</span> <span class=""n"">Almeroth</span> <span class=""o"">&lt;</span><span class=""n"">sroth77</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">5</span> <span class=""n"">Rolando</span> <span class=""n"">Espinoza</span> <span class=""n"">La</span> <span class=""n"">fuente</span> <span class=""o"">&lt;</span><span class=""n"">darkrho</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">4</span> <span class=""n"">Michal</span> <span class=""n"">Danilak</span> <span class=""o"">&lt;</span><span class=""n"">mimino</span><span class=""o"">.</span><span class=""n"">coder</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">4</span> <span class=""n"">Alex</span> <span class=""n"">Cepoi</span> <span class=""o"">&lt;</span><span class=""n"">alex</span><span class=""o"">.</span><span class=""n"">cepoi</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">4</span> <span class=""n"">Alexandr</span> <span class=""n"">N</span> <span class=""n"">Zamaraev</span> <span class=""p"">(</span><span class=""n"">aka</span> <span class=""n"">tonal</span><span class=""p"">)</span> <span class=""o"">&lt;</span><span class=""n"">tonal</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">3</span> <span class=""n"">paul</span> <span class=""o"">&lt;</span><span class=""n"">paul</span><span class=""o"">.</span><span class=""n"">tremberth</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">3</span> <span class=""n"">Martin</span> <span class=""n"">Olveyra</span> <span class=""o"">&lt;</span><span class=""n"">molveyra</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">3</span> <span class=""n"">Jordi</span> <span class=""n"">Llonch</span> <span class=""o"">&lt;</span><span class=""n"">llonchj</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">3</span> <span class=""n"">arijitchakraborty</span> <span class=""o"">&lt;</span><span class=""n"">myself</span><span class=""o"">.</span><span class=""n"">arijit</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">2</span> <span class=""n"">Shane</span> <span class=""n"">Evans</span> <span class=""o"">&lt;</span><span class=""n"">shane</span><span class=""o"">.</span><span class=""n"">evans</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">2</span> <span class=""n"">joehillen</span> <span class=""o"">&lt;</span><span class=""n"">joehillen</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">2</span> <span class=""n"">Hart</span> <span class=""o"">&lt;</span><span class=""n"">HartSimha</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">2</span> <span class=""n"">Dan</span> <span class=""o"">&lt;</span><span class=""n"">ellisd23</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Zuhao</span> <span class=""n"">Wan</span> <span class=""o"">&lt;</span><span class=""n"">wanzuhao</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">whodatninja</span> <span class=""o"">&lt;</span><span class=""n"">blake</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">vkrest</span> <span class=""o"">&lt;</span><span class=""n"">v</span><span class=""o"">.</span><span class=""n"">krestiannykov</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">tpeng</span> <span class=""o"">&lt;</span><span class=""n"">pengtaoo</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Tom</span> <span class=""n"">Mortimer</span><span class=""o"">-</span><span class=""n"">Jones</span> <span class=""o"">&lt;</span><span class=""n"">tom</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Rocio</span> <span class=""n"">Aramberri</span> <span class=""o"">&lt;</span><span class=""n"">roschegel</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Pedro</span> <span class=""o"">&lt;</span><span class=""n"">pedro</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">notsobad</span> <span class=""o"">&lt;</span><span class=""n"">wangxiaohugg</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Natan</span> <span class=""n"">L</span> <span class=""o"">&lt;</span><span class=""n"">kuyanatan</span><span class=""o"">.</span><span class=""n"">nlao</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Mark</span> <span class=""n"">Grey</span> <span class=""o"">&lt;</span><span class=""n"">mark</span><span class=""o"">.</span><span class=""n"">grey</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Luan</span> <span class=""o"">&lt;</span><span class=""n"">luanpab</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Libor</span> <span class=""n"">Nenadál</span> <span class=""o"">&lt;</span><span class=""n"">libor</span><span class=""o"">.</span><span class=""n"">nenadal</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Juan</span> <span class=""n"">M</span> <span class=""n"">Uys</span> <span class=""o"">&lt;</span><span class=""n"">opyate</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Jonas</span> <span class=""n"">Brunsgaard</span> <span class=""o"">&lt;</span><span class=""n"">jonas</span><span class=""o"">.</span><span class=""n"">brunsgaard</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Ilya</span> <span class=""n"">Baryshev</span> <span class=""o"">&lt;</span><span class=""n"">baryshev</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Hasnain</span> <span class=""n"">Lakhani</span> <span class=""o"">&lt;</span><span class=""n"">m</span><span class=""o"">.</span><span class=""n"">hasnain</span><span class=""o"">.</span><span class=""n"">lakhani</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Emanuel</span> <span class=""n"">Schorsch</span> <span class=""o"">&lt;</span><span class=""n"">emschorsch</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Chris</span> <span class=""n"">Tilden</span> <span class=""o"">&lt;</span><span class=""n"">chris</span><span class=""o"">.</span><span class=""n"">tilden</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Capi</span> <span class=""n"">Etheriel</span> <span class=""o"">&lt;</span><span class=""n"">barraponto</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">cacovsky</span> <span class=""o"">&lt;</span><span class=""n"">amarquesferraz</span><span class=""o"">@...&gt;</span>
  <span class=""mi"">1</span> <span class=""n"">Berend</span> <span class=""n"">Iwema</span> <span class=""o"">&lt;</span><span class=""n"">berend</span><span class=""o"">@...&gt;</span>
</pre></div>","130 Pablo Hoffman <pablo@...>
 97 Daniel Graña <dangra@...>
 20 Nicolás Ramírez <nramirez.uy@...>
 13 Mikhail Korobov <kmike84@...>
 12 Pedro Faustino <pedrobandim@...>
 11 Steven Almeroth <sroth77@...>
  5 Rolando Espinoza La fuente <darkrho@...>
  4 Michal Danilak <mimino.coder@...>
  4 Alex Cepoi <alex.cepoi@...>
  4 Alexandr N Zamaraev (aka tonal) <tonal@...>
  3 paul <paul.tremberth@...>
  3 Martin Olveyra <molveyra@...>
  3 Jordi Llonch <llonchj@...>
  3 arijitchakraborty <myself.arijit@...>
  2 Shane Evans <shane.evans@...>
  2 joehillen <joehillen@...>
  2 Hart <HartSimha@...>
  2 Dan <ellisd23@...>
  1 Zuhao Wan <wanzuhao@...>
  1 whodatninja <blake@...>
  1 vkrest <v.krestiannykov@...>
  1 tpeng <pengtaoo@...>
  1 Tom Mortimer-Jones <tom@...>
  1 Rocio Aramberri <roschegel@...>
  1 Pedro <pedro@...>
  1 notsobad <wangxiaohugg@...>
  1 Natan L <kuyanatan.nlao@...>
  1 Mark Grey <mark.grey@...>
  1 Luan <luanpab@...>
  1 Libor Nenadál <libor.nenadal@...>
  1 Juan M Uys <opyate@...>
  1 Jonas Brunsgaard <jonas.brunsgaard@...>
  1 Ilya Baryshev <baryshev@...>
  1 Hasnain Lakhani <m.hasnain.lakhani@...>
  1 Emanuel Schorsch <emschorsch@...>
  1 Chris Tilden <chris.tilden@...>
  1 Capi Etheriel <barraponto@...>
  1 cacovsky <amarquesferraz@...>
  1 Berend Iwema <berend@...>
",1
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.16.5 (released 2013-05-30),#scrapy-0-16-5-released-2013-05-30,,,210
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.16.4 (released 2013-01-23),#scrapy-0-16-4-released-2013-01-23,,,211
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.16.3 (released 2012-12-07),#scrapy-0-16-3-released-2012-12-07,,,212
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.16.2 (released 2012-11-09),#scrapy-0-16-2-released-2012-11-09,,,213
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.16.1 (released 2012-10-26),#scrapy-0-16-1-released-2012-10-26,,,214
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.16.0 (released 2012-10-18),#scrapy-0-16-0-released-2012-10-18,,,215
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.14.4,#scrapy-0-14-4,,,216
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.14.3,#scrapy-0-14-3,,,217
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.14.2,#scrapy-0-14-2,,,218
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.14.1,#scrapy-0-14-1,,,219
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.14,#scrapy-0-14,,,220
https://docs.scrapy.org/en/latest/news.html,,###,3,New features and settings,#new-features-and-settings,,,221
https://docs.scrapy.org/en/latest/news.html,,###,3,Code rearranged and removed,#code-rearranged-and-removed,,,222
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.12,#scrapy-0-12,,,223
https://docs.scrapy.org/en/latest/news.html,,###,3,New features and improvements,#new-features-and-improvements,,,224
https://docs.scrapy.org/en/latest/news.html,,###,3,Scrapyd changes,#scrapyd-changes,,,225
https://docs.scrapy.org/en/latest/news.html,,###,3,Changes to settings,#changes-to-settings,,,226
https://docs.scrapy.org/en/latest/news.html,,###,3,Deprecated/obsoleted functionality,#deprecated-obsoleted-functionality,,,227
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.10,#scrapy-0-10,,,228
https://docs.scrapy.org/en/latest/news.html,,###,3,New features and improvements,#id107,,,229
https://docs.scrapy.org/en/latest/news.html,,###,3,Command-line tool changes,#command-line-tool-changes,,,230
https://docs.scrapy.org/en/latest/news.html,,###,3,API changes,#api-changes,,,231
https://docs.scrapy.org/en/latest/news.html,,###,3,Changes to settings,#id108,,,232
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.9,#scrapy-0-9,,,233
https://docs.scrapy.org/en/latest/news.html,,###,3,New features and improvements,#id109,,,234
https://docs.scrapy.org/en/latest/news.html,,###,3,API changes,#id110,,,235
https://docs.scrapy.org/en/latest/news.html,,###,3,Changes to default settings,#changes-to-default-settings,,,236
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.8,#scrapy-0-8,,,237
https://docs.scrapy.org/en/latest/news.html,,###,3,New features,#id111,,,238
https://docs.scrapy.org/en/latest/news.html,,###,3,Backward-incompatible changes,#id112,,,239
https://docs.scrapy.org/en/latest/news.html,,##,2,Scrapy 0.7,#scrapy-0-7,,,240
https://docs.scrapy.org/en/latest/contributing.html,,#,1,Contributing to Scrapy,#contributing-to-scrapy,"<div class=""highlight""><pre><span></span><span class=""n"">tox</span> <span class=""o"">-</span><span class=""n"">e</span> <span class=""n"">docs</span><span class=""o"">-</span><span class=""n"">coverage</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tox</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tox</span> <span class=""o"">-</span><span class=""n"">e</span> <span class=""n"">py37</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tox</span> <span class=""o"">-</span><span class=""n"">e</span> <span class=""n"">py37</span><span class=""p"">,</span><span class=""n"">py38</span> <span class=""o"">-</span><span class=""n"">p</span> <span class=""n"">auto</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tox</span> <span class=""o"">--</span> <span class=""n"">scrapy</span> <span class=""n"">tests</span> <span class=""o"">-</span><span class=""n"">x</span>  <span class=""c1""># stop after first failure</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tox</span> <span class=""o"">-</span><span class=""n"">e</span> <span class=""n"">py37</span> <span class=""o"">--</span> <span class=""n"">scrapy</span> <span class=""n"">tests</span> <span class=""o"">-</span><span class=""n"">n</span> <span class=""n"">auto</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">loader</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tests</span><span class=""o"">/</span><span class=""n"">test_loader</span><span class=""o"">.</span><span class=""n"">py</span>
</pre></div>","tox -e docs-coverage
,tox
,tox -e py37
,tox -e py37,py38 -p auto
,tox -- scrapy tests -x  # stop after first failure
,tox -e py37 -- scrapy tests -n auto
,scrapy.loader
,tests/test_loader.py
",8
https://docs.scrapy.org/en/latest/contributing.html,,##,2,Reporting bugs,#reporting-bugs,,,2
https://docs.scrapy.org/en/latest/contributing.html,,##,2,Writing patches,#writing-patches,"<div class=""highlight""><pre><span></span><span class=""n"">tox</span> <span class=""o"">-</span><span class=""n"">e</span> <span class=""n"">docs</span><span class=""o"">-</span><span class=""n"">coverage</span>
</pre></div>","tox -e docs-coverage
",1
https://docs.scrapy.org/en/latest/contributing.html,,##,2,Submitting patches,#submitting-patches,,,4
https://docs.scrapy.org/en/latest/contributing.html,,##,2,Coding style,#coding-style,,,5
https://docs.scrapy.org/en/latest/contributing.html,,##,2,Documentation policies,#documentation-policies,,,6
https://docs.scrapy.org/en/latest/contributing.html,,##,2,Tests,#tests,"<div class=""highlight""><pre><span></span><span class=""n"">tox</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tox</span> <span class=""o"">-</span><span class=""n"">e</span> <span class=""n"">py37</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tox</span> <span class=""o"">-</span><span class=""n"">e</span> <span class=""n"">py37</span><span class=""p"">,</span><span class=""n"">py38</span> <span class=""o"">-</span><span class=""n"">p</span> <span class=""n"">auto</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tox</span> <span class=""o"">--</span> <span class=""n"">scrapy</span> <span class=""n"">tests</span> <span class=""o"">-</span><span class=""n"">x</span>  <span class=""c1""># stop after first failure</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tox</span> <span class=""o"">-</span><span class=""n"">e</span> <span class=""n"">py37</span> <span class=""o"">--</span> <span class=""n"">scrapy</span> <span class=""n"">tests</span> <span class=""o"">-</span><span class=""n"">n</span> <span class=""n"">auto</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">loader</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tests</span><span class=""o"">/</span><span class=""n"">test_loader</span><span class=""o"">.</span><span class=""n"">py</span>
</pre></div>","tox
,tox -e py37
,tox -e py37,py38 -p auto
,tox -- scrapy tests -x  # stop after first failure
,tox -e py37 -- scrapy tests -n auto
,scrapy.loader
,tests/test_loader.py
",7
https://docs.scrapy.org/en/latest/contributing.html,,###,3,Running tests,#running-tests,"<div class=""highlight""><pre><span></span><span class=""n"">tox</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tox</span> <span class=""o"">-</span><span class=""n"">e</span> <span class=""n"">py37</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tox</span> <span class=""o"">-</span><span class=""n"">e</span> <span class=""n"">py37</span><span class=""p"">,</span><span class=""n"">py38</span> <span class=""o"">-</span><span class=""n"">p</span> <span class=""n"">auto</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tox</span> <span class=""o"">--</span> <span class=""n"">scrapy</span> <span class=""n"">tests</span> <span class=""o"">-</span><span class=""n"">x</span>  <span class=""c1""># stop after first failure</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tox</span> <span class=""o"">-</span><span class=""n"">e</span> <span class=""n"">py37</span> <span class=""o"">--</span> <span class=""n"">scrapy</span> <span class=""n"">tests</span> <span class=""o"">-</span><span class=""n"">n</span> <span class=""n"">auto</span>
</pre></div>","tox
,tox -e py37
,tox -e py37,py38 -p auto
,tox -- scrapy tests -x  # stop after first failure
,tox -e py37 -- scrapy tests -n auto
",5
https://docs.scrapy.org/en/latest/contributing.html,,###,3,Writing tests,#writing-tests,"<div class=""highlight""><pre><span></span><span class=""n"">scrapy</span><span class=""o"">.</span><span class=""n"">loader</span>
</pre></div>,<div class=""highlight""><pre><span></span><span class=""n"">tests</span><span class=""o"">/</span><span class=""n"">test_loader</span><span class=""o"">.</span><span class=""n"">py</span>
</pre></div>","scrapy.loader
,tests/test_loader.py
",2
https://docs.scrapy.org/en/latest/versioning.html,,#,1,Versioning and API stability,#versioning-and-api-stability,,,1
https://docs.scrapy.org/en/latest/versioning.html,,##,2,Versioning,#id1,,,2
https://docs.scrapy.org/en/latest/versioning.html,,##,2,API stability,#api-stability,,,3
https://docs.scrapy.org/en/latest/versioning.html,,##,2,Deprecation policy,#deprecation-policy,,,4
